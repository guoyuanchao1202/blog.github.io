<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[二叉树三种遍历详解]]></title>
    <url>%2F2021%2F03%2F20%2F%E4%BA%8C%E5%8F%89%E6%A0%91%E4%B8%89%E7%A7%8D%E9%81%8D%E5%8E%86%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[最近刷了很多二叉树相关的题目，发现二叉树相关的题目各式各样，最终的基础还是二叉树的三种遍历方式(还有一种层次遍历，不是本文的主题)。所以专门总结一下二叉树三种遍历的两种解法。 递归解法递归实现的遍历，代码最为简洁优美，并且思路也很好理解。 前序遍历前序遍历，即 中 – 左 – 右 的顺序遍历二叉树 123456789101112public void preOrder(TreeNode root)&#123; // 递归结束条件 if(root == null)&#123; return; &#125; // 打印当前子树根节点 System.out.println(root.val); // 递归打印当前子树的左子树 preOrder(root.left); // 递归打印当前子树的右子树 preOrder(root.right);&#125; 中序遍历中序遍历，即 左 – 右 – 中 的顺序遍历二叉树 123456789101112public void inOrder(TreeNode root)&#123; // 递归结束条件 if(root == null)&#123; return; &#125; // 递归打印当前子树的左子树 inOrder(root.left); // 打印当前子树根节点 System.out.println(root.val); // 递归打印当前子树的右子树 inOrder(root.right);&#125; 后序遍历后序遍历，即 左 – 右 – 中 的顺序遍历二叉树 123456789101112public void postOrder(TreeNode root)&#123; // 递归结束条件 if(root == null)&#123; return; &#125; // 递归打印当前子树的左子树 postOrder(root.left); // 递归打印当前子树的右子树 postOrder(root.right); // 打印当前子树根节点 System.out.println(root.val);&#125; 迭代解法迭代法实现的遍历，需要借助栈来实现。 前序遍历1234567891011121314151617181920212223public void preOrder(TreeNode root)&#123; if(root == null)&#123; return; &#125; Deque&lt;TreeNode&gt; stack = new LinkedList(); // 先将根节点入栈 stack.push(root); while(!stack.isEmpty())&#123; // 从栈中弹出当前子树根节点 TreeNode curNode = stack.push(); // 直接打印根节点值 System.out.println(curNode.val); // 如果该节点含有右节点，将右节点入栈 if(curNode.right != null)&#123; stack.push(curNode.right); &#125; // 如果该节点含有左节点，将左节点入栈 if(curNode.left != null)&#123; stack.push(curNode.left); &#125; // 因为是栈，所以要先将右节点入栈，后入栈左节点，这样出栈时才能先得到左节点 &#125;&#125; 中序遍历12345678910111213141516public void inOrder(TreeNode root)&#123; if(root == null)&#123; return; &#125; Deque&lt;TreeNode&gt; stack = new LinkedList(); while(!stack.isEmpty() || root != null)&#123; // 一直遍历左节点，直到找到最左边的节点为止 while(root != null)&#123; stack.push(root); root = root.left; &#125; root = stack.pop(); System.out.println(root.val); root = root.right; &#125;&#125; 后序遍历1234567891011121314151617181920212223public void postOrder(TreeNode root)&#123; if(root == null)&#123; return; &#125; Deque&lt;TreeNode&gt; stack = new LinkedList(); stack.push(root); // 不能初始化为null，例如对于[1, null, 2, 3]这种子树时，节点2的右子树为null，cur如果初始化为null， // 那么这里就会判断为左右子树访问完毕，但实际上左右子树都没有访问到 TreeNode cur = new TreeNode(-1); while(!stack.isEmpty())&#123; TreeNode peek = stack.peek(); if(peek.left != null &amp;&amp; peek.left != cur &amp;&amp; peek.right != null)&#123; stack.push(peek.left); continue; &#125; if(peek.right != null &amp;&amp; peek.right != cur)&#123; stack.push(peek.right); continue; &#125; System.out.println(stack.pop().val); cur = peek; &#125;&#125;]]></content>
      <categories>
        <category>算法之美</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
        <tag>二叉树</tag>
        <tag>遍历</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入剖析基于AQS互斥锁ReentrantLock]]></title>
    <url>%2F2021%2F02%2F17%2F%E6%B7%B1%E5%85%A5%E5%89%96%E6%9E%90%E5%9F%BA%E4%BA%8EAQS%E4%BA%92%E6%96%A5%E9%94%81ReentrantLock%2F</url>
    <content type="text"><![CDATA[在深入剖析Java抽象队列同步器AQS一文中对AQS的实现原理进行详细介绍，这里就来介绍Java类库中基于AQS实现的互斥锁(也叫可重入锁)ReentrantLock。有了前面AQS的基础，学习ReentrantLock就会变得非常容易。 ReentrantLock简介ReentranLock是Java提供的锁机制，它能够实现比synchronized更加丰富的功能。我们直到synchronized是不支持中断的，如果线程无法获取到锁就只能一直阻塞，而ReentrantLock提供了可以响应中断的方法，在线程因获取不到锁而阻塞时，可以响应外部中断；并且synchronized是非公平锁，ReentrantLock支持公平锁和非公平锁两种机制。 ReentrantLock的内部架构如上图所示，可以看到ReentrantLock内部有三个类：Sync、NonFairSync、FairSync。顾名思义，NonFairSync用来实现非公平锁，FairSync用来实现公平锁，这两者都是继承自Sync，而Sync又是继承自前面说过的AQS，从图中我们可以很清楚的看到ReentrantLock是基于AQS实现。 Sync类 如图，Sync是一个抽象类，继承自AQS。并重写了父类的tryRelease和isHeldExclusively方法，如果你看过前一篇文章并且还有印象的话，那么你一定记得这两个方法正式AQS提供给子类实现的模板方法。此外，Sync还提供了一个抽象方法lock。对于Sync的成员方法将会在介绍lock/unlock时，再对相关的方法进行介绍 NonFairSync类 NonFairSync用于实现非公平锁，继承自Sync并且是实现了父类的lock方法，同时还实现了AQS的模板方法tryAcquire方法。该类的成员方法非常简单，我们留到介绍lock/unlock时展开 FairSync类 FairSync用于实现公平锁，继承体系和NonFairSync一样，并且同样实现了lock方法和AQS的模板方法tryAcquire方法。通过对比我们不难发现，公平锁和非公平锁的区别就在lock和tryAcquire中。具体细节后面介绍 ReentrantLock类介绍完ReentrantLock的三个内部类的大体架构，现在正式开始介绍ReentrantLock的成员属性、构造方法以及几个主要的成员方法。 ReentrantLock成员属性ReentrantLock的成员属性非常简单(还有一个序列化ID，和本文无关)，就是一个Sync对象 1private final Sync sync; ReentrantLock构造方法12345678// 无参构造方法，非公平锁public ReentrantLock() &#123; sync = new NonfairSync();&#125;// 带参构造方法，可以创建公平锁/非公平锁public ReentrantLock(boolean fair) &#123; sync = fair ? new FairSync() : new NonfairSync();&#125; ReentrantLock成员方法lock()–非公平锁123public void lock() &#123; sync.lock();&#125; 可以看到，lock的实现非常简单，就是调用sync的lock方法，通过前面的构造方法可以看出，公平锁和非公平锁它们的sync的实现是不同的，一个是NonFairSync一个是FairSync；而对于这两个子类，它们对于lock的实现也是不同的，我们就以非公平锁为例，来具体看看它的实现 NonFairSync.lock()123456789final void lock() &#123; // 使用CAS来设置同步状态 if (compareAndSetState(0, 1)) // 如果设置成功，当前线程获取锁 setExclusiveOwnerThread(Thread.currentThread()); else // 如果获取失败，调用acquire方法 acquire(1);&#125; acquire(int arg)在上一篇介绍AQS时我们介绍过这个方法，acquire是AQS的一个成员方法，并且还说道其中的tryAcquire()方法是AQS提供的模板方法，由子类进行重写。通过前面NonFairSync的架构图我们可以看到，NonFairSync确实重写了tryAcquire方法 12345public final void acquire(int arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; NonFairSync.tryAcquire(int arg)可以看到NonFairSync在tryAcquire中调用了父类Sync的nonfairTryAcquire方法 12345// NonFairSync重写AQS的模板方法tryAcquireprotected final boolean tryAcquire(int acquires) &#123; // 调用父类Sync的成员方法nonfairTryAcquire return nonfairTryAcquire(acquires);&#125; Sync.nonfairTryAcquire(int acquires)子类基于AQS实现lock的核心逻辑 1234567891011121314151617181920212223242526final boolean nonfairTryAcquire(int acquires) &#123; // 获取当前线程 final Thread current = Thread.currentThread(); // 获取当前锁状态 int c = getState(); // 如果是0，说明没有线程持有锁 if (c == 0) &#123; // 使用CAS修改锁状态 if (compareAndSetState(0, acquires)) &#123; // 如果修改成功则当前线程获取锁，调用AQS的父类方法 setExclusiveOwnerThread(current); return true; &#125; &#125; // 如果不是0，说明已经有线程获取到了锁，判断是否是当前线程 else if (current == getExclusiveOwnerThread()) &#123; // 如果是当前线程，则表明当前线程重入了锁 int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error("Maximum lock count exceeded"); // 修改锁状态 setState(nextc); return true; &#125; return false;&#125; lock()方法总结对于非公平锁的lock方法到这里就介绍完毕了，其中涉及到了ReentrantLock、Sync、NonFairSync、AQS、AQS父类之间的方法调用，你可能已经迷糊了，不过没有关系，我总结了lock非公平锁的调用关系图，通过这个图，再结合前面的介绍，相信你能够把lock方法的来龙去脉梳理清楚 如图，就是ReentrantLock的lock实现，可以看到ReentrantLock主要是通过重写AQS的tryAcquire方法来实现，并且根据锁类型不同(公平锁或非公平锁)，进行不同的重写 lock()–公平锁介绍完lock()公平锁的实现，现在介绍lock()非公平锁。通过上面的图发现，公平锁和非公平锁的区别在于Sync.lock和tryAcquire两个方法，我们分别看一看 FairSync.lock()可以看到公平锁和非公平锁的lock方法在实现上有细微的不同：线程使用非公平锁时会首先尝试获取锁，获取失败后才会调用acquire方法，但是公平锁不会尝试获取锁，而是直接调用acquire。这恰恰是公平锁的语义，线程需要按照先来后到的顺序依次获取锁。我们考虑下面这种情况：当前线程A持有公平锁，同步队列中已经有B线程等待锁，线程C尝试调用lock获取锁，此时A释放了锁，那么按照我们对公平锁的定义，B应该获取锁，而C进入同步队列等待。如果C在lock方法中首先尝试获取锁，那么C就有可能在B之前获取锁，这就违背了我们对公平锁的定义 123final void lock() &#123; acquire(1);&#125; FairSync.tryAcquire(int acquires)和非公平锁一样，acquire是AQS的方法，acquire中回首先调用tryAcquire方法，而tryAcquire方法是由子类实现的，我们来看一下公平锁的tryAcquire方法 1234567891011121314151617181920212223242526 protected final boolean tryAcquire(int acquires) &#123; // 获取当前线程 final Thread current = Thread.currentThread(); // 获取当前锁状态 int c = getState(); // 如果状态为0，说明没有线程持有锁 if (c == 0) &#123; // 这里相对于非公平锁多了一个判断条件：如果当前节点是头节点的后继节点 // 使用CAS修改锁状态，如果修改成功，则当前线程获取锁 if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; // 和非公平锁一样 else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) throw new Error("Maximum lock count exceeded"); setState(nextc); return true; &#125; return false; &#125;&#125; 通过源码我们发现，非公平锁和公平锁的tryAcquire方法唯一的不同在于公平锁比非公平锁多了一个判断条件，即调用了hasQueuedPredecessors方法，我们来看一看这个方法 AQS.hasQueuedPredecessors()12345678910public final boolean hasQueuedPredecessors() &#123; Node t = tail; // Read fields in reverse initialization order Node h = head; Node s; // 如果当前同步队列为空(h==t),返回false // 如果当前同步队列不为空并且当前头节点的后继节点为空或后继节点不是当前线程，返回true // 如果当前同步队列不为空并且头节点的后继节点就是当前线程，返回false return h != t &amp;&amp; ((s = h.next) == null || s.thread != Thread.currentThread());&#125; 这个方法是AQS提供的方法，主要是用来判断同步队列中是否有已经在等待的线程，如果有的话队列中第一个等待的线程是否是当前线程；从而判断在当前线程是否应该尝试获取锁。这就是公平锁的实现原理。 unlock()介绍完lock，我们来介绍一下unlock 1234public void unlock() &#123; // 调用sync的release，实际上release是AQS提供的方法 sync.release(1);&#125; 如果你看过上一篇AQS的文章，那么你一定对release有影响，这不就是AQS中的方法么，我们再来看一下AQS的release方法 AQS.release(int arg)123456789101112public final boolean release(int arg) &#123; // 调用模板方法tryRelease方法，如果成功 // 唤醒一个同步队列上等待的线程，并返回true if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; // 否则，返回false return false;&#125; tryRelease就是我们在前面提到的AQS提供给子类实现的模板方法，对于非公平锁和公平锁，他们的tryRelease方法都是一样的，都是由Sync来实现，我们来看一看Sync对tryRelease的实现 Sync.tryRelease(int arg)12345678910111213141516protected final boolean tryRelease(int releases) &#123; // 计算释放后的锁状态，支持可重入。 int c = getState() - releases; // 如果当前线程不是持有锁的线程，抛出异常 if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; // 如果锁状态为0，说明当前线程已经不持有锁 // 否则说明当前线程仍然持有锁，即当前线程重入过该锁 if (c == 0) &#123; free = true; setExclusiveOwnerThread(null); &#125; setState(c); return free;&#125; unparkSuccessor方法我们在AQS那一篇中介绍过，这里就不多介绍了，不记得了可以回看一下 unlock()方法总结至此，ReentrantLock的unlock已经介绍完毕。同样的，我总结一张图来表示unlock的大致逻辑 通过源码得知，如果当前线程在持有锁后又多次调用了lock(重入)，那么就需要相应次数的unlock才能够释放锁。如果是最后一次unlock，那么需要将同步队列中最靠前的没有被取消的线程唤醒(unpark)。 ReentrantLock总结到目前为止，已经将AQS、ReentrantLock的主要内容介绍完毕，但是你可能还有不少疑问，如当一个线程释放锁后，应该唤醒哪一个线程，被唤醒的线程又是如何重新获取锁，获取到锁之后同步队列会发生什么变化；当一个线程尝试获取锁失败后，什么时候加入到同步队列，什么时候被阻塞…等等。下面我将通过几幅图搭配文字将前面讲的串联起来，希望能够为你解惑。由于公平锁和非公平锁的实现基本类似，所以下面的示例基于非公平锁演示。 ReentrantLock对象刚创建，没有线程申请过锁 此时还不存在同步队列，锁状态为0，没有线程持有锁 线程A申请锁 此时没有只有线程A申请锁，通过lock源码可知，线程A直接获取到锁，锁状态为1，由于仍然没有线程等待锁，因此同步队列仍为空 线程B、线程C申请锁 此时A并没有释放锁，因此线程B和线程C尝试获取锁失败，调用acquire方法，并且在acquire中调用tryAcquire失败(因为我们假设在这个过程中线程A一直持有锁)，因此线程B和线程C会并发的将自己插入到同步队列中，两者在同步队列中的顺序无法保证。我们假设是线程C先进入同步队列。紧接着线程B和线程C会并发调用acquireQueued方法。在该方法中，C线程会进入到一个死循环中，在死循环中首先尝试获取锁，因为此时A并没有释放锁，因此获取失败，此时C线程会将它的前驱节点(此时是头节点)waitStatus修改为Signal(-1)，最后调用park阻塞。同样的，B线程会做和C一样的操作，不过B线程会将它的前驱节点(此时是C节点)waitStatus修改为Signal(-1)，最后调用park阻塞。因此最终的结果就是：B和C加入到同步队列；B和C线程代表的节点以及头节点状态都是Signal(-1)。 线程A释放锁 A释放锁，调用AQS的release方法，release方法首先会调用Sync实现的tryRelease方法，由于A并没有对锁进行重入，因此A线程此时已经完全的释放了锁，并且同步队列不为空(B和C线程正在等待锁)，所以release方法还会调用AQS的unparkSuccessor方法，唤醒同步队列中的一个等待线程。在unparkSuccessor方法中，会首先将头结点的状态修改为0，并且找到最靠近头节点的非Cancelled节点(在本例中即C节点)，调用unpark唤醒该节点上的线程。 C被唤醒，再次尝试获取锁 当C线程被唤醒以后，由于是一个死循环，因此会重新尝试获取锁。我们假设此时没有别的线程与C竞争(实际上可能会刚好线程D在此时也要获取锁，逻辑是一样的，不过说起来篇幅较长，这里就假设只有C再获取锁)，此时C是头节点的后继节点，因此C调用tryAcquire方法尝试获取锁并且获取成功，获取成功后C会重新设置头节点：将原来的head节点丢弃，将C节点设置为head节点，并且将C中的thread字段置null，因为C代表的线程已经获得了锁，这里就不需要了。 以三个线程为例，通过图示，简单的将它们的获取锁成功、获取锁失败、释放锁、重新获取锁的过程串联在了一起，希望你能够有所收获。对ReentrantLock的介绍就到这里。后面会对Condition、Semaphore逐一进行介绍。]]></content>
      <categories>
        <category>Java并发编程</category>
      </categories>
      <tags>
        <tag>源码</tag>
        <tag>ReentrantLock</tag>
        <tag>AQS</tag>
        <tag>Java并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入剖析Java抽象队列同步器AQS]]></title>
    <url>%2F2021%2F02%2F16%2F%E6%B7%B1%E5%85%A5%E5%89%96%E6%9E%90Java%E6%8A%BD%E8%B1%A1%E9%98%9F%E5%88%97%E5%90%8C%E6%AD%A5%E5%99%A8AQS%2F</url>
    <content type="text"><![CDATA[AbstractQueuedSynchronizer又称为队列同步器(后面简称AQS)，它提供了一套完整的同步编程框架，开发人员只需要实现其中几个简单的方法就能自由的使用诸如独占，共享，条件队列等多种同步模式。我们常见的ReentrantLock、Semaphore、CountDownLatch等都是基于AQS实现的，足以说明这套框架的强大之处。本文将基于JDK1.8对AQS进行剖析。 AQS简介AQS是用来构建锁或者其它同步器组件的重量级基础框架及整个JUC体系的基石，通过内置的CLH(FIFO)队列的变种来完成资源获取线程的排队工作,将每条将要去抢占资源的线程封装成一个Node节点来实现锁的分配，有一个int类变量表示持有锁的状态,通过CAS完成对status值的修改(0表示没有,1表示阻塞)。 如图所示，常见锁或者同步组件都是基于AQS实现的。 AQS内部架构图 如图，AQS有两个内部类： final 静态内部类Node 普通内部类ConditionObject 前面说过，AQS会将抢占资源的线程包装为一个Node节点，放到队列中；ConditionObject则和Condition有关。 AQS成员属性1234567891011121314// 队头节点private transient volatile Node head;// 队尾节点private transient volatile Node tail;// 同步状态private volatile int state;// 用于支持CAS，可以忽略private static final Unsafe unsafe = Unsafe.getUnsafe();private static final long stateOffset;private static final long headOffset;private static final long tailOffset;private static final long waitStatusOffset;private static final long nextOffset; AQS内部类–Node前面说过，AQS会将请求资源的线程包装为一个Node，放到同步队列(有Node节点组成的双向虚拟队列)中，因此Node对于AQS来说至关重要。 Node成员属性1234567891011121314151617181920// 共享模式static final Node SHARED = new Node();// 独占模式static final Node EXCLUSIVE = null;// 节点等待状态volatile int waitStatus;// 同步队列中当前节点的前驱节点volatile Node prev;// 同步队列中当前节点的后继节点volatile Node next;// 请求锁的线程volatile Thread thread;// 等待队列中当前节点的后继节点，与Condition有关Node nextWaiter;// waitStatus的取值static final int CANCELLED = 1;static final int SIGNAL = -1;static final int CONDITION = -2;static final int PROPAGATE = -3; Canceled(1) 在同步队列中等待的线程等待超时或被中断，需要从同步队列中取消该Node的结点，其结点的waitStatus为CANCELLED，即结束状态，进入该状态后的结点将不会再变化。 Signal(-1) 就是处于唤醒状态，只要前继结点释放锁，就会通知标识为SIGNAL状态的后继结点的线程执行。 Condition(-2) 与Condition相关，该标识的结点处于等待队列中，结点的线程等待在Condition上，当其他线程调用了Condition的signal()方法后，Condition状态的结点将从等待队列转移到同步队列中，等待获取同步锁。 Propagate(-3) 与共享模式相关，在共享模式中，该状态标识结点的线程处于可运行状态。 Init状态(0) 表明该节点处于初始状态 Node构造方法Node有三个构造方法，分别是： 123Node() &#123; &#125;Node(Thread thread, Node mode) // 用于addWaiter()方法Node(Thread thread, int waitStatus) // 用于Condition 这三个方法我们后面遇到了再介绍 Node实例方法 isShared()：判断是否为共享模式 123final boolean isShared() &#123; return nextWaiter == SHARED;&#125; predecessor()：获取当前节点的前驱节点 1234567final Node predecessor() throws NullPointerException &#123; Node p = prev; if (p == null) throw new NullPointerException(); else return p;&#125; AQS内部类–ConditionObject ConditionObject架构如上图所示，该类实现了Condition接口的抽象方法。 ConditionObject成员属性1234567// 等待队列的头节点private transient Node firstWaiter;// 等待队列的尾节点private transient Node lastWaiter;// 用于相应中断，后面介绍具体用法private static final int REINTERRUPT = 1;private static final int THROW_IE = -1; ConditionObject成员方法await()当前线程进入等待状态，直到被Signal/中断唤醒 123456789101112131415161718 public final void await() throws InterruptedException &#123;1. if (Thread.interrupted())2. throw new InterruptedException();3. Node node = addConditionWaiter(); 4. int savedState = fullyRelease(node);5. int interruptMode = 0;6. while (!isOnSyncQueue(node)) &#123;7. LockSupport.park(this);8. if ((interruptMode = checkInterruptWhileWaiting(node)) != 0)9. break;10. &#125;11. if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE)12. interruptMode = REINTERRUPT;13. if (node.nextWaiter != null) // clean up if cancelled14. unlinkCancelledWaiters();15. if (interruptMode != 0)16. reportInterruptAfterWait(interruptMode); &#125; await源码如上所示，下面一行一行的介绍它的含义 1~2：判断当前线程是否被中断，如果被中断则抛出异常 3：将当前线程加入到等待队列中，并返回当前线程的Node节点 4：释放当前线程持有的同步状态 5：将中断模式初始化为0(后面会用到) 6~10：这是一个while循环，isOnSyncQueue()函数用于判断线程是否在同步队列中。跳出循环的情况如下 线程被唤醒：当调用singnal唤醒该线程时，会将线程加入到同步队列中，不满足循环条件 线程被中断：当线程被中断时，线程会从park阻塞中回复，执行第8行代码时满足if条件，跳出循环 11：获取同步状态。如果线程发生了中断，那么acquireQueued()函数返回true，这时分两种情况 interruptMode == THROW_IE：说明线程阻塞在park调用时被中断 interruptMode != THROW_IE：说明线程没有被中断或被singnal()唤醒后被中断 如果是第二种，那么将interruptMode设为REINTERRUPT 13~14：清除等待队列中状态为Canceled(1)的Node节点 15~16：如果interruptMode != 0，说明线程在await中肯定发生了中断，根据中断发生的时机分两种情况 在singnal唤醒之前发生中断(park()调用并不是被unpark()唤醒而是从中断中返回)，那么此时会抛出异常 在singnal唤醒之后发生中断，此时会将该线程的中断标志位置位 下面我们就来分析await中调用的方法 addConditionWaiter()将线程加入等待队列并返回当前线程的Node节点 123456789101112131415161718192021222324252627282930313233343536373839private Node addConditionWaiter() &#123; Node t = lastWaiter; // 如果队为节点不为空并且状态不是Condition，调用unlinkCancelledWaiters()方法清除 // 等待队列中所有状态不是Condition(-2)节点 if (t != null &amp;&amp; t.waitStatus != Node.CONDITION) &#123; unlinkCancelledWaiters(); t = lastWaiter; &#125; // 为当前线程创建一个Node节点，状态为Condition(-2) Node node = new Node(Thread.currentThread(), Node.CONDITION); if (t == null) firstWaiter = node; else t.nextWaiter = node; lastWaiter = node; return node;&#125;===========================================private void unlinkCancelledWaiters() &#123; Node t = firstWaiter; Node trail = null; // 遍历等待队列，将所有状态不是Condition(-2)的Node删除 while (t != null) &#123; Node next = t.nextWaiter; if (t.waitStatus != Node.CONDITION) &#123; t.nextWaiter = null; if (trail == null) firstWaiter = next; else trail.nextWaiter = next; if (next == null) lastWaiter = trail; &#125; else trail = t; t = next; &#125;&#125; 看到这里你可能会有疑问：为什么addConditionWaiter()函数的实现没有任何同步机制？因为该函数只在线程获取同步状态后才会被调用，此时只有当前线程在执行，其他线程或者在等待队列，或者在同步队列，根本不存在竞争问题，因此不需要同步机制。 总结：addConditionWaiter方法主要做了两件事 删除等待队列中无效节点 将当前节点添加到等待队列中 fullyRelease(Node node)释放同步状态，并唤醒同步队列上的一个线程。 123456789101112131415161718final int fullyRelease(Node node) &#123; boolean failed = true; try &#123; // 获取当前同步状态 int savedState = getState(); // 调用release释放同步状态,如果释放成功，返回当前线程持有的同步状态 // 如果调用失败，抛出异常并且将当前线程代表的节点状态设为Cancelled(1) if (release(savedState)) &#123; failed = false; return savedState; &#125; else &#123; throw new IllegalMonitorStateException(); &#125; &#125; finally &#123; if (failed) node.waitStatus = Node.CANCELLED; &#125;&#125; 总结：可以看到fullRelease方法只做了一件事，就是调用release方法并且返回当前线程持有的同步状态，如果调用release失败，将当前线程代表的节点状态修改为Cancelled(1) release(int arg)/tryRelease(int arg)fullyRelease()调用了release()方法，让我们来看看这个方法 1234567891011121314151617public final boolean release(int arg) &#123; // 调用tryRelease方法 // 如果tryRelease方法返回true，满足if判断后调用unparkSuccessor唤醒一个同步队列上的线程并返回true // 如果返回false，release失败，返回false if (tryRelease(arg)) &#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; return false;&#125;======================protected boolean tryRelease(int arg) &#123; throw new UnsupportedOperationException();&#125; 看到上面的tryRelease方法你肯定觉得奇怪，为什么该方法直接抛出一个异常？那调用这个方法还有什么意义呢？由于本节主要介绍AQS的内部类，因此原因等到下节介绍。 总结：release方法做了两件事 调用tryRelease释放同步状态 唤醒同步队列上的一个线程 unparkSuccessor()1234567891011121314private void unparkSuccessor(Node node) &#123; int ws = node.waitStatus; if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); Node s = node.next; if (s == null || s.waitStatus &gt; 0) &#123; s = null; for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; &#125; if (s != null) LockSupport.unpark(s.thread);&#125; 总结：该方法比较简单，获取头节点的后继节点，如果节点的waitStatus小于0，那么直接唤醒该节点的线程；否则，从尾节点开始遍历，找到一个waitStatus&lt;=0的节点，唤醒此节点的线程即可。 isOnSyncQueue(Node node)该方法用于判断一个Node节点是否在同步队列中 12345678910111213141516171819202122final boolean isOnSyncQueue(Node node) &#123; // 如果当前Node的状态是Condition状态或者node没有前驱节点，说明不在同步队列中 if (node.waitStatus == Node.CONDITION || node.prev == null) return false; // 如果node含有后继节点，说明一定在同步队列中 if (node.next != null) // If has successor, it must be on queue return true; // 从队尾开始寻找该节点 return findNodeFromTail(node);&#125;==============================private boolean findNodeFromTail(Node node) &#123; Node t = tail; for (;;) &#123; if (t == node) return true; if (t == null) return false; t = t.prev; &#125;&#125; 总结：该方法只有一个作用，就是判断一个给定节点是否在同步队列中 checkInterruptWhileWaiting(Node node)该方法用于判断该线程是被singnal()唤醒还是被中断唤醒 1234567891011121314151617181920212223private int checkInterruptWhileWaiting(Node node) &#123; // 调用Thread的静态方法，判断线程的中断标志 // 如果发生了中断，调用transferAfterCancelledWait方法检测中断发生在singnal之前还是之后 // 如果没有发生中断，返回0 return Thread.interrupted() ? (transferAfterCancelledWait(node) ? THROW_IE : REINTERRUPT) : 0;&#125;==================================final boolean transferAfterCancelledWait(Node node) &#123; // 使用cas修改node的状态，如果修改成功，说明当前node是被中断唤醒 // 这是因为：如果node被singal唤醒，那么node的状态一定不是Condition状态，而是0(初始状态) // 后面会介绍signal()。因此，将node添加到同步队列中，返回true if (compareAndSetWaitStatus(node, Node.CONDITION, 0)) &#123; enq(node); return true; &#125; // 直到node已经被添加到同步队列中，返回false while (!isOnSyncQueue(node)) Thread.yield(); return false;&#125; 总结：该方法只做一件事，当当前node从park中被唤醒时，判断唤醒的原因 没有发生中断，被signal唤醒 发生了中断，但是实在signal后 发生了中断，被中断唤醒 enq(final Node node)当线程因为中断而唤醒时，该线程的node还没有被添加到同步队列中，因此需要添加进去。该方法用于把一个node添加进同步队列，并返回node的前驱节点 123456789101112131415161718private Node enq(final Node node) &#123; for (;;) &#123; Node t = tail; // 如果队列为空 if (t == null) &#123; // Must initialize // 使用CAS初始化同步队列 if (compareAndSetHead(new Node())) tail = head; &#125; else &#123; node.prev = t; // 使用CAS将node设为尾节点 if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125;&#125; acquireQueued(final Node node, int arg)12345678910111213141516171819202122232425262728293031final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; // 自旋 for (;;) &#123; // 获取node节点的前驱节点 final Node p = node.predecessor(); // 如果node的前驱节点是head，则尝试获取同步状态 if (p == head &amp;&amp; tryAcquire(arg)) &#123; // 如果获取成功，那么设置新的头节点 setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; // 如果前序节点不是head或者获取同步状态失败，判断是否需要挂起线程 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125;===============================protected boolean tryAcquire(int arg) &#123; throw new UnsupportedOperationException();&#125; 同样的，我们发现tryAcquire和前面的tryRelease一样，我们留到后面说。 总结：该方法做了三件事 当node被唤醒并重新加入同步队列时，尝试获取同步资源，如果获取成功则返回 如果获取失败后判断线程是否应该被挂起 shouldParkAfterFailedAcquire(Node pred, Node node)如果该节点应该被挂起，返回true。否则返回false 12345678910111213141516171819202122232425262728private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; // 获取node前驱节点predwaitStatus int ws = pred.waitStatus; // 如果node的前驱节点为Signal(1)状态，返回true // 说明node前面已经有一个准备好的节点，当前线程需要挂起 if (ws == Node.SIGNAL) return true; // 如果node的前驱节点为Cancelled状态，说明该前驱节点已经无效 // 那么一直向前遍历，找到一个waitStatus不为Cancelled的node if (ws &gt; 0) &#123; do &#123; node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next = node; &#125; else &#123; // 如果node的前驱节点不为Cancelled状态，那么使用CAS将前驱节点的ws // 修改为Signal状态，最后返回false，即当前线程不需要挂起 compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; return false;&#125;=================================// 挂起当前node并且返回线程的中断状态 private final boolean parkAndCheckInterrupt() &#123; LockSupport.park(this); return Thread.interrupted();&#125; reportInterruptAfterWait(int interruptMode)123456789private void reportInterruptAfterWait(int interruptMode) throws InterruptedException &#123; // 说明该线程是由于发生中断而被唤醒，因此会抛出异常 if (interruptMode == THROW_IE) throw new InterruptedException(); // 说明线程发生了中断，但是实在被唤醒之后，因此只是简单的设置中断标志位即可 else if (interruptMode == REINTERRUPT) selfInterrupt();&#125; await()总结我们由await方法展开，深入的剖析了await方法的实现逻辑：await方法必须在同步区调用，否则会抛出异常，调用后会将当前线程节点加入到等待队列中并且释放锁。最后会调用park阻塞。该方法可以被signal唤醒，也可以被中断唤醒。线程从await唤醒后会加入到同步队列中尝试重新获取锁。 signal()介绍完await方法，就该介绍signal方法了，因为这两个方法总是成对使用。signal()方法唤醒一个在该Condition上await的线程。 1234567891011public final void signal() &#123; // 判断是否持有独占锁，如果没有持有锁则抛出异常 // 说明signal必须在同步区执行 if (!isHeldExclusively()) throw new IllegalMonitorStateException(); // 等待队列的首节点 Node first = firstWaiter; if (first != null) // 调用doSignal doSignal(first);&#125; 总结 ：signal方法会判断当前线程是否持有独占锁，然后调用doSignal方法 doSignal(Node first)123456789101112// 将等待队列中的首节点移到同步队列中，如果失败，则遍历等待队列，直到移成功为止private void doSignal(Node first) &#123; do &#123; // 移除条件等待队列中的第一个结点， // 如果后继结点为null，那么说没有其他结点将尾结点也设置为null if ( (firstWaiter = first.nextWaiter) == null) lastWaiter = null; first.nextWaiter = null; // 如果该节点加入同步队列失败，并且等待队列中仍然含有节点，继续尝试 &#125; while (!transferForSignal(first) &amp;&amp; (first = firstWaiter) != null);&#125; transferForSignal(Node node)12345678910111213141516final boolean transferForSignal(Node node) &#123; // 使用CAS将node状态设置为0，如果设置失败，说明node的状态不是Condition(-2) // 那么状态只能是Cancelled，因此返回false // 注意此时是同步区域，只有一个线程再执行，不存在并发，也就不存在其他线程并发修改 // 导致CAS失败 if (!compareAndSetWaitStatus(node, Node.CONDITION, 0)) return false; // 将node加入同步队列，并返回node的前驱节点p Node p = enq(node); int ws = p.waitStatus; // 如果p处于Cancelled状态，获取修改p状态为Signal失败 // 则唤醒该node代表的线程 if (ws &gt; 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL)) LockSupport.unpark(node.thread); return true;&#125; signal()总结signal相对于await来说比较简单，调用后将等待队列中的一个node移到同步队列中。可能会伴随一些其他的操作 ConditionObject总结前面主要队ConditionObject的await()和signal方法进行了详细的介绍，其实还有其他一些类似的方法，不过他们的实现大同小异，因此这里就不多介绍了。ConditionObject的介绍就到这里~ AQS的模板方法AQS作为基础组件，封装的是核心并发操作，但是实现上分为两种模式，即共享模式与独占模式，而这两种模式的加锁与解锁实现方式是不一样的，但AQS只关注内部公共方法实现并不关心外部不同模式的实现，所以提供了模板方法给子类使用，也就是说实现独占锁，如ReentrantLock需要自己实现tryAcquire()方法和tryRelease()方法，而实现共享模式的Semaphore，则需要实现tryAcquireShared()方法和tryReleaseShared()方法，这样做的好处是显而易见的，无论是共享模式还是独占模式，其基础的实现都是同一套组件(AQS)，只不过是加锁解锁的逻辑不同罢了，更重要的是如果我们需要自定义锁的话，也变得非常简单，只需要选择不同的模式实现不同的加锁和解锁的模板方法即可，AQS提供给独占模式和共享模式的模板方法如下 123456789101112131415161718192021222324// 独占锁下获取锁的方法protected boolean tryAcquire(int arg) &#123; throw new UnsupportedOperationException();&#125;// 独占锁下释放锁的方法protected boolean tryRelease(int arg) &#123; throw new UnsupportedOperationException();&#125;// 共享锁下获取锁的方法protected int tryAcquireShared(int arg) &#123; throw new UnsupportedOperationException();&#125;// 共享锁下释放锁的方法protected boolean tryReleaseShared(int arg) &#123; throw new UnsupportedOperationException();&#125;// 判断是否为持有独占锁protected boolean isHeldExclusively() &#123; throw new UnsupportedOperationException();&#125; 可以看到这些方法在AQS的实现中同意抛出异常，需要其子类根据需要重写不同的方法去实现。 AQS中成员方法AQS中成员方法很多，在这里不会一一去介绍，只介绍其中的几个成员国方法为后续介绍ReentrantLock、Semaphore做铺垫。 acquire(int arg)线程获取同步状态，如果获取失败则将线程加入到同步队列尾 12345678public final void acquire(int arg) &#123; // tryQcquire模板方法，留给子类实现 // 如果获取同步状态失败，那么将线程包装为node添加到同步队列尾 // 调用acquireQueued方法，该方法前面介绍过 if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; addWaiter(Node mode)该方法用于将线程包装为一个独占模式node，并添加到同步队列尾 123456789101112131415161718private Node addWaiter(Node mode) &#123; // 将线程包装为一个独占模式的node Node node = new Node(Thread.currentThread(), mode); Node pred = tail; // 如果同步队列已经存在 if (pred != null) &#123; node.prev = pred; // 使用CAS将node设为同步队列尾节点 if (compareAndSetTail(pred, node)) &#123; pred.next = node; return node; &#125; &#125; // 如果同步队列还未初始化或CAS失败，则调用enq，将node加入到同步队列中 enq(node); // 返回线程的node return node;&#125; release释放同步状态，并唤醒同步队列中的线程 123456789101112public final boolean release(int arg) &#123; // tryRelease为模板方法，由子类实现 if (tryRelease(arg)) &#123; Node h = head; // 如果同步队列头节点不为空并且状态不为0，调用unparkSeuucssor方法并返回true if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &#125; // 如果tryRelease失败，返回false return false;&#125; unparkSuccessor(Node node)1234567891011121314151617181920private void unparkSuccessor(Node node) &#123; // 这里的node就是同步队列的头节点 int ws = node.waitStatus; // 尝试将头节点的waitStatus设为0，允许失败 if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); // s为紧接着head的后继节点 Node s = node.next; // 如果s为空或s已经是Cancelled状态，那么从同步队列的尾节点开始向前找 // 找到队列中最靠近头节点并且waitStatus不为Cancelled的node if (s == null || s.waitStatus &gt; 0) &#123; s = null; for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; &#125; // 如果找到了满足条件的node，则唤醒该node代表的线程 if (s != null) LockSupport.unpark(s.thread);&#125; 总结 ：该方法主要作用是用unpark()唤醒同步队列中最前边未放弃线程(也就是状态为CANCELLED的线程结点s)。还记得acquire中acquireQueued()方法是怎么做的么，s结点的线程被唤醒后，会进入acquireQueued()函数的if (p == head &amp;&amp; tryAcquire(arg))的判断，此时被唤醒的node可能不是head的后继节点，所以不能满足if条件，但是它会执行shouldParkAfterFailedAcquire()，由于s通过unparkSuccessor()操作后是同步队列中最前边未放弃的线程结点，那么通过shouldParkAfterFailedAcquire()内部对结点状态的调整，s最终会成为head的next结点，因此再次自旋时p==head就成立了，然后s把自己设置成head结点，表示自己已经获取到资源，最终acquire()也执行完毕。 总结对于AQS的介绍到这里就告一段落，AQS本质上就是一个FIFO队列+status，通过status表示同步状态，通过FIFO管理等待同步状态的线程。将想要获取同步状态的线程包装成node交由FIFO队列管理。后面将会介绍基于AQS实现的可重入锁(独占锁)ReentrantLock的实现原理。]]></content>
      <categories>
        <category>Java并发编程</category>
      </categories>
      <tags>
        <tag>AQS</tag>
        <tag>Java并发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入剖析局部类与final关键字]]></title>
    <url>%2F2020%2F03%2F24%2F%E6%B7%B1%E5%85%A5%E5%89%96%E6%9E%90%E5%B1%80%E9%83%A8%E7%B1%BB%E4%B8%8Efinal%E5%85%B3%E9%94%AE%E5%AD%97%2F</url>
    <content type="text"><![CDATA[Java中有一种神奇的类，那就是局部内部类。定义在方法或某个作用域内的类，就是局部内部类。而匿名内部类就是一种局部内部类。关于局部内部类，我一直很疑惑为什么它只能访问final修饰的局部变量？它访问成员变量时需要加final修饰么？我上网查阅，网上给出的答案五花八门让人无法分辨真假，于是我花了点儿时间，自己动手一个一个的实验，终于整理出了头绪，特此来记录一下。 概述在文章的开头，先给出结论(本结论基于JDK1.8版本)：局部内部类访问只能访问final修饰的局部变量，可以访问非final修饰的局部内部类所属类的成员属性。至于原因，我在演示后在文章的末尾进行总结。 局部内部类访问局部变量在本节中，我将在方法内部定义一个局部内部类，让其访问方法的局部变量，通过反汇编查看编译后的字节码文件 演示 在方法内部定义一个局部内部类，并在内部类中使用内部类所述方法的User类型的变量。 12345678910111213141516171819202122class Outter&#123; public static void test(User user)&#123; user.name=&quot;hello &quot;; class Inner&#123; public void show()&#123; System.out.println(user.name); &#125; &#125; new Inner().show(); &#125; public static void main(String[] args)&#123; test(new User()); &#125;&#125;//定义一个类class User&#123; public int id; public String name;&#125; 使用javac Outter.java编译该类，会得到两个class文件(不考虑User.class) 其中一个和外围类(Outter)的名字相同，另外一个应该是局部内部类的class文件，我们来反编译一下Outter.class 查看Outter反编译后的代码，我们发现，它test方法中的参数竟然是final的，我们写的代码中明明没有final啊，这是为什么呢？原来，在以前，我们是需要显式的用final修饰该局部变量的，但是后来，Java使用了语法糖，不用我们去加final了，它在编译时会自动加上final。 我们再来反编译下局部内部类Inner的字节码文件Outter$1Inner.class 通过查看反编译的代码，我们发现，当我们的局部内部类使用局部变量时，会将该局部变量当作自己的成员变量使用(在构造方法中赋值)。 总结通过演示，我们可以得出结论：在方法内部定义局部内部类时，如果局部内部类使用了局部变量，即使我们没有将该局部变量显式的声明为final，JVM在编译会自动将该局部变量加上final修饰。并且局部内部类会将该局部变量当作自己的成员属性使用。 局部内部类访问成员变量在本节中，我将定义一个方法，在方法中定义一个局部内部类，并在局部内部类中访问其所属方法所属的类的成员属性，通过反汇编查看编译后的字节码文件 演示 定义一个方法，在方法中定义一个局部内部类，内部类中访问外围类的成员属性 1234567891011121314151617181920212223242526272829303132public class Outter &#123; //定义一个外围类的成员属性 private User OutterUser = new User(); public void show() &#123; this.OutterUser.name = &quot;Outter&quot;; //定义一个方法的局部内部类 class Inner&#123; public void InnerMethod() &#123; //局部内部类访问外围类的成员属性 System.out.println(OutterUser.name); &#125; &#125; //修改成员属性，使其指向新的User对象 this.OutterUser=new User(); //执行局部类的方法 new Inner().InnerMethod(); &#125; public static void main(String[] args) &#123; //调用show()方法 new Outter().show(); &#125;&#125;class User&#123; public int id; public String name;&#125; 我们使用javac Outter.java编译java文件，除去User.class，我们仍得到两个class文件 我们通过反汇编查看Outter.class文件 这里我们发现了，此时成员属性并没有被final修饰。方法执行时使用Outter.this调用外围类的成员属性。这里有个小细节需要特别注意：我们在代码中，修改成员属性的动作写在定义局部内部类之后，但是反编译后，该动作被提到了前面执行，这也就意味着我们InnerMethod()方法时，打印的不是Outter，而是null。我经过测试发现结果确实是这样。 我们再来看看局部内部类的class文件 在局部内部类中，此时和前面的不同，此时直接将外围类的引用传递了进来，这也就意味着局部内部类可以访问外围类的任何东西。 总结通过演示，我们可以得出结论：当局部内部类使用外围类的成员属性时，局部内部类在构造方法中会传入外围类的引用，当需要访问外围类的成员属性时，直接使用该引用调用。 匿名内部类匿名内部类是一种特殊的局部内部类，区别只是在于它没有名字而已，我在本地演示过，和局部内部类的规则一摸一样，这里就不演示了。 总结 访问局部变量通过演示可以发现，确实如网上有些答案所说，局部内部类只能访问final修饰的局部变量，那么这是什么原因呢？这要从Java的特点说起了，我们知道Java中采用的是值传递。也就是说，当传递一个基本类型时，方法内部会复制一份，方法中对该基本类型的任何修改都不会影响到外部变量本身；当传递一个引用类型时，方法内部会复制一份引用，方法内如果引用发生了变化，同样不会影响到外部变量。当一个局部变量被局部内部类使用时，局部内部类会拷贝一份(如果是引用类型拷贝引用)作为自己的成员属性使用，因此无论是方法或者是类谁对它做了修改，都不会影响到另一方….为了避免这种尴尬的情况，保持一致性。因此简单粗暴的将局部变量设置为final，既然不能同步，那我们大家都不要修改咯。这也就是只能访问final修饰的局部变量的原因。 访问成员属性在访问成员属性时有所不同，此时局部内部类并不会拷贝一份变量作为自己的成员属性，而是将外围类的引用传递进来(更加霸道..)，此时成员属性仍然只有一份，因此就不会出现不一致的情况了。 辟谣关于网上说的延长生命周期一说，纯属无稽之谈，不知道从谁那里传过来的，真的是害人不浅！！！ 最后疑问当访问成员属性时，会将外围类的引用传递进来，那么有的同学可能会问了：既然是值传递，如果外围类对象的引用改变了不同样会造成不一致么？这个问题其实很简单，局部内部类定义在方法中，而方法属于外围类对象，当外围类对象引用改变了，那么当前对象就成了垃圾对象，还有存在的必要么？]]></content>
      <categories>
        <category>Java编程思想</category>
      </categories>
      <tags>
        <tag>局部内部类</tag>
        <tag>final关键字</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Lambda表达式的底层实现]]></title>
    <url>%2F2020%2F03%2F23%2FLambda%E8%A1%A8%E8%BE%BE%E5%BC%8F%E7%9A%84%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[今天写多线程代码时，用到了Lambda表达式实现Runnable接口，于是我突然想到一个问题：Lambda是Jdk8的新特性，那么Lambda表达式到底是怎么实现的呢？于是我进行了一番测试和上网查找，终于弄明白了Lambda的底层实现，所以特此来记录一下。 前言Lambda表达式是JDK1.8出现的新特性，能够大大的简化我们的代码，并且Lambda经常和函数式接口一同搭配使用，这是由函数式接口的特点决定的：函数式接口(@FunctionalInterface)只允许有一个抽象方法(静态方法和默认方法不做要求，如果要将Object类的方法变成抽象方法，那么抽象方法也不做要求)。这样在实现函数式接口时，就可以直接使用Lambda表达式来实现。极其方便快捷。但有一点需要注意：Lambda表达式无法处理重载方法 12345678910111213141516171819202122232425262728293031public class LambdaTest &#123; //方法的重载版本：接收InterTest1接口的参数 public static void method(InterTest1 interTest1) &#123; &#125; //方法的重载版本：接收InterTest2接口的参数 public static void method(InterTest2 interTest2) &#123; &#125; public static void main(String[] args) &#123; //这里无法使用Lambda表达式，因为无法判断出该方法需要接受哪个接口作为参数 method(()-&gt;&#123; &#125;); &#125;&#125;两个函数式接口@FunctionalInterfaceinterface InterTest1 &#123; void test(String msg);&#125;@FunctionalInterfaceinterface InterTest2 &#123; void test(String msg);&#125; 从上面的测试可以看出，当出现方法重载时，我们还是要使用匿名内部类的方式。 演示Lambda表达式底层原理 我们写一个使用Lambda表达式的类，如下所示 1234567891011121314public class App&#123; public static void main(String[] args)&#123; //使用Lambda表达式创建一个接口实现类 IMarkUp mu=(msg)-&gt;System.out.println(msg); //调用该接口方法 mu.test(&quot;lambda&quot;); &#125;&#125;interface IMarkUp&#123; void test(String msg);&#125; 在cmd窗口，使用javac App.java 命令编译该App类，会发现得到了两个Class文件 我们使用javap -p App命令反编译一下App类 通过反编译我们发现，反编译后出现了一个私有静态方法，并且该方法是我们的java源码中不存在的，它接受一个String类型作为参数 1234private static void lambda$main$0(java.lang.String)&#123; //该方法的方法体就是我们Lambda表达式的内容 System.out.println(msg);&#125; 使用java -Djdk.internal.lambda.dumpProxyClasses App来查看接口的实现类，但是我电脑上该命令执行不出来，于是我在IDEA上将前面的命令配置成参数执行，得到了JVM生成的接口的实现类 123456789101112131415import java.lang.invoke.LambdaForm.Hidden;//该实现类是JVM创建的，继承了我们的函数式接口final class LambdaTest$$Lambda$1 implements InterTest &#123; //私有的构造方法 private LambdaTest$$Lambda$1() &#123; &#125; //实现了接口中的抽象方法 @Hidden public void test(String var1) &#123; //通过调用前面的私有静态方法完成功能 LambdaTest.lambda$main$0(var1); &#125;&#125; 总结最后我们可以总结JDK1.8下Lambda表达式的底层原理：JVM仍然会生成接口的一个实现类，并在调用方法类中生成一个私有的静态方法，在实现类的方法中调用该方法。可以发现，Lambda只是简化了我们的书写，但是它还是通过实现类完成的。]]></content>
      <categories>
        <category>Java编程思想</category>
      </categories>
      <tags>
        <tag>Java基础</tag>
        <tag>Lambda表达式</tag>
        <tag>底层实现</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅谈MySQL架构]]></title>
    <url>%2F2020%2F03%2F21%2F%E6%B5%85%E8%B0%88MySQL%E6%9E%B6%E6%9E%84%2F</url>
    <content type="text"><![CDATA[一直以来都在学习MySQL，学了MySQL的事务、事务的四大特性及实现原理、索引的使用和实现等等一些MySQL相关的知识，但是对于MySQL的架构，或者通俗的说，MySQL是由哪几部分组成的却忽略了，实际上这是很不应该的，因为只有对MySQL的架构有了一个了解，才能对于SQL语句的执行流程有一个认识，从而能够进行更好的优化。今天就来简单地学习一个MySQL的架构，本文基于MySQL5.5版本。 总体架构 如图，这就是MySQL的基础架构，可以看到MySQL总体上可以分为三层 客户层 Server层 存储引擎层 下面我将会对每个部分进行一个简单地介绍 客户层客户层用于向MySQL数据库发送请求，比如我们用的JDBC、以及一些可视化工具如sqlyog和我们使用MySQL的客户端，都属于客户层。客户端发送的请求交给下层的Server层。 Server层这一层比较重要，从上面图中可以看到，这一层分了很多个组件： 连接器 分析器 优化器 执行器 缓存 下面分别对这几个组件进行简单地介绍 连接器我们在登陆时，需要输入用户名，输入密码；在远程登陆时还要输入主机的ip地址以及端口号，从而和MySQL建立连接。这些功能都是由连接器完成。当我们登录MySQL的时候，连接器会建立客户端和服务器的连接(TCP/IP协议)，建立好连接后会验证输入的用户名和密码是否正确。因此连接器主要用于管理连接，进行相关权限的认证。我们可以使用show processlist;命令查看服务器的连接。 分析器我们知道，SQL语句是用来操作数据库的，但是我们写的SQL语句服务器是看不懂的，SQL语句是为了方便我们学习使用而发明的。服务器会将我们写的SQL语句编译为它能够看懂的语言(选择投影连接)。分析器会对我们的SQL语句进行 词法分析，判断我们写的SQL语句中是否有无法识别的词 语法分析，判断我们的SQL语句是否存在语法错误。比如，我写了SELECT却没有写FROM，这就不能通过语法分析 生成抽象语法树，这一步主要是方便后面优化器对我们的SQL语句进行优化 优化器这一组件会根据我们前面生成的抽象语法树对我们的SQL语句做一个优化。我们写一条SQL语句，他可能有很多执行的方式，优化器会对其进行优化，选择比较好的方式执行该SQL语句。优化器非常复杂，这里简单的说几点可能的优化手段： 重新定义表的关联顺序 (多张表关联查询时，并不一定按照 SQL 中指定的顺序进行，但有一些技巧可以指定关联顺序) 优化 MIN() 和 MAX()函数 (找某列的最小值，如果该列有索引，只需要查找 B+Tree索引 最左端，反之则可以找到最大值) 提前终止查询 (比如 : 使用 Limit 时，查找到满足数量的结果集后会立即终止查询) 优化排序 (在老版本 MySQL 会使用两次传输排序，即先读取行指针和需要排序的字段在内存中对其排序，然后再根据排序结果去读取数据行，而新版本采用的是单次传输排序，也就是一次读取所有的数据行，然后根据给定的列排序。对于I/O密集型应用，效率会高很多) 执行器执行器是直接跟我们的存储引擎进行数据交互的，数据交互就涉及到I/O的问题。我们常听说的一条优化手段是尽量不要使用SELECT * ，这是什么原因呢？如果我们在本地操作数据库，很重要的一点就是I/O，我们常说的优化优化，其实就是减少I/O的次数，减少每次的I/O量，当我们使用SELECT *的时候，会取出一些不必要的字段，加大了I/O。因此我们要养成用什么就取什么的习惯。再回来说说执行器吧，当我们对SQL进行优化后，就得到了最终的执行计划，执行器就会根据该执行计划调用存储引擎查询数据。 缓存这一组件已经在后续版本被移除，当时我正在使用的MySQL5.5仍然存在该组件。简单地说，当我们执行SQL语句后，会将查询的结果放入缓存中，如果我们下次仍执行这条SQL语句，那么这时就会直接查询缓存直接返回数据。但是有一点要明确：并不是执行所有SQL语句后都会放入缓存。但是该缓存的效率是不高的，这是因为：我们一般不会执行一条SQL语句多次，并且当我们输入不同的SQL语句时，还会对缓存进行更新。由于缓存命中率低，并且占用内存空间，所以在MySQL8时被移除。 存储引擎层存储引擎是我们听过最多的MySQL的部分了，存储引擎用于管理和组织我们的数据文件，它是数据库中非常重要的组件。存储引擎是表级别的，不是库级别的，我们在创建表时可以为不同的表使用不同的存储引擎。MySQL有很多不同的存储引擎，我们可以使用show engines;命令查看MySQL的存储引擎。MySQL有一个非常好的设计，MySQL是一个可插拔的存储引擎系统，也就是说，如果我们自己实现了一个符合规范的存储引擎，我们就可以将自己实现的存储引擎插到MySQL中使用。MySQL的存储引擎种类很多，主要说的就两个：InnoDB和MyISAM存储引擎，不同的存储引擎差别较大，因此我们在说存储引擎的时候，一定要说明是哪一种存储引擎。 InnoDB存储引擎文件格式使用InnoDB存储引擎的表，有两种不同后缀的文件 .frm文件，存储表的结构(可以理解为创建表语句) .ibd文件，存储表的索引 索引结构 InnoDB的数据表是以索引的形式存在的，表的主键就是一个聚簇索引。索引采用B+树的结构，B+树的每个叶子节点存储着表的记录。InnoDB内部可能会使用哈希索引，但这是我们无法干预的。 InnoDB的辅助索引，同样使用B+树结构，辅助索引的叶子节点存储的是对应的主键的值 InnoDB不支持全文索引，5.7以后InnoDB已经支持 加锁InnoDB支持表锁和行锁两种锁，并且InnoDB的锁锁的是索引，因为前面说过，InnoDB的表本身就是一个索引文件。如果我们的访问命中了索引，那么会使用行锁索引相应的记录行，如果没有命中索引，则会使用表锁锁全表。因此创建合适的索引并编写合适的SQL语句对于提高查询性能至关重要 事务InnoDB是支持事务的，对于InnoDB，每一条SQL语句都默认封装成事务，自动提交(set autocomit=0关闭自动提交)。 其它 InnoDB支持外键，这个我们平常也经常使用 InnoDB不保存表的具体行数，当执行select count(*)时，需要进行全表扫描 MyISAM存储引擎文件格式使用MyISAM存储引擎的表，有三种不同后缀的文件 .frm文件，存储表的结构(可以理解为创建表语句) .MYD文件，存储表的数据 .MYI文件，存储表的索引 MyISAM同样使用B+树结构的索引，但是和InnoDB不同的是，MyISAM不支持聚簇索引。通过上面文件格式也可以发现，MyISAM中索引和数据是分离的。B+树索引的叶子节点存储的是对应记录的地址。 索引结构加锁MyISAM只支持表锁，并且锁的是数据文件，那么为什么MyISAM不支持行锁呢？这点我上网了解了一下，表锁虽然在高并发下性能低，但是它开销小锁表快，可能是以前对于并发要求并不高，于是MyISAM也并不需要使用行锁。 事务MyISAM是不支持事务的，因此它的故障恢复能力较差。 其它 MyISAM不支持外键 MyISAM中有一个变量保存了整个表的行数，执行COUNT(*)时速度很快，只需要读出该变量即可。 那么为什么InnoDB中不使用该变量呢？这是因为，由于InnoDB事务的特性，在同一时刻表中的行数对于不同的事务来说是不一样的，因此count(*)会统计对于当前事务来说可以统计到的行数。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>索引</tag>
        <tag>MySQL架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入浅出Https]]></title>
    <url>%2F2020%2F03%2F20%2F%E6%B7%B1%E5%85%A5%E6%B5%85%E5%87%BAHttps%2F</url>
    <content type="text"><![CDATA[本文对于基本的Http协议不再做赘述(如果对Http协议不了解的建议先学习一下Http协议)。在本文中，首先指出Http协议的缺陷，紧接着提出各种解决方法，最后剖析一下Https协议的实现原理。最后对比Http协议和Https协议，分别介绍它们的优缺点。 Http协议存在的问题我们知道，Http协议是基于请求响应模型，客户端发送请求，服务器回送响应。这里的关键在于，无论是客户端发送的请求还是服务器回送的响应，都是没有加密的，也就是明文传输。由于Http协议是明文传输，因此会造成安全性问题。如图，当你使用http协议上网时，你在浏览什么网站，你的隐私等等，别人都能够轻而易举地获取，这无疑是很不安全的。 对称加密传输当出现了上面的问题，人们就像，我能不能在发送方对数据进行加密，在接收方对数据进行解密，这样不就安全了么。我们发送方和接收方只需要在交换数据之前，先约定一下加密解密的方法(秘钥)，这样发送方发送数据时先对数据进行加密，然后接收方接收到数据后用对应的解密方法对数据解密。这种加密传输看起来是安全的，但实际上毫无作用，我们来看一下。就像图中说的，虽然客户端和服务器对数据进行加密传输，但是由于它们的密钥能够被其他人获取到，所以这种对称加密方法和明问传输无异。 非对称加密为了解决对称加密出现的问题(密钥能够被第三方获取到)，人们又想出了非对称加密算法。对于非对称加密算法：有一对密钥，一个是公钥、一个是私钥。公钥加密的数据只能用私钥解密，而私钥加密的数据只能用公钥解密(至于原理不用深究，只需要知道这一点就足够)。其中私钥是服务器私有的，只有服务器知道，而公钥是发送给客户端的(这就意味着公钥是很容易获取到的)。让我们来看看非对称加密算法能不能解决问题，它又存在哪些问题从图中可以看到，使用了非对称加密后，客户端发往服务器的数据安全能够得到保障，但是服务器发送给客户端的数据却能够轻易的被他人获取，这仍然是不安全的。那么怎么解决呢？我们继续往下看 非对称加密+对称加密我们可以看到，无论是对称加密还是非对称加密，都存在安全问题，于是人们又想出了一种办法：将对称加密和非对称加密结合使用。它的大致思路是这样的： 客户端先获取服务器的公钥，然后自己生成一个密钥(这里假设是K)。 客户端使用公钥对该密钥K进行加密，注意是对密钥K加密而不是对数据加密(由于这一步是安全的，因此黑客无法获取到该密钥K) 服务器收到加密数据后，使用私钥解密数据得到客户端的密钥K。 然后客户端和服务器使用该密钥K对数据进行加密解密(对称加密) 我们可以看到，客户端和服务器使用非对称加密算法保证密钥K的安全，然后使用对称加密算法对数据进行加密。但是这样就万无一失了么？我们看看这样会存在什么问题？通过分析我们发现，使用非对称加密+对称加密算法后，黑客仍然能够获取到对称加密的密钥，从而获取篡改数据，这种方法也不是万无一失的。 CA认证通过分析我们可以发现，使用非对称+对称加密时之所以会出现问题，是因为客户端无法辨别服务器的身份，换句话说，就是它不知道它收到的公钥是来自服务器还是来自客户端。既然知道了问题所在，那我们就来解决。于是CA机构就出现了。 什么是CA认证呢？我们来打个比方：现在有两个人A、B和C，它们互相都不认识。当A和B想要进行交流时，C插入进来，C对A说它是B，然后对B说它是A。由于A、B互相不认识并且都不认识C，因此它们并不会怀疑C的身份，于是它们就开始交流。这样A和B交流的所有内容都被C得知，并且C还可以改变它们对对方说的话。而CA机构就像一个警察，它认识A、B和C，并且三者都信任他。当C对A说它是B时，警察就告诉A：他不是B，它是C...这样以来，A就知道C是伪装的，C就无法窃取数据了。 ![](/深入浅出Https/6.png) 如图，由于网络中的计算机都是信任CA机构的，因此借助CA机构，在非对称加密阶段，客户端就能够识别出它收到的公钥是来自黑客还是来自服务器，这样就能够保证安全。 CA证书CA证书是网站向CA机构申请认证，然后CA机构向网站颁发的能够标识网站身份的电子证书(可以理解为网站的身份证，不同的网站CA证书是不同的)。当网站向CA机构申请认证时，需要将自己的公钥、域名、等等信息提交给CA认证(不同级别的认证提交的信息不同)。CA机构对网站提交的域名、公钥等明文信息使用hash算法(MD5)生成数字数字摘要。最后，CA机构使用自己的私钥对数字摘要进行加密，就得到了数字签名。最后的CA证书中包含了明文和由明文生成的数字签名 CA认证+非对称加密+对称加密下面就介绍一下CA机构+非堆成加密+对称加密是如何保证数据安全的。 客户端向服务器请求服务器公钥，服务器将自己的CA证书发送给客户端 客户端收到服务器的CA证书后，使用操作系统的对应的CA机构的公钥解密CA证书的数字签名，获取数字摘要 这里是关键的一步：客户端使用相同的哈希算法(如MD5)对CA证书的明文部分进行哈希运算，得到网站的数字摘要，然后将生成的数字摘要和解密出的CA证书的数字摘要对比，如果相同，说明该CA证书没有被篡改过 如果CA证书没有被篡改过，客户端又会根据域名判断该证书是否被掉包 如果CA证书是真的且没有被掉包，也就是说客户端已经能够确认收到的公钥是服务器的公钥 客户端生成一个密钥，并使用hash算法对密钥进行hash，将密钥原文和得到的hash值一起使用公钥加密后发送给服务器 服务器收到后使用私钥解密，并对密钥原文使用同样的hash算法进行hash，如果和客户端发来的哈希值相同，则说明没有被篡改 此后客户端和服务器通信使用该密钥对称加密。 Https和Http区别Https实际上是Http+TLS/SSL，它并不是一个新的协议，而是在TCP之上，Http之下加了一个TLS/SSL安全套接字。 它们的端口号不同，Http为80而Https为443 Http明文传输数据，而Https加密传输数据，安全性更高 Https需要CA证书，安全性越高的证书费用越高 Https协议比Http协议耗时开销大。]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>Https</tag>
        <tag>应用层</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅谈MySQL三种日志]]></title>
    <url>%2F2020%2F03%2F15%2F%E6%B5%85%E8%B0%88MySQL%E4%B8%89%E7%A7%8D%E6%97%A5%E5%BF%97%2F</url>
    <content type="text"><![CDATA[我们都知道数据库有ACID四大特性，分别是原子性、隔离性、一致性和持久性，那么数据库是通过什么手段来实现原子性的呢？又是通过什么手段来实现持久性的呢？答案就是日志。下面让我们来看一看MySQL InnoDB的三种日志：Redo log、Undo log、bin log。 Redo logRedo log是MySQL InnoDB引擎所产生的。当事务开始时，就开始记录每次变更信息。现在我们假设下面一条语句： 1update table set name=&quot;tom&quot; where id=3; MySQL执行这条语句时，先把id=3的记录查出来然后将name字段给改掉。我们知道MySQL InnDB 的基本存储结构是页(每个树节点一页)，所以MySQL先把对应的页加载进内存，然后修改相应的记录。那么这就有一个问题：如果在内存中把数据改了，该没来得及往磁盘上写，数据库就挂了，这怎么办？这可能会违反一致性。但是如果每次请求都将数据立马写入磁盘，那么速度就会很慢。因此MySQL InnoDB引入了Redo log。 当内存写完了，就会写一份Redo log，这份log记录的是这次在某个页(物理位置)上做了什么修改，其实在写Redo log时也会先写如缓冲区，至于什么时候写入内存，可以自行配置。写Redo log也是需要写入磁盘的，但是它是顺序I/O，要比随机I/O快很多。因此Redo log的存在是为了：当我们修改时，写完内存但数据还没有写入磁盘中，此时数据库挂了，我们可以用Redo来进行数据恢复。Redo log顺序I/O，写入速度快，并且文件体积小，恢复速度快。 bin logbin log是所有数据库都有的一种日志。和Redo log不同的是，bin log是在事务提交的时候才记录。bin log记录了数据库表结构和表数据的变更，例如update/delete/insert/drop等，他不会记录select语句。对于bin log，我们可以理解为：存储着每条变更的SQL语句，在什么时间、什么事务(事务ID)执行了什么SQL语句。 bin log主要用来复制和恢复数据，其实这也很好理解，bin log记录着每条改变数据库表结构和数据的语句，那么我们将这些语句再执行一遍，不就可以得到一个一样的数据库了么？ bin log和Redo log到这里你可能会有疑惑，Redo log和bin log好像很相似，其实它们的区别还是挺大的，我们来看看： 存储内容前面说过，Redo记录的是磁盘的那一页修改了什么内容，是实际的物理变化。而bin log记录的是什么事务在什么时间执行了什么SQL语句，并不对应着磁盘的位置，是一个逻辑变化 功能Redo log的作用是为了持久化而生的，写完内存后如果数据库挂了，Redo log能够保证更新的数据能够持久化到磁盘上。而bin log的作用是复制和恢复。还有一点：Redo log存储的是物理数据的变更，如果我们已经将数据刷到了磁盘上，那么Redo log就失效了。 Redo log和bin log写入细节到这你可能会想，这两种log的写入顺序又是什么样的呢？前面说了，Redo log在事务开始的时候就开始记录变更信息，而bin log在事务提交时才记录。那么现在有一个问题：我写其中某一个log，失败了该怎么办？现在假设我们先写Redo log再写bin log 如果Redo log失败了，那么我们就会滚这次事务，不再写bin log 如果Redo log成功了，但是bin log写了一半失败了，此时我们还是会对数据库进行回滚(撤销Redo log的影响)，将无效的bin log删除。 只有两者都写成功了，事务才算是真正成功了。 两阶段提交简单地说：MySQL需要保证Redo log和bin log的数据是一致的，为了保证这种一致性，MySQL使用了两阶段提交 阶段一InnDB Redo log写入磁盘，事务进入prepare状态 阶段二bin log写入磁盘，InnoDB事务进入commit状态 每个bin log的末尾，都会记录一个XID event，标志着事务是否提交成功。也就是说，在恢复时，bin log最后一个XID event之后的内容都应该被清除。 Undo log其实Undo log我们在MVCC时就已经介绍过了，它主要有两个作用：回滚和MVCC。前面说过，在数据修改时，不仅记录了Redo log还记录了Undo log。如果因为某些原因导致事务失败或者回滚，可以用Undo log进行回滚。 Undo log主要存储逻辑日志，比如我现在insert了一条语句，那么Undo log会记录一条delete语句，这很好理解，因为回滚时就是要做相反的操作嘛。Undo log保证了事务地原子性，一个事务要么全部完成要么什么都不做。这个"什么都不做"就是通过Undo log回滚实现的。 参考文章：微信公众号]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>日志</tag>
        <tag>Redo</tag>
        <tag>Undo</tag>
        <tag>bin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IDEA快捷配置Maven插件方式]]></title>
    <url>%2F2020%2F03%2F13%2FIDEA%E5%BF%AB%E6%8D%B7%E9%85%8D%E7%BD%AEMaven%E6%8F%92%E4%BB%B6%E6%96%B9%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[我们都知道，使用Maven构建Java Web项目时需要在pom.xml文件中配置jar包坐标以及各种插件，而每次配置插件时都需要做一些大致相同的操作，比较繁琐，因此这里记录一种使用IDEA工具的快捷配置方式。 配置步骤 进入IDEA的设置页面，file-&gt;settings。 在设置界面的搜索框输入live，就能找到Live Templates设置 点击+号，选择下面的Template Group，创建一个组 设置好组的名字后在上面的列表中找到自己创建的组(我这里创建的MyLive)，选中我创建的组后，再点击+号，选择上面的Live Template创建一个模板 如图，设置模板的名称，和模板的代码内容 我这里设置的模板名称为jdk1.8，作用在XML文件上(pom.xml文件就是XML形式) 这样一来，我们的JDK模板就配置好了。 使用演示打开pom.xml文件，在标签中输入我们之前设置的模板名称(jdk1.8)，会自动弹出之前设置好的配置，直接选择就好。]]></content>
      <categories>
        <category>IDEA</category>
      </categories>
      <tags>
        <tag>Maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis入门学习]]></title>
    <url>%2F2020%2F03%2F12%2FRedis%E5%85%A5%E9%97%A8%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[Redis是一款高性能的NOSQL系列的非关系型数据库。它是一种支持Key-Value等多种数据结构的存储系统。可用于缓存，事件发布或订阅，高速队列等场景。该数据库使用ANSI C语言编写，支持网络，提供字符串，哈希，列表，队列，集合结构直接存取，基于内存，可持久化。今天就对Redis进行一个入门的学习。 什么是Redis前面说了，Redis是一款非关系型数据库，和传统的关系型数据库不同，它采用key-value的方式存储数据，将数据存储在内存中(适当的时候可以持久化到磁盘上)。和传统的关系型数据库相比，Redis具有以下优点： 成本低：NOSQL数据库简单易部署，基本都是开源软件，不需要像使用oracle那样花费大量成本购买使用，相比关系型数据库价格便宜。 查询速度：NOSQL数据库将数据存储于缓存之中，关系型数据库将数据存储在硬盘中，自然查询速度远不及NOSQL数据库。 存储数据的格式：NOSQL的存储格式是key,value形式、文档形式、图片形式等等，所以可以存储基础类型以及对象或者是集合等各种格式，而数据库则只支持基础类型。 扩展性：关系型数据库有类似join这样的多表查询机制的限制导致扩展很艰难。 相应的，NOSQL系列数据库也有一些缺点 维护的工具和资料有限，因为NOSQL是属于新的技术，不能和关系型数据库10几年的技术同日而语。 不同的NOSQL数据库操作不一样，学习和使用成本高。 不提供关系型数据库对事务的处理(Redis支持事务操作)。 为什么使用Redis随着互联网web2.0网站的兴起，传统的关系数据库在应付web2.0网站，特别是超大规模和高并发的SNS类型的web2.0纯动态网站已经显得力不从心，因为传统的关系型数据库需要进行磁盘操作，查询速度较慢。NOSQL数据库的产生就是为了解决大规模数据集合多重数据种类带来的挑战，尤其是大数据应用难题。一般来说，我们将Redis和传统的关系型数据库搭配使用，将数据存储在关系型数据库中，在nosql数据库中备份存储关系型数据库的数据。在需要数据库查询时，如果NOSQL里面有，那么就不需要进行磁盘操作只需要从内存读取，这样速度就会快很多。 Redis简单操作Redis是以键值对的形式存储数据，并且Redis的键只能是String类型，但是它的值有5种类型： String类型 hash类型 list类型 set类型 sortedset类型 下面就分别介绍一下这几种类型以及相应的操作 String类型字符串类型是redis中最基本的数据类型，它能存储任何形式的字符串，包括二进制数据。你可以用它存储用户的邮箱、json化的对象甚至是图片。一个字符类型允许存储的最大容量是512M。 添加/修改操作set 键名:向数据库种添加键值对。如果键值对不存在，那么添加进去，如果键值对存在，则修改键值对的值 获取操作get 键名:获取指定键对应的值，如果不存在返回空 删除操作del 键名:删除指定键对应的值 hash类型类似于Java中的hashmap，是一个key+(key-value)的数据结构，对于值为hash类型的键值对，每一个键对应一个hashmap。 添加/修改操作hset 键名 key value:向数据库种添加hash值类型的键值对，并向值得hashmap种添加一个键值对。如果该键值对存在则覆盖原来的值 获取操作 hget 键名 key:获取指定键值对得值(hashmap)，在从该值中获取指定key得value hgetall 键名:获取该键值对得值(hashmap)，并获取该值中所有的key-value 删除操作hdel 键名 key:类似的，删除指定键值对中值的指定键值对。 list类型该类型可以存储一个有序的字符串列表，允许存储重复元素。常用的操作是向列表两端添加元素或者获得列表的某一个片段。列表类型内部使用双向链表实现，所以向列表两端添加元素的时间复杂度为O(1), 获取越接近两端的元素速度就越快。这意味着即使是一个有几千万个元素的列表，获取头部或尾部的10条记录也是很快的。 添加 lpush key value: 将元素加入列表左表 rpush key value：将元素加入列表右边 获取lrange 键名 start end：范围获取。如果start=0 end=-1，那么表示获取list的所有元素 删除 lpop 键名:删除列表最左边的元素，并将元素返回 rpop 键名:删除列表最右边的元素，并将元素返回 set类型是一个集合类型，和list类型不同，它不允许存储重复元素。同时集合类型中的数据是无序的。一个集合类型值可以存储至多232-1个数据。集合类型和列表类型的最大的区别是有序性和唯一性。集合类型的常用操作是向集合中加入或删除元素、判断某个元素是否存在。由于集合类型在redis内部是使用的值为空的散列表(hash table)，所以这些操作的时间复杂度都是O(1)。 存储sadd 键名 value:向指定键值对的值中添加元素 获取smembers 键名:获取指定键值对的值中set集合的所有元素 删除srem 键名 value:删除指定键值对中值的set集合的某个元素 sortedset类型和前面讲的集合类型的区别就是多了有序的功能。在集合类型的基础上，有序集合类型为集合中的每个元素都关联了一个double类型分数，Redis正是通过分数来为集合中的成员进行从小到大的排序。这使得我们不仅可以完成插入、删除和判断元素是否存在等集合类型支持的操作，还能获得分数最高(或最低)的前N个元素、获得指定分数范围内的元素等与分数有关的操作。虽然集合中每个元素都是不同的，但是他们的分数却可以相同。 存储zadd 键名 score value:向指定键值对的值的sortde集合中添加一个元素，并为该元素关联一个source 获取zrange key start end [withscores]:从指定键值对的值的有序集合中获取指定范围内元素，如果start=0，end=-1则获取所有元素。如果加上withscores还可以获取每个值对应的source。 删除zrem key value:删除指定键值对值得集合中的指定元素。 通用命令下面介绍三个命令对于所有的数据类型通用 keys * : 查询所有的键 type key ： 获取键对应的value的类型 del key：删除指定的key value Redis持久化前面我们说过，Redis将数据存储在内存中，那我们都知道内存断电后数据会消失，因此Redis还提供了持久化机制。它能够将数据库中的数据持久化到磁盘上，下次启动时重新加载进内存。Redis提供了两种持久化机制： RBD AOF 下面对这两种持久化机制做一个简单地介绍。 RBD该方式是Redis的默认方式，不需要进行配置，默认就使用这种机制。RBD方式在一定的间隔时间中，检测key的变化情况，然后持久化数据。这就意味着可能会引起数据的丢失。通过修改redis.windows.conf配置文件中的save字段我们可以设置持久化条件，Redis默认设置如下 12345678//如果15分钟内至少有一条数据发生改变，则进行持久化save 900 1//如果5分钟内至少有10条记录发生改变，则进行持久化save 300 10//如果1分钟内至少有10000条记录发生改变，则进行持久化save 60 10000 AOF日志记录的方式，可以记录每一条命令的操作。可以每一次命令操作后，持久化数据。我们编辑redis.windwos.conf文件，设置appendonly字段为yes开启AOF持久化。同时AOF下也有三种方式： 123appendfsync always：每一次操作都进行持久化appendfsync everysec：每隔一秒进行一次持久化(AOF默认方式)appendfsync no：不进行持久化 总结对于Redis的入门学习就到这里，Redis还有许许多多的操作，留到后面慢慢学习。另外Redis的一些实现原理，底层结构后续也会慢慢介绍。]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>NOSQL</tag>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[接口和抽象类的区别]]></title>
    <url>%2F2020%2F03%2F07%2F%E6%8E%A5%E5%8F%A3%E5%92%8C%E6%8A%BD%E8%B1%A1%E7%B1%BB%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[最近在复习Java的基础知识为面试做准备，发现对于Java中接口和抽象类的区别还是说不完整。因此这里做一下总结，方便后期回顾。本文基于JDK1.8版本 接口和抽象类的区别 概念不一样。接口是对动作的抽象，抽象类是对本质的抽象。抽象类表示的是，这个对象是什么。接口表示的是，这个对象能做什么。比如，男人，女人，这两个类（如果是类的话……），他们的抽象类是人，说明他们都是人。人可以吃东西，狗也可以吃东西，你可以把“吃东西”定义成一个接口，然后让这些类去实现它。所以，在高级语言上，一个类只能继承一个类（抽象类）(正如人不可能同时是生物和非生物)，但是可以实现多个接口(吃饭接口、走路接口)。 当你关注一个事物的本质的时候，用抽象类；当你关注一个操作的时候，用接口。抽象类的功能要远超过接口，但是，定义抽象类的代价高。因为Java中每个类只能继承一个类。在这个类中，你必须继承或编写出其所有子类的所有共性。虽然接口在功能上会弱化许多，但是它只是针对一个动作的描述。而且你可以在一个类中同时实现多个接口。在设计阶段会降低难度的。 语法不一样，这点我会在下面一节着重进行对比 接口和抽象类的语法区别抽象类 类访问控制权限：抽象类的访问控制权限可以是public和default两种。实际上Java中所有的类，要么是public、要么是default(除了内部类，内部类可以使用private和protected)。 方法访问控制权限 抽象方法：JDK1.8后默认是default，可以使用public和protected，不能使用private、static、final等修饰 非抽象方法：都可以使用，和类没有区别。 成员属性控制权限：和类一样。 拥有构造方法，但是不能实例化。 如果子类继承该抽象类，那么该子类要么是抽象类，要么实现父类所有抽象方法。 总结：抽象类除了抽象方法不能用private、static、final修饰(这也很好理解，因为这些方法都不能被重写)，不能实例化对象以外，和正常的类没有区别。 接口 接口访问权限控制：接口默认是default的，也可以使用public，但是不能使用其他访问权限控制 方法访问控制权限： 抽象方法：接口中的抽象方法只能是public abstruct修饰 静态方法：默认public static修饰。可以在实现类中通过接口名.方法名调用 默认方法：顾名思义，该方法为default修饰。子类可以重写该方法。(JDK1.8及以后才有) 私有方法：peivate修饰 私有静态方法：private static修饰(4和5两个方法在JDK1.9时添加) 成员属性控制权限：public static final修饰(事实上可以省略)。在接口中如果定义了属性，那么默认是public常量。 一个类可以继承多个接口，接口没有构造方法。 一个接口同样可以继承多个接口。 对比通过前面的介绍我们可以得出结论： 除了内部类以外，接口、抽象类、类的访问权限都只能是public和default 抽象类除了抽象方法有些不同、不能实例化以外，其他方法和普通的类基本一样。 接口中的属性只能是常量，接口中抽象方法只能是public。]]></content>
      <categories>
        <category>Java编程思想</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>Java基础</tag>
        <tag>接口</tag>
        <tag>抽象类</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[详解Java实例构造器]]></title>
    <url>%2F2020%2F03%2F05%2F%E8%AF%A6%E8%A7%A3Java%E5%AE%9E%E4%BE%8B%E6%9E%84%E9%80%A0%E5%99%A8%2F</url>
    <content type="text"><![CDATA[说到构造方法，学习Java的人应该都使用过，通过构造方法我们能得到一个类的实例。但是你真的了解构造方法么？下面我将对构造方法进行一个详细全面的介绍。 构造方法的使用在Java中，每个类都必须有构造方法，如果你没有写构造方法，那么编译器会自动添加一个空参数构造方法。但是如果写了构造方法，那么编译器不会自动添加空参构造方法。 在调用子类构造方法时，如果没有显式的在第一行使用super(...)调用父类构造方法，那么会自动调用父类的空参构造方法。因此我们在编写Java类时，一定要手动写一个空参构造方法(哪怕该方法什么都不执行)。如果不这样做，一旦有类继承了该类，那么子类执行构造方法时有可能会调用父类空参构造方法，此时会报错。 在构造方法中调用构造方法 调用其他构造器我们可以在一个构造方法中调用该类的其他构造方法，使用this(…)进行调用，并且该this()语句必须是第一条语句，否则编译器会报错。 调用父类构造器前面说过，如果没有显式调用，那么子类构造方法可以自动调用父类的无参构造方法，其实我们也可以使用super(…)显式的调用父类的构造方法。同样的，该语句必须是第一条语句，否则会报错。 总结不知道你发现没有，this(…)和super(….)都必须是构造器中的第一行语句。那么这就意味着：如果你要调用该类的其他构造方法，那么就不能显式的调用父类的构造方法，反之亦然。即this(…)和super(…)只能二选一。 疑问前面说过，在子类构造方法中如果不显式调用，则会默认调用父类的无参数构造方法。那么我们如果在构造方法中调用了子类其他构造方法，那么此时还会调用父类的无参构造方法么？如果会，两者谁先被调用呢？我们来演示一下 1234567891011121314151617181920212223242526class father&#123; father() &#123; System.out.println(&quot;father&apos;s constructor()&quot;); &#125;&#125;public class Son extends father&#123; int x; Son() &#123; this(1); &#125; Son(int x) &#123; System.out.println(&quot;Son&apos;s constructor&quot;); &#125; public static void main(String[] args) &#123; Son son = new Son(); &#125;&#125;=====================Output:father&apos;s constructor()Son&apos;s constructor 通过实验可以发现，此时仍会调用父类无参构造方法，并且先于this(…)执行。即：子类构造器在执行的时候一定会最先执行父类的构造方法，如果在子类构造方法中使用了this(…)调用子类的其他构造方法，那么就不能使用super(…)，只能自动地调用父类无参构造方法。 构造方法的作用构造方法执行过程看到这里你可能会觉得奇怪，构造方法不就是创建实例的么？还能有什么作用？如果你这样认为，那就大错特错了。让我们接着往下看： 12345678910还是上面的例子，我们创建一个对象Son son = new Son(1);=================查看编译后的字节码文件0: new #6 // class jvmtest/Son3: dup4: iconst_15: invokespecial #1 // Method &quot;&lt;init&gt;&quot;:(I)V8: astore_1 以上5条指令创建了一个Son实例，来分析一下这5条指令 通过new指令可以创建出一个空对象(这里的空对象是指实例数据为空，不是null)，该对象除了对象头以外都是初始化值。(参见我的博客深入理解JVM虚拟机一) 。此时，创建出来的空对象位于堆中，栈顶保存的是该空对象的引用。 dup指令复制栈顶内容并压会栈顶，那么此时栈顶和次栈顶都是空对象的引用。 iconst_1指令将int型常量1压倒栈顶 此时执行&lt; init&gt;方法，到这里才开始执行构造方法。通过查看元数据得知，该方法需要两个参数：this(隐式传入)和int型变量；因此从栈顶弹出两个值执行构造方法。 构造方法执行完毕后，才创建出我们想要创建的对象，此时栈顶元素还是对象的引用。 astore_1指令将栈顶的引用存入局部变量表，到此为止。 总结通过上述构造方法的执行过程，可以发现：构造方法的作用仅仅是初始化对象，不负责创建对象，new关键字用来创建对象。并且构造方法只能在new表达式(或其他构造方法)中被调用，这保证了对象的创建和初始化是一起的不能被分开。并且调用构造方法时会自动传入this参数。 构造方法是静态方法么静态方法我们先解释一下什么是静态方法，静态方法有哪些特征 被static修饰的方法 静态方法属于类，不属于对象，因此不能被重写 静态方法中没有this隐式参数。这很好理解，因为静态方法不和对象绑定 因为不会产生多态，所以静态方法在类加载时就被解析，属于静态绑定。 调用静态方法时使用invokestatic指令 对于静态方法的特点大致就这么多，和静态方法相对的就是实例方法，下面来介绍一下实例方法。 实例方法 实例方法分为两种：虚方法和非虚方法 对于final或者private修饰的方法(非虚方法)，无法被重写进而不会产生多态，因此在类加载时被解析，属于静态绑定 对于虚方法，可能会产生多态，一般需要等到运行时根据调用者的实际类型来选择调用哪个版本的方法，属于运行时绑定 调用虚方法时使用invokevirtual指令 调用实例构造器、显式父类实例构造器(super)、final方法和private方法时使用invokespecial指令 实例方法调用时都会隐式添加this参数 结论实例构造器无法被重写不参与多态，因而可以是静态绑定，从这种意义上可以称实例构造器是”静态的“，但并不能说实例构造器是一个静态方法。前面对静态方法和实例方法的介绍可以得出结论：实例构造器不是静态方法！ 参考参考书籍：《深入理解JVM虚拟机》参考文章：构造方法是静态方法么]]></content>
      <categories>
        <category>Java编程思想</category>
      </categories>
      <tags>
        <tag>Java基础</tag>
        <tag>构造方法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[详解Java的直接引用与符号引用]]></title>
    <url>%2F2020%2F03%2F05%2F%E8%AF%A6%E8%A7%A3Java%E7%9A%84%E7%9B%B4%E6%8E%A5%E5%BC%95%E7%94%A8%E4%B8%8E%E7%AC%A6%E5%8F%B7%E5%BC%95%E7%94%A8%2F</url>
    <content type="text"><![CDATA[如果你看过《深入理解JVM虚拟机》，那么你一定对里面的直接引用和符号引用有印象。在很长一段时间，我对这两个概念的理解仅仅停留在一个可以标识目标一个可以找到目标的层面上，对于具体细节一概不知。知道最近看了一篇文章，茅塞顿开，所以特此来记录一下。 书上概念下面我先把《深入理解JVM虚拟机中》中的解释贴出来 符号引用符号引用以一组符号来描述所引用的目标，符号可以是任何形式的字面量，只要使用时能够无歧义地定位目标即可。符号引用与虚拟机实现的内存布局无关，引用的目标并不一定已经加载到内存中。 直接引用直接引用可以是直接指向目标的指针、相对偏移量或一个能间接定位到目标的句柄，直接引用是和虚拟机实现的内存布局相关的，同一个符号引用在不同地虚拟机翻译出来的直接引用一般不会相同。如果有了直接引用，那么引用的目标必定已经在内存中存在。 符号引用我们先看一下class文件里的”符号引用”。以下面的Java类为例 1234567891011package jvmtest;public class test &#123; public void foo() &#123; bar(); &#125; public void bar() &#123; &#125;&#125; 编译出来的class文件为 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283Classfile /F:/IDEA/Java_Review/out/production/Java_Review/jvmtest/test.class Last modified 2020年3月5日; size 397 bytes MD5 checksum 87203ab04d5632033698e70476839318 Compiled from &quot;test.java&quot;public class jvmtest.test //类信息 minor version: 0 major version: 56 flags: (0x0021) ACC_PUBLIC, ACC_SUPER this_class: #3 // jvmtest/test super_class: #4 // java/lang/Object interfaces: 0, fields: 0, methods: 3, attributes: 1 //class文件常量池Constant pool: #1 = Methodref #4.#16 // java/lang/Object.&quot;&lt;init&gt;&quot;:()V #2 = Methodref #3.#17 // jvmtest/test.bar:()V #3 = Class #18 // jvmtest/test #4 = Class #19 // java/lang/Object #5 = Utf8 &lt;init&gt; #6 = Utf8 ()V #7 = Utf8 Code #8 = Utf8 LineNumberTable #9 = Utf8 LocalVariableTable #10 = Utf8 this #11 = Utf8 Ljvmtest/test; #12 = Utf8 foo #13 = Utf8 bar #14 = Utf8 SourceFile #15 = Utf8 test.java #16 = NameAndType #5:#6 // &quot;&lt;init&gt;&quot;:()V #17 = NameAndType #13:#6 // bar:()V #18 = Utf8 jvmtest/test #19 = Utf8 java/lang/Object//无参构造方法&#123; public jvmtest.test(); descriptor: ()V flags: (0x0001) ACC_PUBLIC Code: stack=1, locals=1, args_size=1 0: aload_0 1: invokespecial #1 // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V 4: return LineNumberTable: line 3: 0 LocalVariableTable: Start Length Slot Name Signature 0 5 0 this Ljvmtest/test;//foo()方法 public void foo(); descriptor: ()V flags: (0x0001) ACC_PUBLIC Code: stack=1, locals=1, args_size=1 0: aload_0 1: invokevirtual #2 // Method bar:()V 4: return LineNumberTable: line 5: 0 line 6: 4 LocalVariableTable: Start Length Slot Name Signature 0 5 0 this Ljvmtest/test;//bar()方法 public void bar(); descriptor: ()V flags: (0x0001) ACC_PUBLIC Code: stack=0, locals=1, args_size=1 0: return LineNumberTable: line 10: 0 LocalVariableTable: Start Length Slot Name Signature 0 1 0 this Ljvmtest/test;&#125;SourceFile: &quot;test.java&quot; 可以看到，Class文件中有一段叫做常量池(Class文件常量池)，里面存储的该Class文件里的大部分常量的内容。我们看看foo()方法里的一条字节码指令 11: invokevirtual #2 // Method bar:()V 这在Class文件中的二进制编码为 1[B6] [00 02] 其中0xB6是invokevirtual指令的操作码，后面的0x0002是该指令的操作数，用于指定要调用的目标方法。这个参数是Class文件里常量池的下标，那么去找下标为2的常量： 1#2 = Methodref #3.#17 // jvmtest/test.bar:()V 这在Class文件中的二进制编码为(Class文件使用高位在前) 1[0A] [00 03] [00 17] 其中0x0A是CONSTANT_Methodref_info的tag(CONSTANT_Methodref_info其实是一张表，如果不知道可以参考《深入理解JVM虚拟机中》第八章》)，后面的0x0003和0x0011是该表的两项：class_index和name_and_type+index分别引用这另外两个常量池项。其实从名字就可以看出：一个能够找到该方法所属的类，一个能够找到该方法的名字返回值信息。我们顺着这条线索把引用的常量池项都找出来： 123456#2 = Methodref #3.#17 // jvmtest/test.bar:()V#3 = Class #18 // jvmtest/test#18 = Utf8 jvmtest/test#17 = NameAndType #13:#6 // bar:()V#13 = Utf8 bar#6 = Utf8 ()V 我们将这几个常量的引用关系化成一棵树： 12345 #2 Methodref jvmtest/test.bar:()V / \ #3 Class #17 = NameAndType | / \#18 jvmtest/test #13 bar #6 ()V 通过这棵树就可以发现：Class文件中的invokevirtual指令的操作数经过几层间接搜索之后，最后都是又字符串表示的。这就是Class文件里的”符号引用”：带有类型(tag)/结构(如上例所示的符号间的引用层次)的字符串。 直接引用我们在来看看JVM中直接引用的样子，在开始介绍本节之前，你要对Java的虚方法表有简单地认识(如果你不了解，《深入理解JVM虚拟机》p257)。在这里不拿hotspot VM举例(较为复杂)，使用Sun的元祖JVM–Sun JDK 1.0.2的32位x86上的做法。Sun Class VM 123456789HObject ClassObject -4 [ hdr ]--&gt; +0 [ obj ] --&gt; +0 [ ... fields ... ] +4 [ methods ] \ \ methodtable ClassClass &gt; +0 [ classdescriptor ] --&gt; +0 [ ... ] +4 [ vtable[0] ] methodblock +8 [ vtable[1] ] --&gt; +0 [ ... ] ... [ vtable... ] 该元祖JVM在做类加载时会把Class文件的各个部分分别解析为JVM的内部数据结构。例如类的元数据记录在ClassClass结构体中，每个方法的元数据记录在各自的methodblock结构体中... 在刚加载好一个类时，Class文件里的Class文件常量池和每个方法的字节码(Code属性)会被原样拷贝到内存中，也就是说仍处于使用符号引用的状态；直到真的要被使用到的时候才会被解析为直接引用(hotspot中一部分方法和字段会在类加载时解析)。 假定我们要第一次执行到foo()方法里调用bar()方法的那条invokevirtual指令了。此时JVM会发现该指令尚未被解析，所以会先解析一下。 通过其操作数所记录的常量池下标0x0002，找到常量池项#2，发现该常量池项也尚未被解析（resolve），于是进一步去解析一下。 通过Methodref所记录的class_index找到类名，进一步找到被调用方法的类的ClassClass结构体；然后通过name_and_type_index找到方法名和方法描述符，到ClassClass结构体上记录的方法列表里找到匹配的那个methodblock；最终把找到的methodblock的指针写回到常量池项#2里。 也就是说，原本常量池项#2在类加载后的运行时常量池里的内容跟Class文件里的一致，是： 123[00 03] [00 17]（tag被放到了别的地方。小细节：刚加载进来的时候数据仍然是按高位在前字节序存储的） 而在解析后，假设找到的methodblock *是0x45762300，那么常量池项#2的内容会变为： 123[00 23 76 45]（解析后字节序使用x86原生使用的低位在前字节序（little-endian），为了后续使用方便） 这样，以后再查询到常量池项#2时，里面就不再是一个符号引用，而是一个能直接找到Java方法元数据的methodblock了。这里的methodblock就是一个“直接引用”。解析好常量池项#2之后回到invokevirtual指令的解析。回顾一下，在解析前那条指令的内容是： 1[B6] [00 02] 而在解析后，这块代码被改写为： 1[D6] [06] [01] 其中opcode部分从invokevirtual改写为invokevirtual_quick，以表示该指令已经解析完毕。原本存储操作数的2字节空间现在分别存了2个1字节信息，第一个是虚方法表的下标（vtable index），第二个是方法的参数个数。这两项信息都由前面解析常量池项#2得到的methodblock*读取而来。也就是： 1invokevirtual_quick vtable_index=6, args_size=1 这里例子里，类test对应在JVM里的虚方法表会是这个样子的： 1234567[0]: java.lang.Object.hashCode:()I[1]: java.lang.Object.equals:(Ljava/lang/Object;)Z[2]: java.lang.Object.clone:()Ljava/lang/Object;[3]: java.lang.Object.toString:()Ljava/lang/String;[4]: java.lang.Object.finalize:()V[5]: test.foo:()V[6]: test.bar:()V 所以JVM在执行invokevirtual_quick要调用test.bar()时，只要顺着对象引用查找到虚方法表，然后从中取出第6项的methodblock*，就可以找到实际应该调用的目标然后调用过去了。 假如类test还有子类Y，并且Y覆写了bar()方法，那么类Y的虚方法表就会像这样： 1234567[0]: java.lang.Object.hashCode:()I[1]: java.lang.Object.equals:(Ljava/lang/Object;)Z[2]: java.lang.Object.clone:()Ljava/lang/Object;[3]: java.lang.Object.toString:()Ljava/lang/String;[4]: java.lang.Object.finalize:()V[5]: test.foo:()V[6]: Y.bar:()V 于是通过vtable_index=6就可以找到类Y所实现的bar()方法。所以说在解析/改写后的invokevirtual_quick指令里，虚方法表下标（vtable index）也是一个“直接引用”的表现。 总结在现在的HotSpot VM里，围绕常量池、invokevirtual的解析（再次强调是resolve）的具体实现方式跟元祖JVM不一样，但是大体的思路还是相通的。由此可见： 符号引用通常是设计字符串的——用文本形式来表示引用关系。 直接引用是JVM（或其它运行时环境）所能直接使用的形式。它既可以表现为直接指针（如上面常量池项#2解析为methodblock*），也可能是其它形式（例如invokevirtual_quick指令里的vtable index）。关键点不在于形式是否为“直接指针”，而是在于JVM是否能“直接使用”这种形式的数据。 本文内容基本全部来自于知乎回答]]></content>
      <categories>
        <category>JVM虚拟机</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构-红黑树]]></title>
    <url>%2F2020%2F03%2F03%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E7%BA%A2%E9%BB%91%E6%A0%91%2F</url>
    <content type="text"><![CDATA[大家都知道，从JDK1.8开始，HashMap从原来的数组+链表变成了数组+链表+红黑树。不管是面试还是日常应用，HashMap都逃不开，因此我也在很久之前就看过了HashMap的源码，但是看的时候对于其中的红黑树部分真的是一塌糊涂因此就跳过这部分没看。最近复习HashMap源码，决定先学习红黑树，再认真的看一下HashMap。下面就让我们来看看红黑树到底有什么神秘之处吧。 概述红黑树是一种自平衡的二叉查找树，是一种高效的查找树。它是由Rudolf Bayer于1972年发明，在当时被称为对称二叉B树(symmetric binary B-trees)。后来，在1978年被 Leo J. Guibas 和 Robert Sedgewick 修改为如今的红黑树。红黑树具有良好的效率，它可在O(logN)时间内完成查找、增加、删除等操作。因此，红黑树的应用很广泛，比如Java中的TreeMap，JDK1.8中的HashMap、C++ STL中的map均是基于红黑树结构实现的。在本文中，只涉及红黑树的插入操作(对于删除中的双黑修复我没整明白)，最后手动实现一颗红黑树作为总结。 什么是红黑树红黑树的每个节点包含四个属性&lt;color,left,right,p&gt;：这四个属性的含义分别是：颜色、指向左子节点的指针、指向右子节点的指针、指向父节点的指针。 红黑树的性质我们看看红黑树有哪些性质： 节点是红色或黑色。 根节点是黑色。 所有叶子都是黑色(叶子是NIL节点)。 每个红色节点必须有两个黑色的子节点。也就是说，从每个叶子到根的所有路径上不能有两个连续的红色节点。 从任一节点到其每个叶子的所有简单路径都包含相同数目的黑色节点(简称黑高)。 每次新插入的节点为红色节点。 红黑树的最长路径有了上面的几个性质作为限制，即可避免二叉查找树退化成单链表的情况。但是，仅仅避免这种情况还不够，这里还要考虑某个节点到其每个叶子节点路径长度的问题。如果某些路径长度过长，那么，在对这些路径上的及诶单进行增删查操作时，效率也会大大降低。这个时候性质4和性质5用途就凸显了，有了这两个性质作为约束，即可保证任意节点到其每个叶子节点路径最长不会超过最短路径的2倍。 为什么会出现这样的情况，我们来分析一下原因： 最短路径一个节点到其所有子节点的路径什么时候是最短呢？我们通过性质可知，红黑树不允许两个连续红节点，允许连续的黑节点。但是要保证节点到其每个叶子节点的路径上的黑节点个数相同。那么最短路径很容易得到：即如果某节点P到它的某个叶子节点S路径上的所有节点均为黑节点，那么P到其所有叶子节点的最短路径为P-&gt;S。 最长路径分析完了最短路径，我们来看看最长路径。还是前面的例子，如果P到其子节点的最短路径已知(为P-&gt;S)，那么P到其所有所有子节点路径上的黑节点数目就已知了(性质5)。黑节点数量确认了，那么就能够得到最长路径：如果P到其叶子节点N的路径为最长路径，那么N一定是红节点，并且P和N之间的左右节点红黑交替。 总结通过上面的分析我们得知：最短路径为全黑，最长路径为红黑交替。因此最长路径不能超过最短路径的2倍。我们来看下面一张图 从图中可以看到：节点M到其所有叶子节点的最短路径为M-&gt;E，其中一条最长路径为M-&gt;Q-&gt;Y-&gt;Z。 为什么新插入节点为红节点不知道在介绍红黑树性质的时候你有没有疑问：为什么新插入的节点是红节点而不是黑节点呢？ 原因也不难理解。如果插入的节点是黑色，那么这个节点所在路径比其他路径多出一个黑色节点，这个调整起来会比较麻烦（参考红黑树的删除操作，就知道为啥多一个或少一个黑色节点时，调整起来这么麻烦了）。如果插入的节点是红色，此时所有路径上的黑色节点数量不变，仅可能会出现两个连续的红色节点的情况。这种情况下，通过变色和旋转进行调整即可，比之前的简单多了。 红黑树的操作在这里主要介绍红黑树的两大操作：插入和删除。其实如果这两个操作搞清楚了，那么红黑树也就没问题了。 旋转和染色在介绍插入删除操作之前，先介绍一下和红黑树有关的三个基本操作，对红黑树的插入和删除大多离不开这三个基本操作。在这之前，如果你知道AVL树，那么你要注意，这里的左旋和右旋与AVL树里的LR调整、RL调整相似却又不同。一定要注意区分。 左旋 右旋 染色 染色很简单，就是修改节点的color属性。旋转操作分为左旋和右旋，左旋是将某个节点旋转为其右孩子的左孩子，而右旋是节点旋转为其左孩子的右孩子。乍一听，有点儿绕口。我们来看图： 该图包含对M进行右旋和对E进行左旋操作。具体的左旋右旋过程如下图所示： 插入红黑树的插入过程和二叉查找树插入过程基本类似。不同的地方在于：红黑树插入新节点后，需要进行调整，以满足红黑树的性质。接下来，将分析插入红色节点后红黑树的情况。这里假设要插入的节点为 N，N的父节点为P，祖父节点为G，叔叔节点为U。插入红色节点后，会出现5种情况，分别如下： 情况一插入的新节点N是红黑树的根节点。这种情况下：我们把节点N的颜色由红色变为黑色。性质2(根是黑色)被满足。同时N被染成黑色后，红黑树所有路径上的黑色节点数量增加一个，性质5(从任一节点到其每个叶子的所有简单路径都包含相同数目的黑色节点)仍然被满足。 情况二要插入节点N的父节点是黑色。这种情况下，性质4(每个红色节点必须有两个黑色的子节点)和性质5没有受到影响，不需要调整。 染色型插入节点N的父节点是红色(节点P为红色，P的父节点必然为黑色)，叔叔节点U也是红色。由于P和N均为红色，性质4被打破，此时需要进行调整。这种情况下，先将P和U的颜色染成黑色，再将G的颜色染成红色。此时经过G的路径上的黑色节点数量不变，性质5仍然满足。但需要注意的是：G被染成红色后，可能会和它的父节点形成连续的红色节点，此时需要递归向上调整。 左左型N的父节点P为红色，叔叔节点U不存在或者为黑色。节点N是P的左孩子，且节点P是G的左孩子。我们称这种情况为左左型 如图：插入节点N为65，父节点P为66，祖父节点G为69，叔叔节点U不存在。此时我们对祖父节点G右旋，并交换G和P的颜色 左右型N的父节点P为红色，叔叔节点U不存在或者为黑色。节点N是P的右孩子，且节点P是G的左孩子。我们称这种情况为左右型 如图：各个节点对应情况：N-67 P-66 G-69 U-null。先将父节点左旋，转换为左左型。然后按照左左型处理 右右型和左左型镜象对称：N的父节点P为红色，叔叔节点U不存在或者为黑色。节点N是P的右孩子，且节点P是G的右孩子。我们称这种情况为右右型 如图：插入节点N为70，父节点P为69，祖父节点G为66，叔叔节点U为null。此时我们对祖父节点G左旋，并交换G和P颜色 右左型同样的，和左右型镜像对称：N的父节点P为红色，叔叔节点U不存在或者为黑色。节点N是P的左孩子，且节点P是G的右孩子。我们称这种情况为右左型 如图：我们先对P右旋，转换成右右型处理 总结我们发现，前两种情况比较简单。后面四种情况其实最终都转换成左左和右右两种类型处理。可以看到红黑树的插入操作还是比较简单的。 代码实现红黑树插入123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243public class RBTree&lt;T extends Comparable&lt;? super T&gt;&gt; &#123; //静态内部类表示树节点 private static class RBNode&lt;T extends Comparable&lt;? super T&gt;&gt; &#123; T val; RBNode&lt;T&gt; parent; RBNode&lt;T&gt; left; RBNode&lt;T&gt; right; //表明节点的颜色(红色为true) boolean color; public RBNode() &#123; &#125; public RBNode(T val) &#123; this(val, null, null, null); &#125; //创建出来的节点默认为红色 public RBNode(T val, RBNode&lt;T&gt; parent, RBNode&lt;T&gt; left, RBNode&lt;T&gt; right) &#123; this.val = val; this.parent = parent; this.left = left; this.right = right; this.color = true; &#125; &#125; //根节点 private RBNode&lt;T&gt; root; /** * 对节点t左旋 * * @param t */ private void LeftRotate(RBNode&lt;T&gt; t) &#123; if (t != null) &#123; RBNode&lt;T&gt; right = t.right; RBNode&lt;T&gt; parent = t.parent; //将right的左子节点赋给t的右子节点 t.right = right.left; if (t.right != null) &#123; t.right.parent = t; &#125; //将t变为right的左子节点 right.left = t; t.parent = right; right.parent = parent; if (parent == null) &#123; root = right; &#125; else if (parent.left == t) &#123; parent.left = right; &#125; else &#123; parent.right = right; &#125; &#125; &#125; /** * 对节点t右旋 * * @param t */ private void RightRotate(RBNode&lt;T&gt; t) &#123; if (t != null) &#123; RBNode&lt;T&gt; left = t.left; RBNode&lt;T&gt; parent = t.parent; t.left = left.right; if (left.right != null) &#123; left.right.parent = t; &#125; left.right = t; t.parent = left; left.parent = parent; if (parent == null) &#123; root = left; &#125; else if (parent.left == t) &#123; parent.left = left; &#125; else &#123; parent.right = left; &#125; &#125; &#125; /** * 获取当前当前节点的父节点 * * @param t * @return */ private RBNode&lt;T&gt; getParent(RBNode&lt;T&gt; t) &#123; return (t == null) ? null : t.parent; &#125; /** * 获取当前节点的祖父节点 * * @param t * @return */ private RBNode&lt;T&gt; getGrandfather(RBNode&lt;T&gt; t) &#123; RBNode&lt;T&gt; father; if ((father = getParent(t)) != null) &#123; return getParent(getParent(t)); &#125; return null; &#125; /** * 插入节点 * * @param val */ public void insert(T val) &#123; //如果插入值为null，抛出异常 if (val == null) &#123; throw new IllegalStateException(); &#125; //如果当前RBTree为空，那么插入根节点 //颜色为黑，直接返回 if (root == null) &#123; root = new RBNode&lt;&gt;(val); root.color = false; &#125; //和二叉搜索树插入原理一样，找到合适的插入节点 int res; RBNode&lt;T&gt; temp = root; RBNode&lt;T&gt; current; res = val.compareTo(root.val); if (res &lt; 0) &#123; current = root.left; &#125; else if (res &gt; 0) &#123; current = root.right; &#125; else &#123; return; &#125; while (current != null) &#123; temp = current; res = val.compareTo(current.val); if (res &lt; 0) &#123; current = current.left; &#125; else if (res &gt; 0) &#123; current = current.right; &#125; else &#123; return; &#125; &#125; RBNode&lt;T&gt; newNode = new RBNode&lt;&gt;(val, temp, null, null); if (res &lt; 0) &#123; temp.left = newNode; &#125; else &#123; temp.right = newNode; &#125; //插入节点后，对RBTree进行调整 balance(newNode); &#125; private void balance(RBNode&lt;T&gt; t) &#123; //如果当前节点不为空，且不为根节点 //并且当前节点的父节点为红色，这时候需要调整 while (t != null &amp;&amp; t != root &amp;&amp; t.parent.color) &#123; //如果满足while条件，那么当前节点一定有祖父节点 //当前节点的父节点和祖父节点 RBNode&lt;T&gt; grandfather = getGrandfather(t); RBNode&lt;T&gt; father = getParent(t); //t的父节点是祖父节点的左子节点 if (grandfather.left == father) &#123; //叔叔节点 RBNode&lt;T&gt; uncle = grandfather.right; //如果叔叔节点存在且为红节点==&gt;直接变色 if (uncle != null &amp;&amp; uncle.color) &#123; grandfather.color = true; uncle.color = false; father.color = false; //继续向上调整 t = grandfather; &#125; //叔叔节点为空或为黑色==&gt;旋转+变色 else &#123; //三角形==&gt;左旋转换为直线型 if (t == father.right) &#123; t = father; LeftRotate(t);//执行完毕后，t仍为直线型中最低的节点 &#125; grandfather.color = true; t.parent.color = false; //对祖父节点右旋，完成调整 RightRotate(grandfather); &#125; &#125; //当前节点的父节点是祖父节点的右子节点 else &#123; //叔叔节点 RBNode&lt;T&gt; uncle = grandfather.left; //如果叔叔节点为红色==&gt;变色 if (uncle != null &amp;&amp; uncle.color) &#123; father.color = false; uncle.color = false; grandfather.color = true; //继续向上调整 t = grandfather; &#125; //叔叔节点为空或者是黑色 else &#123; //三角形，通过左旋转换为直线型 if (father.left == t) &#123; t = father; RightRotate(t);//执行完毕后，t仍为直线型中最低的节点 &#125; //直线型==&gt;右旋+变色 else &#123; grandfather.color = true; t.parent.color = false; //调整完毕 LeftRotate(grandfather); &#125; &#125; &#125; &#125; //根接待你永远为黑色 root.color = false; &#125;&#125; 红黑树的查询、遍历等操作和二叉搜索树完全一样，这里就不做赘述。上述代码亲测保证正确性。 参考本文参考一下文章：关于红黑树(R-B tree)原理，看这篇如何红黑树详细分析，看了都说好动画演示红黑树操作]]></content>
      <categories>
        <category>DataStructure</category>
      </categories>
      <tags>
        <tag>递归</tag>
        <tag>数据结构</tag>
        <tag>红黑树</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[为什么String是final的]]></title>
    <url>%2F2020%2F03%2F03%2F%E4%B8%BA%E4%BB%80%E4%B9%88String%E6%98%AFfinal%E7%9A%84%2F</url>
    <content type="text"><![CDATA[在实际开发中，开发者会用到大量的字符串，可以说我们无时无刻不在与字符串打交道。我们都知道String类是final修饰的，这意味着它不可被继承。但是如题：为什么String是final的？下面我们就探讨一下这个问题(基于JDK1.8版本)。 final关键字Java的关键字final通常指的是”这是无法改变的”，不想做出改变可能出于两种理由：设计和效率。final关键字可以修饰类、方法和数据。下面分别介绍final这三种用法各有什么作用 修饰数据 final修饰基本类型当final修饰一个基本类型数据时，这意味着该数据的值是不能被改变的。 123456//一个编译时常量，在编译时可以知道值public final int c=9//不是编译时常量public static Random rand=new Random(47)public final int c=rand.nextInt(29) final修饰引用类型当final修饰一个引用类型时，这意味着该引用不可变，但是引用指向的实例本身数据可以改变。 final修饰类的成员属性当final修饰类的成员属性时，必须在定义处赋值或在构造器中用表达式进行赋值。要确保该成员属性在使用前必须被初始化。 final修饰参数Java允许参数列表中以声明的方式指明参数未final，这在向匿名内部类传递数据时很有用，这里不是重点。 修饰方法Java中使用final方法的原因是处于设计的考虑：把一个方法锁定，防止任何继承类修改它的含义。即确保在继承中方法的行为不变，不会被子类重写。 final类如果一个类被定义为final，这意味着不能被继承。同时，这个类中所有的方法被隐式的指明为final方法，如果该类无法被继承，那么该类的方法自然也就不能被重写。 关于String类简单地介绍了一下final关键字，下面我们就来看看String类。 如图所示，String中用于保存数据的char数组也是final修饰的，那么这么做到底是什么原因？ 前面说过，final类意味着不可被继承，String类用final修饰是设计人员不希望客户端程序员继承String类并有可能重写其中的方法。使用String的最佳实践应该是关联或依赖而不是继承。String被定义为final主要从两个方面来考虑：安全和性能 final修饰char数组通过上面图我们可以看到，不仅String类被定义为final，该类的成员属性–char类型的数组也被定义为final。我们先说一说这个final char[]。我们在日常使用中，会有大量的字符串被轻易创建出来，这就涉及到一个很严重的问题：性能的开销。我们知道分配给JVM的内存是有限的，如果不加节制的创建字符串对象，那么弊端显而易见：内存迅速被占满，程序执行缓慢。于是Java设计者想到了一个非常好的解决方法：共享字符串。共享字符串对象的方法是将字符串对象放到JVM堆中(之前是在方法区)的字符串常量池中。不同的类、不同的方法甚至是不同的线程，可以使用同一个字符串，这样极大的降低了内存的损耗，提高了程序的运行效率。 因此我们说：字符串共享是解决内存损耗以及庞大的性能开销的必然选择。说了这么多，我们还没有解释为什么char数组要用final修饰。用final修饰的原因来自于字符串带来的问题：安全性问题。这里的安全性指的是线程安全性。 现在我们已经确定了一个前提：字符串共享。但是共享的问题在于：不同的线程可能会修改这个共享对象。 123例如：thread_1正在循环一个List，每个元素和&quot;abc进行比较&quot;同时thread_2也在使用&quot;abc&quot;这个对象，如果thread_2改变了这个共享字符串那么这将会造成thread_1的结果不可预测 并且通过查看String源码发现，String中的方法都避免了对char数组中的值进行改变，基本都是通过复制生成一个新数组然后返回一个新的String对象，这种做法保证了一个String对象一旦构造出来，那么它保存在char数组中的值就不会发生变化。保证了线程安全性 final修饰String类说完了final修饰char数组，现在来说一下为什么还要用final修饰类。在这里我也从安全性和性能两方面来说明 安全性前面一节说了，为了保证安全性，String内部的方法全都避免了对char数组进行修改的操作，但是如果String可以被继承，那么就意味着它的方法可以被子类重写。这太危险了，因为使用者完全可以在重写的方法中对char数组进行修改。之所以用final修饰String，是为了表明这个类是不可被继承的。确保使用使用String对象的代码是绝对安全的。 性能我们知道，多态是Java的三大特性之一。虚函数是实现多态的基础，什么是虚函数：可以定义一个父类的指针，指向一个子类的对象，当通过父类指针调用函数时，可以在运行时决定应该调用父类函数还是子类函数。大致过程是这样的：当通过父类指针调用一个方法时，JVM会在虚函数表中查找并判断究竟应该调用父类方法还是子类方法，甚至是调用哪个子类的方法。在大量使用字符串的情况下，会影响性能。(虚函数表相关知识不做赘述，《深入理解JVM虚拟机》P257) 总结用final修饰String和其内部保存数据的char数组，并且String内部的所有修改字符串的方法都会返回一个新的String而不是在原来的char数组上进行修改。这些设计保证了：一个String实例一旦创建，就不可被改变。一个不可变的对象一定是线程安全的。 性能方面：实现了字符串共享(常量池)，减少内存开销。避免了频繁创建和回收字符串带来的时间开销。 安全方面：String类不可被继承，确保了不会产生子类，防止因多态带来了安全隐患；并且还避免了查找虚函数表的时间开销。]]></content>
      <categories>
        <category>Java编程思想</category>
      </categories>
      <tags>
        <tag>面试</tag>
        <tag>String类</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[详解String.intern()方法]]></title>
    <url>%2F2020%2F03%2F02%2F%E8%AF%A6%E8%A7%A3String-intern-%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[最近又重新回顾了一下String的源码。对于其中的interrn()方法还是有点疑惑，因此特意上网再次查了一番，在这里做一下记录方便日后回顾。下面主要介绍一下String.intern()方法。这个方法还是非常有意思的，我们来看一看 到底有几个对象我们来看下面几条语句 123456789101. String str1=new String(&quot;Think In Java&quot;);=====================2. String str2=&quot;我爱学习&quot;;=====================3. String str3=&quot;a&quot;+&quot;b&quot;+&quot;c&quot;+&quot;d&quot;;=====================4. String str4=new String(&quot;a&quot;)+&quot;b&quot;; 你知道这些语句到底创建了几个对象么？我们来分析一下 String str1=new String(“Think In Java”);分情况而定： 如果常量池中没有”Think In Java”，那么会创建两个对象，一个位于常量池，一个位于堆中；并且str1指向堆中的实例。此时创建了两个对象 如果常量池已经存在了该字符串，那么只在堆中创建一个实例，str1指向堆中。此时创建了一个对象 String str2=”我爱学习”;一个对象，当使用””形式创建String实例时，会在字符串常量池中添加该实例，并且str2指向常量池。 String str3=”a”+”b”+”c”+”d”;一个对象。赋值符号右边的”a”、”b”、”c”、”d”、”e”都是常量。对于常量，编译时就直接存储它们的字面值而不是它们的引用，即在编译时就直接讲它们连接的结果提取出来变成了”abcde”。该语句在class文件中就相当于String s = “abcde”我们来看看字节码验证一下： 可以看到，常量池中只有一个字符串常量，那就是”abcde”。 String str4=new String(“a”)+”b”;一共创建了5个对象：其中”a”和”b”放在常量池中、还有一个”a”的实例在堆中、另外创建了一个StringBuilder对象，调用它的append()方法将字符串拼接起来，然后调用toString()方法生成一个新的字符串实例”ab”放在堆中，因此一共是5个对象。但是在JDK9之后情况不一样了(通过字节码发现的，此时没有创建StringBuilder实例，这里我也不清楚具体情况)。 关于intern()方法因为该方法在JDK1.7前后发生了变化，因此在本节我分不同版本的JDK进行介绍。 JDK1.7之前我们看下面两条语句 1234567String ps3 = new String(&quot;Something&quot;);String ps4 = ps3.intern();System.out.println(ps3==ps4);===============Output:false 我们来分析一下原因： 首先第一句分别在常量池和堆上创建了两个实例”Something”，并且ps3指向堆中实例 我们调用ps3.intern方法时，会这样做：首先检查常量池中是否有”Something”实例 如果有，那么直接返回常量池中该实例的引用 如果没有，则在常量池创建该实例，然后返回常量池中该实例的引用 在本例中，常量池中存在”Something”，因此，直接返回引用，此时ps4指向常量池中的”Something” 结论：在JDK1.7之前，调用intern方法时，会先检查常量池中是否存在该实例(调用者的实例)。如果存在，那么直接返回对常量池中该实例的引用；否则，现在常量池中创建该实例，然后再返回常量池中该实例的引用。 JDK1.7之后我们来看下面语句 1234567891011121314String str1 = new String(&quot;1&quot;)+new String(&quot;2&quot;);String str2 = &quot;12&quot;;str1.intern();System.out.println(str1==str2);Output:false==========================String str1 = new String(&quot;1&quot;)+new String(&quot;2&quot;);str1.intern();String str2 = &quot;12&quot;;System.out.println(str1==str2);Output:false 我们看到，上面两个演示，唯一的区别在于intern()方法执行的顺序不同，得到的结果也不同，这是为什么呢？我们来逐个分析 演示一 先不考虑str1的创建到底创建了几个对象，有一点很明确，此时常量池中没有”12”，str1指向堆中”12”实例 创建str2后，常量池中存在”12”实例，并且str2指向该实例 此时由于常量池中已经存在”12”，因此什么也不做，直接返回常量池中该实例的引用 此时str1指向堆中，str2指向常量池中，因此返回false 演示二 这条语句和演示一一样，此时常量池中没有”12”，str1指向堆中实例 这里很关键，调用instern()时，发现常量池中没有”12”，这时候做法和JDK1.7之前不同：它将堆中”12”的引用放到常量池中(不是在常量池中创建一个实例了)。 由于常量池中已经存在”12”(确切的说是存在指向”12”的引用)，所以直接返回该引用。 通过第三步可以发现，此时str1和str2实际上指向同一个对象，即位于堆中的”12”实例。 总结：在JDK1.7之后调用instern()方法，会先检查常量池中是否存在该实例(调用者的实例)。如果存在，那么直接返回对常量池中该实例的引用；否则，而是生成一个指向堆中该对象的引用在常量池中。 总结 jdk1.7之前，如果常量池中存在”12”字符串，则返回常量池中”12”字符串的引用；否则，就将”12”字符串添加到常量池，并返回常量池中”12”字符串的引用。 jdk1.7及之后版本，如果常量池中存在”12”字符串，则返回常量池中”12”字符串的引用(如果常量池中存的是”12”字符串的引用，则返回该引用)。否则，就将Java堆中”12”字符串的引用添加到常量中，并返回该引用。 参考文章：java String的intern方法java.lang.String中intern方法的作用]]></content>
      <categories>
        <category>JDK源码</category>
      </categories>
      <tags>
        <tag>源码</tag>
        <tag>面试</tag>
        <tag>String类</tag>
        <tag>interrn</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅谈MySQL索引使用]]></title>
    <url>%2F2020%2F03%2F01%2F%E6%B5%85%E8%B0%88MySQL%E7%B4%A2%E5%BC%95%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[在前面一篇我们对MySQL InnoDB/MyISAM 存储引擎索引的实现原理进行了简单的介绍。今天我们就来实际的介绍一下MySQL中索引的种类、不同的索引如何创建使用以及如何让索引发挥更大的作用(优化策略)。本文所有实验演示全部基于Win10环境下MySQL5.5版本(InnoDB)。 MySQL索引的分类索引是在存储引擎中实现的，也就是说不同的存储引擎，会使用不同的索引。MyISAM和InnoDB存储引擎只支持BTREE索引，也就是说默认使用BTREE(虽然说是BTree，但实际上使用的是B+Tree结构，这点要注意)。总体来说，MySQL中索引分为一下几种： 普通索引最简单的索引，对索引列没有任何要求 唯一索引该索引要求索引列必须唯一，但索引列可以存在空值 主键索引顾名思义，在主键列上的索引，要求非空且唯一 组合索引指多个字段上创建的索引 全文索引全文索引，只有在MyISAM引擎上才能使用，只能在CHAR,VARCHAR,TEXT类型字段上使用全文索引 空间索引(了解) MySQL中的索引大概就是这些，其中只有主键索引是聚簇索引。在介绍索引的创建和使用时主要介绍前四种索引。 MySQL索引的创建和删除其实对于不同的索引，创建的方式大同小异，创建的时间也分为几种：创建表时直接创建索引，创建表后添加索引以及删除索引。下面我们创建Index_test表，并以Index_text表为例进行演示。 12345CREATE TABLE Index_test( ID INT PRIMARY KEY, name VARCHAR(16) NOT NULL, count INT); 在介绍如何创建索引之前，先看一条SQL语句 1SHOW INDEX FROM 表名; 该SQL语句能够查看表中已创建的所有索引。介绍这条语句是为了方便我们在测试时能够随时查看索引创建情况。 CREATE方式创建这是最直接的创建方式，用于表创建之后添加索引，格式为 12CREATE [UNIQUE|FULLTEXT|SPATIAL] INDEX [索引名称] ON 表名(字段名) [USING 索引方法]； 我们解释一下各个字段含义 UNIQUE:表示该索引是唯一索引。 FULLTEXT:表示该索引是全文索引。 SPATIAL:表示该索引是空间索引。 MySQL默认的索引方法为B+Tree。并且InnoDB和MyISAM也只能用B+Tree。 在count列上创建普通索引12CREATE INDEX index_count ON Index_test(count); 如图所示，可以看到我们创建的索引。其Non_unique=1，说明不是唯一的；其NULL=YES，说明可以有空值。 在count列上创建非空索引123我们先将count列上原来的索引删除(删除语句后面说)CREATE UNIQUE INDEX index_count ON Index_test(count); 如图所示，可以看到我们创建的索引。其Non_unique=0，说明是唯一索引；其NULL=YES，说明可以有空值。 主键索引对于主键索引，InnoDB会在创建表时自动在主键上创建该索引。如果创建表时没有定义主键，则InnoDB选择第一个唯一非空的列作为主键并在其上创建主键索引；否则，InnoDB添加一个6字节大小的自增主键(该列称为ROWID)并在其上创建主键索引。在本例中，我们指定ID为主键，因此InnoDB在ID列上创建了主键索引。 在(name,count)列上创建联合索引 12CREATE INDEX index_count ON Index_test(name,count); 如图，我们创建了一个联合索引，由于创建表示约束了name列非空，因此索引中name也不能为NULL。联合索引中列的顺序对索引的性能影响很大，后面我们会说到。 ALTER方式创建除了以CREATE的方式直接创建以外，我们还可以使用ALTER操作，以修改表的方式创建索引，其语法格式如下。 123ALTER TABLE 表名 ADD [UNIQUE|FULLTEXT|SPATIAL] INDEX|KEY [索引名] (字段名1[(长度)] [ASC|DESC]) [USING 索引方法]； 如图，除了创建方式不同以外，创建出来的索引没有任何区别，对于其他索引也一样，这里就不做演示。 创建表时添加索引我们可以在创建表时直接给相应的列添加索引 1234567CREATE TABLE 表名( 字段名 数据类型 [完整性约束条件], ...... [UNIQUE|FULLTEXT|SPATIAL] INDEX|KEY [索引名](字段名1[(长度)] [ASC|DESC]) [USING 索引方法]); 同样的，创建出来的索引没有什么不同，这里不做演示。 删除索引删除索引也有两种方式，其实和创建很类似，可以对比记忆 1234567使用DROP直接删除DROP INDEX 索引名 ON 表名============================使用ALTER以修改表的方式删除ALTER TABLE 表名 DROP INDEX 索引名 这里只演示其中一种即可，我们来使用DROP直接删除索引，如图所示： 索引的优缺点及使用原则了解了如何创建/删除索引，那么我们再来看看索引的优点和缺点，从而进一步学习索引的使用原则：即什么时候创建索引、在哪些列上创建索引以及什么时候不能使用索引等等。 索引的优点其实这个问题的答案在前面一篇MySQL索引的实现原理已经提到，索引的优点主要有三 索引大大减少了存储引擎需要扫描的数据量 索引可以帮助我们进行排序以避免使用临时表 索引可以把随机I/O变为顺序I/O，大大减少I/O次数，提升插叙速度 MySQL中，所有的字段类型都可以被索引，即可以给任意字段设置索引 索引的缺点任何事务都是有两面性的，索引也不例外，索引有这么多的优点，它自然也有一些缺点，其缺点主要有三 创建索引和维护索引要耗费时间，并且随着数据量的增加所耗费的时间也会增加 索引也是数据，也需要占空间。我们知道数据表中的数据也会有最大上线设置的，如果我们有大量的索引，索引文件可能会比数据文件更快达到上线值 当对表中的数据进行增加、删除、修改时，索引也需要动态的维护，降低了数据的维护速度 知道了索引的优缺点后，在下面一节将介绍一些索引的使用原则。即什么时候使用索引，什么时候不该使用索引。 索引使用原则 定义有主键的列一定要建立索引(InnoDB自动实现)。因为主键可以加速定位到表中的某行。 定义有外键的列一定要建立索引。外键列通常用于表与表之间的连接，在其上创建索引可以加快表间的连接。 对经常查询的数据列最好建立索引。 对于需要在指定范围内快速或频繁查询的数据列，因为索引已经排序，其指定的范围是连续的，查询可以利用索引的排序，加快查询的时间。 经常用在where子句中的数据列，将索引建立在where子句的集合过程中，对于需要加速或频繁检索的数据列，可以让这些经常参与查询的数据列按照索引的排序进行查询，加快查询的时间。 对经常更新的表就避免对其进行过多的索引。因为表的更新会导致索引结构的变化，系统维护索引需要耗费时间。 数据量小的表最好不要使用索引。因为由于数据较少，可能查询全部数据花费的时间比遍历索引的时间还要短，索引就可能不会产生优化效果。 在不同值少的列上(字段上)不要建立索引，比如在学生表的”性别”字段上只有男，女两个不同值。相反的，在一个字段上不同值较多可以建立索引。 索引的使用远不止这些，这里只是简单地总结几点。要想用好索引，最好是通过实际应用来学习，由于我是在校生，所以只能到这里了… 最左前缀原理与相关优化EXPLAIN的使用在开始这部分内容之前，需要再补充一条SQL语句，用好了它对于我们查看索引的使用大有裨益。 12EXPLAIN SELECT ....即在SELECT语句之前添加EXPLAIN字段 使用EXPLAIN关键字可以模拟优化器执行SQL查询语句，从而知道MySQL是如何处理你的SQL语句的。对于EXPLAIN的使用这里不是重点，因此不做赘述。如果你还不了解，文末EXPLAIN的学习博客链接。 组合索引MySQL中的索引可以以一定顺序引用多个列，这种索引叫做组合索引。一个联合索引是一个有序元组，其中各个元素均为数据表的一列。 创建一个组合索引index(rol1,rol2,rol3)，相等于创建了三个索引：index(rol1)，index(rol1,rol2)，index(rol1,rol2,rol3)。 选择列的顺序前面说了，使用组合索引时列的顺序对至关重要，那么如何选择列的顺序呢？原则有三 经常被用到的列优先 选择性高的列优先 宽度小的列优先 覆盖索引(Covering Indexes)索引包含满足查询的所有列(SELECT 后面跟的列)。只需要读取索引而不用读取数据，大大提高查询性能。 索引项通常比记录要小，使得MySQL访问更少的数据 索引都按值排序存储，相对于随机访问记录，需要更少的I/O 大多数据引擎能更好的缓存索引，比如MyISAM只缓存索引。这样如果使用了覆盖索引，那么就能避免MyISAM表进行系统调用。 覆盖索引对于InnoDB表尤其有用，因为InnoDB使用聚集索引组织数据，如果二级索引中包含查询所需的数据，就不再需要在聚集索引中查找了。 覆盖索引不能是任何索引，只有B-TREE索引存储相应的值。并且并不是所有存储引擎都实现了覆盖索引 索引覆盖查询(index-covered query)，使用EXPLAIN时可以在Extra列中看到Using index。记住这点，后面再演示的时候你会看到什么情况下会使用覆盖索引。 不能使用覆盖索引的情况： 存储引擎不支持覆盖索引 查询中使用了太多的列，如果有一个列不在索引中，就不能使用覆盖索引 使用了双%的模糊查询 实战测试我们创建一张表，下面的所有实验都基于该表进行。 1234567 CREATE TABLE titles( emp_no INT, title VARCHAR(50), from_date DATE, to_date DATE, PRIMARY KEY(emp_no,title,from_date)); 我们来看看这张表上有几个索引如图，由于该表包含一个联合主键，因此该表的主索引是一个组合索引。 覆盖索引测试为了更好的进行演示，我们在from_date列上创建一个辅助索引，如图所示： 我们知道，InnoDB中辅助索引存储的是主键的值，那么只要我们要查询的列在(emp_no,title,from_date)之间，就会使用到覆盖索引。 可以看到，Extra中Using Index，使用到了覆盖索引 在这里，要查询的列包括to_date，因此需要回表查数据，此时不能使用覆盖索引。Extra中是Using Where 全值匹配 当按照索引中所有列进行精确匹配（这里精确匹配指“=”或“IN”匹配）时，索引可以被用到。&lt;/b这里有一点需要注意，理论上索引对顺序是敏感的，但是由于MySQL的查询优化器会自动调整where子句的条件顺序以使用适合的索引，例如我们将where中的条件顺序颠倒： 效果是一样的 最左前缀匹配 当查询条件精确匹配索引的左边连续一个或几个列时，如或&lt;emp_no, title&gt;，所以可以被用到，但是只能用到一部分，即条件所组成的最左前缀。上面的查询从分析结果看用到了PRIMARY索引，但是key_len为4，说明只用到了索引的第一列前缀。 精确匹配中间缺少条件 此时索引使用情况和情况二相同，因为title未提供，所以查询只用到了索引的第一列，而后面的from_date虽然也在索引中，但是由于title不存在而无法和左前缀连接，因此虽然使用到了索引，但需要对结果进行扫描过滤from_date(这里由于emp_no唯一，所以不存在扫描)。 查询条件未指定索引首列 不是最左前缀，因此不会用到索引 匹配某列的前缀字符串 此时可以用到索引原，如果通配符%不出现在开头，则可以用到索引，但根据具体情况不同可能只会用其中一个前缀 范围查询 由于B+树的顺序特点,尤其适合此类查询。范围列可以用到索引(必须是最左前缀)，但是范围列后面的列无法用到索引。同时，索引最多用于一个范围列，因此如果查询条件中有两个范围列则无法全用到索引。 查询条件中含有函数或表达式 如果查询条件中含有函数或表达式，则MySQL不会为这列使用索引。虽然图中所示的两个查询的效果是一样的，但是对于第一个查询，不会使用emp_no上的索引。 B+Tree索引限制 如果不是按照索引最左列开始查找，无法使用索引 使用索引时不能跳过中间的列 Not IN和&lt;&gt;操作无法使用索引 如果查询中有某个列的范围查询，那么其右边所有的列都无法使用索引 OR语句前后没有同时使用索引 以%开头的模糊查询 InnoDB的主键选择与插入优化使用InnoDB存储引擎时，如果没有特别的需要，请永远使用一个与业务无关的自增字段作为主键。 InnoDB使用聚集索引，数据记录本身被存于主索引（一颗B+Tree）的叶子节点上。这就要求同一个叶子节点内(大小为一个内存页或磁盘页)的各条数据记录按主键顺序存放。因此每当有一条新的记录插入时，MySQL会根据其主键将其插入适当的节点和位置，如果页面达到装载因子(InnoDB默认为15/16)，则开辟一个新的页(节点)。如果表使用自增主键，那么每次插入新的记录，记录就会顺序添加到当前索引节点的后续位置，当一页写满，就会自动开辟一个新的页。如下图所示： 这样就会形成一个紧凑的索引结构，近似顺序填满。由于每次插入时也不需要移动已有数据，因此效率很高，也不会增加很多开销在维护索引上。 如果使用非自增主键（如果身份证号或学号等），由于每次插入主键的值近似于随机，因此每次新纪录都要被插到现有索引页得中间某个位置：此时MySQL不得不为了将新记录插到合适位置而移动数据，甚至目标页面可能已经被回写到磁盘上而从缓存中清掉，此时又要从磁盘上读回来，这增加了很多开销，同时频繁的移动、分页操作造成了大量的碎片，得到了不够紧凑的索引结构，后续不得不通过OPTIMIZE TABLE来重建表并优化填充页面。 所以说，如果可以，请尽量在InnoDB上采用自增字段做主键。 参考文章本文参考借鉴了一下几篇博客：MySQL索引及其实现原理(基于MyISAM及InnoDB引擎)MySQL索引的创建与使用MySQL高级-EXPLAIN用法和结果分析回表查询的说明mysql覆盖索引与回表]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>MySQL</tag>
        <tag>索引</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL索引及其实现原理]]></title>
    <url>%2F2020%2F02%2F29%2FMySQL%E7%B4%A2%E5%BC%95%E5%8F%8A%E5%85%B6%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[前面在介绍MySQL加锁处理的时候，多次的提到了索引，也简单地对MySQL InnoDB的索引进行了介绍，索引在数据库中有着至关重要的作用，通过索引能够大大提高我们的查询速度。那么索引到底是什么？今天我们就对索引进行详细的介绍。 数据结构和算法基础在介绍索引之前，我们先介绍两种基本的数据结构：B树和B+树结构 索引的本质官方对索引的定义为：索引(Index)是帮助MySQL高效获取数据的数据结构。因此索引本质上是一种数据结构。 查询是数据库的最主要功能之一。我们都希望查询速度能尽可能快，因此数据库系统的设计者会从查询算法角度优化。最基本的查询算法当然是顺序查找(linear search)，这种复杂度为O(n)的算法在数据量很大时显然是糟糕的。好在CS的发展提供了很多更优秀的查找算法，如二分查找(binary search)、二叉树查找(binary tree search)等。稍微分析一下会发现，每种查找算法都只能应用于特定数据结构之上，如二分查找要求被检索数据有序，而二叉树查找只能应用于二叉查找树，但数据本身的组织结构不可能完全满足各种数据结构（例如，理论上不可能同时将两列都按顺序进行组织）。所以，在数据之外，数据库系统还维护着满足特定查找算法的数据结构，这些数据结构以某种方式引用（指向）数据，这样就可以在这些数据结构上实现高级查找算法。这种ADT，就是索引。图1展示了一种可能的索引方式：左边是数据表，一共有两列14条记录，最左边是数据记录的物理地址（注意逻辑上相邻的记录在磁盘上并不一定物理相邻）。为加快Col2的查找，可维护一个右边所示二叉查找树，每个节点分别包含索引键值及一个指向对应数据记录物理地址的指针，这样就可以运用二叉查找在O(log2 N)内取到相应数据。虽然这是一个货真价实的索引，但实际数据库系统几乎没有使用二叉查找树或其进化品种红黑树（red-black tree）实现 B树和B+树目前大多数数据库和文件系统都采用B树及其变种B+树作为索引结构。 B-树我们定义一条数据库记录为(key,data)的二元组 key：记录的键值，不同的记录key不同 data：该条记录中除了key以外的部分 对于一棵n阶B-树，它有如下性质 根节点除非整棵树只有一个节点，否则根节点的指针数在区间[2,n] 非叶节点key的数目在[(n-1)/2(取上界),n-1]之间，指针数目在[n/2(取上界),n]之间。每个key同时对应一个data。 叶节点和非叶节点的结构相同，不过叶节点指针均为null 如果某个指针在节点node最左边且不为null，则其指向节点的所有key小于v(key1),v(key1)为node的第一个key的值 如果某个指针在节点node最右边且不为null，则其指向节点的所有key大于v(keym),v(keym)为node的最后一个key的值。 如果某个指针在节点node的左右相邻key分别是keyi,keyi+1且不为null，则其指向节点的所有key小于v(keyi+1)且大于v(keyi) 对于概念可能比较陌生，我们来看图 B+树B+树是B树的变种，和B树相比主要有一下几点不同 对于B-树，每个节点指针数=key的数量+1；而B+树不同，B+树的每个节点，节点指针数=key的数量。 非叶节点不存储数据，只存储key值和指针。数据只存储在叶节点中 如图所示，一颗3阶B+树。可以看到数据只存储在叶节点中。 并且数据库实现时对B+树做了进一步的优化，得到了顺序B+树如图：在B+Tree的每个叶节点增加一个指向相邻叶节点指针，形成带有顺序访问指针的B+Tree。此优化的目的是提高区间访问的性能，例如图4中如果要查询key为从18到49的所有数据记录，当找到18后，只需顺着节点和指针顺序遍历就可以一次性访问到所有数据节点，极大提高了区间查询效率 计算机硬件知识红黑树也可用来实现索引，但是文件系统及数据库系统普遍采用B/+Tree。这是为什么？ 一般来说，索引本身也很大，不可能全存内存，往往以索引文件的形式存在磁盘。索引查找过程中就要产生磁盘I/O消耗，相对于内存存取，I/O存取的消耗要高几个数量级，所以评价一个数据结构作为索引的优劣最重要的指标就是在查找过程中磁盘I/O操作次数的渐进复杂度。换句话说，索引的结构组织要尽量减少查找过程中磁盘I/O的存取次数。 主存存取原理我们知道，计算机使用的主存一般为随机读写存储器(RAM)。这里抛却具体差别，抽象出一个十分简单的存取模型来说明RAM的工作原理从抽象角度看，主存是一系列的存储单元组成的矩阵，每个存储单元存储固定大小的数据。每个存储单元有唯一的地址，现代主存的编址规则比较复杂，这里将其简化成一个二维地址：通过一个行地址和一个列地址可以唯一定位到一个存储单元存取过程当系统需要读取主存时，将地址信号通过地址总线传给主存，主存读到地址信号后，解析信号并定位到指定存储单元，然后将此存储单元数据放到数据总线，供其它部件读取写主存的过程类似，系统将要写入单元地址和数据分别放在地址总线和数据总线上，主存读取两个总线的内容，做相应的写操作这里可以看出，主存存取的时间仅与存取次数呈线性关系，因为不存在机械操作，两次存取的数据的“距离”不会对时间有任何影响。例如，先取A0再取A1和先取A0再取D3的时间消耗是一样的。 磁盘存储原理上文说过，索引一般以文件形式存储在磁盘上，索引检索需要磁盘I/O。对于主存来说，”距离”不会对存储时间产生影响，但是对于磁盘来说并非如此。与主存不同，磁盘I/O存在机械消耗，因此磁盘I/O时间消耗巨大磁盘的整体结构示意图磁盘由大小相同且同轴的圆形盘片组成，磁盘可以转动（各磁盘必须同步转动）。在磁盘的一侧有磁头支架，磁头支架固定了一组磁头，每个磁头负责存取一个磁盘的内容。磁头不能转动，但是可以沿磁盘半径方向运动（实际是斜切向运动），每个磁头同一时刻也必须是同轴的，即从正上方向下看，所有磁头任何时候都是重叠的（不过目前已经有多磁头独立技术，可不受此限制）。磁盘结构的示意图盘片被划分成一系列同心环，圆心是盘片中心，每个同心环叫做一个磁道，所有半径相同的磁道组成一个柱面。磁道被沿半径线划分成一个个小的段，每个段叫做一个扇区，每个扇区是磁盘的最小存储单元。为了简单起见，我们下面假设磁盘只有一个盘片和一个磁头。当需要从磁盘读取数据时，系统会将数据逻辑地址传给磁盘，磁盘的控制电路按照寻址逻辑将逻辑地址翻译成物理地址，即确定要读的数据在哪个磁道，哪个扇区。为了读取这个扇区的数据，需要将磁头放到这个扇区上方，为了实现这一点，磁头需要移动对准相应磁道，这个过程叫做寻道，所耗费时间叫做寻道时间，然后磁盘旋转将目标扇区旋转到磁头下，这个过程耗费的时间叫做旋转时间。 局部性原理与磁盘预读由于存储介质特性，磁盘本身存取就比主存慢，再加上机械运动耗费，磁盘的存取速度往往是主存的几百万分之一，因此为了提高效率，要尽量减少磁盘I/O。为了达到这个目的，磁盘往往不是严格按需读取，而是每次都会预读。即使只需要一个字节，磁盘也会从这个位置开始，顺序向后读取一定长度的数据放入内存。这样做的理论依据是计算机科学中著名的局部性原理：当一个数据被用到时，其附近的数据也通常会马上被使用。程序运行期间所需要的数据通常比较集中由于磁盘顺序读取的效率很高（不需要寻道时间，只需很少的旋转时间），因此对于具有局部性的程序来说，预读可以提高I/O效率。预读的长度一般为页（page）的整数倍。页是存储器的逻辑块，操作系统往往将主存和磁盘存储区分割为连续的大小相等的块，每个存储块称为一页（在许多操作系统中，页大小通常为4k），主存和磁盘以页为单位交换数据。当程序要读取的数据不在主存中时，会触发一个缺页异常，此时系统会向磁盘发出读盘信号，磁盘会找到数据的起始位置并向后连续读取一页或几页载入内存中，然后异常返回，程序继续运行 B/B+树性能分析到这里终于可以分析B-/+Tree索引的性能了。上文说过一般使用磁盘I/O次数评价索引结构的优劣。 先分析B-Tree根据B-Tree的定义，可知检索一次最多需要访问h个节点(h为树的高度)。数据库系统的设计者巧妙利用了磁盘预读原理，将一个节点的大小设为等于一个页，这样每个节点只需要一次I/O就可以完全载入。为了达到这个目的，在实际实现B-Tree还需要使用如下技巧：每次新建节点时，直接申请一个页的空间，这样就保证一个节点物理上也存储在一个页里，加之计算机存储分配都是按页对齐的，就实现了一个node只需一次I/O。B-Tree中一次检索最多需要h-1次I/O(根节点常驻内存)，渐进复杂度为O(h)=O(lognN)(N为总记录数)。一般实际应用中，出度n(指针数)是非常大的数字，通常超过100，因此h非常小(通常不超过3)。综上所述，用B-Tree作为索引结构效率是非常高的。 为什么不使用红黑树我们知道红黑树的出度d最大为2，因此对于相同数量的数据，红黑树h明显要深的多。由于逻辑上很近的节点（父子）物理上可能很远，无法利用局部性，所以红黑树的I/O渐进复杂度也为O(h)，效率明显比B-Tree差很多。 为什么使用B+树而不是B树通过前面这么多的介绍，这个问题应该很好回答，主要有三点： B+树的磁盘读写代价更低：前面说过，B+树的非叶节点不存储data域，因此对于一个节点(页)，B+树比B树存储的key更多，这就意味着B+树的非叶节点的出度更多。进行一次I/O能够获得更多的信息，从而减少I/O次数。 B+树的查询效率更加稳定：由于所有数据都存于叶子节点。所有关键字查询的路径长度相同，每一个数据的查询效率相当。 B树在提高了IO性能的同时并没有解决元素遍历效率低下的问题，正是为了解决这个问题，B+树应用而生。B+树只需要去遍历叶子节点就可以实现整棵树的遍历。 这一章从理论角度讨论了与索引相关的数据结构与算法问题，下一章将讨论B+Tree是如何具体实现为MySQL中索引，同时将结合MyISAM和InnDB存储引擎介绍非聚集索引和聚集索引两种不同的索引实现形式。 MyISAM引擎索引实现MyISAM引擎使用B+Tree作为索引结构，叶节点data域存放数据记录的地址。 主索引(聚簇索引)MyISAM主索引的原理图设Col1为主键，则图8是一个MyISAM表的主索引（Primary key）示例。可以看出MyISAM的索引文件仅仅保存数据记录的地址。 辅助索引在MyISAM中，主索引和辅索引(Secondary key)在结构上没有任何区别，只是主索引要求key是唯一的，而辅索引的key可以重复。如果我们在Col2上建立一个辅索引，则此索引的结构如下图所示：如图：同样也是一颗B+Tree，data域保存数据记录的地址 MyISAM中索引检索的算法首先按照B+Tree搜索算法搜索索引，如果指定的Key存在，则取出其data域的值，然后以data域的值为地址，读取相应数据记录。 InnoDB引擎索引实现虽然InnoDB也使用B+Tree作为索引结构，但具体实现方式却与MyISAM截然不同。一个重大区别是InnoDB的数据文件本身就是索引文件。通过上面的介绍，我们知道： MyISAM索引文件和数据文件是分离的，索引文件仅保存数据记录的地址 在InnoDB中，表数据文件本身就是按B+Tree组织的一个索引结构，这棵树的叶节点data域保存了完整的数据记录。这个索引的key是数据表的主键，InnoDB表数据文件本身就是主索引 主索引(辅助索引)InnoDB主索引(同时也是数据文件)的示意图可以看到叶节点包含了完整的数据记录，这种索引叫做聚集索引。因为InnoDB的数据文件本身要按主键聚集，所以InnoDB要求表必须有主键(MyISAM可以没有)，如果没有显式指定，则MySQL系统会自动选择一个唯一非空列作为主键，如果不存在这种列，则MySQL自动为InnoDB表生成一个隐含字段作为主键，这个字段长度为6个字节，类型为长整形。 辅助索引InnoDB的辅助索引和MyISAM也不一样。InnoDB的辅索引data域存储相应记录主键的值而不是地址。换句话说，InnoDB的所有辅助索引都引用主键作为data域。并且当我们创建表时，InnoDB会自动为表中的唯一列(unique约束)创建唯一索引聚集索引这种实现方式使得按主键的搜索十分高效，但是辅助索引搜索需要检索两遍索引：首先检索辅助索引获得主键，然后用主键到主索引中检索获得记录。 总结了解不同存储引擎的索引实现方式对于正确使用和优化索引都非常有帮助。例如 知道了InnoDB的索引实现后，就很容易明白为什么不建议使用过长的字段作为主键，因为所有辅索引都引用主索引，过长的主索引会令辅索引变得过大。 非单调(varchar等)的字段作为主键在InnoDB中不是个好主意，因为InnoDB数据文件本身是一颗B+Tree，非单调的主键会造成在插入新记录时数据文件为了维持B+Tree的特性而频繁的分裂调整，十分低效，而使用自增字段作为主键则是一个很好的选择 今天的学习就到这里，对于索引的使用和索引的优化我会另写一篇文章 参考书籍：《数据库系统概念》一文搞懂MySQL索引MySQL索引及其实现原理(基于MyISAM及InnoDB引擎)]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>MySQL</tag>
        <tag>索引</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[详解MySQL加锁处理]]></title>
    <url>%2F2020%2F02%2F29%2F%E8%AF%A6%E8%A7%A3MySQL%E5%8A%A0%E9%94%81%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[在前面的文章中，对MySQL的MVCC机制进行了介绍，我们知道MVCC的特点就是读不加锁写加锁，实现了读写分离，那么今天就来介绍一下MySQL在并发控制中的加锁处理，理解这一点对于我们编写高效的SQL语句和处理死锁情况尤为重要。本文基于Win10环境下MySQL5.5版本/InnoDB存储引擎。 MVCC回顾MySQL InnoDB存储引擎，实现的是基于多版本并发控制协议MVCC(与MVCC相对的是基于锁的并发控制协议)。MVCC最大的好处，相信也是耳熟能详：读不加锁，读写不冲突。在读多写少的OLTP应用中，读写不冲突是非常重要的，极大的增加了系统的并发性能，这也是为什么现阶段，几乎所有的RDBMS，都支持了MVCC。 在MVCC并发控制中，读操作可以分成两类：快照读(snapshot read)与当前读(current read)。快照读：读取的是记录的可见版本(有可能是历史版本)，不用加锁。当前读：读取的是记录的最新版本，并且，当前读返回的记录，都会加上锁，保证其他事务不会再并发修改这条记录。 在一个支持MVCC并发控制的系统中，哪些读操作是快照读？哪些操作又是当前读呢？以MySQL InnoDB为例： 快照读简单的select操作，属于快照读，不加锁。(在SERIALIZABLE下情况有所不同，后面会说) 1SELECT * FROM table where ? 当前读特殊的读操作，插入/更新/删除操作，属于当前读，需要加锁。 12345select * from table where ? lock in share mode;select * from table where ? for update;insert into table values (…);update table set ? where ?;delete from table where ?; 除了第一条SQL加S锁以外，其他都加X锁 为什么将 插入/更新/删除 操作，都归为当前读？可以看看下面这个 更新 操作，在数据库中的执行流程： 从图中，可以看到，一个Update操作的具体流程：当Update SQL被发给MySQL后，MySQL Server会根据where条件，读取第一条满足条件的记录，然后InnoDB引擎会将第一条记录返回，并加锁 (current read)。待MySQL Server收到这条加锁的记录之后，会再发起一个Update请求，更新这条记录。一条记录操作完成，再读取下一条记录，直至没有满足条件的记录为止。因此，Update操作内部，就包含了一个当前读。同理，Delete操作也一样。Insert操作会稍微有些不同，简单来说，就是Insert操作可能会触发Unique Key的冲突检查，也会进行一个当前读。 注：根据上图的交互，针对一条当前读的SQL语句，InnoDB与MySQL Server的交互，是一条一条进行的，因此，加锁也是一条一条进行的。先对一条满足条件的记录加锁，返回给MySQL Server，做一些DML操作；然后在读取下一条加锁，直至读取完毕。 Cluster Index-聚簇索引MySQL InnoDB引擎使用的是B+树索引，InnoDB实现方式是这样的：表数据文件本身就是按B+Tree组织的一个索引结构，这棵树的叶节点data域保存了完整的数据记录。这个索引的key是数据表的主键，因此InnoDB表数据文件本身就是主索引，所以加锁锁的也是索引。对于辅助索引，也是B+树结构，辅助索引的data域存储的是主键的值。聚集索引这种实现方式使得按主键的搜索十分高效，但是辅助索引搜索需要检索两遍索引：首先检索辅助索引获得主键，然后用主键到主索引中检索获得记录。(对于本文来说，索引理解到这里就够了，但是对于索引的学习是远远不够的，我会另开博客进行介绍) 2PL-两阶段封锁协议这个在前面介绍过，2PL比较容易理解，说的是锁操作分为两个阶段：加锁阶段与解锁阶段，并且保证加锁阶段与解锁阶段不相交。但是MySQL在实际应用时为了提高性能，有时可能会违反2PL协议，后面会说。 Isolation Level隔离级别，前面也介绍过，这里简单提一下MySQL/InnoDB定义的4种隔离级别： Read Uncommited可以读取未提交记录。此隔离级别，基本不会使用，忽略。 Read Committed(RC)快照读前面介绍过，本文不考虑。针对当前读，RC隔离级别保证对读取到的记录加锁 (记录锁)，存在幻读现象。 Repeatable Read(RR)快照读本文不考虑。针对当前读，RR隔离级别保证对读取到的记录加锁 (记录锁)，同时保证对读取的范围加锁，新的满足查询条件的记录不能够插入 (间隙锁)，不存在幻读现象。 Serializable从MVCC并发控制退化为基于锁的并发控制。不区别快照读与当前读，所有的读操作均为当前读，读加读锁 (S锁)，写加写锁 (X锁)。Serializable隔离级别下，读写冲突，因此并发度急剧下降，在MySQL/InnoDB下不建议使用。 一条简单SQL是加锁分析12SQL1：select * from t1 where id = 10;SQL2：delete from t1 where id = 10; 对于上面两条SQL语句，如果你问我分别加什么锁，那么我可能会说： 12SQL1：不加锁，因为MVCC实现了快照读SQL2：加对id=10这条记录加记录锁(行级锁)，走主键索引。 但是这样说对么？可能对也可能不对。因为已知条件不足，这样问问题的无异于耍流氓。在不同的条件下加锁情况是不一样的。那么可能需要哪些条件呢？ 前提一：id列是不是主键？ 前提二：当前系统的隔离级别是什么？ 前提三：id列如果不是主键，那么id列上有索引吗？ 前提四：id列上如果有二级索引，那么这个索引是唯一索引吗？ 前提五：两个SQL的执行计划是什么？索引扫描？全表扫描？ 没有这些条件，直接给一条SQL语句问我怎么加锁，那太不专业了。而有了这些条件，那么再来回答加锁情况，答案就显而易见了。下面我将分不同的隔离级别，对这些问题进行组合，然后看看MySQL分别加什么锁。 RC级别在该级别下，我们有四种组合 组合一：id列是主键 组合二：id列是二级唯一索引 组合三：id列是二级非唯一索引 组合四：id列上没有索引 对于这四种情况，SQL1语句全都是快照读不加锁，我们主要讨论SQL2。 id列是主键这个组合是最简单、最容易分析的组合。id是主键，Read Committed隔离级别，给定SQL：delete from t1 where id = 10; 只需要将主键上id = 10的记录加上X锁即可。结论：where中使用主键进行等值查询时，只需要对指定记录加行级X锁。 id列是二级唯一索引id不是主键，而是一个Unique的二级索引键值(唯一索引)。那么在RC隔离级别下，delete from t1 where id = 10; 需要加什么锁呢？注意：在InnoDB中索引都是B+树结构，这里为了方便简化了实际结构。此组合中，id是unique索引，而主键是name列。 由于id是unique索引，因此delete语句会选择走id列的索引进行where条件的过滤 在找到id=10的记录后，首先会将unique索引上的id=10索引记录加上X锁 同时，会根据读取到的name列，回主键索引(聚簇索引)，然后将聚簇索引上的name = ‘d’ 对应的主键索引项加X锁。 为什么聚簇索引上的记录也要加锁？试想一下，如果有一个并发的SQL语句，是通过主键索引来更新：update t1 set id = 100 where name = ‘d’; 此时，如果delete语句没有将主键索引上的记录加锁，那么并发的update就会感知不到delete语句的存在，违背了同一记录上的更新/删除需要串行执行的约束。 结论：where中使用唯一索引(辅助索引)进行等值查询时，需要对聚簇索引和辅助索引上的记录分别加锁，即加两次锁。 id列是二级非唯一索引id列上的约束又降低了，id列不再唯一，只有一个普通的索引。假设delete from t1 where id = 10; 语句，仍旧选择id列上的索引进行过滤where条件，那么此时会持有哪些锁？可以看到， id列索引上，满足id = 10查询条件的记录，均已加锁。 同时，这些记录对应的主键索引上的记录也都加上了锁。 结论：加锁步骤和唯一索引相同。区别在于：使用唯一索引时最多只有一个满足等值查询的记录，而使用普通索引时会将所有满足查询条件的记录都加锁。 id列上没有索引此时更加特殊，id列上没有索引。where id = 10;这个过滤条件就没法通过索引进行过滤，那么只能走全表扫描做过滤。对应于这个组合，SQL会加什么锁？或者是换句话说，全表扫描时，会加什么锁？ 由于id列上没有索引，因此只能走聚簇索引，进行全部扫描。从图中可以看到，满足删除条件的记录有两条，但是聚簇索引上所有的记录，都被加上了X锁。无论记录是否满足条件，全部被加上X锁。既不是加表锁，也不是在满足条件的记录上加行锁。 为什么不是只在满足条件的记录上加锁呢？这是由于MySQL的实现决定的。如果一个条件无法通过索引快速过滤，那么存储引擎层面就会将所有记录加锁后返回，然后由MySQL Server层进行过滤。因此也就把所有的记录，都锁上了。 MySQL的改进在实际的实现中，MySQL有一些改进：在MySQL Server过滤条件，发现不满足后，会调用unlock_row方法，把不满足条件的记录放锁 (违背了2PL的约束)。这样做，保证了最后只会持有满足条件记录上的锁，但是每条记录的加锁操作还是不能省略的。 结论：若id列上没有索引，SQL会走聚簇索引的全扫描进行过滤，由于过滤是由MySQL Server层面进行的。因此每条记录，无论是否满足条件，都会被加上X锁。但是，为了效率考量，MySQL做了优化，对于不满足条件的记录，会在判断后放锁；最终持有的是满足条件的记录上的锁，但是不满足条件的记录上的加锁/放锁动作不会省略。该优化违背了2PL的约束。 RR级别同样的，我们也介绍和RC一样的四种组合 组合一：id列是主键 组合二：id列是二级唯一索引 组合三：id列是二级非唯一索引 组合四：id列上没有索引 但是在介绍之前，需要介绍一种锁：间隙锁–Gap_Lock。这是RR级别防止幻读的关键锁。 Gap_Lock–间隙锁和记录锁(行级锁)不同，间隙锁锁的不是索引，而是索引之间的间隙。 123456789假设现在又有下列值1 3 5 8 9那么这些值之间的间隙有(-∞,1)(1,3)(3,5)(5,8)(8,9)(9,+∞) 间隙锁和记录锁组合称为Next-Key Lock(下一键锁)，该锁在RR级别下进行当前读时预防了幻行现象。(注：进行快照读时，MVCC本身能够预防幻行) id列是主键结论：在RR级别下，where条件使用主键进行等值查询时，加锁情况和RC级别一样。只对指定记录加记录锁(行级锁)。 id列是二级唯一索引结论：在RR级别下，使用唯一索引(辅助索引)进行等值查询时，加锁情况和RC级别一样。需要对聚簇索引和辅助索引上的记录分别加锁，即加两次锁。 id列是二级非唯一索引我们知道：RC隔离级别允许幻读，而RR隔离级别不允许存在幻读。但是在前面讲到的两种情况下，加锁行为又是与RC下的加锁行为完全一致。那么RR隔离级别下，如何防止幻读呢？在这种组合下我们将会用到间隙锁。 Repeatable Read隔离级别，id上有一个非唯一索引，执行delete from t1 where id = 10; 假设选择id列上的索引进行条件过滤，最后的加锁行为，是怎么样的呢？我们看到，和RC级别不同的是，RR级别在聚簇索引上不仅加了记录锁(行级锁)，还加上了前面介绍的间隙锁(Gap_Lock)。这样就能防止幻行了么？我们来详细分析一下 幻行解决原理分析所谓防止幻行：就是同一个事务，连续做两次当前读 (例如：select * from t1 where id = 10 for update;)，那么这两次当前读返回的是完全相同的记录 (记录数量一致，记录本身也一致)，第二次的当前读，不会比第一次返回更多的记录 (幻象)。 为了保证两次当前读返回一致的记录，那就需要在第一次当前读与第二次当前读之间，其他的事务不会插入新的满足条件的记录并提交。为了实现这个功能，GAP锁应运而生。从图中我们可以发现，由于B+树的有序性，当聚簇索引上加上了三个Gap_Lock以后，其他事务就不能在插入id=10的记录，因此就不会出现幻行。 看到这里你可能会问，为什么前两种组合不使用Gap_Lock，而这种情况需要使用呢？这个问题其实很简单，对于主键和唯一索引，值是唯一的，那么进行等值查询时最多只会返回一条记录，因此也就避免了Gap_Lock的使用。 结论RR级别下，id列上有一个非唯一索引，对应SQL：delete from t1 where id = 10; 首先，通过id索引定位到第一条满足查询条件的记录，加记录上的X锁，并加上相应的GAP锁 然后加主键聚簇索引上的记录X锁，返回读取下一条，重复进行。直至进行到第一条不满足条件的记录 此时，不需要加记录X锁，但是仍旧需要加GAP锁，最后返回结束。 注意：在这种情况下Gap_Lock加在辅助索引上而不是聚簇索引上！！！！ id列上没有索引RR级别下，id列上没有索引。此时SQL：delete from t1 where id = 10; 没有其他的路径可以选择，只能进行全表扫描。最终的加锁情况，如下图所示： 这是一个很恐怖的现象。首先，聚簇索引上的所有记录，都被加上了X锁。其次，聚簇索引每条记录间的间隙(GAP)，也同时被加上了GAP锁。这个示例表，只有6条记录，一共需要6个记录锁，7个GAP锁。试想，如果表上有1000万条记录呢？ 此时，除了不加锁的快照读，其他任何加锁的并发SQL，均不能执行:不能更新、不能删除也不能插入，全表被锁死。 结论：若id列上没有索引，SQL会走聚簇索引的全扫描进行过滤，对表的每一条记录加记录锁(行级锁)，并对所有的间隙加间隙锁(Gap_Lock)。和RC不同，此时不会释放不满足条件的锁！！ SERIALIZABLR级别在该级别下，MVCC退化为基于锁的协议，读均为当前读，读写都要加锁。遵循严格两阶段封锁协议，即所有的锁只在事务提交/终止时释放。 对于复杂的SQL语句到目前为止，我们介绍的所有情况都是WHERE后面为等值检索的情况，那么对于范围检索呢？我们来看一看。 RR级别同样的分两种情况 如果WHERE中的检索条件有索引(聚簇索引/唯一索引/普通索引)，那么使用记录锁(行级锁)+Gap_Lock。 如果没有索引，则走聚簇索引进行全表扫描，锁定每一条记录和相应的间隙。 RC级别 如果WHERE中检索条件有索引，那么使用记录锁(行级锁)锁定满足条件的记录，不使用Gap_Lock。 如果没有索引，同样走聚簇索引进行全表扫描，首先对所有的记录都加锁，但是不使用Gap_Lock，最后释放不满足条件的记录上的锁(违反2PL规定)。 RC级别RC级别基本不使用，这里简单介绍一下 读为当前读(每次读取最新数据)，并且不加锁 写加锁，加锁方式和RC级别类似。 RR级别下的特殊情况前面说了，在RR级别下，WHERE检索条件中使用聚簇索引/唯一索引进行等值查询时候，不需要使用Gap_Lock。因为Gap_Lock主要用于防止幻读，而在这种情况下最多检索出一条记录。那么现在有一种特殊情况：如果没有检索到满足条件的记录，此时Gap_Lock能省略么？如图，假设我们在SQL语句为update table set name=’E’ where id=3;此时由于表中没有id=3的记录，那么此时应该使用Gap_Lock，将id=3所在的间隙使用间隙锁锁住，防止其他事务在此期间插入数据。 总结对于MySQL InnoDB存储引擎在并发环境下的加锁情况大概就是这些，对于更复杂情况(WHERE中有多个不同的检索条件)，这里不做介绍。有一点需要注意：不管是什么隔离级别，对于满足条件的记录，一旦加锁，锁只能等到事务提交/终止时释放。 MySQL加锁分析–简书]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>MySQL</tag>
        <tag>并发控制</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[查看MySQL正在执行的事务/锁/等待信息]]></title>
    <url>%2F2020%2F02%2F28%2F%E6%9F%A5%E7%9C%8BMySQL%E6%AD%A3%E5%9C%A8%E6%89%A7%E8%A1%8C%E7%9A%84%E4%BA%8B%E5%8A%A1-%E9%94%81-%E7%AD%89%E5%BE%85%E4%BF%A1%E6%81%AF%2F</url>
    <content type="text"><![CDATA[在5.5中，information_schema库中增加了三个关于锁的表，它们分别是：innodb_trx–当前运行的所有事务、innodb_locks–当前出现的锁以及innodb_lock_waits–锁等待的对应关系。今天看了一篇博客，对这方面进行了介绍。觉得写得很好，为了防止原博客404，特此记录一下。 常用的showstatus命令 查询返回的行数show status like ‘%innodb_rows_read%’ 插入成功的行数show status like ‘%innodb_rows_inserted%’ 更新成功的行数show status like ‘%innodb_rows_updated%’ 删除成功的行数show status like ‘%innodb_rows_deleted%’ 查看慢查询show status like ‘%Slow%’ 查看运行时间show status like ‘%up%’ 查看锁的时间分布show status like’%innodb_row_lock%’; 执行select的计数show status like ‘%Com_select%’ 执行insert的计数，批量插入算一次show status like ‘%Com_insert%’ 执行更新操作的计数show status like ‘%Com_update%’ 执行删除操作的计数show status like ‘%Com_delete%’ 提交事务计数show status like ‘%Com_commit%’ 回滚事务计数show status like ‘%Com_rollback%’ 查看警告信息show warnings1234567891011121314151617mysql&gt; show status like &apos;innodb_row_lock_%&apos;;+-------------------------------+-----------+| Variable_name | Value |+-------------------------------+-----------+| Innodb_row_lock_current_waits | 2 || Innodb_row_lock_time | 334377476 || Innodb_row_lock_time_avg | 50678 || Innodb_row_lock_time_max | 51974 || Innodb_row_lock_waits | 6598 |+-------------------------------+-----------+解释如下：Innodb_row_lock_current_waits : 当前等待锁的数量Innodb_row_lock_time : 系统启动到现在，锁定的总时间长度Innodb_row_lock_time_avg : 每次平均锁定的时间Innodb_row_lock_time_max : 最长一次锁定时间Innodb_row_lock_waits : 系统启动到现在总共锁定的次数 innodb_locks 在MySQL下使用desc information_schema.innodb_locks;语句可以查看innodb_locks表的结构，如图所示 使用select * from information_schema.innodb_locks\G;查看表中数据 123456789101112131415表各个字段含义+-------------+---------------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+-------------+---------------------+------+-----+---------+-------+| lock_id | varchar(81) | NO | | | |#锁ID| lock_trx_id | varchar(18) | NO | | | |#拥有锁的事务ID| lock_mode | varchar(32) | NO | | | |#锁模式| lock_type | varchar(32) | NO | | | |#锁类型| lock_table | varchar(1024) | NO | | | |#被锁的表| lock_index | varchar(1024) | YES | | NULL | |#被锁的索引| lock_space | bigint(21) unsigned | YES | | NULL | |#被锁的表空间号| lock_page | bigint(21) unsigned | YES | | NULL | |#被锁的页号| lock_rec | bigint(21) unsigned | YES | | NULL | |#被锁的记录号| lock_data | varchar(8192) | YES | | NULL | |#被锁的数据+-------------+---------------------+------+-----+---------+-------+ innodb_lock_waits 使用desc information_schema.innodb_lock_waits;命令查看innodb_lock_waits表的结构，如图所示 使用select * from information_schema.innodb_lock_waits\G;查看表中数据123456789表各个字段含义+-------------------+-------------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+-------------------+-------------+------+-----+---------+-------+| requesting_trx_id | varchar(18) | NO | | | |#请求锁的事务ID| requested_lock_id | varchar(81) | NO | | | |#请求锁的锁ID| blocking_trx_id | varchar(18) | NO | | | |#当前拥有锁的事务ID| blocking_lock_id | varchar(81) | NO | | | |#当前拥有锁的锁ID+-------------------+-------------+------+-----+---------+-------+ innodb_trx 使用desc information_schema.innodb_trx;命令查看innodb_trx表的结构，如图所示 使用select * from information_schema.innodb_trx\G;查看表中数据12345678910111213141516171819202122232425262728表各个字段的含义desc information_schema.innodb_trx;+----------------------------+---------------------+------+-----+---------------------+-------+| Field | Type | Null | Key | Default | Extra |+----------------------------+---------------------+------+-----+---------------------+-------+| trx_id | varchar(18) | NO | | | |#事务ID| trx_state | varchar(13) | NO | | | |#事务状态：| trx_started | datetime | NO | | 0000-00-00 00:00:00 ||#事务开始时间；| trx_requested_lock_id | varchar(81) | YES | | NULL ||#innodb_locks.lock_id| trx_wait_started | datetime | YES | | NULL | |#事务开始等待的时间| trx_weight | bigint(21) unsigned | NO | | 0 | |#| trx_mysql_thread_id | bigint(21) unsigned | NO | | 0 ||#事务线程ID| trx_query | varchar(1024) | YES | | NULL | |#具体SQL语句| trx_operation_state | varchar(64) | YES | | NULL ||#事务当前操作状态| trx_tables_in_use | bigint(21) unsigned | NO | | 0 ||#事务中有多少个表被使用| trx_tables_locked | bigint(21) unsigned | NO | | 0 ||#事务拥有多少个锁| trx_lock_structs | bigint(21) unsigned | NO | | 0 | |#| trx_lock_memory_bytes | bigint(21) unsigned | NO | | 0 ||#事务锁住的内存大小（B）| trx_rows_locked | bigint(21) unsigned | NO | | 0 ||#事务锁住的行数| trx_rows_modified | bigint(21) unsigned | NO | | 0 ||#事务更改的行数| trx_concurrency_tickets | bigint(21) unsigned | NO | | 0 ||#事务并发票数| trx_isolation_level | varchar(16) | NO | | | |#事务隔离级别| trx_unique_checks | int(1) | NO | | 0 | |#是否唯一性检查| trx_foreign_key_checks | int(1) | NO | | 0 | |#是否外键检查| trx_last_foreign_key_error | varchar(256) | YES | | NULL ||#最后的外键错误| trx_adaptive_hash_latched | int(1) | NO | | 0 | |#| trx_adaptive_hash_timeout | bigint(21) unsigned | NO | | 0 ||#+----------------------------+---------------------+------+-----+---------------------+-------+ 总结一旦事务开启，innodb_trx表就有数据，有多少个未提交事务就有多少条数据。只有产生锁等待时，innodb_locks和innodb_lock_waits这两张表才会有数据。查看Mysql正在执行的事务，锁，等待mysqlshowstatus常用命令]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL中获取锁超时和死锁问题]]></title>
    <url>%2F2020%2F02%2F28%2FMySQL%E4%B8%AD%E8%8E%B7%E5%8F%96%E9%94%81%E8%B6%85%E6%97%B6%E5%92%8C%E6%AD%BB%E9%94%81%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[MySQL地InnoDB引擎地并发控制有两种形式：分别是MVCC和两阶段封锁协议。在前面说过，两阶段封锁协议可能会出现死锁问题，那么出现死锁之后该如何处理呢？通过本文你将了解MySQL处理死锁问题以及获取锁超时问题地方式。本文所有实验演示全部基于Win10环境下MySQL5.5版本 前言在多个事务并发执行时，可能会出现两种情况 一个事务长时间地持有锁，导致其他事务长时间阻塞–获取锁超时。 死锁问题。 下面我将通过实验演示MySQL如何解决这两种情况。 什么是死锁在数据库中，死锁的定义如下：两个事务都持有对方需要的锁，并且在等待对方释放，并且双方都不会释放自己已经持有的锁。由于MySQL使用的是两阶段封锁协议，因此MySQL在并发环境下可能会出现死锁。 死锁检测和恢复MySQL不能保证不产生死锁，那么它就必须采用检测和恢复机制。检查系统状态的算法周期新激活，判断有无死锁发生。如果发生死锁，则系统必须尝试着从死锁中恢复。 死锁检测死锁可以用称为等待图的有向图来描述，该图由G=(V,E)来描述，其中V是顶点集，E是边集。顶点集由系统中所有事务组成，边集E的每个元素是一个有序对Ti–&gt;Tj。如果Ti–&gt;Tj属于E，则表示Ti在等待Tj释放所需要的数据项。当Ti申请的数据项被Tj持有时，边Ti–&gt;Tj被插入等待图中，只有当Tj不再持有Ti需要的数据项时，Ti–&gt;Tj才被删除。当且仅当等待途中包含环时，系统中存在死锁，该环的每一个事务称为处于死锁状态。要检测死锁，系统需维护等待图，并周期性的激活一个在等待图中搜索环的算法。如上图，第一张图中不存在环，因此没有死锁发生；而在第二张图中存在环，因此T2、T3以及T4处于死锁状态，需要进行死锁恢复。 死锁恢复当检测到死锁时，系统必须从死锁中恢复，解除死锁最通常的做法是回滚一个或多个事务。采取的动作有三个： 选择牺牲者死锁发生后，系统选择插入更新或者删除数量最少的事务进行回滚(基于INFORMATION_SCHEMA.INNODB_TRX表中的trx_weight字段来判断) 12使用该SQL语句可以查看事务信息(后面的博客会详细介绍)select * from information_schema.innodb_trx\G; 饿死防止某个事务在发生死锁时总是被回滚，导致该事务总是无法执行完毕，这样就发生饿死。为了防止这种情况，可以将事务的回滚次数作为一个影响因素来计算trx_weight。 死锁实验我们创建一张表 12345create table deadlock_test( ID int primary key, number int);并插入几条记录 开启两个事务T1和T2 123456T1: update deadlock_test set number=-1 where ID=13; update deadlock_test set number=-1 where ID=1; update deadlock_test set number=-1 where ID=3;T2:update deadlock_test set number=-2 where ID=3; update deadlock_test set number=-2 where ID=1; 为了更明显的区分，我让T1多做了一次update操作，这样发生死锁时就会回滚T2。以上事务执行顺序如下 T1先执行前两个SQL语句 T2执行第一条SQL语句 T1再执行第三条SQL语句 T2执行第二条SQL语句 ，再RR级别下，只有更新操作时，被回滚的事务直接终止。 超时等待在MySQL中，还有一种情况：那就是当一个事务长时间持有锁时，被阻塞的事务会一直等待该锁，那么等待多久呢？超时之后呢？ 等待多久在MySQL中，InnoDB默认的行级锁等待时间为50s。可以通过设置innodb_lock_wait_timeout的值来改变超时时间 1234innodb_lock_wait_timeout默认值：50s最小值：1s最大值：1073741824 可以通过下面命令查看超时等待时间 show variables like ‘innodb_lock_wait_timeout’;–查看当前会话 show global variables like ‘innodb_lock_wait_timeout’;–查看全局设置 通过下面SQL语句修改会话当前会话行级锁超时时间 set innodb_lock_wait_timeout=?； 超时之后当事务等待锁超时之后，会进行事务回滚，回滚到当前SQL语句(使事务等待锁的语句)上一步。 测试锁超时的实验很好测试，表还是上面的表，开启两个事务 123T1:update deadlock_test set number=-1 where ID=1;T2:update deadlock_test set number=-2 where ID=1; 两事务同时对一条记录进行修改，就会发生锁争用现象，后面的事务会被阻塞，知道获得锁或者超时。 附(查看修改超时时间操作截图) 查看行级锁超时时间 设置当前会话行级锁超时时间 总结对于MySQL中的死锁问题的介绍就到这里，由于MySQL使用两阶段封锁协议，不能保证不发生死锁，因此InnoDB具有完善的死锁检测和恢复机制。今天的介绍就到这里。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>MySQL</tag>
        <tag>死锁</tag>
        <tag>锁超时</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库封锁协议]]></title>
    <url>%2F2020%2F02%2F28%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E5%B0%81%E9%94%81%E5%8D%8F%E8%AE%AE%2F</url>
    <content type="text"><![CDATA[在前一篇文章中介绍了数据库中常见的锁，本文主要介绍数据库并发控制中的两种封锁协议，它们分别是：三级封锁协议和两阶段封锁协议。 三级封锁协议三级封锁协议，主要约定了申请锁、释放锁的时机。 一级封锁协议事务T要修改数据A时必须加X锁，直到T结束才释放锁。可以解决丢失修改问题(脏写)，因为不能同时有两个事务对同一个数据进行修改，那么事务的修改就不会被覆盖。 二级封锁协议在一级封锁协议的基础上，事务对数据的访问必须加S锁，访问完毕后立刻释放。可以解决读脏数据问题，因为如果一个事务在对数据A进行修改，根据一级封锁协议，会加X锁，那么就不能再加S锁了，也就是不会读入数据。 三级封锁协议在二级封锁协议的基础上，要求读取数据A时必须加S锁，直到事务结束了才能释放S锁。可以解决不可重复读的问题，因为读A时，其它事务不能对A加X锁，从而避免了在读的期间数据发生改变。可以发现，对于第三级封锁协议，所有的锁都在事务结束时释放。 两阶段封锁协议定义该协议要求每个事务分两个阶段提出加锁和解锁申请 增长阶段事务可以获得锁，但是不能释放锁 缩减阶段事务可以释放锁，但是不能获得新锁。 最初事务处于增长阶段，事务根据需要获得锁，一旦事务释放了锁，那么事务就进入了缩减阶段，并且不能再发出加锁请求。在两阶段封锁协议中，解锁阶段不必出现在事务末尾。 冲突可串行化 冲突可串行化如果一个调度与一个串行调度冲突等价，那么我们称该调度是冲突可串行化的。简而言之，一个冲突可串行化的调度可以转换为一个串行调度。 可以证明：两阶段封锁协议保证了冲突可串行化。对于任何事务，在调度中获得其最后加锁的位置(增长阶段结束点)称为事务的封锁点。这样，多个事务可以根据可以根据它们的封锁点进行排序。实际上，这个顺序就是事务地一个可串行化顺序。 严格两阶段封锁协议(S2PL)在两阶段封锁协议下，级联回滚是可能发生的。 级联回滚一个事务T1读取到了T2未提交的数据并对该数据进行了操作，当T2回滚时，T1也必须跟着回滚，这就是级联回滚。级联回滚导致大量撤销工作，是我们不希望发生的如图所示，三个事务都满足两阶段封锁协议，但是会出现级联回滚现象：T3事务读取到A的数据后T1发生回滚，那么T2和T3都要回滚。 为了防止级联回滚现象，我们可以使用严格两阶段锁协议：在两阶段封锁协议的基础上，严格两阶段封锁协议要求所有的锁只能在事务提交时释放。这样以来，就不会出现级联回滚。如图所示，所有的锁在事务结束时释放。 锁转换我们考虑下面两个事务 12345678910T1: read(a1); read(a2); ...... read(an); write(a1);===============T2: read(a1); read(a2); display(a1+a2); 如果我们使用两阶段封锁协议或者是严格两阶段封锁协议，那么T1必须对a1加排他锁。这样一来，两个事务相当于是串行执行。如果我们这样做：T1在开始时对a1加共享锁，然后在需要时将其变更为排他锁，那么可以获得更高的并发度。我们对两阶段封锁协议加以修改，使之允许锁转换。我们提供将共享锁升级为排他锁，以及将排他锁降级为共享锁的机制。 升级：共享锁–&gt;排他锁，只发生在增长阶段。 降级：排他锁–&gt;共享锁，只发生在缩减阶段。 三级封锁协议和两阶段封锁协议区别个人认为两种协议的目的是不一样的，对于三级封锁协议，目的是为了保证一致性，能够解决脏写、脏读、不可重复读等一致性问题；而对于两阶段封锁协议，是为了保证事务的隔离性，前面说过，使用两阶段封锁协议的调度一定是冲突可串行化的，也就是说，一个调度如果使用两阶段协议，那么该调度一定能保证多个事务在并发情况下可以串行执行。 总结严格两阶段封锁协议(含锁转换)在数据库管理系统中广泛使用(如MySQL的SERIALIZABLE下使用的就是该协议)，我们总结一下该协议 当事务T进行read(Q)操作时，系统产生lock-S(Q)指令，该read(Q)紧跟其后 当事务T进行write(Q)操作时，系统检查R是否已在Q上持有共享锁 若有，则系统进行锁升级。发出upgrade(Q)指令，后面紧跟write(Q)指令 否则，系统发出lock-X(Q)指令，write(Q)指令紧跟其后 当一个事务提交或终止后，该事务释放所有的锁。 另外需要注意，无论是2PL还是S2PL，都可能会出现死锁。至于死锁出现后如何解决，后面介绍。 参考书籍：《数据库系统概念》参考文章]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>并发控制</tag>
        <tag>封锁协议</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库的锁类型]]></title>
    <url>%2F2020%2F02%2F28%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E9%94%81%E7%B1%BB%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[本文主要介绍数据库并发控制中几种不同的锁类型，为后面MySQL在四种隔离级别下的加锁情况做铺垫。 锁分类 按锁的粒度分 表级锁 行级锁 页级锁 按加锁方式分 自动锁(隐式锁) 显式锁 按锁的级别分 共享锁 排他锁 意向锁 按使用方式分 乐观锁 悲观锁 下面我们就来介绍一下这些锁 行级锁、表级锁和页级锁行级锁行级锁分为共享锁(S)和排他锁(X)，行级锁是MySQl中粒度最细的锁。InnoDB引擎支持行级锁和表级锁，只有通过索引条件检索数据时，才会使用行级锁，否则就会使用表级锁。行级锁开销大，加锁粒度最小，发生锁争用概率最低，性能最高。 表级锁表级锁也分为共享锁(S)和排他锁(X)。表级锁开销小，加锁快，锁定力度大，发生锁争用概率高，并发度最低。 页级锁页级锁是MySQL中锁定粒度介于行级锁和表级锁之间的锁。表级锁速度快，但冲突多，行级锁锁定满但冲突少；于是取了折中的页级锁，一次锁定相邻的一组记录。BDB支持页级锁。 隐式/显式锁如果某个事务T对数据库中的一个表加了共享的或者是排他的表级锁，那么该事务T隐式的对该表的所有记录加上了相同类型的(S/X)行级锁。前者是显式锁，而后者是隐式锁。 共享锁、排他锁和意向锁排他锁(X-exclusive Lock)排他锁又叫写锁，如果事务T对A加上排他锁，那么其他事务都不能对A加任何类型的锁(即其他事务对A的访问修改必须等到该锁被释放之后)。持有排他锁的事务既能读取数据，又能修改数据。 共享锁(S-share Lock)共享锁又叫读锁，如果事务T对A加上共享锁，则其他事务可以继续对A加共享锁，但是不能加排他锁(即多个事务可以同时持有数据的共享锁)。持有共享锁的事务只能读取数据，不能修改数据。 意向锁意向锁是表级锁，又分为两种 意向共享锁(IS) 意向排他锁(IX) 现在来考虑一个问题：事务T1锁住了表的一行r1，而事务T2要锁住整张表。这样明显会出现问题，两个事务在r1上会发生冲突。这时行级锁和表级锁就会发生冲突，这时候就需要用到意向锁。有了意向锁之后，当事务A在申请行级锁(写锁)之前，数据库会自动给事务A申请表的意向锁(写锁)。当事务B去申请表的写锁时就会失败，因为表上有意向排他锁之后事务B申请表的写锁时会被阻塞。 下面是S锁、X锁、IS锁和IX锁之间的兼容关系 乐观锁和悲观锁乐观锁和悲观锁实际上说的是并发控制的两种思想，其中悲观锁会假设事务在访问数据的时候一定会发生冲突，因此每次在访问的时候都会加锁，这里的锁是指前面讲到的行级锁、表级锁等。而乐观锁，顾名思义比较乐观，假定事务每次访问数据时不会发生冲突，因此不会对数据进行加锁，当出现冲突时再进行补救。 总结对锁的介绍就到这里，其实还有一些锁没有介绍，例如间隙锁(Gap Lock)、下一键锁(Next-Key Lock)等，这两种锁能够解决幻行问题，在介绍MySQL可重复读级别下加锁情况时再另外介绍。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>并发控制</tag>
        <tag>锁</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[详解MySQL的InnoDB引擎MVCC机制]]></title>
    <url>%2F2020%2F02%2F27%2F%E8%AF%A6%E8%A7%A3MySQL%E7%9A%84InnoDB%E5%BC%95%E6%93%8EMVCC%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[在前面两篇博客中分别介绍了数据库的四大特性和数据库的四大隔离级别。那么不知道你有没有想过：数据库是怎么实现四大隔离级别的呢？由于不同的数据库实现方法可能不同，我就以我常用的MySQL为例，介绍一下MySQL的InnoDB如何实现数据库四大隔离级别，本文基于Win10环境下MySQL5.5版本。 前言多版本并发控制(MVCC)是MySQL的InnoDB存储引擎实现隔离级别的一种具体方式，该方式主要实现了提交读和可重复读两种隔离级别，至于未提交读较为简单，要求很低，无需使用MVCC；而较高的隔离级别SERIALIZABLE，通过两阶段锁协议实现。这些在后文我会一一进行介绍。 MySQL行记录的元信息我们在创建一张表时，会指明这张表有哪些列(属性)，列名以及列的类型(int char等)。但是在InnoDB中，除了我们指定的列以外，MySQL还会添加两个隐藏列： trx_id存储操作(增删改)这条记录的事务ID，后面会介绍ID的概念。 db_roll_ptr一个指向Undo记录的指针。同样，后面会介绍Undo记录。 这两个列被称为ROW HEADER–元信息。我们来举例说明，假设我们创建一张表 1234create table t( ID int, count int); 那么该表在InnoDB中是这样的：在本节中，我们只需要了解行记录的元信息即可，至于它们的作用在后面的小节介绍。 MySQL版本号MySQL维护了两个版本号 系统版本号(sys_id)是一个递增的数字，每开启一个事务，该版本号+1。 事务版本号(trx_id)事务开始时系统的版本号。事务的版本号能够表明事务开启的先后顺序。 其中行记录元信息中的trx_id即为事务的版本号。 MySQL索引InnoDB中使用B+树索引结构，并且主键所在的索引为聚簇索引。索引的每个叶子节点中保存了对应的数据内容。一个表只能有一个主键，所以只能有一个聚簇索引。在MySQL中，聚簇索引只能是主键。如果我们在创建表时候没有指定索引，那么对于InnoDB 如果创建表时定义了主键，那么系统会自动为该主键创建聚簇索引 如果创建表时没有定义主键，则系统会自动选择一个可以唯一标识数据记录的列作为主键。 如果没有满足条件的列，那么InnoDB会生成一个隐藏的主键作为聚簇索引。该隐藏主键6字节，并且自增。 如果你对B+树有一定的了解，那么到目前为止你应该已经知道了MySQL中数据的组织方式。即一张表就是一个B+树，树的每一个叶子节点就是表中的一条记录。 回滚日志-Undo LogMySQL的InnoDB中存在多种日志，如Redo Log、bin Log以及Undo Log等，而今天要介绍的就是和MVCC相关的Undo Log–回滚日志。当然，这里只是对回滚日志进行极其简单的学习，为后面的学习做准备。Undo Log用于数据的撤回操作，它记录了修改的反向操作，如插入对应删除、修改对应修改为原来的数据，通过Undo Log可以实现事务回滚，并且可以回滚到某个特定版本的数据，实现MVCC。Undo Log分为INSERT和UPDATE两种(DELETE被视为特殊的更新，在记录上修改删除标记) 当进行插入操作时，生成的INSERT Undo Log在事务提交后即可删除，这很容易理解，因为其他事务不需要这个Undo Log 进行删除修改操作时，生成对应的Undo Log。记录相应信息。 123456例如在MySQL创建了一个表t，包含主键id和一个字段x，并假设系统版本号sys_id=1我们对该表进行如下操作：INSERT INTO t VALUES(1,&apos;a&apos;);UPDATE t SET x=&apos;b&apos; WHERE id=1;UPDATE t SET x=&apos;c&apos; WHERE id=1; 我们没有使用start transaction来开启一个事务，因此根据MySQL的AUTOCOMMIT机制，每一条SQL语句都被当作一个事务执行，因此一共执行了三个事务，事务的版本号分别为1，2，3。到目前为止，我们知道了数据在MySQL中的组织方式以及Undo记录，上图中Undo记录中每一个数据行被称为一张快照。 事务执行状态的快照–ReadViewMVCC维护了一个被称为READ VIEW的结构，它的基本结构如下。 12345678ReadView&#123; creator_trx_id trx_id_min trx_id_max id1 id2 ...&#125; 该结构包含了当前系统所有活动的事务(未提交的事务)的trx_id。MVCC还维护了最大值(TRX_ID_MAX)和最小值(TRX_ID_MIN)，这表示当前未提交的事务中最年轻事务(最新开启)的ID和最年老事务(最早开启)的ID。ReadView用于进行可见性判断，我们在后面详细说，现在你只需要知道：ReadView是由事务创建的(至于什么时候创建什么时候更新由不同的隔离级别决定)，用于可见性判断。 快照读和当前读在正式介绍四大隔离级别的实现时，我们先介绍两个概念，个人觉得这两个概念对于后面的学习至关重要。 快照读(snapshot read)MVCC中的SELECT操作读取的是快照中的数据，你可以理解为前面图中Undo记录中的数据，并不是B+树的节点。该操作不需要加锁。在提交读和可重复读两种隔离级别下： 1SELECT ? FROM table WHERE ? 这类普通的SELECT语句全部都是快照读！ 当前读MVCC其他修改数据的操作读取的是最新的数据，你可以理解为前面图中B+树的叶子节点。该操作需要加锁，至于加什么锁怎么加锁视情况而定。在提交读和可重复读两种隔离级别下： 12345SELECT ? FROM table WHERE ? FOR SHARE MODE--加共享锁SELECT ? FROM table WHERE ? FOR UPDATEUPDATEINSERTDELETE 除了第一条加共享锁外，其余都加排他锁。 总结不知道你发现没有，MVCC在进行普通SELECT时，读的都是快照中的数据，而在进行修改时，修改的都是B+树叶子节点上的数据(最新的数据)–这一结论仅在提交读和可重复读级别下成立。这很类似于Java中的CopyOnWrite，实现了读写分离。 READ COMMIT-提交读在此隔离级别下，会存在不可重复读的问题。我们来看看此时MVCC是如何工作的 ReadView的创建和更新时机事务每一次快照读(snapshot read)都会创建一个新的ReadView，可以理解为每次SELECT时都会更新ReadView，得到所有当前最新的未提交的事务。 MVCC具体实现–判断可见性在进行普通SELECT操作时，根据数据行快照的trx_id与ReadView中trx_id_min和trx_id_max之间的关系，判断快照是否可用 trx_id==creator_trx_id表示该数据行的快照是当前事务创建的，可以使用。 trx_id&lt;trx_id_min表示该数据行快照在当前所有未提交事务启动之前更改的，因此可以使用(即SELECT读取到该快照)。 trx_id&gt;trx_id_max表示该数据行快照是在事务启动后被修改的，因此不可使用该快照。 trx_id_min&lt;=trx_id&lt;=trx_id_max此时有两种情况 如果该快照的trx_id在ReadView中，说明该快照对应的事务还没有提交，则该快照不可使用 如果该快照的trx_id不在ReadView中，说明该快照对应的事务已提交，在该隔离级别下可以使用。 如果当前数据行快照不可使用，那么沿着db_roll_ptr找到该数据行的下一个快照重复上述步骤。 READ REAPETABLE-可重复读该隔离级别解决了不可重复读的问题，但是会存在幻行。 ReadView的创建和更新时机和提交读不同，在RR级别下，ReadView只创建一次，创建以后不会改变，在事务开始后第一此快照读(snapshot read)时创建。 MVCC具体实现在进行普通SELECT操作时，根据数据行快照的trx_id与ReadView中trx_id_min和trx_id_max之间的关系，判断快照是否可用 trx_id==creator_trx_id表示该数据行的快照是当前事务创建的，可以使用。 trx_id&lt;trx_id_min表示该数据行快照在当前所有未提交事务启动之前更改的，因此可以使用(即SELECT读取到该快照)。 trx_id&gt;trx_id_max表示该数据行快照是在事务启动后被修改的，因此不可使用该快照。 trx_id_min&lt;=trx_id&lt;=trx_id_max所有的快照都不可使用，因为如果可以使用的话，那么就会产生不可重复读的问题。 如果当前数据行快照不可使用，那么沿着db_roll_ptr找到该数据行的下一个快照重复上述步骤。 READ UNCOMMITTED-未提交读在当前隔离级别下，每次读取只会读取最新的数据，不会遍历版本链(Undo记录)，不会进行查找可见版本，因此可能会出现脏读。即读取到其他未提交事务修改的数据。 SERIALIZABLE-可串行化在此隔离级别上，MySQL执行严格两阶段锁(S2PL)并发控制协议，读操作全部是当前读，并且读写都要加锁！ 总结对于MySQL并发事务的读操作，通过本文你应该了解了MVCC是如何进行控制的。我们知道，除非特别指定，MVCC下普通的读都是快照读，写都是要加锁的。那么问题来了，在不同的隔离级别下分别怎么加锁，要加什么锁呢？我会在后面的博客进行介绍。 参考文章来自知乎解答InnoDB存储引擎MVCC实现原理来自个人博客]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>隔离级别</tag>
        <tag>InnoDB</tag>
        <tag>MVCC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[事务的四大隔离级别]]></title>
    <url>%2F2020%2F02%2F26%2F%E4%BA%8B%E5%8A%A1%E7%9A%84%E5%9B%9B%E5%A4%A7%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB%2F</url>
    <content type="text"><![CDATA[在上一篇博客中介绍了事务的四大特性，并且也说：为了提高性能和利用率，我们有时候会弱化一致性，设置不同的隔离级别。那么到底怎么做呢？设置不同的隔离级别之后又会带来哪些负面效果呢？下面就让我们来看一看事务的四大隔离级别。本文中相关实验基于Windows10环境下的MySQL实现。 前言数据库事务有四中隔离级别，级别越高，并发执行中安全性越高，但是性能相对越差，它们分别是： READ UNCIMMITTED–未提交读 READ COMMITTED–提交读 REPEATABLE READ–可重复读 SERIALIZABLE–可串行化 下面我会通过实验分别介绍MySQL事务在四种隔离级别下会出现的问题。在此之前，我再介绍MySQL数据库中两条和隔离级别相关的SQL语句 SELECT @@TX_ISOLATION查看当前会话的隔离级别 SET SESSION TRANSACTION ISOLATION LEVEL 隔离级别设置当前会话的隔离级别 前期准备在正式开始介绍隔离级别之前，为了方便后面的实验演示，先为后面的相关实验做一下铺垫 在Windows10下打开两个CMD窗口，并且在两个窗口中都登陆MySQL。如图所示 我们先创建一个银行账户表(isolation_demo)，只有ID和count两个属性。方便我们后面做测试。如图我已经创建好了 下面我们对于四种隔离级别下存在的问题将会在这张表上进行测试。 未提交读作用及存在问题这是数据库事务最低的隔离级别，在此隔离级别下：事务中的修改，即使没有提交，对其他事务也都是可见的。事务可以读取未提交的数据，这种情况被称为脏读。这个级别会导致许多问题，并且从性能上来说，该级别不会比其他级别好太多，但是却缺乏其他级别的很多好处，因此除非真的有非常必要的理由，在实际应用中很少使用。 实验演示 为了方便起见，我们将两个CMD窗口下的会话隔离级别都设置为READ UNMMITTED。 在两个会话中各开启一个事务(先开启T1后开启T2)(start transaction;)，分别称为T1和T2(左图为T1)。 我们在T2中完成转账操作：A向B转账50元。在T1中进行查询余额。 12345678T2的SQL操作update isolation_demo set count=count-50 where ID=&apos;A&apos;;--语句1update isolation_demo set count=count+50 where ID=&apos;B&apos;;--语句2=============================T1的SQL操作select * from isolation_demo;...执行多次该语句 在T2事务的语句1执行之前，我们执行一次查询，得到如图所示结果 我们转过来执行T2事务的语句1，得到如图所示结果 我们在T1事务中再执行一次查询(select)和在第四步中查询得到的结果不同。这时候问题来了，我们看到T1中此时查询得到的是T2事务没有提交的修改，违反了事务的一致性，这样会导致很严重的问题。 在T2中执行语句2后，在T1中再执行一次查询，可以看到T1查询得到的结果再次发生变化，这里不做演示。 总结我们可以看到，在未提交读级别下，会出现很严重的问题：如果另一个事务在对数据进行修改，修改的过程中可能会违反数据库的一致性(如转账)，导致数据库处于不一致状态(在前面介绍ACID四大特性时有提到)，此时其他事务居然可以获取到该不一致状态，这是很严重的问题。因此我们说，非必须情况下不适用该级别。 提交读作用及存在问题 作用大多数数据库的默认隔离级别都是READ COMMITTED(不包括MySQL)。该隔离级别解决了前面提到的脏读的问题。也就是说，一个事务从开始到提交之前，所做的任何修改对其他事务是不可见的。 存在问题这个级别也叫做不可重复读，因为一个事务两次执行相同的查询，可能由于其他事务的修改可能得到不同的结果 实验演示 同样的，我们将隔离级别改为READ COMMITTED。 分别开启两个事务(先开启T1后开启T2)，并且两个事务的操作和前面相同。 在T2事务语句1执行前，语句1执行后语句2执行前，T2事务提交后这三个时刻T1事务各执行一次查询T2事务语句1执行前T2事务语句1执行后，语句2执行前T2事务提交后如图，我们可以发现，T2事务中所做的修改对于T1是不可见的，但是由于T2事务对数据的修改，T1事务执行相同的查询得到了不一样的结果，这就是不可重复读。 可重复读作用及存在问题 作用通过名字不难理解，该级别不仅解决了脏读的问题，也解决了不可重复读的问题。也就是说，该级别保证了同一个事务多次读取同样的记录结果是一致的。MySQL默认的隔离级别即为可重复读。 存在问题在该级别下，会存在幻行的问题，所谓幻行，指的是当事务A在读取某个范围内的记录时，另外一个事务B又在该范围内插入了新的记录，当之前的事务A再次读取该范围内的记录时，会产生幻行(即读取到事务B新插入的数据)。 实验演示 我们将隔离级别改为REPEATABLE READ。 分别开启两个事务(先开启T1后开启T2)，并且两个事务的操作和前面相同。 在T2事务语句1执行前，语句1执行后语句2执行前，T2事务提交后这三个时刻T1事务各执行一次查询T2事务语句1执行前T2事务语句1执行后，语句2执行前T2事务提交后可以看到，当T1事务开启时，无论T2对数据进行怎样的修改，T1中重复查询多次得到的结果相同，这就叫做可重复读。至于该级别下的幻行问题，已经由MySQL的InnoDB执行引擎通过MVCC(多版本并发控制)解决，因此这里无法进行演示。 可串行化作用及存在问题 作用这是四大隔离级别中最高的级别。它通过强制事务串行执行，避免了前面说到的换行问题。简单来说，SERIALIZABLE会在读取的每一行数据上都加锁，所以可能导致大量的超时和锁争用问题，实际应用中也很少使用这一级别。只有在非常需要确保数据一致性并且可以接受没有并发的情况下才考虑使用。 存在问题性能低下，没有并发。 实验演示 分别开启两个事务(顺序无所谓)，并且两个事务的操作和前面相同。 我们将隔离级别改为SERIALIZABLE。 T2事务先执行语句1(此时T2事务对表加锁)，然后T1事务进行查询。由于是截图，所以不够直观，但是可以告诉你：由于T2对表进行加锁，因此T1对该表的任何操作都会等到T2提交释放锁，T1获得锁之后才能进行，因此图中T1的查询操作会阻塞知道获得锁为止。可以看到，此时所有事务串行执行，没有并发，性能低下。 对于事务四大隔离级别的介绍就到这里，文中提到的MVCC会在后续的博客中进一步介绍。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>隔离级别</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[事务的ACID四大特性]]></title>
    <url>%2F2020%2F02%2F25%2F%E4%BA%8B%E5%8A%A1%E7%9A%84ACID%E5%9B%9B%E5%A4%A7%E7%89%B9%E6%80%A7%2F</url>
    <content type="text"><![CDATA[本文主要介绍数据库中事务的ACID四大特性。那么什么是事务？构成单一逻辑工作单元的操作集称作事务，一个事务可能包含很多个操作(多条SQL语句)，这些操作要么全部执行，要么全都不执行。 前言既然说到了事务的四大特性，那么究竟是哪四大特性呢？我们来看看 A(Atomic)–原子性 C(Consistency)–一致性 I(Isolation)–隔离性 D(Durebility)–持久性 下面将分别对以上四大特性进行介绍，其中事务的一致性相对于其它三个特性比较模糊，因此着重介绍。 Atomic–原子性一个事务必须被视为一个不可分割的最小单元，整个事务中所有的操作要么全部提交成功，要么全部失败回滚，对于一个事务来说，不可能只执行其中一部分操作，这就是事务的原子性。 123456例如：假设有两个银行账户A(余额1000)和B(余额2000)现在A要向B转账100元，即A=A-100；-----&gt;发生故障B=B+100； 如上所示，数据库在实行完A-100后发生故障(如断电等)，那么由于事务的原子性，该事务将会回滚，即回到事务执行前的状态(A=1000，B=2000)，就像事务没有发生过一样。 保证事务原子性的一个思路是对于事务要执行写的数据项，数据库系统再磁盘上记录其旧值(本例中旧值分别为1000和2000)。这个信息记录在一个称为日志的文件中。如果事务没有完成它的执行，那么数据库从日志中恢复这个旧值，使得事务看上去从未执行过。而这项恢复任务是通过数据库的恢复系统完成，也就是说，保证原子性是数据库本身的责任。 Isolation–隔离性事务可能并发执行，当多个用于并发访问数据库时，系统保证：对于任何一对事务T1和T2，在T1看来，T2要么在T1开始之前已经完成，要么在T1结束之后开始执行。事务的隔离性确保事务在并发执行后的系统状态与这些事务以某种次序一个接一个地执行后的状态是等价的。确保隔离性由数据库系统中的并发控制系统完成，也是数据库本身地任务。隔离性描述的是当前事务能够看到其他事务中间状态的能力，这个能力通过设置隔离级别来体现。在下一篇文章中，将对事务地四大隔离级别进行着重介绍。 Consistency–一致性数据库一致性这个概念和另外三个特性相比确实抽象一些导致难以理解。通过翻阅书籍和网上查询，得到了一个我认为正确的、能够理解地解释。 定义数据库一致性是指事务执行的结果必须是使数据库从一个一致性状态变到另一个一致性状态。即数据库中的数据是正确的，随着状态的迁移，总是保持正确。那么什么时候数据是正确的什么时候数据又是不正确的呢？我们知道，数据库以一定的模式存储数据，本质是对真实世界建模，因此这里的正确是指：数据能够反映现实世界的状态。 举例说明我们举例说明： 案例1假设有一个账户表12345create table&#123; ID pramary key, count &gt;0 not null&#125;;假设有一条记录(张三，90)：表示张三账户余额90元 现在张三要向外转账100元，由于90-100&lt;0，违反了完整性约束。不满足事务的一致性 案例2先假设有两条记录12(张三，1000)(李四，1000) 现在张三向李四转账，那么在本案例中一致性要求事务的执行不会改变两人账户余额之和，即事务开始前两者和为2000，事务提交后和仍位2000。 案例31234567现在假设另外一种情况账户表为create table&#123; ID pramary key, count not null&#125;;和前面的不同，此时对于count属性没有&gt;0的完整性约束。 和案例1一样，张三向外转账100元，此时没有违反完整性约束，但是由于在现实世界中账户余额是不能为负的，此时数据不能够反应现实世界的真实状态，因此该操作也违反了事物的一致性。由此可见，和前面另外三个特性不同，如何保证事务的一致性是编写事务人员的职责，而不是数据库系统的职责。 三者之间联系我们已经介绍了原子性、隔离性和一致性，那么它们三者之间有什么区别呢？ 一致性和原子性同样的，还是转账的案例 1234567891011121314现假设有两个账户进行转账(张三，1000)(李四，1000)张三向李四转账100元，我们开启一个事务start transaction;update demo set count=count-100 where ID=张三;update demo set count=count+100 where ID=李四;commit;我们知道，这个事务在执行前和执行后都满足一致性。但是要注意系统仍会在某一时刻处于不一致状态，即使该事务能够执行完毕最终提交，但是在执行第一条语句和第二条语句之间时，此时张三余额为900，而李四余额为1000 虽然上述不一致状态最终会被一致性状态代替，但是我们必须保证上述转账过程中的不一致状态在数据库中是不可见的。这样，一个事务要么不开始，要么全部执行。这样以来不一致状态除了在事务执行当中以外，在其他时刻是不可见的。这就是需要原子性的原因：如果具有原子性，某个事务的所有动作要么在数据库中全部反映出来，要么全部不反映。 一致性和隔离性如果多个事务并发的执行，即使每个事务都能确保原子性和一致性，但是它们的操作会以人们所不希望的某种方式交叉执行，这也会导致不一致状态(数据不能反映真实世界的状态)。 123456789101112现在开启两个事务T1和T2T1事务为转账事务(A向B转账100元)A=A-100;B=B+100;T2事务为查询A和B账户余额和并存储SUM=A+B;=================有两条记录(A,1000)(B,1000) 我们考虑这样一种执行情况：在事务T1执行完A=A-100后，执行B=B+100之前，T2事务查询A和B账户余额和，那么此时事务2存储的两者和为1900。我们发现：事务1和事务2都满足原子性和一致性，但是最终却导致数据库处于不一致状态。 解决事务在并发执行下所引起的问题，其中一种解决方案是让事务一个接一个的执行。这样就保证了即使多个事务并发执行，仍能够保证一致性。但是这种方法效率比较低，有时候我们会适当的弱化一致性，设置较低的隔离级别来提升性能，至于怎么做，我们留到我们下一篇文章介绍的四大隔离级别。 持久性持久性和其它三个特性关系不是特别大，并且比较简单。因此留在最后进行介绍。一个事务提交后，该事务对数据库的改变必须是永久的，即使发生故障信息也不会丢失。 对事务ACID四大特性的介绍就到这里，在写博客的同时我也在边查阅边学习边记录，因此修修改改了很久，到现在也算是对ACID四大特性有了一定的认识，如果有哪里不准确欢迎指正。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>数据库</tag>
        <tag>事务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库范式那点儿事]]></title>
    <url>%2F2020%2F02%2F23%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E8%8C%83%E5%BC%8F%E9%82%A3%E7%82%B9%E5%84%BF%E4%BA%8B%2F</url>
    <content type="text"><![CDATA[什么是范式？范式是符合某一级别的关系模式的集合。关系型数据库中的关系必须满足一定的要求，满足不同程度要求的为不同范式。下面将主要介绍数据库的三大范式，并对BC范式进行简单了解。 前言在正式学习范式之前，我们先要了解几个介绍范式用到的概念。由于书本的严谨性，书上讲解的关于范式的理论过于抽象，在本文将尽力用通俗易懂的说法和适当的举例把范式这块介绍清楚。 函数依赖对于关系模式r(R)，关系模式名为r，属性集为R。对于其中的两个属性集α和β(α∈R且β∈R)。如果某两行记录他们在属性集α上的取值相同，那么这两条记录他们在β上的取值一定相同，记作α-&gt;β(β函数依赖α)。 12345举例说明：对于一个关系模式(一张表)r&lt;ID,name,class,phone,address&gt;属性集α&lt;ID&gt; 属性集β&lt;name,class,phone,address&gt;我们知道ID是唯一的，ID相同的两条记录他们的&lt;name,class,phone,address&gt;一定相同。因此说明β依赖于α，即α-&gt;β。 完全依赖如果存在两个属性集α和β，并且α-&gt;β。那么β依赖于α中所有属性，而不是依赖于α中的某些属性，则称β完全依赖与α。说起来可能难以理解，我们举个例子 123456789属性集α&lt;商品数量,单价&gt;属性集β&lt;总价&gt;在上述两个属性集中，β由α中所有属性决定，因此β完全依赖于α==============属性集α&lt;商品数量，单价，日期&gt;属性集β&lt;总价&gt;在上述两个属性集中，β只由α中的两个属性&lt;商品数量,单价&gt;决定，不受日期影响因此β部分依赖于α 传递依赖有三个属性集α、β、γ。其中α-&gt;β，β-&gt;γ。那么可以得到α-&gt;γ，即γ传递依赖于α。同样的我们举例说明 123456789现有一关系模式r&lt;student_ID,name,dept_ID(系编号),dept_name&gt;，其中student_ID是主码假设三个属性集α&lt;student_ID&gt;β&lt;dept_ID&gt;γ&lt;dept_name&gt;我们可以得到α-&gt;β，β-&gt;γ。这不难理解那么我们可以得到α-&gt;γ，即&lt;student_ID&gt; -&gt; &lt;dept_ID&gt;事实上也是这样，因为α是主码属性集 对于概念的介绍就到这里，不知道你理解了没有。接下来就一次介绍三大范式 第一范式(1NF)范式定义第一范式的定义为：符合1NF关系中的所有属性都不可再分，同一列不能有多个值(不能有多值属性)。 反面案例 属性可再分该关系模式就不满足第一范式，因为进货属性和售价属性可以被分割成属性 多值属性对于图中关系模式的phone属性，一个人可以有多个电话号码(同一列有多个值)，因此该关系模式不符合第一范式。 解决方法 对于非原子属性(复合属性)，解决方法很简单，我们直接将该属性的所有子属性拿出来作为关系模式的属性即可。如图，该关系模式就符合第一范式 对于多值属性，将该属性单独拆分成一个关系。对于多值属性，单独创建一个关系，和原关系模式进行外码约束 12关系1&lt;ID,name&gt; ID为主码关系2&lt;ID,phone&gt; ID为关系1的外码，&lt;ID,phone&gt;共同构成关系2主码 总结对于关系型数据库而言，1NF是最基本的要求。我们在关系型数据库(MySQL,SQLServer,Oracle等)中创建表的时，如果不符合1NF，那么操作是一定不可能成功的。换句话说，只要在关系型数据库中存在的表，一定符合1NF。 第二范式(2NF)范式定义第二范式的定义为：在满足第一范式的基础上，所有的非主属性对码完全函数依赖。 反面案例对于图中所示的关系模式，它是满足第一范式的，但是仍然存在许多问题 数据冗余过大每一个学生的学号、姓名、系名、系主任重复多次。每个系的系主任重复多次 插入异常加入学校新创建了一个系，但是还没有招生，那么该系的信息无法插入进数据 删除异常假设某个系所有的学生都转走了，即该系中所有学生相关的记录都删除了，那么这个系相应的信息也没有了 修改异常如果李小明要转到法律系，为了保证一致性，要修改三条记录。 对于一个符合1NF的关系模式，仍然可能存在许许多多的问题，因此我们需要提高设计标准。使其符合第二范式 解决方法对于满足第一范式不满足第二范式的关系模式，要使其满足第二范式，我们应该这么做：若存在非主属性依赖于码的部分属性，那么要将发生部份依赖的这一组属性单独新建一个关系模式，并使用外码约束和原关系模式相连。具体为一下四个步骤 找出数据表中所有的码(能作为主键的属性集) 根据第一步的码，找到所有的主属性 数据表中，去掉主属性，剩下的就是非主属性 是否存在非主属性对码的部份依赖 对于上述关系模式，我们四步走 12341. 找码：α&lt;学号，课名&gt;2. 主属性：学号和课名3. 非主属性：姓名、系名、系主任、分数4. 判断是否存在部份依赖 如图得到关系模式中所有的依赖关系：可以发现，属性集&lt;学号,姓名,系名,系主任&gt;存在部份依赖。因此将该属性集提取出来创建一个新的关系模式上图所示，分解得到的两个表是满足第二范式的。 总结我们再来看看对于前面存在的4个问题，满足第二范式后还存在么？ 数据冗余：学生的姓名、系名、系主任重复次数减少，冗余情况得到改善。但是仍存在冗余(系主任) 插入异常：仍无法插入一个没有学生的新系–&gt;无改进 删除异常：删除某个系所有学生记录后，该系信息随之丢失–&gt;无改进 修改异常：李小明转到法律系后，只需要修改一条对应记录，得到改善。由此看来，当关系模式满足2NF后，仍会存在一些问题。我们发现出现问题的原因在于：存在非主属性对码的传递依赖。为了进一步解决问题，我们要使关系模式满足第三范式 第三范式(3NF)范式定义第三范式的定义为：在满足2NF的基础上，关系模式中的所有非主属性直接依赖于码，不存在传递依赖 反面案例对于该满足第二范式的两个表，我们来看一看它们是否也满足第三范式 选课表主码为&lt;学号,课名&gt;，主属性为学号和课名，非主属性为分数。不可能存在传递依赖，所以选课表满足3NF。 学生表主码为学号，主属性为学号，非主属性为姓名、系名和系主任。因为学号-&gt;系名，并且系名-&gt;系主任，因此学号-&gt;系主任。存在传递依赖，故学生表不满足3NF。 解决方法如果关系模式中存在非主属性对主码的传递依赖，那么我们将发生传递依赖的属性创建一个新的关系模式，并和原关系模式外码约束。从图中可以看到，学生表的系主任对主码存在传递依赖，因此我们将发生传递依赖的部分&lt;系名,系主任&gt;单独创建关系模式，并使用外码约束： 总结经过分解，由最开始的一个关系模式得到现在的三个关系模式，并且三个模式都满足3NF，那么我们再来看看满足第三范式后，前面的问题还存在么？ 数据冗余：在2NF的基础上，更加少了。 插入异常：可以插入一个没有学生的系。 删除异常：删除某个系所有的学生记录，那么该系仍然存在。 总结我们看到，在满足第三范式，基本上就解决了数据冗余、插入异常、删除异常和修改异常的问题。除了第三范式以外，还有BC范式，第四范式，第五范式甚至是第六范式。那么我们在设计数据库时，是满足范式等级越高越好么？当然不是这样！！！我们可以看到，满足的范式等级越高，表的数量越多。这往往也会带来一些问题:我们在使用数据库时，往往是查询操作比较多，当表过多时，查询时就需要连接多个表，增加了查询的复杂性，降低了数据库的性能。因此我们在实际应用中只一般只需要满足第三范式即可。最后再对三大范式进行总结 1NF：字段是最小的的单元不可再分 2NF：满足1NF,表中的字段必须完全依赖于全部主键而非部分主键 (一般我们都会做到) 3NF：满足2NF,非主键外的所有字段必须互不依赖 参考书籍：《数据库系统概念》详细图文讲解(包含BC范式)知乎总结回答]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>三大范式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一个Web页面的请求(计网知识综合)]]></title>
    <url>%2F2020%2F02%2F21%2F%E4%B8%80%E4%B8%AAWeb%E9%A1%B5%E9%9D%A2%E7%9A%84%E8%AF%B7%E6%B1%82-%E8%AE%A1%E7%BD%91%E7%9F%A5%E8%AF%86%E7%BB%BC%E5%90%88%2F</url>
    <content type="text"><![CDATA[学习计算机网络以来，我陆陆续续写了很多这方面的博客，到上一篇为止，链路层的以太网已进行了介绍。因此在本文中，我希望对之前学过的知识做一个全面的整合梳理，所以我就以一个Web页面的请求过程为例，来对前面学过的知识进行整合梳理。 前言如图所示：一名学生A将他的笔记本与学校的以太网交换机相连，下载一个Web页面(假设是谷歌的主页)。我们假定A启动他的计算机，然后用一根以太网电缆连接到学校的以太网交换机，交换机又和学校的路由器相连。学校的路由器和一个ISP相连(图中ISP为comcast.net)。comcast.net为学校提供了DNS服务，并且DHCP服务器运行在路由器中。 准备：DHCP、UDP、IP和以太网当A将计算机和网络连接时，该主机还没有IP地址，如果没有IP地址那么它就不能做任何事情。因此，计算机所采取的第一个网络相关动作是运行DHCP协议，从本地DHCP服务器中获得一个IP地址以及其他信息。 计算机的操作系统生成一个DHCP请求报文(为了方便起见，这里省略了DHCP协议的前两步骤，实际上前面两步并不是必须的)，并将这个报文放到目的端口为67(DHCP服务器)和源端口68(DHCP客户端)的UDP报文段。该报文段被封装在目的地址为255.255.255.255(受限广播地址)、源地址为0.0.0.0的IP数据报中。 包含DHCP请求的IP数据报被放置到以太网帧中。该以太网帧的目的地址为ff:ff:ff:ff:ff:ff(广播地址)，将该帧广播到与交换机相连的所有设备中；该帧的源MAC地址为A携带计算机地MAC地址00:16:D3:23:68:8A。 包含DHCP请求的广播以太网帧是第一个由主机发送到以太网交换机的帧，交换机在所有的出端口转发该帧。 路由器在它00:22:6B:45:1F:1B的端口接收到该广播帧，并从中抽取出IP数据报，并以此向上拆分得到DHCP请求报文(由于DHCP服务器运行在路由器中，实际上进行拆分的是DHCO服务器，路由器只能处理IP数据报)。 我们假设路由器能够以CIDR块68.85.2.0/24分配IP地址。所以在本例中，在学校内使用的所有IP地址都在Comcast地址快中。我们假设DHCP服务器分配地址68.85.2.101给计算机。DHCP服务器生成包含这个IP地址以及DNS服务器的IP地址(68.87.71.226)、默认网关路由器的IP地址(68.85.2.1)和子网块(68.85.2.0.24,等价为网络掩码)的DHCP ACK报文。该DHCP报文被放到UDP报文段中，UDP报文段被封装到IP数据报中，IP数据报又被封装到以太网帧中(这里源IP/MAC地址是路由器归属网络这一端端口的IP/MAC地址，目的IP/MAC地址是计算机的IP/MAC地址)。 包含DHCP ACK的以太网帧由路由器发送给交换机。由于交换机自学习特性，该帧会直接从和计算机关联的端口转发出去。 计算机收到包含DHCP ACK的以太网帧，层层提取得到DHCP ACK报文。DHCP客户端记录它的IP地址和DNS服务器的IP地址，并在其IP转发表中安装默认网关地址。此后计算机会向默认网关发送目的地址为其子网以外的所有数据报。 到此为止，一台刚刚连接网络的计算机有了属于自己的IP地址以及其它信息，能够和网络进行交互。 继续准备：DNS和ARP当计算机可以上网后，当学生A将www. google.com的URL键入到其Web浏览器时，他开启了一系列事件，最终谷歌主页会显示到浏览器上。A的浏览器通过生成一个TCP套接字开始了该过程，套接字用于向www. google.com发送HTTP请求。为了生成该套接字，计算机需要知道www .google.com的IP地址，因此我们会用到DNS协议。 计算机的操作系统生成一个DNS查询报文，该报文被放到端口号53的UDP报文段中。该报文段被放置到目的地址为68.87.71.226(DNS服务器IP地址，在DHCP ACK中得知)中 将包含DNS查询报文的IP数据报封装到以太网帧中发往网关路由器(68.85.2.1)，那么问题来了：主机只知道网关路由器的IP地址(来自DHCP ACK)，并不知道该路由器的MAC地址，为了获取路由器的MAC地址，要用到ARP协议。 计算机生成一个ARP查询报文(该报文的目的IP为路由器的IP地址，目的MAC地址为00:00:00:00:00:00)，并将该查询报文封装到广播帧中，交换机广播该帧。 网关路由器收到包含ARP请求报文的广播帧后，生成一个ARP响应报文(在该报文中附带了自己的MAC地址)，并将该响应报文封装到目的MAC地址为00:16:D3:23:68:8A(计算机)的以太网帧中。向交换机发送该帧，再由交换机发送给计算机。 计算机收到该ARP响应报文后，从中得到网关路由器的MAC地址。 最终，包含DNS查询报文的IP数据报被封装到以太网帧中，该帧的目的地址为网关路由器靠近网络一端的MAC地址。计算机向交换机发送该帧，再由交换机发送给路由器。 仍在准备：跨越网络的DNS查询 网关路由器接受该帧，并抽取得到IP数据报，路由器通过IP数据报的目的IP地址和转发表决定将该数据报发送到Comcast网络的最左边路由器。于是IP数据报放置到链路层帧(此时链路层运行的可能不是以太网协议)中，发往下一台路由器。 在Comcast网络最左边的路由器接收到该帧，抽取得到IP数据报，检查目的地址并根据转发表确定出口，封装成帧后继续往下一个路由器出发。 经过若干路由器后，最终包含DNS查询报文的IP数据报到达DNS服务器。DNS服务器得到www. google.com的IP地址(64.233.169.105)。形成DNS应答报文返回给计算机。(这里假设DNS服务器缓存有相应的记录，并不需要进行递归+迭代查询) 计算机得到DNS应答报文，从中获取www. google.com的IP地址。经过大量工作后，下一步就能和www. google.com服务器正式接触了。 Web交互：TCP和HTTP 既然得知了www. google.com的IP地址，那么套接字也就能够生成了。该套接字用于向www. google.com服务器发送HTTP GET报文。当计算机生成TCP套接字时，必须先进行三次握手。 在www. google.com的HTTP服务器从TCP套接字中获取HTTP GET报文，生成一个HTTP响应报文，将计算机请求的Web页面放到响应体中，并将响应报文推送进套接字。 包含HTTP响应报文的数据通过谷歌、Comcast和学校网络转发，到达学生A的计算机。计算机的Web浏览器程序从套接字读取HTTP响应报文，从响应体中获取html文件。最终显示到Web浏览器上。 小结一个Web页面的请求过程大致就是这些，可能在实际工作中有一些差异，但基本流程大同小异。有一点我还是有疑惑的：通过ipconfig/all命令我发现，默认网关、DHCP服务器以及DNS服务器的地址是一样的。如图所示：个人猜测，可能是将DHCP服务器和本地DNS服务器都放到了网关路由器中，因此三者的IP地址一样。]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[链路层协议之以太网协议的前世今生]]></title>
    <url>%2F2020%2F02%2F19%2F%E9%93%BE%E8%B7%AF%E5%B1%82%E5%8D%8F%E8%AE%AE%E4%B9%8B%E4%BB%A5%E5%A4%AA%E7%BD%91%E5%8D%8F%E8%AE%AE%E7%9A%84%E5%89%8D%E4%B8%96%E4%BB%8A%E7%94%9F%2F</url>
    <content type="text"><![CDATA[我们知道，在因特网五层体系中，链路层位于第二层。而以太网协议又是当今世界上最流行的局域网协议，今天就让我们走进链路层，了解一下以太网协议的前世今生。 前言在链路层的讨论中，我们将看到两种截然不同的链路层信道 点对点链路其中，点对点链路由链路一端的单个发送方和链路另一端的单个接收方组成，许多链路层协议如点对点协议(PPP)、高级数据链路控制协议(HDLC)就是为点对点链路设计。 广播链路能够让多个发送和接收节点都连接到相同的、单一的、共享的广播信道上。这里之所以使用广播这一术语，是因为当任何一个节点传输一个帧时，信道广播该帧，每个其他节点都收到一个副本。以太网和无线局域网就是广播链路层技术的例子。 多路访问问题在具体介绍以太网之前，我们先研究一个对链路层很重要的一个问题：如何协调多个发送节点和接收节点对一个共享信道的访问，即多路访问问题。因为所有的节点都能够传输帧，所以多个节点可能会同时传输帧。当发生这种情况时，所有的节点同时接收到多个帧；也就是说，传输的帧在所有的接受方处发生碰撞。当碰撞发生时，没有一个节点能够有效地获得任何传输的帧。当许多节点要频繁的传输帧时，如果不进行协调，那么就会发生大量的碰撞，导致许多帧失效，从而造成信道的浪费。大量的链路层技术中已经实现了几十种多路访问协议，我们可以将这些协议分为三类 信道划分协议(频分复用、时分复用、码分复用) 随机接入协议 轮流协议 其中，信道划分协议和轮流协议在这里不是重点，我们主要对随机接入协议进行介绍，因为以太网采用的就是这类协议。 局域网协议的鼻祖-ALOHA协议ALOHA协议属于随机接入协议。对于一个纯ALOHA协议： 如果一个节点有数据，则立即发送(想发就发，并不关心此时广播信道是否被占用)。并通过信号反馈检测信道以确定是否发送成功。 如果发送失败，则经随机时延后再发送 总结一下就是每个站点可在任意时间发送数据，不关心信道是否被占用，两个以上的节点在发送数据时就会发生冲突 我们可以看到，这种纯ALOHA协议在活跃节点较多时可能会发生严重的碰撞。事实上，通过计算可以知道该协议的信道利用率最高仅为18%。即82%的信道都被浪费。 ALOHA协议的改进-时隙ALOHA协议人们对ALOHA协议进行了改进，发明了时隙ALOHA协议。在时隙ALOHA协议中 把时间分成时间片，时隙的长度对应一帧的传输时间 帧是随机产生的(数据随即到达节点)，但是时隙ALOHA不允许随机发送(和纯ALOHA的区别)，规定每个节点必须在时隙的起点发送帧 这样冲突只会在时隙的起点发生，冲突发生时只会浪费一个时隙。 可以看出，和纯ALOHA相比，时隙ALOHA只会在时隙开始部分发生碰撞。相比于纯ALOHA信道利用率提高了一倍，事实上通过计算可以得到时隙ALOHA的信道利用率为37%。虽然ALOHA协议从今天看来效率并不算高，但是正是在ALOHA协议的启发下，Metcalfe修改了ALOHA协议，创造了CSMA协议和以太网 载波侦听多路访问-CSMA协议无论是纯ALOHA协议还是时隙ALOHA协议，一个节点的传输独立于连接到这个广播上的其他节点的活动。即，一个节点不关心在它开始传输时是否有其它节点在传输。在CSMA协议中： 节点在发送数据之前，先侦听信道 如果信道忙，则等待；如果信道空闲，则立即发送数据 CSMA协议分为三种 1-坚持CSMA：侦听到信道忙，则持续侦听，一旦空闲立刻发送 0-坚持CSMA：侦听到信道忙，则等待一随机时间后重新侦听。 p-坚持CSMA：侦听到信道忙，则持续侦听，信道空闲后p概率发送，(1-p)概率等待一个时隙发送。 但是在CSMA协议中还存在一个问题：当发生碰撞后，节点还在继续传输帧，造成信道浪费。你可能会好奇，在发送之前都已经侦听了为什么还会出现碰撞？这个问题留到后面介绍总线型以太网时解答。 具有碰撞检测的CSMA-CSMA/CD协议CSMA/CD工作流程在CSMA/CD协议中(我们假设以太网采用CSMA/CD协议，事实上现在以太网已经不使用该协议)： 准备发送：适配器从网络层获得一个分组，加上以太网首部，组成以太网帧放到缓存中，在发送之前先侦听信道 侦听信道：不同的侦听信道(1-坚持)，一直等到信道空闲，并在96bite时间(帧间隙，以太网规定连续发送两个帧，他们之间应该间隔的时间)内信道保持空闲，就发送该帧 在发送的过程中持续侦听信道，即边发送边侦听 如果在发送的过程中没有检测到碰撞，则该帧发送成功 如果在发送过程中检测到碰撞，则停止传送该帧，并发送32bite人为干扰信号。然后执行指数退避算法，等待一定时间后回到步骤2。若重传16次仍不能成功，则停止重传向上报错。 因此以太网每发送一帧，一定要将已经发送的帧暂时保留，如果在发送时检测到碰撞，那么还要进行重传。 指数退避算法当传输一个给定帧时，在该帧经历了一连串的n次碰撞后，该节点随机从{0,1,2,…,2(n次方)-1}中随机选择一个值K(K的最大值为10)，等待K*512bite时间后重新发送该帧。这就是二进制指数退避算法。 以太网协议在介绍以太网时，我将先介绍以太网帧的格式。这样做是由原因的，以太网经过这么多年的发展，早已和最初的以太网大不相同，唯一不变的就是以太网帧的格式了。其次我将一次介绍三个阶段的以太网：总线型、集线器型以及交换机型。 以太网帧格式如图所示即为以太网帧格式图 前同步码(8个字节)：用于唤醒接收适配器并同步接收方和发送方时钟 目的地址/源地址(各6字节)：使用的是MAC地址 类型(2字节)：当以太网帧到达主机适配器，适配器通过该字段得知该帧需要交给哪一个网络层协议 数据(46~1500)：封装的是网络层数据报，有时还有一些填充数据 CRC校验码(4字节)：以太网采用CRC来完成差错控制 为什么数据字段的长度为46~1500？以太网帧的首部加尾部(前同步码不算)一共6+6+2+4=18字节，而以太网帧最短为64字节(后面会说到原因)，因此当网络层数据报小于46字节时，以太网帧要进行填充，保证数据部分最小为46字节。 以太网帧的最大长度是多少？以太网帧的最大长度(不包括前同步码)：帧首部+帧尾部+最大数据=14+1500+4=1518。这里要注意的是，TCP的最大数据字段(MSS)为1460，IP数据报最大为最大传输单元(MTU)1500，以太网帧最大为1518。 以太网的发展上面介绍了这么多，重点在于CSMA/CD协议。而介绍CSMA/CD协议，也是为了以太网协议做铺垫。以太网协议经历了三个阶段 20世纪70年代中期，初期以太网问世，初始的以太网用同轴电缆来连接节点，使用总线拓扑结构。此时以太网还是一个半全工网络，采用了CSMA/CD协议。 20世纪90年代后期，基于集线器的星形拓扑结构的以太网问世，此时以太网仍是采用CSMA/CD协议(后面会介绍集线器) 21世纪初，以太网经发生了革命性变化，基于以太网交换机的星形拓扑结构的以太网得到了应用，由于交换机的特性，CSMA/CD协议已经不再使用，此时以太网协议为双全工。 总线型以太网如图即为早期的总线拓扑结构的以太网。当一台计算机发送数据时，总线上的所有计算机都能检测到这个数据。当我们需要在总线上进行1对1通信时，就需要使每一台计算机的网卡拥有一个与其他网卡都不同的地址(MAC地址)，我们发送帧时表明接收方的地址，只有地址与其相同的主机才接受该帧，否则否则丢弃帧。 无连接工作方式为了通信方便，以太网采用了无连接的工作方式，即不必建立连接就可以直接发送数据。网卡对发送的数据帧不进行编号，也不要求对方进行确认，这样做可以使以太网工作起来非常简单。以太网所提供的服务是尽力而为服务，即不可靠的服务。 CSMA发生碰撞原因？前面有一个问题：既然CSMA(或CSMA/CD)在发送之前已经侦听信道，为什么还是会出现碰撞？我们现在假设一个以太网上只有两台主机A、B。它们都挂在一个总线上 此时主机A要发送数据，A侦听信道，发现空闲，则开始传输帧 过了很短的时间，主机B也要发送数据，此时由于A的数据还没有传播到B，因此B侦听信道时发现信道也是空闲的，B开始传输帧。 这样一来，就会发生碰撞。 以太网帧最小长度SMA/CD协议在帧的传输期间如果检测到碰撞，则会停止传输帧发送干扰信号，等待一定时间(指数退避)后重传该帧。那么可能存在这样一种情况：节点A发送了一个帧，但发生了碰撞，不过在帧发送完后才检测到发生了碰撞(即帧传输完后碰撞信号才到达节点A)，这时已经没有办法中止帧传输，该帧也无法重传，就会产生错误。注：数据帧能够重传需要保证发送节点在收到冲突信号时帧没有传输完基于上述情况，以太网规定了以太网帧的最短长度为64字节，即512bite。如图，一个站点在发送帧后，持续侦听2d时间就能够确定此次传输不会出现碰撞。这段时间就是所谓的争用期。争用期通常取值为51.2μs，对于10Mb/s的以太网来说，在争用期可以发送512bite，也就是64字节。这就是以太网帧长最短为64字节的原因。 那么节点一定能在51.2μs中检测到冲突么？我们来算一算:12345电磁波在1km电缆的传播时延为5μs，即信号在以太网上传播1km需要5μs以太网两端点的最大传播时延应该小于争用期的一半(小于25.6μs)即侦听信号一来一回的时间小于51.2μs，因此以太网的最大端到端长度为25.6/5≈5km。而实际上以太网覆盖范围远没有那么大，因此实际应用的以太网都能在争用期检测可能发生的碰撞。 但是要注意，以太网选择51.2μs作为争用期，并不仅仅考虑了端到端时延，还考虑了其他很多因素。 以太网帧最大长度前面说了，以太网帧的最大长度为1518，那么为什么要这样设置呢？ 为了防止节点占用信道时间过长 相对于小包来说，大包更容易发生丢包。 如果最大帧长过小，传输速率又不高。例如12345678如果选择以太网最大帧长为218Byte那么TCP可携带数据=218-以太网首部/尾部-IP首部-TCP首部=160此时有效传输速率为160/218=73%======================当最大帧长为1518时有效传输速率为1460/1518=96% 以太网为什么建立重传机制？我们知道CSMA/CD中当帧出现碰撞时，节点会在之后重传该帧，那么这样做的原因是什么呢？首先，我们前面说过，以太网是无连接的，这样能够提高效率；但是以太网又想实现一定的重传机制，因为以太网的重传是微妙级，而传输层的重传如TCP达到毫秒级，应用层的重传更是达到了秒级。因此在以太网上实现一定的重传机制能够提高效率。 基于集线器以太网集线器是一个物理层设备，它作用于bite而不是帧。当一个bite到达集线器其中一个接口时，集线器重新生成该bite并对其进行放大，然后将其转发到其他所有接口。如图为基于集线器的以太网结构，由于集线器具有以下特点 集线器只是简单地转发bite，不会进行碰撞检测 集线器不会对帧进行缓存 当有两个不同的端口同时收到帧时，就会出现碰撞 事实上基于集线器的以太网在逻辑上仍是总线网，各节点共享逻辑上的总线，仍使用CSMA/CD协议。 集线器的作用基于集线器的以太网要比总线以太网好在哪里呢？让我们来看一下集线器的作用 能够对信号进行放大，使其传播距离更远 当其中一个端口出现故障时，集线器能够自动隔离该端口。不会影响其他节点 避免各个网段之间发生冲突，如上图，A向B发送数据可以和E向F发送数据同时进行。 总结集线器和我们后面说到的以太网交换机不同，它不具有MAC地址，只是简单的转发放大bite，因此基于集线器的星形拓扑以太网在逻辑上仍是总线型以太网，只不过和总线型以太网相比它更加健壮。 基于交换机以太网从集线器到以太网交换机，这是以太网的革命性进步。以太网仍采用星形拓扑结构，不过集线器被交换器所取代。接下来我们将认识到：由于交换机的使用，此时的以太网已经不需要使用CSMA/CD协议了，因为交换机本身就是无碰撞的，并且能够实现存储转发分组。 以太网交换机和集线器不同，以太网交换机工作于链路层。交换机自身对于子网中的主机来说是透明的，即某主机/路由器向另一个主机/路由器寻址一个帧(而不是向交换机寻址该帧)，然后将该帧送进局域网，并不知道某交换机将会接受该帧并将它转发到另一个节点。并且交换机的输出接口设有缓存，让我们来看一下交换机的工作原理。 转发和过滤过滤是决定一个帧应该转发到某个接口还是应该将其丢弃的交换机功能。转发是决定一个帧应该被导向哪个接口，并把该帧移动到那些接口的交换机功能。交换机的转发和过滤借助于交换机表完成。交换机表和路由器表类似，由{MAC地址|接口|时间}三项组成。借助该表和帧的目的MAC地址，交换机能够将该帧丢弃或者转发到对应的接口。如上图是一张交换机表，为了便于理解该表我们举例说明假定目的地址为DD:DD:DD:DD:DD:DD的帧从接口1到达。交换机用该目的地址对交换机表进行索引，此时有三种情况： 表中没有DD:DD:DD:DD:DD:DD的表项，此时交换机向除了接口1的所有接口转发该帧 表中有DD:DD:DD:DD:DD:DD的表项，但是该项和接口1关联，那么交换机丢弃该帧 表中有DD:DD:DD:DD:DD:DD的表项，并且和除了接口1的其他接口关联(假设是接口2)，交换机将该帧从接口2转发出去 自学习方式通过前面的介绍我们了解了交换机如何借助交换机表进行工作，那么问题来了：交换机表是怎么来的呢？是人工配置的么？答案当然是否定的。事实上交换机具有令人惊奇的特性，那就是它的表是自动、动态和自治地建立地。换句话说，交换机是自学习的。 交换机表初始为空 对于在每个接口收到的每个入帧，该交换机在其表中存储{该帧地源MAC地址|该帧到达地接口|该帧到达的时间}。 如果在一段时间(老化期)后，交换机没有收到以该地址为源地址地帧，那么就在表中删除该项。 链路层交换机的性质上面介绍了交换机的工作原理，这里补充一点：交换机是即插即用设备(不需要认为干预)并且是双全工的。下面就介绍一下交换机的性质 消除碰撞这一点非常重要，在使用交换机的以太网中，没有因碰撞而浪费带宽。也是由于这一点，基于交换机的以太网已经不再使用CSMA/CD协议 异质的链路交换机将链路彼此隔离，因此局域网中不同的链路能够以不同的速率运行并且能够在不同的媒体上运行。 总结对于以太网的介绍就到这里，以太网经过几十年的发展，几乎占领着整个有线局域网市场。而以太网经过不断的改革进化已经发展成如今的基于以太网交换机的、星型拓扑结构的双全工以太网。今天的以太网经过了千变万化，唯一保持不变的就是以太网帧格式，或许这才是以太网标准的一个真正重要的特征。 参考书籍：《计算机网络自顶向下方法》链路层帧长度集线器相关CSMA/CD协议(较全面)]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>以太网协议</tag>
        <tag>链路层</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网络工具之科来数据包生成器]]></title>
    <url>%2F2020%2F02%2F19%2F%E7%BD%91%E7%BB%9C%E5%B7%A5%E5%85%B7%E4%B9%8B%E7%A7%91%E6%9D%A5%E6%95%B0%E6%8D%AE%E5%8C%85%E7%94%9F%E6%88%90%E5%99%A8%2F</url>
    <content type="text"><![CDATA[学习完了ARP协议后，准备模拟一下ARP欺骗。上网查阅相关资料发现，要自行实现ARP欺骗，需要WireShark抓包工具和一个数据包生成器协助实现，并且需要两台主机(或者一台主机上安装一个虚拟机)，因此这里先学习一下科来数据包生成器的使用，开学后借助室友电脑来完成ARP欺骗。 下载安装(Win10环境) 百度搜索科来，点击第一条进入科来官网下载界面并点击下载中心 如图，进入下载中心后不要直接下载科来数据包生成器(直接下载该应用会出现找不到网卡的错误) 剩下的就是下载安装，傻瓜式一直下一步即可。 科来数据包生成器使用 安装完成后打开界面，如图点击左上角按钮-&gt;点击工具-&gt;选择数据包生成器工具 打开数据包生成器界面后，点击添加按钮，可以选择要生成的数据包。 可以对数据包进行编辑，修改IP地址、MAC地址等。 点击发送即可将构造好的ARP分组发给指定主机/路由器。 总结备忘有了以上的知识基础，再搭配WireShark抓包工具。就可以实现ARP欺骗，开学后完成该实验，特此备忘！]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>网络工具</tag>
        <tag>科来</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网络层协议之ARP协议]]></title>
    <url>%2F2020%2F02%2F18%2F%E7%BD%91%E7%BB%9C%E5%B1%82%E5%8D%8F%E8%AE%AE%E4%B9%8BARP%E5%8D%8F%E8%AE%AE%2F</url>
    <content type="text"><![CDATA[尽管有些书上将ARP协议看作是位于网络层和链路层之间的协议，但是和IP协议一样，ARP协议是封装在链路层帧上在网络中传输的。因此我更倾向于把ARP协议当作网络层协议。下面就让我们来学习一下ARP协议。 简介网络设备有数据要发送给另一台网络设备时，必须要知道对方的网络层地址（即IP地址）。IP地址由网络层来提供，但是仅有IP地址是不够的，IP数据报文必须封装成帧才能通过数据链路进行发送。数据帧必须要包含目的MAC地址，因此发送端还必须获取到目的MAC地址。通过目的IP地址获取的MAC地址的过程是由ARP（Address Resolution Protocol）协议来实现的。 MAC地址IP地址前面介绍过，就不做赘述。这里主要介绍一下MAC地址。实际上，并不是主机或者路由器具有MAC地址，而是它们的适配器(网络接口)具有MAC地址。因此，如果一个主机或路由器有多个网络接口，那么它就有多个MAC地址。MAC地址长度为6个字节，通常用十六进制表示法，每个字节用一个十六进制数表示，字节之间用’-‘连接，例如：ff-ff-ff-ff-ff-ff。 MAC的获取和IP地址不同，MAC地址是一个硬件地址，是制造商在制造的时候添加的，一旦确定不会发生变化。并且每个网络接口的MAC地址都是独一无二的。那么制造商的MAC地址是哪来的呢？答案是IEEE。该机构在管理着MAC地址空间，当一个公司要生产适配器时，它象征性的支付一定的费用购买组成2(24次方)个地址的一块地址空间。IEEE分配的方式是：前24个比特由IEEE指定，后面24个bite由生产厂商自己搭配。 ARP协议ARP分组格式这里直接简单的介绍一下ARP分组的格式作为了解，对于ARP协议，主要在于了解它的工作流程 硬件类型：发送方硬件接口类型，1为以太网 协议类型：发送方请求解析的协议地址类型，0x0800为IP协议地址 硬件地址长度：发送方硬件地址长度，MAC地址(以太网地址)为48 协议地址长度：请求解析的协议地址长度，IP协议为32 操作类型：本报文的操作类型，1为ARP请求、2为ARP响应、3和4分别为RARP请求和响应 剩下的就是源IP地址和源MAC地址以及目的IP地址和目的MAC地址 ARP协议工作流程(重要)现在假设在一个局域网内有两台主机A、B。现A要向B发送数据。因此数据在主机A中被层层封装，应用层、传输层、网络层、链路层。但是问题来了：A只知道B的IP地址，因此只能封装到网络层(即将数据封装成IP数据报)，如果要将IP数据报成帧，那么就必须知道B的MAC地址。那么A如何得知B的MAC地址呢？ 每台主机内都有一个ARP缓存表，该表记录了最近运行时使用过的(IP-MAC)映射对，如果A的ARP缓存表中有B的IP-MAC映射，那么直接将B的MAC地址作为目的MAC地址，成帧后发送给主机B。如果所示在Windows下使用arp-a查看本机ARP缓存： 如果本机的ARP缓存中没有目标主机的(IP-MAC)映射对，则在本局域网内发送广播帧(即链路层帧首部的目的MAC地址字段为ff-ff-ff-ff-ff-ff-ff)，本局域网内的所有主机都会收到该ARP广播帧，但是只有IP地址和ARP中的目的IP相同的主机在会进行响应，向发送方回送一个标准帧(目的地址为发送方MAC地址)，其余的主机会丢弃该分组。 当主机A收到B的ARP响应后，就得知了主机B的MAC地址，因此就能和主机B进行数据传输了。 有一点需要区分清楚：ARP请求分组中的源IP地址和源MAC地址为A的IP地址和MAC地址，而目的IP地址为B的IP地址，目的MAC地址为0-0-0-0-0-0(因为A并不知道B的MAC地址)。 通过WireShark捕获的一组ARP请求/响应报文从图中我们可以清楚的看到，ARP请求报文中目的MAC地址为0-0-0-0-0-0，但是应该是由于缓存的原因，该请求报文是一个标准帧而不是一个广播帧。 免费ARP前面介绍的ARP又被称为标准ARP，那么我们接下来就介绍另外一种：即免费ARP协议(又称无偿ARP协议)。免费ARP的主要作用为验证同一个局域网中该主机的IP地址是否冲突。当一个ARP请求分组满足以下条件时： 源IP和目的IP相同，都是发送该ARP报文的主机IP地址 源MAC地址为该主机的MAC地址 目的MAC地址为0-0-0-0-0-0(和ARP请求报文一样) 是一个广播帧(链路层首部字段的目的MAC地址为ff-ff-ff-ff-ff-ff-ff)。 通俗的说，免费ARP可以这么理解：一个主机A对一个局域网内的所有其他主机发起询问:我的IP地址是….，有没有和我重复的。]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>网络层</tag>
        <tag>ARP协议</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[通过WireShark抓包学习DHCP协议]]></title>
    <url>%2F2020%2F02%2F17%2F%E9%80%9A%E8%BF%87WireShark%E6%8A%93%E5%8C%85%E5%AD%A6%E4%B9%A0DHCP%E5%8D%8F%E8%AE%AE%2F</url>
    <content type="text"><![CDATA[当我们的主机接入网络时，它还没有自己的IP地址、子网掩码等一些必要的信息，这些信息需要从别处获取。那么这些信息是如何获取的？是人为配置的么？当然不是的。如果每一台主机的接入和断开都需要网络管理员进行配置(IP的分配回收等)，那管理员是忙不过来的。幸好，有DHCP协议来自动完成这些配置。下面，我将通过WireShark抓包来具体的介绍DHCP是如何工作的。 前期准备在学习DHCP协议之前，先介绍一个Windows命令行指令(打开CMD窗口)以及基本的WireShark操作 ipconfig命令(对于下面命令可以自己在cmd上进行试验)该命令能够查询本机的IP地址以及一些其他的信息。 ipconfig/all：显式更详细的信息 ipconfig/release：断开网络连接，主机IP变为0.0.0.0，主机与网络断开，不能访问网络。 ipconfig/renew：更新适配器信息，请求连接网络，这条命令结束之后，主机会获得一个可用的IP，再次接入网络。 WireShark操作这是WireShark3的界面，我使用的WiFi连接，因此点击WLAN选项如图，在过滤器中输入DHCP(只捕获DHCP协议的分组) 关于前期准备就介绍到这里，下面开始介绍DHCP协议。 DHCP协议DHCP简介DHCP(Dynamic Host Configuration Protocol),动态主机配置协议，是一个应用层协议并且运行在UDP协议之上。当我们将客户主机ip地址设置为动态获取方式时，DHCP服务器就会根据DHCP协议给客户端分配IP，使得客户机能够利用这个IP上网。 DHCP协议工作过程DHCP的实现分为4步，分别是： 第一步(DHCP发现)：Client端在局域网内发起一个DHCP Discover包，目的是想发现能够给它提供IP的DHCP Server。 第二步(DHCP提供)：可用的DHCP Server接收到Discover包之后，通过发送DHCP Offer包给予Client端应答，意在告诉Client端它可以提供IP地址。 第三步(DHCP请求)：Client端接收到Offer包之后，发送DHCP Request包请求分配IP。 第四步(DHCP响应)：DHCP Server发送ACK数据包，确认信息。 WireShark抓包实验实验环境 操作系统:Windows10 WireShark版本:3.2.1 网络环境:无线连接 实验步骤 使用ipconfig/release命令断开连接此时能观察到WireShark捕获到一个DHCP Release分组 使用ipconfig/renew命令重新连接此时WireShark再次捕获到4个DHCP分组在这里，有一点很重要:DHCP的四个分组中，目的地址应该都是255.255.255，但是在实际抓包实验中发现DHCP OFFER和DHCP ACK包的目的地址都是实际给主机分配的地址。这应该是缓存导致的。至于DHCP四个包的内容，有兴趣可以自行使用WireShark抓包观察一下，比较简单就不做赘述。 DHCP协议如何工作最后，将前面的文章梳理一遍，再对DHCP的工作流程进行进一步的介绍。 DHCP发现:一台新到达主机的首要任务就是发现一个要与其交互的DHCP服务器。此时主机并不知道DHCP服务器的地址，甚至还没有自己的IP地址，因此该分组的源地址为0.0.0.0，目的地址为255.255.255.255。 DHCP提供:当DHCP服务器收到一个DHCP发现报文时，用DHCP提供报文向客户作出响应，此报文的目的地址仍为255.255.255。这是因为，一个子网中可能有多个DHCP服务器，客户可以从这几个服务器中选择一个合适的。(此时DHCP为客户机保留该选中的IP，如果在此期间收到了其他主机的DHCP发现报文，该IP不会被分配给其他主机) DHCP请求:新到达主机从一个或多个服务器提供中选择一个，并向选中的服务器发送DHCP请求报文，回显DHCP 提供报文中服务器配置的参数 DHCP响应:服务器用DHCP ACK报文对客户机的请求作出响应，证实所要求的参数。 客户端在接收到DHCP ack广播后，会向网络发送三个针对此IP地址的ARP解析请求以执行冲突检测(免费ARP，后面会说到)，查询网络上有没有其它机器使用该IP地址；如果发现该IP地址已经被使用，客户机会发出一个DHCP decline数据包给DHCP服务器，拒绝此IP地址租约，并重新发送DHCP discover信息。此时，在DHCP服务器管理控制台中，会显示此IP地址为BAD_ADDRESS。 如果没有，则该IP地址正式被主机使用。 参考文章1(参考较多)参考文章2(较详细深入)]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>应用层</tag>
        <tag>DHCP协议</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[子网号全0全1那些事儿]]></title>
    <url>%2F2020%2F02%2F17%2F%E5%AD%90%E7%BD%91%E5%8F%B7%E5%85%A80%E5%85%A81%E9%82%A3%E4%BA%9B%E4%BA%8B%E5%84%BF%2F</url>
    <content type="text"><![CDATA[前面对IP编址进行了简单的介绍，同时也留下了一些问题:为什么使用分类编址时全0全1的子网号不能使用，而使用CIDR编址时子网号却可以使用全0全1？我将在这篇文章中进行详细说明。 IP寻址如果要详细的说明原因，就不得不先对IP寻址进行一个简单地介绍。 什么是IP寻址每一个路由器中都保存有一张路由表。路由表中主要有两项:网络地址(主机号全0)、下一跳地址(最佳输出链路)。当分组到达一个路由器时，需要根据分组的目的地址选择一条链路输出，这就是IP寻址。下面就分别介绍一下划分子网的IP寻址和CIDR的IP寻址 划分子网的IP寻址 当一个IP分组到达时，路由器通过子网掩码(与运算)获取该分组的网络地址(网络号+子网号) 如果是本网，则启动寻找主机过程 如果是其他网络，则根据网络前缀和路由表选择输出链路，将分组发送到下一个路由器 如果路由表中找不到目的网络，则将分组转发到缺省路由器中，缺省路由器具有更加广泛的路由信息 CIDR的IP寻址此时在查找路由表时可能会匹配到不止一个网络地址，这时应当从匹配结果中选择具有最长网络前缀的路由，即最长匹配前缀原则。网络前缀越长，其地址块就越小，因而路由就越具体。 举例说明现假设一个路由器中的路由表有两个项目 12206.0.68.0/22 出口1206.0.71.128/25 出口2 此时路由器中到达了一个分组A，该分组的目的地址为:206.0.71.128 1234567891011121314151617181. 查找路由器的第一个项目，项目1的掩码为22个连续的1，即[11111111 11111111 111111]00 00000000我们将分组A的目的地址和该掩码做与运算11001110 00000000 01000111 1000000011111111 11111111 11111100 00000000————————————————————————————————11001110 00000000 01000100 00000000即206.0.68.0，和项目1的网络地址匹配=====================================2. 查找路由器第二个项目，项目2的掩码为25个连续的1，即[11111111 11111111 11111111 1]0000000同样的，我们将分组A的目的地址和该掩码做与运算11001110 00000000 01000111 1000000011111111 11111111 11111111 10000000—————————————————————————————————11001110 00000000 01000111 10000000即206.0.71.128，和项目2的网络地址也匹配 在上述情况下，由于两个都匹配，因此选择两个匹配地址中更长的一个，即项目2。因此该分组最终从出口2转发。这就是最长匹配原则 分类编址子网划分现假设我们有一个网络：192.168.0.0(C类网络，前24位位网络号)，我们现在需要两个子网。由于子网号全0和全1不能使用，因此我们就需要从主机号中划分2位作为子网号，即 12192.168.0.64-&gt;[192.168.0.01]000000192.168.0.128-&gt;[192.168.0.10]000000 下面我们假设子网号全0和全1可以使用，那么就可以划分四个子网，即 12345678四个子网:192.168.0.0-&gt;[192.168.0.00]000000192.168.0.64-&gt;[192.168.0.01]000000192.168.0.128-&gt;[192.168.0.10]000000192.168.0.192-&gt;[192.168.0.11]000000==============================主网络:192.168.0.0 我们对上面五个网络，分别得到它们网络地址和广播地址 1234567891011121314151617181920212223主网络:192.168.0.0网络地址:192.168.0.0广播地址:192.168.0.255================子网1:192.168.0.0 -&gt;子网号全0的子网网络地址:192.168.0.0广播地址:192.168.0.63================子网2:192.168.0.64网络地址:192.168.0.64广播地址:192.168.0.127================子网3:192.168.0.128网络地址:192.168.0.128广播地址:192.168.0.191================子网4:192.168.0.192 -&gt;子网号全1的子网网络地址:192.168.0.192广播地址:192.168.0.255 通过上面的对比我们不难发现： 对于子网号全0的子网，它的网络地址和主网络的网络地址相同 对于子网号全1的子网，它的网络地址和主网络的广播地址相同 显然，这样会造成混乱。比如一个192.168.0.255的广播是发送给主网络还是发送给子网呢？这就是使用分类IP编址时子网号不能全0和全1的原因。 CIDR子网划分我们再来看看CIDR子网划分，当使用CIDR表示法时，每个IP地址后面都会有一个”/+前缀长度”。回到前面的例子，即使你使用了全0的子网(子网1)，启用CIDR的路由器总是以prefix+length的形式记录网络地址，所以 12子网的网络地址:192.168.0.0/26主网的网络地址:192.168.0.0/24 这样一来，两个网络就得到了区分。 特殊的IP地址最后，再说两个特殊的IP地址 0.0.0.0，该IP地址在主机刚进入网络还没有被分配IP地址时使用，此时主机向DHCP服务器发送分组(后面会说到)，分组的源地址即为0.0.0.0 255.255.255.255，受限广播地址。尽在本地网络广播，路由器不会转发这类分组。和0.0.0.0搭配使用，前面发送给DHCP服务器的分组源地址为0.0.0.0，目的地址就是255.255.255.255 255.255.255.255，受限广播地址。尽在本地网络广播，路由器不会转发这类分组。和0.0.0.0搭配使用，前面发送给DHCP服务器的分组源地址为0.0.0.0，目的地址就是255.255.255.255]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>IP编址</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅谈IP编址]]></title>
    <url>%2F2020%2F02%2F15%2F%E6%B5%85%E8%B0%88IP%E7%BC%96%E5%9D%80%2F</url>
    <content type="text"><![CDATA[我们知道，我们的电脑都有一个IP地址(确切的说，是一个接口对应一个IP地址，不过在这里不影响)，它能够唯一的标识我们的主机，那么电脑的IP地址又是怎么来的呢？这就涉及到了IP编址。(本文仅涉及到IPv4编址，并不涉及IPv6) IP编址的前世今生IP地址经历了三个阶段，它们分别是 分类的IP地址阶段 划分子网阶段 无分类间域路由选择(CIDR)阶段 目前主要采用CIDR编址，分类编址已经渐渐被淘汰，因此本文主要介绍CIDR编址。 分类编址早期的IP地址被分为5类，它们分别是A、B、C、D、E类。不过我们常用的只有A类、B类和C类。IP地址由网络号+主机号组成，这几类地址的不同之处在于网络号和主机号各自占的位数不同。并且对于任意一类地址，它们主机号全0和全1不能使用(有特殊用途)，因此各类地址能表示的主机数： 主机号全0:表示这个网络的地址 主机号全1:本子网内的广播地址 例如:210.45.240.0就表示一个C类地址，同样的210.45.240.255就表示该C类地址的广播地址 划分子网后来发现，使用分类编址有两个问题： 造成IP地址的大量浪费。例如：现有一个公司需要分配一个网络地址，已知该公司内有300台主机。这时候，就需要给该公司分配一个B类地址(因为C类地址最多表示254台主机)，但是问题来了，一个B类地址能够表示65534台主机，而在这里只用了300个，那么剩余的65234个IP地址都被浪费了。这样会造成IP地址的迅速衰竭。 给每一个物理网络分配一个网络号会使路由表太大。 划分方法子网划分实际上就是将原来的两级IP地址转变为三级IP地址，此时IP地址为{网络号+子网号+主机号}。从这里可以看出，子网划分其实就是从32位中拿出几位来表示子网号。要注意的是，这里网络号不变，子网号就是从主机号接走的。所以就很好理解了，子网划分实际上就是减少了主机数，分配到不同的子网，每个子网包含一定的主机数。但是对于网络外部来说，还是一个大的网络，从外部看并没有变化。有一点非常重要，由于子网号是从主机号中拿出几位表示的，而前面说过，主机号全0和全1不能使用，因此每次划分子网时，子网号全0和全1仍不能使用，因此每划分一次子网，同样会浪费一些IP地址 子网掩码子网划分中有一个十分重要的概念就是子网掩码。大家想一想，在在传输的过程中，路由器是怎么识别子网划分后的IP地址中的网络地址的？如果不提供任何信息，路由器是无法分清楚的，所以就出现了子网掩码。子网掩码很简单，就是将网络号和子网号对应的位置1，将主机号对应位置0，就得到了子网掩码。将子网掩码和IP地址做“与”逻辑运算，就得到了网络地址。 CIDR编址CIDR的全称是无分类间域路由选择，该方法在一定程度上解决了路由表过大问题。之所以被称为无分类，是因为CIDR完全放弃了之前的分类表示法，消除了传统的A类、B类、C类以及划分子网的概念。使用CIDR时，IP地址={网络前缀+主机号}/网络前缀所占位数。CIDR仅将IP地址划分为网络前缀和主机号两部分，可以说又回到了二级IP表示。但是有一点要注意，最后用斜线/分隔，并写上网络前缀所占的位数，这样就不需要告知路由器地址掩码，仅需要通过网络前缀所占位数就可以得到地址掩码。为了便于介绍，CIDR中的地址掩码在本文中仍称作子网掩码。CIDR表示法给出任何一个IP地址，就相当于给出了一个地址块，一个由连续地址构成的地址块，这样就实现了路由聚合：即从一个IP地址就可以得知一个CIDR地址块。 1234567891011例如:已知一个IP地址128.14.35.7/20。我们来分析一下128.14.35.7/20=[10000000 00001110 0010]0011 00000011即前20位是网络前缀，后12位是主机号，那么我们令主机号全0和全1就可以得到一个CIDR地址块的最小地址和最大地址128.14.32.0=[10000000 00001110 0010]0000 00000000-&gt;最小地址128.14.47.255=[10000000 00001110 0010]1111 11111111-&gt;最大地址255.255.240.0=[11111111 11111111 1111]0000 00000000-&gt;子网掩码可以看出，该CIDR地址块可以指派(47-32+1)*255=4096个IP地址包括全0和全1 CIDR子网划分CIDR表示法也可以进行进一步的子网划分，和前面的子网划分类似，我们只需要从主机号中借走一定的位数即可。但是和前面不同的是，这里子网号全0和全1可以使用。也就是说，如果借走两位作为子网号，那么可以划分4个子网。 总结(重要)通过上面的介绍，相信你对IP地址的划分已经有了初步的了解，这里再强调几点 不管是CIDR编址还是传统的分类编址，主机号全0和主机号全1都有特殊意义 主机号全0:本网络的地址 主机号全1:本网络的IP地址 CIDR的子网划分和分类编址子网划分不同的是，CIDR子网划分时子网号全0和全1可以使用(是子网号而不是主机号)。 对于上面两点你可能会疑惑为什么，但是没关系，我将在下面一篇文章中详细说明。 参考书籍：《计算机网络自顶向下方法》参考文章(内含CIDR子网划分举例)]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>IP编址</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅谈IP分片机制]]></title>
    <url>%2F2020%2F02%2F15%2F%E6%B5%85%E8%B0%88IP%E5%88%86%E7%89%87%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[我们知道，并不是所有的链路层协议都能承载相同长度的网络层分组，因为IP数据报被封装在链路层协议中，因此链路层协议的的最大传送单元(MTU)就限制了IP数据报的长度。 概念介绍在正式介绍IP分片之前，我们先学习一下几个概念 最大传送单元(MTU)一个链路层帧能够承载的最大数据量就叫做最大传送单元(MTU)。以太网的MTU为1500字节。 最大报文段长度MSS网络传输数据的最大值，不包括报头。MSS+20(TCP首部)+20(IP首部)=MTU IP分片定义在发送方，将一个较大的数据报分成几个小的数据报，使其能够封装成链路层帧；在接收方，将收到的小数据报按序组装成较大的数据报。这就是IP分片 相关首部字段IP分片借助IP首部的16比特标识、标志(R,MF,DF)以及13比特片偏移三个字段来完成。我们来一次介绍这三个字段的作用 16比特标识前面说了，在接收方将IP数据报的各个片重新组装。那么问题来了，接收方怎么知道哪些片原来是一个数据报呢？这就要借助16比特标识来分辨。在接收方，所有该字段值相同的片原来属于一个数据报，它们需要被重新组装。 标志 R:保留未用 DF:不分片标志。该位置1时，则不进行分片 MF:更多分片标志。当进行分片时，除了最后一片为0其余片都置1 13比特片偏移该字段表示分片后，该片在原来数据中的相对位置，接收方借此对片进行组装。以8个字节为单位 举例说明1234567现假设一个长4000B的数据报(那么数据部分为3980B)，到达了一个路由器，需要转发到一个MTU为1500B的链路上，这时就要进行IP分片。由题意知道一共要分三片，现假设16比特标识为777，那么分片结果片一：标识=777 DF=0 MF=1 片偏移=0(该片有效数据为1500-20=1480)片二：标识=777 DF=0 MF=1 片偏移=1480/8=185(该片有效数据为1500-20=1480)片三：标识=777 DF=0 MF=0 片偏移=1480*2/8=370(该片有效数据为3980-1480-1480=1020) TCP分片前面说到了MSS(TCP首部中的选项字段中)。MSS是TCP数据包每次能够传输的最大数据分段(不包括TCP/IP首部)，当TCP报文段长度大于MSS时，要进行分段传输。TCP协议在建立连接时双方协商MSS值(MSS选项只出现在SYN报文段中，即TCP握手的前两次)，MSS值一般为MTU减去两个首部大小。TCP报文段的分段和重组是在传输层完成的。TCP分段的原因是MSS，而IP分段的原因是MTU，由于MSS&lt;=MTU，因此TCP报文段很少会发生IP分片。和TCP不同的是，UDP报文段不会自己进行分段，当长度超过MTU时，会在网络层进行IP分片。同样的，ICMP(网络层中)同样会出现IP分片。]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>TCP/IP</tag>
        <tag>IP分片</tag>
        <tag>TCP分片</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DOS攻击之SYN泛洪攻击]]></title>
    <url>%2F2020%2F02%2F15%2FDOS%E6%94%BB%E5%87%BB%E4%B9%8BSYN%E6%B3%9B%E6%B4%AA%E6%94%BB%E5%87%BB%2F</url>
    <content type="text"><![CDATA[DOS:Denial of Service。即拒绝服务攻击，该攻击使系统过于忙碌而不能执行有用的业务。常见的DOS攻击有:SYN泛洪攻击、ping泛洪、UDP泛洪、ICMP路由重定向炸弹、分片炸弹等。这里简单地介绍一下TCP的SYN泛洪攻击。 背景我们知道，当服务器收到一个来自客户端的SYN报文段时，会为该报文段分配缓冲区并初始化连接变量，然后发送SYNACK报文段进行响应，并等待来自客户的ACK报文段。如果客户端不发送ACK报文段来完成三次握手的第三步，在一段时间后服务器将终止该半开的连接并回收资源。 实现原理TCP的SYN泛洪攻击就是在这种背景下实现的，攻击者发送大量的TCP SYN报文段，而不完成第三次握手的步骤。这样一来，服务器就会不断地为这些SYN报文段分配资源(但实际上并不会被使用)，导致服务器的资源被耗尽而不能完成正常的服务。 解决方案有一种有效的防御系统被称为SYN cookie被部署在大多数主流的操作系统中。 当服务器收到一个SYN报文段时，他并不知道该报文段是来自一个合法用户还是来自攻击者。因此服务器并不会为该报文段分配资源。这时，服务器生成一个初始TCP序列号，该序列号是SYN报文段的源和目的IP地址与端口号以及仅有该服务器知道的秘密数的复杂函数(散列函数)。该TCP序列号被称作cookie。服务器发送这种具有特殊序列号的SYNACK报文段。要注意：服务器并不记忆该cookie或任何对应于SYN的状态信息。 如果客户端是合法的，则他将返回一个ACK报文段。当服务器收到该ACK，需要验证该ACK是与前面的某些SYN对应的。前面说过，服务器并不会记忆SYN的任何信息。此时通过cookie来完成，如果合法则服务器生成一个具有套接字的全开的连接 如果客户端没有返回ACK报文段，那么并不会产生任何影响，因为服务器并没有为它分配资源。]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>网络安全</tag>
        <tag>DOS攻击</tag>
        <tag>TCP/IP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TCP协议的四大定时器]]></title>
    <url>%2F2020%2F02%2F15%2FTCP%E5%8D%8F%E8%AE%AE%E7%9A%84%E5%9B%9B%E5%A4%A7%E5%AE%9A%E6%97%B6%E5%99%A8%2F</url>
    <content type="text"><![CDATA[对于TCP协议，有四个非常重要的定时器，它们分别是:重传定时器、坚持定时器、保活定时器、2MSL定时器。下面就分别介绍一下这四大定时器的作用和使用场景。 重传定时器该定时器在TCP的可靠数据传输中起到至关重要的作用。有一点很重要：在一个TCP连接中，只有一个重传计时器。那么该计时器是如何工作的呢？我们举例说明： 如果有{1,2,3}三个包需要发送，先发送了1，在没有收到ACK1的情况下发送了2。定时器在发送1的时候启动，在发送2的时候不会被重置，因为当前窗口内仍有已发送但未被确认的报文段。 同样的有三个包要发送，如果先发送了1，在收到ACK1的情况下发送了2。定时器在发送1的时候启动，在发送2的时候会被重置，因为发送2时，窗口内没有已发送未被确认的报文段(1已经得到确认)。 通过上述举例我们知道： 一个TCP连接只有一个重传定时器 在TCP数据发送过程中，只有当前窗口内没有已发送但未被确认的报文段，重传定时器才会被重置。也就是说，如果发送了很多段，如果前面的段没有得到确认，那么后面发送的时候不会重置该定时器。 坚持定时器该定时器在TCP的流量控制中起到了预防死锁的作用。我们来思考这样一个场景:当接收方窗口大小为0时，接收方向发送方发送一个0窗口确认报文段，当发送方收到后，将会停止向接收方发送报文段。这样一来，发送方并不知道什么时候可以继续发送报文段，这就要用到坚持定时器。发送方收到0窗口确认报文时启动该定时器，当该定时器超时后，如果仍没有收到来了接收方的非0窗口确认(可能是接收方发送了但是丢失了，也有可能是接收方缓存仍满)，那么发送方发送一个1字节数据大小的探测报文并重新启动坚持计时器(每次重新启动定时器的超时时间加倍，最大为64)。这样当接收方缓存有空余时，发送方就能得知，坚持定时器在发送方收到非0窗口确认报文时关闭。 保活定时器该定时器用于确认两主机间TCP连接是否可用。现假设客户端和服务器之间有一个TCP连接，而客户端由于故障关闭了，这时候服务器并不知道客户端的情况，那么服务器端的TCP连接就会一直保持开启状态，但事实上该连接已经没有用了，这种情况下就会造成资源的浪费。要解决这种问题，我们使用保活定时器，每当服务器收到客户端的信息，就重置该定时器。定时器的超时时间通常为2小时，如果服务器在2小时内没有收到客户的信息，它就发送一个探测报文，如果发送了10个探测报文(每隔75s发一个)都没有响应，就假定客户端出了故障，服务器就终止该TCP连接。 2MSL定时器在断开TCP连接中使用(四次挥手)，当最后一次挥手(客户端对服务器的FIN报文段进行确认)后，客户端并不会立刻关闭连接，而是等待2MSL后再关闭(MSL:报文的最大生存时间)。至于为什么等待2MSL，有两点原因: 为了保证最后的ACK报文段能够到达 为了使本次连接中所产生的所有报文段都从网络中消失，而不会对下次连接产生影响。]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>TCP/IP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GBN协议、SR协议以及TCP协议区别]]></title>
    <url>%2F2020%2F02%2F15%2FGBN%E5%8D%8F%E8%AE%AE%E3%80%81SR%E5%8D%8F%E8%AE%AE%E4%BB%A5%E5%8F%8ATCP%E5%8D%8F%E8%AE%AE%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[我们知道GBN协议、SR(选择重传)协议以及TCP协议都能够保证可靠数据传输，那么问题来了:TCP到底采用的是GBN协议还是SR协议来实现的可靠数据传输呢？这里不对三种协议进行详细的介绍，主要介绍三者的区别和联系。 GBN协议 发送方对于发送方来说，如果某个报文段在超时时间内没有收到来自接收方的ACK应答，那么包括这个报文段在内所有的已发送但是未被确认(即未收到ACK应答报文)都要重新发送。因此发送方需要维护两个变量:send_base(当前窗口内最早的已发送但未被确认报文段序号)和nextseq(当前窗口内最早可以发送但未被发送的报文段序号)；除此之外发送方还需要一个缓冲区来存储哪些已发送但未被确认的报文段，这是为重传做准备。 接收方对于接收方而言，如果收到一个按序到达的报文段(假设上次到达的报文段序号为n，那么此次到达的报文段序号如果是n+1，那么此报文段就是按序到达的)，则接收方发送一个ACK进行应答，并且将该分组中的数据部分提交给上一层。除此之外的所有情况，接收方丢弃该分组，并未最近按序接受的分组重新发送ACK。因此接受方只需要维护一个变量:exnextseq(下一个按序接受的报文段序号)。 累计确认GBN协议使用的是累计确认，通过上面的介绍我们发现，在GBN协议中，接收方一次向上层递交一个分组，也就是说，如果分组k已接受并交付，则所有序号比k小的分组也已经交付。 SR协议接收方也设置一个缓冲区，为每个报文段设置计时器，对于乱序到达的报文段，先存储在接收方缓冲区中并发送此报文段的ACK应答。当缺失的报文段到达之后，接收方进行整理排序统一提交给上层(注意和GBN协议的区别)。 TCP协议TCP协议可以理解为GBN协议和SR协议的结合体，它具有累计确认机制(GBN协议)，但是对于失序到达的报文段，接收方并不是丢弃掉而是缓存起来，最后整理排序后提交给上一层(SR协议)，接收方只会对最后一个按序到达的报文段进行确认(发送ACK报文段)(GBN协议)。并且TCP还有快速重传机制:当累计收到对同一个报文段的3个ACK后，不必等待超时时间，立刻重传该报文段。 举例]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>TCP/IP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[传输层与链路层校验和]]></title>
    <url>%2F2020%2F02%2F14%2F%E4%BC%A0%E8%BE%93%E5%B1%82%E4%B8%8E%E9%93%BE%E8%B7%AF%E5%B1%82%E6%A0%A1%E9%AA%8C%E5%92%8C%2F</url>
    <content type="text"><![CDATA[我们知道，在传输层协议中，无论是TCP还是UDP都提供了差错检测功能(通过首部字段中的检验和字段实现)。同时，许多链路层协议(如著名的以太网协议)也实现了差错检测功能。说到这里你可能会有疑问：这是否是冗余功能呢？让我们来分析一下。 答案当然是不冗余的，甚至说是必须实现的。原因有两个 第一，我们知道，在两台主机之间，有多个交换机和多段通信链路，这些不同的通信链路可能使用不同的链路层协议，我们并不能保证这些链路都实现了差错检测(有些链路层协议并不提供差错检测功能)，因此在传输层提供差错检测是必要的。 第二，更重要的是，即使两台主机之间的所有通信链路都实现了差错检测，当报文存储在路由器中时，也有可能会引入比特差错。链路层协议的差错检测仅仅保证了点到点(路由器到路由器之间)的正确性，并不能保证端到端的正确性(主机到主机之间)，如果要实现端到端的差错检测，就必须在传输层协议实现差错检测功能。这就是系统设计中被称颂的端到端原则。]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>校验和</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DNS解析的工作原理及递归与迭代的区别]]></title>
    <url>%2F2020%2F02%2F13%2FDNS%E8%A7%A3%E6%9E%90%E7%9A%84%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%E5%8F%8A%E9%80%92%E5%BD%92%E4%B8%8E%E8%BF%AD%E4%BB%A3%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[最近在复习计算机网络，发现有些地方之前记录的不够深入。今天让我们来看一看DNS的解析。如题所示，本文不会对DNS进行详细的介绍，主要介绍DNS解析的过程以及递归与迭代的区别。 递归和迭代的区别 递归查询就是查询的递交者更替变换 迭代查询则是查询的递交者保持不变 举个例子 你想知道某个女孩的电话，并且你偷偷拍了她的照片，回到寝室告诉一个很仗义的哥们儿，这个哥们儿二话没说，拍着胸脯告诉你，甭急，我替你查(此处完成了一次递归查询，问询者的角色更替)。 然后他拿着照片问了学院大四学长，学长告诉他，这姑娘是xx系的； 然后这哥们儿马不停蹄又问了xx系的办公室主任助理同学，助理同学说是xx系yy班的， 然后很仗义的哥们儿去xx系yy班的班长那里取到了该女孩儿电话。最后，他把号码交到了你手里，完成整个查询过程。 (以上完成若干次迭代查询，问询者角色不变，但反复更替问询对象) DNS解析的工作过程现在假设我用我的笔记本，在浏览器中输入www. baidu. com，让我们来看看DNS到底是怎么做的 操作系统会先检查笔记本内的hosts文件是否有该(域名-&gt;IP地址)的映射关系。如果有，就直接使用该IP地址，完成域名解析 如果hosts里没有这个(域名-&gt;IP地址)映射，则在本地DNS解析器缓存中查找是否有该(域名-&gt;IP地址)映射关系。如果有则直接返回，完成域名解析 如果仍然没有找到(域名-&gt;IP地址)映射关系，则在TCP/IP参数中设置的首选DNS服务器(即本地DNS服务器)中查询。此服务器收到查询时，如果其中包含(域名-&gt;IP地址)映射关系，则返回解析结果给我的笔记本，完成域名解析 如果本地DNS服务器中仍没有(域名-&gt;IP地址)映射关系，那么该本地DNS服务器向根DNS服务器发送查询。得到该域名的顶级域服务器IP地址并返回给本地DNS服务器 本地DNS服务器得到顶级域服务器IP后，向该顶级域服务器发送查询。得到该域名的权威服务器IP地址并返回给本地DNS服务器 本地DNS服务器得到权威服务器IP后，向该权威服务器发送查询。得到www. baidu. com的IP地址并返回给本地DNS服务器 最后，本地DNS服务器将解析得到的www .baidu. com的IP地址返回给我的笔记本，完成整个查询过程。 我的笔记本收到IP地址后，向位于给IP地址的主机的80端口发起TCP连接。 参考资料:《计算机网络自顶向下方法》参考文章]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>DNS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库设计之E-R模型]]></title>
    <url>%2F2019%2F12%2F08%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AE%BE%E8%AE%A1%E4%B9%8BE-R%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[E-R模型，即实体-联系模型(entity-relationship)。该数据模型能够方便我们的数据库设计，它将在现实世界实体的含义和交互映射到概念模式上。E-R模式涉及到三个基本概念:实体集、联系集和属性。 基本概念这一小节中，主要介绍E-R模型涉及到的三个基本概念，为后面的深入学习做准备，它们分别是实体集、联系集和属性。 实体集 实体实体是现实世界中可区别于所有其他对象的一个事物或对象。例如：一个人是一个实体，一支笔也是一个实体…简单地说，实体是现实世界中的任何事物(虽然不准确，但可以简单理解为关系型数据库中的一条记录)。 实体集实体集是具有相同类型(具有相同性质)的一个实体集合，本质上是一个集合。例如:一个大学的所有教师是一个实体集、所有学生是一个实体集、甚至一个大学的所有人也是一个实体集。通俗的讲，实体集就是一类事物的总和，不同的实体集可以相交(可以不准确的理解为关系型数据库中的一张表)。 属性实体通过属性来表示，属性是实体集中每个成员所拥有的描述性性质。比如一个人，他有身高、体重、年龄等等不同的属性。(一个属性可以不准确的理解为表的一个列) 每个实体的每个属性都有一个值，现在可以准确的说，该实体所有属性值的集合就相当于关系型数据库中一张表的一条记录。数据库包含一组实体集(若干张表)，每个实体集包括任意数量的相同类型的实体(若干条记录)。 联系集 联系联系是指多个实体间的相互关联。例如：我们可以定义关联老师张三和学生李四的联系advisor，这一联系指明张三是李四的导师。(联系实际上也是一张表) 联系集联系集是相同类型联系的集合。正规的说：联系集是N(N&gt;=2)个实体集(可能相同)上的数学关系，如果E1,E2,…,En为实体集，那么联系集R是{(e1,e2,…,en)|e1∈E1,e2∈E2,…en∈En}的一个子集，而(e1,e2,…,en)是一个联系。事实上，虽然不够准确，但是可以理解为联系可以通过SQL语言中的主码外码和表来表示。 参与和角色实体集之间的关联称为参与；也就是说，实体集E1,E2,…En参与联系集R。E-R模型中的一个联系实例表示在所建模的现实世界中实体间的一个关联：一个ID为45566的教师实体张三和一个学生ID为12345的学生实体李四参与到了advisor的一个联系实例中。这一联系实例表示在大学中张三是李四的导师。实体在联系中扮演的功能称为实体的角色。一般来说，参与一个联系集的实体集通常是互异的(类比于一张表参照于另一张表)，这时候角色是隐含的并且一半并不指定。但是，当参与联系的实体集是同一张表时，即同一个实体集以不同的角色参与一个联系集多次，我们需要用到角色。这类联系集有时被称作闭环联系集。例如：一个记录大学开设的所有课程的信息的实体集course，我们用course的有序对来建立一个联系集prep，以描述一门课程(C2)是另一门课程(C1)的先修课。每对课程中的第一门课具有C1角色，第二门课具有C2角色。这时，所有的联系通过(C1,C2)来表示，就排除了(C2,C1)对。(可以类比于SQL表中表自身的依赖关系) 联系的属性联系也可以具有描述性属性。例如：考虑前面介绍的张三和李四的联系advisor联系，我们可以给联系一个date属性，表示教师成为学生导师的日期。该date属性既不在教师集中也不在学生集中，它是advisor联系的一个属性。给定联系集中的一个联系实例必须是由参与实体唯一标识的，而不必使用联系自身的描述属性。参与联系集的实体集的数目称为联系集的度，二元联系集的度为2，三元联系集的度为3。 属性每个属性都有一个可取值的集合，称为该属性的域，或者值集。在E-R模型中，属性有不同的划分： 简单属性和复合属性简单属性是指不能够划分为更小的部分。而复合属性可以再划分为更小的部分(即其他属性)。例如：属性NAME可以设计为包含first_name,middle_name,last_name的复合属性。如果一个用户希望在一些场景中使用复合属性，而在另外一些场景中仅仅使用属性的一部分，那么我们可以将属性设计为复合属性。 单值和多值属性单值属性对于一个特定的实体只有单独的一个值。例如：对于一个学生实体而言，它的ID属性只有一个。而多值属性在某些情况下，对某个特定的实体而言，一个属性值可能对应一组值。例如：对于一个教师实体，他可能有多个电话号码，那么它的phone_number属性可能有一组值。我们用{phone_number}来表示该属性是多值属性。 派生属性这类属性的值可以从别的相关属性或实体派生出来。例如：我们假设教师实体有一个属性students_advised，表示一个教师指导了多少个学生。我们可以通过统计一个教师相关联的所有学生实体数来得到这个属性值。或者我们可以通过教师的birth(出生日期)和当前日期来得到教师的年龄age。派生属性的值不存储，而是在需要时计算出来。 当一个实体在某个属性上没有值时可以使用空值，空值可以表示不适用、属性值未知。 约束E-R模式可以定义一些数据库中的数据必须满足的约束，下面我们就讨论映射基数和参与约束。 映射基数映射基数，表示一个实体通过一个联系集能关联的实体的个数。映射基数在描述二元联系集时非常有用，它也可以用来表述多元联系集，这里主要介绍二元联系集。对于实体集A和B之间的二元联系集R，映射基数必是以下情况之一 一对一A中的多个实体至多与B中的一个实体相关联，并且B中的一个实体也至多与A中的一个实体相关联 一对多A中的一个实体可以与B中任意数目(可以是0个)实体相关联，而B中的一个实体至多与A中的一个实体相关联 多对一A中的一个实体至多与B中的一个实体相关联，而B中的一个实体可以与A中任意数目实体相关联 多对多A中的一个实体可以和B中的任意数目实体相关联，B中的一个实体也可以和A中任意数目实体相关联 如下图所示，你应该注意到，四种情况下两实体集中都可能会存在没有和另外一个实体集关联的实体。 参与约束如果实体集E的每一个实体都参与到联系集R的至少一个联系中，实体集E在联系中的参与称为全部参与。如果E中只有部分实体参与到R的练习中，实体集E到联系集R的参与称为部分的。例如，我们期望每个学生实体通过advisor联系至少同一名教师相联系，因而学生实体集在联系集advisor中的参与是全部的；相反的，每个教师实体不是必须指导一个学生，因此很可能只有一部分教师实体通过advisor联系同学生实体集相联系，于是教师实体集在advisor中的参与是部分的。 码码的定义我们应该有一个区分给定实体集中实体的方法。从概念上说，各个实体间是不同的，但是从数据库观点来看，它们的区别必须通过其属性来体现。我们来介绍三种码 超码超码是一个或多个属性的集合，这些属性的组合可以使我们唯一的标识一个元组(关系模型的概念，可以理解为实体，或者是数据库中的一行记录) 候选码超码中可能包含无关紧要的属性，例如：ID和name的组合是学生关系(关系模型的概念，相当于数据库中的表，E-R模型中的实体集)，但是我们发现，ID属性就已经足够唯一标识一个元组，即该超码的中含有多余的属性name。如果一个超码的任意真子集都不能称为超码，那么这个超码就是候选码。 主码主码是数据库设计者选定的、用来在一个关系中区分不同元组的候选码。(主码仍是候选码) 联系集的码上面介绍的关系模型中的三种码同样适用于实体集，即实体的码是一个足以区分每个实体的属性集。码同样用于唯一的标识联系，从而将联系相互区分开来。假设R是一个涉及实体集E1,E2,…En的联系集。设主码(Ei)代表构成实体集Ei主码的属性集合。目前我们假设所有主码的属性名是互不相同的，联系集的主码构成依赖于同联系集R相关联的属性集合。 如果联系集R没有属性与之相关联，那么属性集合rimary-key(E1)∪primary-key(E2)∪…primary-key(En)描述了集合R中的一个联系 如果联系集R有属性a1,a2,…am与之相关联，那么属性集合rimary-key(E1)∪…primary-key(En)∪{a1,a2,…an}描述了集合R中的一个联系 综合以上两种情况下，属性集合rimary-key(E1)∪primary-key(E2)∪…primary-key(En)构成了联系集R的一个超码 如果实体集间主码的属性名称不是互不相同的，重命名这些属性以区分它们；实体集的名字加属性名可以构成唯一的名称。如果一个实体集不止一次参与某个联系集(前面的prep)，则使用角色名代替实体集名构成唯一属性名。 联系集的主码联系集的主码结构依赖于联系集的映射基数。例如：考虑上面A和B的四种映射基数，假设他们的联系集为AB，则 如果A和B是多对多的关系，那么AB的主码有A和B的主码的并集组成 如果联系是从A到B多对一的，那么AB的主码就是A的主码 如果联系是从A到B一对多的，那么AB的主码就是B的主码 如果A和B之间是一对一关系，那么AB的主码可以是A的主码也可以是B的 对于非二元关系，如果没有基数的限制，那么上面的介绍的超码就是联系集的主码；如果有基数限制，后面再进行介绍。 从实体集中删除冗余属性当我们使用E-R数据模型设计数据库时，通常从确定应当包含哪些实体集，当确定好实体集后，我们必须挑选适当的属性。一旦选择好实体和它们相应的属性，不同实体间的联系集就建立起来了。这些联系集可能会导致不同实体集中的属性冗余，我们需要删除冗余的属性。现在假设： 12345实体集instructor(教师集)包含属性ID,name,dept_name,salary。其中ID为主码实体集department(系名)包含属性dept_name,building,budget。其中dept_name为主码 我们用关联instructor和department的联系集inst_dept对每个教师都有一个关联的系得情况进行建模。属性dept_name在两实体集中都出现了，由于它是department的主码，因此它在实体集instructor中是冗余的，需要将其移除。后面我们会看到，只有当一个教师最多只与一个系关联(多对一)时，属性dept_name才会添加到instructor中。如果一个教师有多个关联的系(一个系也不止一个教师，所以是多对多关系)时，教师与系之间的联系会记录在一个单独的关系inst_dept中。将教师和系之间的关联同统一看成联系，而不是instructor的一个属性，使得逻辑关系明确，并有助于过早的假设每个教师只与一个系关联。 E-R图E-R图可以图形化表示数据库的全局逻辑结构，即简单又清晰，在数据库设计中被广泛使用 基本结构E-R图包括如下几个主要构件 分成两部分的矩形代表实体集，一部分包含实体集的名字；另一部分包含实体集中所有属性的名字 菱形代表联系集 未分割的矩形代表联系集的属性，构成主码的属性下划线表明 线段将实体集连接到联系集 虚线将联系集属性连接到联系集 双线显式实体在联系集中的参与度(双线表示全部参与) 双菱形表示连接到弱实体集的标识性联系集(后面介绍) 映射基数前面我们过了映射基数，下面主要介绍如何在E-R图中表示映射基数。如下图所示通过图我们可以发现规律，在四种映射关系中：如果实体集是一，则联系集用箭头指向该实体集；如果实体集是多，则联系集用线段指向该实体集。 复杂的属性如果一个实体集拥有复杂的属性，那么它的E-R图又该怎么表示？我们假设前面instructor实体集的name属性为复杂属性，则instructor的E-R如下所示可以看到，在E-R图中，我们使用{属性名}表示多值属性。 角色前面介绍过，在闭环联系集中，我们需要用到角色，那么E-R图又是如何表示角色的呢？从图中可以看到，我们使用两条线段分别标识不同的角色。 非二元的联系集非二元的联系集也可以在E-R图中简单地表示，如下图所示如图，在非二元的联系集中，我们可以表示某些类型的多对一关系。假设student在每个项目(project)上最多只能有一位导师(学生和导师多对一)，这种约束可以从proj_guide指向instructor的箭头表示。另外要注意的是：在一个联系集外我们至多允许使用一个箭头。 弱实体集前面在介绍E-R图形的时候，说了双菱形代表连接到弱实体集的标识性联系集，下面就来介绍一下什么是弱实体集。 示例介绍假设一个section(开课)实体，它由课程编号、学期、学年以及开课编号唯一标识。显然，开课实体和课程(course)实体相关联。假定我们在实体集section和course之间创建了一个联系集sec_course。现在，发现sec_course中的信息是冗余的，由于section存在属性course_id，它标识该开课所关联的课程。消除这种冗余的一个方法是删除联系sec_course。然而，这么做会使得section和course之间的联系隐含于一个属性中，这不是一个好办法。消除这种冗余的另一个方法是在实体section中不保留course_id，但是由于course_id参与构成section的主码，去掉之后剩下的属性无法唯一标识一个指定的section实体，为了解决这个问题，我们将联系sec_course视为一个特殊的联系，它给唯一标识section实体提供额外信息，即course_id。 弱实体集定义没有足够的属性以形成主码的实体被称为弱实体集，与之对应的，有主码的实体称作强实体集。弱实体集必须和另外一个称作标识实体集的实体集关联才有意义，每个弱实体集必须和一个标识实体集关联。我们称标识实体集拥有它所标识的弱实体集。弱实体集和标识实体集相连的联系称为标识性联系。标识性联系从弱实体集到标识实体集是多对一的，并且弱实体集是全部参与的，标识性联系不能有自己的属性。 弱实体集主码通过弱实体集的定义可知，弱实体集是没有主码的，但是我们仍需要依赖于特定强实体集的弱实体集中的实体。弱实体集的主码由标识实体集的主码加上该弱实体集的分辨符构成。假设上面的section弱实体集，它的分辨符为{sec_id,semester,year}，该弱实体集所依赖的标识实体集course的主码为course_id，因此该弱实体集的主码为{course_id,sec_id,semester,year}。 弱实体集的E-R图弱实体集和强实体集类似，使用矩形表示，主要有以下两点区别 弱实体集的分辨符以虚下划线表明，而不是实线 关联弱实体集和标识实体集的联系集以双菱形表示 弱实体集是全部参与的并且从标识实体集到弱实体集是一对多的关系 弱实体集可以参与标识性联系以外的其他联系。例如，一个section实体可以和time_slot实体参与一个联系，以标识开课时间 一个弱实体集可以作为另一个弱实体集的标识实体集 一个弱实体集也可能不止与一个标识实体集关联，这样的话，该弱实体集的主码就由这些标识实体集的主码的并集加上弱实体集的分辨符组成。 E-R模式转换为关系模式我们可以将一个复合E-R数据库模式的数据库表示为一些关系模式的集合。在数据库设计中，对于每个实体集以及每个联系集，都有唯一的关系模式与之对应，关系模式名即为相应的实体集或联系集的名称。下面就将介绍如何用关系模式来表示E-R模型 具有简单属性的强实体集表示对于一个只具有简单属性的强实体集，将其转换为关系模式很简单。强实体集的属性就是生成的关系模式的属性，强实体集的主码就是生成的关系模式的主码。 具有复杂属性的强实体集表示当一个强实体集具有一些非简单属性时。根据不同的属性有不同的处理方法 复合属性通过为每个子属性创建一个单独的属性来处理复合属性，同时，我们并不为复合属性创建一个单独的属性。例如：假设实体集(ID,name,address)，其中name为复合属性(first_name,middle_name,last_name)，那么我们得到的关系模式的属性为(ID,first_name,middle_name.last_name,address)。可以看到，在关系模式中我们将复合属性拆成了子属性。 多值属性对于多属性，我们会为这些属性创建一个新的关系模式。例如：假设有一个实体集(ID,name,phone_number)，其中ID为主码，name为复合属性，phone_number为多值属性。对于多值属性M，构造一个关系模式R，该模式包含一个对应于M的属性A，以及对应于M所在的实体集或联系集的主码的属性。因此，对于实体集(ID,name,phone_number)，我们会得到两个关系模式，分别是(ID,first_name,middle_name,last_name)主码为ID，(ID,phone_number)主码为(ID,phone_number)。 为多值属性创建的关系模式的主码由该关系模式的所有属性组成 为多值属性创建的关系模式的外码由该实体集(ID,name,phone_number)的主码生成的属性去参照实体集所生成的关系。(在上例中，多值属性关系模式的外码为ID，参照实体集的ID属性) 在实体集只有两个属性时(一个为主码一个为多值属性)，可以删除掉该实体集对应的关系模式，只保留多值属性对应的关系模式 弱实体集的表示假设A是具有属性a1,a2,…am的弱实体集，设B是A所依赖的强实体集，设B的主码为b1,b2,…,bn。那么得到的关系模式A为(a1,a2,…,am,b1,b2,…,bn) 主码：对于弱实体集转化得到的关系模式，该模式的主码由弱实体集的标识实体集加弱实体集的分辨符组成 外码：模式中来自于标识实体集的属性依赖于标识实体集 联系集的表示设R是联系集，设a1,a2,…,am表示所有参与R的实体集的主码的并集，设R的描述属性(如果有描述属性的话)b1,b2,…,bn，那么由联系集R得到的关系模式为(a1,a2,…,am,b1,b2,…,bn) 主码前面介绍了联系集的主码，现在介绍一下关系模式的主码，其实大体类似 多对多关系，参与实体集的主码属性的并集成为主码 一对一关系，任何一个实体集的主码都可以选作主码 一对多或多对一关系，联系集’多’的那一方的实体集的主码成为主码 对于边上没有箭头的N元联系集，所有参与联系的实体集的主码并集构成主码 对于边上有箭头的N元联系集(前面说过至多有一个)，不在箭头侧的实体集的主码(并集)构成主码 外码对于由联系集R得到的关系模式，模式中来自实体集Ei的属性ei参照关系模式Ei的主码。 模式的冗余连接弱实体集和相应强实体集的联系集比较特殊，一般情况下，连接弱实体集与其所依赖的强实体集的联系集的模式是冗余的。 模式的合并假设从实体集到实体集B的一个一对多联系集AB，并且假设A在该联系中是全部参与的。即A中的每个实体a都必须参与到联系AB中。那么我们可以将A和AB模式进行合并。合并后的模式C的主码就是A的主码，并且B的主码在合并后的模式中作为外码参照B。另外，即使A是部分参与，也可以通过使用null值来进行模式的合并。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>数据库</tag>
        <tag>数据库设计</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL连接表达式]]></title>
    <url>%2F2019%2F12%2F07%2FMySQL%E8%BF%9E%E6%8E%A5%E8%A1%A8%E8%BE%BE%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[在SQL语句中，查询类语句是使用的最多的，当查询时，可能仅仅对一个表进行查询并不能满足我们的要求，需要对多个表进行操作，这时候连接操作不失为一种好选择。下面我们基于MySQL数据库介绍SQL语言中的连接关键字JOIN。 连接种类对于MySQL中的连接，有两种分类 内连接(INNER JOIN)这也是默认的连接，INNER可以省略 外连接(OUTER JOIN)外连接又分为三种 LEFT OUTER JOIN RIGHT OUTER JOIN FULL OUTER JOIN 下面分别对着几种连接进行介绍 自然连接在介绍这几种连接之前，先介绍一下最简单的自然连接，该连接方式不需要连接条件，只需要两个关系有相同的属性即可现有两关系 1234//学生表student(ID,name,dept_name)//选课表takes(ID,course_id,credits,dept_name) 学生表和选课表中有两个相同属性，分别是:ID和dept_name。我们对这两个关系进行自然连接 123student NATURAL JOIN takes或takes NATURAL JOIN student 以上操作得到一个新的关系，新关系的属性依次为：两关系的共有属性，NATURAL JOIN字段前的关系除了共有属性的属性，NATURAL JOIN后的关系除了共有属性的属性。只有在student.ID=takes.ID并且student.dept_name=takes.dept_name元组才会被合并。 123student NATURAL JOIN takes得到新关系属性(ID,dept_name,name,course_id,credits) 普通连接当我们使用自然连接时，我们无法选择两关系连接的条件，例如，在上述两关系中，默认两关系的(ID,dept_name)都相等时才能进行连接，如果我们只需要其中一个条件，即当两关系的ID属性相等时就可以进行连接，自然连接是做不到的，这时候就需要用到普通连接。 连接条件1234student JOIN takes USING(ID)或student JOIN takes ON student.ID=takes.ID该语句表明两关系的ID属性相等的元组(行)可以进行连接 和自然连接不同，以上两种方式所查询到的结果不会去除重复的属性。 123student JOIN takes ON student.ID=takes.ID得到新关系属性(ID,name,dept_name,ID,course_id,credits,dept_name) 左外连接还是对于上面的学生表和选课表，我们假设有一些学生，他们没有选修任何课程。那么student表和takes进行连接时，这些学生是无法被查询到的(因为在takes表中没有这些学生的ID和dept_name)。 1student LEFT OUTER JOIN takes; 对于在student但是没有出现在takes的元组(记录)，合并后从student中的得到的属性值不变，从takes中得到的属性值为null 右外连接和左外连接相同，不过不同的是，右外连接保留右边的关系元组 1student RIGHT OUTER JOIN takes; 能够保留出现在takes中但是不没有出现在student中的元组。 全外连接相当于将左外连接和右外连接结合起来。 1student FALL OUTER JOIN takes; 总结前面介绍了ON条件，你可能会发现，ON条件和WHERE条件非常类似，但实际上，对于普通的连接ON都可以用WHERE条件进行替换。但是对于外连接来说，WHERE条件和ON条件的作用就不一样了 12345678910//ON条件SELECT * FROM student LEFT OUTER JOIN takes ON student.ID=takes.ID; //WHERE条件SELECT * FROM student LEFT OUTER JOIN takes ON TRUE WHERE student.ID=takes.ID; 对于上面两条SQL语句，我们得到的查询结果是不同的，我们使用第一个SQL语句时，能够得到在student中出现的但是没有在takes中出现的元组。但是我们使用第二个SQL语句时，它的执行过程是这样的 由于ON条件是true，所以先将student和takes进行笛卡尔积得到一张新的临时表 再在新的表中使用WHERE子句进行筛选 通过上述过程可以发现，这种方式并不能达到左外连接的效果，这是因为外连接只为那些对相应内连接结果没有贡献的元组补上空值并加入结果，ON条件是外连接声明的一部分，但是WHERE子句却不是。 连接条件对于以下四种连接类型 1234(INNER) JOINLEFT OUTER JOINRIGHT OUTER JOINFULL OUTER JOIN 和以下三种连接条件 123NATURALON 子句USING(A1,A2....) 任意的连接类型可以和任意的连接条件进行组合例如 1NATURAL LEFT OUTER JOIN]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>数据库</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL事务中对完整性约束的违反]]></title>
    <url>%2F2019%2F12%2F07%2FMySQL%E4%BA%8B%E5%8A%A1%E4%B8%AD%E5%AF%B9%E5%AE%8C%E6%95%B4%E6%80%A7%E7%BA%A6%E6%9D%9F%E7%9A%84%E8%BF%9D%E5%8F%8D%2F</url>
    <content type="text"><![CDATA[我们知道，对于一个外码，它所有的取值都能够在其对应的主码中找到，下面将介绍一种特殊的参照关系，在执行过程中会违反这种参照完整性关系，但是执行过后却又满足这种关系，让我们来看一看MySQL数据库是如何处理这种情况。在学习这篇文章之前，你需要对约束、事务、主码、外码有一定的了解。 情景介绍现有一张表person(name,spouse)，该表描述了两个人的配偶关系，其中name属性为person的主码，spouse属性为person表中name的外码，即该表的参照关系是自身。下面是该表的创建语句 12345CREATE TABLE person( NAME VARCHAR(32) PRIMARY KEY, spouse VARCHAR(32), FOREIGN KEY(spouse) REFERENCES person(NAME)); 现在一对配偶数据需要插入，分别是(‘Jack’,’Marry’)和(‘Marry’,’Jack’)，Jack和Marry互为配偶。那么问题来了，我们无论先插入那一条数据，都会违反表的完整性约束。例如，当你先插入(‘Jack’,’Marry’)时，表中并没有name属性值为’Marry’的元组，这就违反了参照完整性约束。 解决方法在《数据库系统概论》(第六版)第75页中介绍了延迟约束检查，但我在MySQL上实验时并没有成功，可能是MySQL不支持，也可能是我没有找到正确的方法。下面就针对不同的情况提供不同的方法来解决 外码可空当外码没有NOT NULL约束(非空约束)时，我们可以这么解决 12345678START TRANSACTION;INSERT INTO person VALUES (&apos;Jack&apos;,NULL), (&apos;Marry&apos;,&apos;Jack&apos;);UPDATE person SET spouse=&apos;Marry&apos; WHERE NAME=&apos;Jack&apos;;COMMIT; 创建一个事务，先将其中一条记录的spouse属性置为NULL，另一条记录正常插入 再对NULL属性值进行修改 提交事务 以上思路比较简单，但是要注意一点，这些操作最好是放在一个事务当中执行以保证其原子性。 外码非空如果创建表时，对外码spouse进行了非空约束，那么以上方法就不能够使用了，这时候可以使用另外一种方法 12345678START TRANSACTION;INSERT INTO person VALUES (&apos;Jack&apos;,&apos;Jack&apos;), (&apos;Marry&apos;,&apos;Marry&apos;);UPDATE person SET spouse=&apos;Jack&apos; WHERE NAME=&apos;Marry&apos;;COMMIT; 创建事务，将两条记录的spouse属性值都设置为自身的name属性值 然后再分别对两条记录的spouse属性值进行修改 提交事务 同样的，这些操作要放到一个事务中执行以保障原子性，可以看到，这样操作还是比较麻烦的。 小结如果你知道MySQL的延迟约束检查执行语句或者有更好的方法，欢迎私信进行讨论。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>数据库</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分发饼干]]></title>
    <url>%2F2019%2F12%2F01%2F%E5%88%86%E5%8F%91%E9%A5%BC%E5%B9%B2%2F</url>
    <content type="text"><![CDATA[LeetCode第四百五十五题难度：简单题目：假设你是一位很棒的家长，想要给你的孩子们一些小饼干。但是，每个孩子最多只能给一块饼干。对每个孩子 i ，都有一个胃口值 gi ，这是能让孩子们满足胃口的饼干的最小尺寸；并且每块饼干 j ，都有一个尺寸 sj 。如果 sj &gt;= gi ，我们可以将这个饼干 j 分配给孩子 i ，这个孩子会得到满足。你的目标是尽可能满足越多数量的孩子，并输出这个最大数值。 注意： 你可以假设胃口值为正。 一个小朋友最多只能拥有一块饼干。 12345678示例 1:输入: [1,2,3], [1,1]输出: 1解释: 你有三个孩子和两块小饼干，3个孩子的胃口值分别是：1,2,3。虽然你有两块小饼干，由于他们的尺寸都是1，你只能让胃口值是1的孩子满足。所以你应该输出1。 思想分析使用贪心算法，用小饼干满足小胃口，大饼干留着满足大胃口 代码实现1234567891011public int findContentChildren(int[] g, int[] s) &#123; Arrays.sort(g); Arrays.sort(s); int res=0; for(int j=0;res&lt;g.length&amp;&amp;j&lt;s.length;)&#123; if(g[res]&lt;=s[j++])&#123; res++; &#125; &#125; return res;&#125;]]></content>
      <categories>
        <category>算法之美</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
        <tag>数组</tag>
        <tag>贪心算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[最小移动次数使数组元素相等]]></title>
    <url>%2F2019%2F12%2F01%2F%E6%9C%80%E5%B0%8F%E7%A7%BB%E5%8A%A8%E6%AC%A1%E6%95%B0%E4%BD%BF%E6%95%B0%E7%BB%84%E5%85%83%E7%B4%A0%E7%9B%B8%E7%AD%89%2F</url>
    <content type="text"><![CDATA[LeetCode第四百五十三题难度：简单题目：给定一个长度为n的非空整数数组，找到让数组所有元素相等的最小移动次数。每次移动可以使n-1个元素增加1。 123456789示例:输入:[1,2,3]输出:3解释:只需要3次移动（注意每次移动会增加两个元素的值）：[1,2,3] =&gt; [2,3,3] =&gt; [3,4,3] =&gt; [4,4,4] 思想分析 数学法每移动一次，就使n-1个元素增加1，那么反过来看，每移动一次，就使1个元素+1；直到所有的元素都等于最大值为止 动态规划首先对数组进行排序，得到一个有序数组a。我们假设前i-1个元素都已经相等，那么我们只需要考虑i位的元素，将差值diff=a[i]-a[i-1]加到总移动次数上，使得第i位也相等(即第i位不变，其他n-1个元素+diff，这样就能使得第i个元素等于前i-1个元素)。moves=moves+diff。但当我们想要继续这一步时，a[i]之后的元素也会被增加diff，亦即a[j]=a[j]+diff，其中 j&gt;i。但当实现本方法时，我们不需要对这样的a[j]进行增加。相反，我们把moves的数量增加到当前元素(a[i])中，a[i]=a[i]+moves。123diff=moves+a[i]-a[i-1] a[i]+=moves --&gt;得到本次移动后，前i个元素的值(前i个元素相等)moves+=diff --&gt;目前为止移动的总次数 代码实现123456789101112131415161718192021222324//数学法public int minMoves(int[] nums) &#123; int min=Integer.MAX_VALUE; int res=0; for(int i=0;i&lt;nums.length;i++)&#123; res+=nums[i]; if(nums[i]&lt;min)&#123; min=nums[i]; &#125; &#125; return res-min*nums.length;&#125;//动态规划public int minMoves(int[] nums) &#123; Arrays.sort(nums); int moves = 0; for (int i = 1; i &lt; nums.length; i++) &#123; int diff = (moves + nums[i]) - nums[i - 1]; nums[i] += moves; moves += diff; &#125; return moves;&#125; 数学法需要反向思考，动态规划比较巧妙。]]></content>
      <categories>
        <category>算法之美</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
        <tag>数组</tag>
        <tag>动态规划</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[两个线程交替打印奇偶数]]></title>
    <url>%2F2019%2F11%2F24%2F%E4%B8%A4%E4%B8%AA%E7%BA%BF%E7%A8%8B%E4%BA%A4%E6%9B%BF%E6%89%93%E5%8D%B0%E5%A5%87%E5%81%B6%E6%95%B0%2F</url>
    <content type="text"><![CDATA[今天看到一个很有意思的面试题：两个线程交替打印奇偶数字，在这里使用synchronized内置锁实现一下。 资源类有两个属性，一个是要打印的数字，还有一个布尔类型的flag来控制两个线程谁来打印该数字 123456789101112131415161718192021222324public class Num &#123; private int num; private boolean flag; public Num(int num) &#123; this.num = num; &#125; public int getNum() &#123; return num; &#125; public void setNum(int num) &#123; this.num = num; &#125; public boolean isFlag() &#123; return flag; &#125; public void setFlag(boolean flag) &#123; this.flag = flag; &#125;&#125; 奇数线程12345678910111213141516171819202122232425262728293031323334public class ThreadA implements Runnable &#123; private Num num; public ThreadA(Num num) &#123; this.num = num; &#125; @Override public void run() &#123; while (num.getNum() &lt;= 100) &#123; synchronized (num) &#123; //当flag=true时，说明应该打印偶数，此时奇数线程阻塞 if (num.isFlag()) &#123; try &#123; num.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; //当flag=false时，打印奇数 else &#123; int currentNum = num.getNum(); System.out.println(&quot;ThreadA:--&quot; + currentNum); //要记得将flag设置为true并唤醒偶数线程 num.setFlag(true); num.setNum(currentNum + 1); num.notify(); &#125; &#125; &#125; &#125;&#125; 偶数线程1234567891011121314151617181920212223242526272829public class ThreadB implements Runnable &#123; private Num num; public ThreadB(Num num) &#123; this.num = num; &#125; @Override public void run() &#123; while (num.getNum() &lt;= 100) &#123; synchronized (num) &#123; if (!num.isFlag()) &#123; try &#123; num.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;else &#123; int currentNum = num.getNum(); System.out.println(&quot;ThreadB:--&quot; + currentNum); num.setFlag(false); num.setNum(currentNum + 1); num.notify(); &#125; &#125; &#125; &#125; 偶数线程和奇数线程逻辑类似 测试类12345678910public class OddAndEvenPrint &#123; public static void main(String[] args) &#123; Num num = new Num(1); //两个线程一定要传递同一个num对象 new Thread(new ThreadA(num)).start(); new Thread(new ThreadB(num)).start(); &#125;&#125; 这个问题实现起来难度不大，只要对多线程有一定的了解应该很容易写出来]]></content>
      <categories>
        <category>Java并发编程</category>
      </categories>
      <tags>
        <tag>多线程</tag>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[fatal:Could not read from remote repository]]></title>
    <url>%2F2019%2F11%2F21%2Ffatal-Could-not-read-from-remote-repository%2F</url>
    <content type="text"><![CDATA[今天上传博客时，可能是由于没有使用hexo clean命令，直接使用了hexo g -d，导致上传失败。记录一下解决方法，方便下次使用。 先来看一下出现的问题截图问题翻译过来就是：无法读取远程存储库。这时候，我们需要重新设置一下SSH了 删除.ssh文件夹里的所有文件。 重新生成SSH，在窗口输入ssh-keygen -t rsa -C 你的邮箱名这时候重新打开.ssh文件夹，会发现里面多出了id_rsa和id_rsa.pub两个文件 打开GitHub，进入设置页面，点击SSH and GPG keys选项 点击NEW SSH key按钮，将id_rsa.pub里的内容拷贝进去即可 之所以出现这种问题，个人猜测可能是由于我在上传之前没有使用hexo clean命令。导致上传失败。]]></content>
      <categories>
        <category>Utils</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>解决问题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo博客如何绑定域名]]></title>
    <url>%2F2019%2F11%2F21%2FHexo%E5%8D%9A%E5%AE%A2%E5%A6%82%E4%BD%95%E7%BB%91%E5%AE%9A%E5%9F%9F%E5%90%8D%2F</url>
    <content type="text"><![CDATA[我们使用Hexo+github搭建的个人博客，每次访问时要使用仓库名.github.io也就是github的二级域名来访问，今天突然想自己申请一个域名，然后使用自己申请的域名来访问个人博客，感觉会更个人一些？这里对于域名是什么等一下基础知识不做赘述，如果还不了解的小伙伴可以去学习以下，当然，即使不了解跟着我的步骤来也是能够成功的。话不多说，我们来演示一下 解析域名我申请的是阿里的域名，所以下面就介绍一下申请阿里域名的步骤。域名我已经申请好了，登陆阿里云官网申请即可。点击图中解析选项将你个人博客的ip地址和登陆博客时使用的二级域名填写进去，下面讲一下如何获取个人博客的ip地址 获取IP地址打开windows的命令行窗口(win+R,然后输入cmd即可)，使用ping命令 修改Hexo和GitHubHexo操作上面我们已经把域名有关操作做完了，接下来就是在Hexo和GitHub上操作了打开个人博客的source文件夹，在里面创建一个CNAME的txt文件，并在文件中输入你申请的域名(注意不是github的二级域名了)，保存后再将文件的txt后缀删掉。 GitHub操作 登录自己的GitHub，点击头像进入设置页面 进入设置页面后点击Repositories 进入Hexo个人博客托管的仓库 进入仓库后再次点击设置 进入设置页面后下拉到底如图所示，输入你申请的域名即可 小结这样你的个人博客就成功地绑定了一个域名，就可以使用自己申请的域名来访问个人博客啦。]]></content>
      <categories>
        <category>Utils</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数组中消失的数字]]></title>
    <url>%2F2019%2F11%2F18%2F%E6%95%B0%E7%BB%84%E4%B8%AD%E6%B6%88%E5%A4%B1%E7%9A%84%E6%95%B0%E5%AD%97%2F</url>
    <content type="text"><![CDATA[LeetCode第四百四十八题难度：简单题目：给定一个范围在1≤a[i]≤n(n=数组大小)的整型数组，数组中的元素一些出现了两次，另一些只出现一次。找到所有在[1,n]范围之间没有出现在数组中的数字。(不使用额外空间并且O(n)复杂度，返回的数组不算) 12345示例:输入:[4,3,2,7,8,2,3,1]输出:[5,6] 算法思想这道题，我们可以在遍历数组的过程中一边遍历一边将数组元素放到正确的位置(即1放在a[0]中)。第二次遍历时如果数组中元素和下标不对应的即为缺失元素。 代码实现1234567891011121314151617181920212223242526public List&lt;Integer&gt; findDisappearedNumbers(int[] nums) &#123; List&lt;Integer&gt; list = new ArrayList(); for(int i = 0;i &lt; nums.length;i++)&#123; //nums[i] != nums[nums[i] - 1]，说明没有放到正确位置上 //当nums[i] == nums[nums[i] - 1]时有两种情况 //1. 元素放置到了正确的位置上 //2. 元素发生重复，并且其中一个放置到了正确的位置 //要用while循环而不能用if，因为交换后的元素可能仍没有在正确位置上 while(nums[i]!=nums[nums[i]-1])&#123; swap(nums,i,nums[i]-1); &#125; &#125; for(int i = 0; i &lt; nums.length;i++)&#123; if(i + 1 != nums[i])&#123; list.add(i + 1); &#125; &#125; return list; &#125;//不使用额外变量交换元素private void swap(int[] nums,int index1,int index2)&#123; nums[index1]=nums[index1]+nums[index2]; nums[index2]=nums[index1]-nums[index2]; nums[index1]=nums[index1]-nums[index2];&#125; 代码注释比较明了，如果不明白最好debug以下就好，主要在于在遍历数组将元素放在正确位置时要使用while循环而不是if循环]]></content>
      <categories>
        <category>算法之美</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
        <tag>数组</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[压缩字符串]]></title>
    <url>%2F2019%2F11%2F17%2F%E5%8E%8B%E7%BC%A9%E5%AD%97%E7%AC%A6%E4%B8%B2%2F</url>
    <content type="text"><![CDATA[LeetCode第四百四十三题难度：简单题目：给定一组字符，使用原地算法将其压缩。压缩后的长度必须始终小于或等于原数组长度。数组的每个元素应该是长度为1 的字符（不是 int 整数类型）。在完成原地修改输入数组后，返回数组的新长度。(你能否仅使用O(1) 空间解决问题) 12345678910111213141516171819202122232425示例 1：输入：[&quot;a&quot;,&quot;a&quot;,&quot;b&quot;,&quot;b&quot;,&quot;c&quot;,&quot;c&quot;,&quot;c&quot;]输出：返回6，输入数组的前6个字符应该是：[&quot;a&quot;,&quot;2&quot;,&quot;b&quot;,&quot;2&quot;,&quot;c&quot;,&quot;3&quot;]说明：&quot;aa&quot;被&quot;a2&quot;替代。&quot;bb&quot;被&quot;b2&quot;替代。&quot;ccc&quot;被&quot;c3&quot;替代。示例 2：输入：[&quot;a&quot;]输出：返回1，输入数组的前1个字符应该是：[&quot;a&quot;]说明：没有任何字符串被替代。示例 3：输入：[&quot;a&quot;,&quot;b&quot;,&quot;b&quot;,&quot;b&quot;,&quot;b&quot;,&quot;b&quot;,&quot;b&quot;,&quot;b&quot;,&quot;b&quot;,&quot;b&quot;,&quot;b&quot;,&quot;b&quot;,&quot;b&quot;]输出：返回4，输入数组的前4个字符应该是：[&quot;a&quot;,&quot;b&quot;,&quot;1&quot;,&quot;2&quot;]。说明：由于字符&quot;a&quot;不重复，所以不会被压缩。&quot;bbbbbbbbbbbb&quot;被“b12”替代。注意每个数字在数组中都有它自己的位置。 思想分析设置三个变量left、right、size，初始化都为0 right向后遍历，直到和left指向的字符不相等为止 更新size，并且将当前字符的数量right-left以字符串形式添加进去 重复1、2，直到数组遍历完毕 代码实现123456789101112131415161718192021public int compress(char[] chars) &#123; //双指针法 int left = 0; int size = 0; for (int right = 0; right &lt;= chars.length; right++) &#123; //当right遍历完数组或者遍历到不相等字符时 if (right == chars.length || chars[right] != chars[left]) &#123; // 更新字符 chars[size++] = chars[left]; // 更新计数，当个数大于 1 时才更新 if (right - left &gt; 1) &#123; for(char c : (&quot;&quot;+(right-left)).toCharArray()) &#123; chars[size++] = c; &#125; &#125; //更新左边指针 left = right; &#125; &#125; return size;&#125;]]></content>
      <categories>
        <category>算法之美</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
        <tag>字符串</tag>
        <tag>双指针法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[字符串相加]]></title>
    <url>%2F2019%2F11%2F17%2F%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%9B%B8%E5%8A%A0%2F</url>
    <content type="text"><![CDATA[LeetCode第四百一十五题难度：简单题目：给定两个字符串形式的非负整数num1和num2，计算它们的和。 12345注意：num1 和num2 的长度都小于 5100.num1 和num2 都只包含数字 0-9.num1 和num2 都不包含任何前导零。你不能使用任何內建 BigInteger 库， 也不能直接将输入的字符串转换为整数形式 思想分析和链表相加类似，倒着遍历两字符串，短的字符串补0，话不多说，直接上代码。 代码实现12345678910111213141516171819202122232425public String addStrings(String num1, String num2) &#123; //判断特殊情况 if(num1==&quot;&quot;||num1==null)&#123; return num2; &#125; if(num2==&quot;&quot;||num2==null)&#123; return num1; &#125; int carry=0; int len1=num1.length(); int len2=num2.length(); StringBuilder sb=new StringBuilder(); //倒着遍历字符串 for(int i=len1-1,j=len2-1;i&gt;=0||j&gt;=0;i--,j--)&#123; int x=i&gt;=0?num1.charAt(i)-48:0; int y=j&gt;=0?num2.charAt(j)-48:0; int sum=x+y+carry; carry=sum/10; sb.append(sum%10); &#125; if(carry==1)&#123; sb.append(1); &#125; return sb.reverse().toString();&#125;]]></content>
      <categories>
        <category>算法之美</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
        <tag>字符串</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第三大的数]]></title>
    <url>%2F2019%2F11%2F17%2F%E7%AC%AC%E4%B8%89%E5%A4%A7%E7%9A%84%E6%95%B0%2F</url>
    <content type="text"><![CDATA[LeetCode第四百一十四题难度：简单题目：给定一个非空数组，返回此数组中第三大的数。如果不存在，则返回数组中最大的数。要求算法时间复杂度必须是O(n)。 123456789101112131415示例 1:输入: [3, 2, 1]输出: 1解释: 第三大的数是 1.示例 2:输入: [1, 2]输出: 2解释: 第三大的数不存在, 所以返回最大的数 2 .示例 3:输入: [2, 2, 3, 1]输出: 1解释: 注意，要求返回第三大的数，是指第三大且唯一出现的数。存在两个值为2的数，它们都排第二。 思想分析这道题的主要思路在于最开始维护三个变量，分别存放前三大的数，在遍历数组时如果有数字满足条件，就更新这三个数。难点在于如何在初始化得到三个前三大的数。下面采用了一种巧妙地方法，直接上代码 代码实现12345678910111213141516171819public static int thirdMax(int[] nums) &#123; //用long保证max的初始值最小 long max = Long.MIN_VALUE; long mid = Long.MIN_VALUE; long min = Long.MIN_VALUE; for (int i = 0; i &lt; nums.length; i++) &#123; if (nums[i] &gt; max) &#123; min = mid; mid = max; max = nums[i]; &#125; else if (nums[i] &gt; mid &amp;&amp; nums[i] &lt; max) &#123; min = mid; mid = nums[i]; &#125; else if ((nums[i] &gt; min &amp;&amp; nums[i] &lt; mid)) &#123; min = nums[i]; &#125; &#125; return min==Long.MIN_VALUE?(int)max:(int)min;&#125; 这道题巧妙之处在于初始化三个变量，需要好好揣摩。]]></content>
      <categories>
        <category>算法之美</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
        <tag>数组</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[最长回文串]]></title>
    <url>%2F2019%2F11%2F17%2F%E6%9C%80%E9%95%BF%E5%9B%9E%E6%96%87%E4%B8%B2%2F</url>
    <content type="text"><![CDATA[LeetCode第四百零九题难度：简单题目：给定一个包含大写字母和小写字母的字符串，找到通过这些字母构造成的最长的回文串。在构造过程中，请注意区分大小写。比如 “Aa” 不能当做一个回文字符串。 1234567示例 1:输入:&quot;abccccdd&quot;输出:7解释:我们可以构造的最长的回文串是&quot;dccaccd&quot;, 它的长度是 7 思想分析我们分析，如果要一个字母要成为回文串的一部分，那么这个字母至少出现两次。并且如果回文串的长度小于字符串长度，那么回文串长度还要加1，因为位于回文串中间的字符可以只出现一次。由于说明存在大小写字母，因此要使用两个大小为26的数组进行统计。 代码实现12345678910111213141516171819202122232425262728293031323334353637383940public int longestPalindrome(String s) &#123; //判断特殊情况 if(s==&quot;&quot;||s==null)&#123; return 0; &#125; int len; if((len=s.length())==1)&#123; return 1; &#125; //分别用于统计大写字母和小写字母的个数 int[] little=new int[26]; int[] big=new int[26]; //遍历字符串 for(int i=0;i&lt;len;i++)&#123; int index; if((index=s.charAt(i))&gt;&apos;Z&apos;)&#123; big[index-&apos;a&apos;]++; &#125; else&#123; little[index-&apos;A&apos;]++; &#125; &#125; //统计回文长度 int res=0; for(int i=0;i&lt;26;i++)&#123; if(little[i]%2==0)&#123; res+=little[i]; &#125; else&#123; res+=little[i]-1; &#125; if(big[i]%2==0)&#123; res+=big[i]; &#125; else&#123; res+=big[i]-1; &#125; &#125; return res&lt;len?res+1:res;&#125;]]></content>
      <categories>
        <category>算法之美</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
        <tag>字符串</tag>
        <tag>回文</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数字转十六进制数]]></title>
    <url>%2F2019%2F11%2F16%2F%E6%95%B0%E5%AD%97%E8%BD%AC%E5%8D%81%E5%85%AD%E8%BF%9B%E5%88%B6%E6%95%B0%2F</url>
    <content type="text"><![CDATA[LeetCode第四百零五题难度：简单题目：给定一个整数，编写一个算法将这个数转换为十六进制数。对于负整数，我们通常使用补码运算方法。 1234567891011示例 1：输入:26输出:&quot;1a&quot;示例 2：输入:-1输出:&quot;ffffffff&quot; 思想分析十六进制数由16个字符组成:0、1、2、3、4、5、6、7、8、9、a、b、c、d、e、f。因此可以使用一个数组来存储这些字符。将数字每四位和15做与运算，映射到数组的相应位置 代码实现1234567891011121314public String toHex(int num) &#123; if(num==0)&#123; return &quot;0&quot;; &#125; char[] count=&quot;0123456789abcdef&quot;.toCharArray(); int mark=15; String s=&quot;&quot;; while(num!=0)&#123; s=count[num&amp;mark]+s; //每四位二进制转换成一位16进制数 num&gt;&gt;&gt;=4; &#125; return s;&#125;]]></content>
      <categories>
        <category>算法之美</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
        <tag>位运算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[左叶子之和]]></title>
    <url>%2F2019%2F11%2F16%2F%E5%B7%A6%E5%8F%B6%E5%AD%90%E4%B9%8B%E5%92%8C%2F</url>
    <content type="text"><![CDATA[LeetCode第四百零四题难度：简单题目：计算给定二叉树的所有左叶子之和。 123456789示例： 3 / \ 9 20 / \ 15 7在这个二叉树中，有两个左叶子，分别是 9 和 15，所以返回 24 思想分析对于二叉树，大部分都可以使用递归，这个题当然也可以。我们来分析一下 如果当前节点为空，返回0(递归出口) 如果当前节点的左子树为空，那么当前节点的左叶子和就是当前节点右子树的左叶子之和 如果当前节点的左子树为叶子，那么当前节点的左叶子和就是当前节点的左叶子+当前节点的右子树的左叶子和 如果当前节点左右子树都存在，那么当前节点的左叶子和就是当前节点的左子树左叶子和+当前节点的右子树的左叶子和 代码实现1234567891011121314public int sumOfLeftLeaves(TreeNode root) &#123; if (root == null) return 0; //如果左子树为空，那么只需返回右子树的左叶子和 if (root.left == null) return sumOfLeftLeaves(root.right); // 如果左子树为叶子节点，那么需返回右子树的左叶子和 + 左孩子的值 if (root.left.left == null &amp;&amp; root.left.right == null) return sumOfLeftLeaves(root.right) + root.left.val; // 其他情况需返回左右子树的左叶子和之和 return sumOfLeftLeaves(root.left) + sumOfLeftLeaves(root.right); &#125; 递归的代码简单明了，关键在于如何捋清思路。]]></content>
      <categories>
        <category>算法之美</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
        <tag>二叉树</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[判断子序列]]></title>
    <url>%2F2019%2F11%2F16%2F%E5%88%A4%E6%96%AD%E5%AD%90%E5%BA%8F%E5%88%97%2F</url>
    <content type="text"><![CDATA[LeetCode第三百九十二题难度：简单题目：给定字符串s和t，判断s是否为t的子序列。你可以认为s和t中仅包含英文小写字母。字符串t可能会很长（长度 ~= 500,000），而s是个短字符串（长度 &lt;=100）。字符串的一个子序列是原始字符串删除一些（也可以不删除）字符而不改变剩余字符相对位置形成的新字符串。（例如，”ace”是”abcde”的一个子序列，而”aec”不是）。 1234567示例 1:s = &quot;abc&quot;, t = &quot;ahbgdc&quot;返回 true.示例 2:s = &quot;axc&quot;, t = &quot;ahbgdc&quot;返回 false. 思想分析这道题需要结合String类的indexOf()方法来做 同时遍历两字符串，如果都没有遍历完并且s串当前字符位于t串中(并且在上一个字符的后面) 遍历下一个字符串，记录当前字符在t串中出现的位置(用于下次循环使用) 循环结束后，判断s串是否遍历完毕，如果遍历完毕，说明s是t的子序列，返回true；否则返回false 代码实现123456789public boolean isSubsequence(String s, String t) &#123; int index = 0,i = 0; //从s的上一个字符在t中的位置+1开始往后搜索 while(index &lt; s.length() &amp;&amp; t.indexOf(s.charAt(index),i) &gt;= i)&#123; i = t.indexOf(s.charAt(index),i) + 1; index++; &#125; return index == s.length();&#125;]]></content>
      <categories>
        <category>算法之美</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
        <tag>字符串</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[找不同]]></title>
    <url>%2F2019%2F11%2F16%2F%E6%89%BE%E4%B8%8D%E5%90%8C%2F</url>
    <content type="text"><![CDATA[LeetCode第三百八十九题难度：简单题目：给定两个字符串 s 和 t，它们只包含小写字母。字符串t由字符串s随机重排，然后在随机位置添加一个字母。请找出在 t 中被添加的字母。 12345678输入：s = &quot;abcd&quot;t = &quot;abcde&quot;输出：e解释：&apos;e&apos; 是那个被添加的字母。 思想分析又是一道字符串问题，并且题目说了，只包含小写字母；这时，我们第一时间应该想到可以使用大小为26的数组干点儿什么。想到这里就很简单了，不多说直接上代码 代码实现12345678910111213141516171819public char findTheDifference(String s, String t) &#123; //边界条件 if(s==&quot;&quot;||s==null) return t.charAt(0); int[] res=new int[26]; int lenS=s.length(); int lenT=t.length(); //遇到t中字符，相应位置+1 for(int i=0;i&lt;lenT;i++) res[t.charAt(i)-&apos;a&apos;]++; //遇到s中字符，相应位置-1 for(int i=0;i&lt;lenS;i++) res[s.charAt(i)-&apos;a&apos;]--; //数组中值为1的下标即为不同的字符 for(int i=0;i&lt;26;i++) if(res[i]==1) return (char)(i+&apos;a&apos;); throw new RuntimeException();&#125;]]></content>
      <categories>
        <category>算法之美</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
        <tag>字符串</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[字符串中唯一字符]]></title>
    <url>%2F2019%2F11%2F16%2F%E5%AD%97%E7%AC%A6%E4%B8%B2%E4%B8%AD%E5%94%AF%E4%B8%80%E5%AD%97%E7%AC%A6%2F</url>
    <content type="text"><![CDATA[LeetCode第三百八十七题难度：简单题目：给定一个字符串，找到它的第一个不重复的字符，并返回它的索引。如果不存在，则返回 -1。(假设只包含小写字符) 12345s = &quot;leetcode&quot;返回 0.s = &quot;loveleetcode&quot;,返回 2. 思想分析这道题，我想出了两种方法解决，一种直接使用哈希表，一种较为巧妙，组要结合String类提供的方法解决 哈希表，遍历字符串，以字符为键，字符出现的次数为值，存入到哈希表中。最后再遍历字符串，找到字符串中第一个值为1的字符。 由于题目说明只包含小写字符，那么遍历[a-z]26个小写字母，记录每个字符再字符串中第一次出现的位置(indexOf())first 如果first==-1，说明字符串中不包含该字符，直接进行下一次循环 再找到该字符再字符串中最后一次出现的位置(lastIndexOf())last，如果first==last(说明该字符只出现一次)。 代码实现1234567891011121314151617181920212223//哈希表实现比较简单，这里说下第二种思路public int firstUniqChar(String s) &#123; //判断特殊情况 if (s == null || s.length() == 0) &#123; return -1; &#125; int min = s.length(); //遍历26个小写字符 for (int i = &apos;a&apos;; i &lt;= &apos;z&apos;; i++) &#123; int first = s.indexOf(i); //如果当前字符不在字符串中，直接判断下一个字符 if (first == -1) &#123; continue; &#125; //如果当前字符在字符串中只出现了一次并且出现的位置最靠前 //更新min if (first == s.lastIndexOf(i) &amp;&amp; min &gt; first) &#123; min = first; &#125; &#125; return min == s.length() ? -1 : min;&#125; 在字符串问题中，会经常使用到大小为26的数组来模拟哈希表结构。]]></content>
      <categories>
        <category>算法之美</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
        <tag>字符串</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[赎金信]]></title>
    <url>%2F2019%2F11%2F16%2F%E8%B5%8E%E9%87%91%E4%BF%A1%2F</url>
    <content type="text"><![CDATA[LeetCode第三百八十三题难度：简单题目：给定一个赎金信 (ransom) 字符串和一个杂志(magazine)字符串，判断第一个字符串ransom能不能由第二个字符串magazines里面的字符构成。如果可以构成，返回 true ；否则返回 false。(两个字符串均只含有小写字母) 123canConstruct(&quot;a&quot;, &quot;b&quot;) -&gt; falsecanConstruct(&quot;aa&quot;, &quot;ab&quot;) -&gt; falsecanConstruct(&quot;aa&quot;, &quot;aab&quot;) -&gt; true 思想分析题目意思很简单，就是判断一个字符串中是否能由另一个字符串中的字符组成。可以使用哈希结构解决，由于题目说明了只包含小写字母，因此可以使用一个大小为26的数据来代替哈希表 代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445public boolean canConstruct(String ransomNote, String magazine) &#123; //如果没有说明只包含小写字母 //特殊边界情况 // if(ransomNote==&quot;&quot;||ransomNote==null) // return true; // if(magazine==null||magazine==&quot;&quot;) // return false; // if(ransomNote.length()&gt;magazine.length()) // return false; // Map&lt;Character,Integer&gt; map=new HashMap&lt;&gt;(); // //将字符串转化为数组 // char[] m=magazine.toCharArray(); // char[] r=ransomNote.toCharArray(); // for(int i=0;i&lt;m.length;i++)&#123; // if(map.containsKey(m[i])) // map.put(m[i],map.get(m[i])+1); // else // map.put(m[i],1); // &#125; // for(int i=0;i&lt;r.length;i++)&#123; // if(map.containsKey(r[i]))&#123; // int count=map.get(r[i]); // map.put(r[i],--count); // if(count&lt;0) // return false; // &#125; // else // return false; // &#125; // return true; //指明了只包含小写字母，因此可以使用数组代替哈希表 int[] num=new int[26]; char[] m=magazine.toCharArray(); char[] r=ransomNote.toCharArray(); //遇到杂志上的字符，哈希表相应位置+1 for(int i=0;i&lt;m.length;i++) num[m[i]-&apos;a&apos;]++; //遇到赎金信上的字符，响应位置-1 //如果&lt;0说明不能组成赎金信，返回false for(int i=0;i&lt;r.length;i++) if(--num[r[i]-&apos;a&apos;]&lt;0) return false; return true; &#125;]]></content>
      <categories>
        <category>算法之美</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
        <tag>字符串</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之生产者-消费者模式]]></title>
    <url>%2F2019%2F11%2F16%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E7%94%9F%E4%BA%A7%E8%80%85-%E6%B6%88%E8%B4%B9%E8%80%85%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[既然前面介绍了阻塞队列，现在就用阻塞队列ArrayBlockingQueue实现一个生产者消费者模式。在本文中，除了使用Java自带的同步容器，还将使用ReentrantLock+Condition的方式实现一个生产者-消费者模式。 概述生产者-消费者模式，生产者消费者模式就是通过一个容器来解决生产者和消费者的强耦合问题。生产者和消费者彼此之间不直接通讯，而通过阻塞队列来进行通讯，所以生产者生产完数据之后不用等待消费者处理，直接扔给阻塞队列，消费者不找生产者要数据，而是直接从阻塞队列里取，阻塞队列就相当于一个缓冲区，平衡了生产者和消费者的处理能力。这个阻塞队列就是用来给生产者和消费者解耦的。在线程世界里，生产者就是生产数据的线程，消费者就是消费数据的线程。在多线程开发当中，如果生产者处理速度很快，而消费者处理速度很慢，那么生产者就必须等待消费者处理完，才能继续生产数据。同样的道理，如果消费者的处理能力大于生产者，那么消费者就必须等待生产者。为了解决这种生产消费能力不均衡的问题，所以便有了生产者和消费者模式 ArrayBlockingQueue实现我们先来个简单地方式，使用阻塞队列来实现。后面你会发现，使用该方法其实也就是免去了自己创建仓库类的步骤。 商品类既然是生产者-消费者模型，那肯定要有一个商品类 123456789101112public class som &#123; private final int count; public som(int count) &#123; this.count = count; &#125; @Override public String toString() &#123; return &quot;商品ID: &quot; + count; &#125;&#125; 商品类很简单，只有一个用于标识商品的count和便于打印商品的toString()方法 生产者123456789101112131415161718192021222324252627public class Producer implements Runnable &#123; //缓冲区 private ArrayBlockingQueue&lt;som&gt; queue; //该线程生产的商品数 AtomicInteger count = new AtomicInteger(0); public Producer(ArrayBlockingQueue&lt;som&gt; queue) &#123; this.queue = queue; &#125; @Override public void run() &#123; try &#123; //生产者一直生产商品 while (true) &#123; som s = new som(count.incrementAndGet()); //将商品添加到缓冲区，使用put方法 //如果缓冲区满则阻塞 queue.put(s); System.out.println(&quot;|生产线程&quot; + Thread.currentThread().getId() + &quot; 生产 &quot; + s); &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 消费者12345678910111213141516171819202122public class Consumer implements Runnable &#123; //缓冲区 private ArrayBlockingQueue&lt;som&gt; queue; public Consumer(ArrayBlockingQueue&lt;som&gt; queue) &#123; this.queue = queue; &#125; @Override public void run() &#123; try &#123; while (true) &#123; //使得消费者消费速度比生产速度慢 Thread.sleep(2000); //take()方法，如果队列为空则阻塞 System.out.println(&quot;|消费线程&quot; + Thread.currentThread().getId() + &quot; 消费 &quot; + queue.take()); &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 测试12345678910111213141516public class ProducerAndConsumer &#123; public static void main(String[] args) &#123; ExecutorService exec = Executors.newCachedThreadPool(); ArrayBlockingQueue&lt;som&gt; queue = new ArrayBlockingQueue&lt;&gt;(10,true); //启动三个生产者线程 for (int i = 0; i &lt; 3; i++) &#123; exec.execute(new Producer(queue)); &#125; //启动10个消费者线程 for (int i = 0; i &lt; 10; i++) &#123; exec.execute(new Consumer(queue)); &#125; &#125;&#125; 以上就是使用阻塞队列ArrayBlockingQueue实现生产者-消费者模式。 ReentrantLock+Concition实现接下来我们使用ReentrantLock+Condition创建缓冲区代替阻塞队列来实现生产者-消费者模式 仓库个人实现，正确性应该没问题，性能应该还好。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135public class MyList&lt;E&gt; &#123; //存放数据的数组 E[] list; //下一次添加和删除的索引 private int putIndex; private int takeIndex; //记录缓冲区元素个数 private AtomicInteger count = new AtomicInteger(0); //数组容量(缓冲区大小) private int cal; //put锁和take锁，分别对put()和take()加锁 private ReentrantLock putlock; private Condition isFull; private ReentrantLock takelock; private Condition isEmpty; public MyList(int cal, ReentrantLock putlock, ReentrantLock takelock) &#123; list = (E[]) new Object[count]; cal = cal; this.putlock = putlock; this.takelock = takelock; this.isEmpty = takelock.newCondition(); this.isFull = putlock.newCondition(); &#125; /** * 唤醒在take方法上阻塞的线程 */ private void isEmpty() &#123; try &#123; takelock.lock(); if (count.get() &gt; 0) &#123; isEmpty.signalAll(); &#125; &#125;finally &#123; takelock.unlock(); &#125; &#125; /** * 唤醒在put方法上阻塞的线程 */ private void isFull() &#123; try &#123; putlock.lock(); if (count.get() &lt; list.length) &#123; isFull.signalAll(); &#125; &#125;finally &#123; putlock.unlock(); &#125; &#125; /** * 同时获得两把锁 */ private void AllLock() &#123; putlock.lock(); takelock.lock(); &#125; /** * 同时释放两把锁 */ private void AllUnlock() &#123; takelock.unlock(); putlock.unlock(); &#125; /** * 获取当前缓冲区元素个数 * @return */ public int size() &#123; try &#123; AllLock(); return count.get(); &#125;finally &#123; AllUnlock(); &#125; &#125; /** * 像缓冲区添加元素 * @param e * @throws InterruptedException */ public void put(E e) throws InterruptedException &#123; //获取put锁 putlock.lockInterruptibly(); try &#123; //如果当前缓冲区满，则阻塞 while (count.get() == list.length) &#123; isFull.await(); &#125; //将元素添加到指定索引位置 list[putIndex] = e; count.getAndIncrement(); //循环 if (++putIndex == list.length) &#123; putIndex = 0; &#125; &#125;finally &#123; putlock.unlock(); &#125; isEmpty(); &#125; /** * 取出缓冲区中元素 * @return 要取出的元素 * @throws InterruptedException */ public E take() throws InterruptedException &#123; E res; takelock.lockInterruptibly(); try &#123; while (count.get() == 0) &#123; isEmpty.await(); &#125; res = list[takeIndex]; list[takeIndex] = null; if (++takeIndex == list.length) &#123; takeIndex = 0; &#125; count.getAndDecrement(); return res; &#125;finally &#123; isFull(); takelock.unlock(); &#125; &#125;&#125; 如上，直接使用数组来实现，具体细节和ArrayBlockingQueue相似，但是锁部分则使用的是LinkedBlockingQueue的锁分离思想外加原子变量，能够使得生产和消费线程同时进行，提高了并发性能。 商品123456789101112public class Som &#123; private final int ID; public Som(int id) &#123; ID = id; &#125; @Override public String toString() &#123; return &quot;商品ID: &quot; + ID; &#125;&#125; 和前面的一样 生产者12345678910111213141516171819202122public class Producer implements Runnable&#123; MyList&lt;Som&gt; list; private AtomicInteger count = new AtomicInteger(0); public Producer(MyList&lt;Som&gt; list) &#123; this.list = list; &#125; @Override public void run() &#123; while (true) &#123; try &#123; Som s = new Som(count.incrementAndGet()); list.put(s); System.out.println(s + &quot; is put in the queue&quot;); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 生产者很简单，开启一个线程，不断地往缓冲区添加商品即可 消费者12345678910111213141516171819public class Consumer implements Runnable&#123; MyList&lt;Som&gt; list; public Consumer(MyList&lt;Som&gt; list) &#123; this.list = list; &#125; @Override public void run() &#123; while (true) &#123; try &#123; Thread.sleep(2000); System.out.println(list.take() + &quot; is out the queue ||&quot;); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 同样的，不断往缓冲区中拿即可 小结为了日后验证方便，所以将全部代码贴上，如果要运行直接拷贝即可。可以看出，用JDK提供的阻塞队列来实现生产者消费者模式还是很方便的。自己实现的时，如果采用ReentrantLock+Condition方式，可以采用LinkedBlockingQueue源码中的锁分离思想，能够提高并发性能。]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>多线程</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ArrayBlockingQueue源码详解]]></title>
    <url>%2F2019%2F11%2F16%2FArrayBlockingQueue%E6%BA%90%E7%A0%81%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[前面介绍了LinkedBlockingQueue，现在来介绍同步队列容器的另一种实现-ArrayBlockingQueue，很容易理解，该队列的底层数据结构为数组。下面就基于JDK1.8来介绍该容器。 整体架构类注释先看一下类注释 有界的阻塞数组，容量一旦创建后续大小无法修改 元素是有序的，按照先入先出的特性，从队头取出数据，从队尾插入数据 队列满时，put操作被阻塞；队列空时，take操作被阻塞 从类注释我们发现，ArrayBlockingQueue和一般的数组结构的容器不同，是不支持后续扩容的。如果队满或队空，put或take会被阻塞 类字段老样子，我们来先看一看该类有哪些字段，便于我们后期学习 12345678910111213141516//存放数据final Object[] items;//下次拿数据的时候的索引位置int takeIndex;//下次放数据的索引位置int putIndex;//当前集合中元素个数int count;//锁结构final ReentrantLock lock;private final Condition notEmpty;private final Condition notFull; 以上代码有两个字段takeIndex和putIndex，分别表示下次拿数据和放数据的索引位置，所以说在添加和删除数据时无需计算，可以直接知道相应的索引位置 源码学习下面我们正式看一下源码 初始化初始化时，有两个重要参数：数组的大小(即队列的容量)，是否公平。和LinkedBlockingQueue一样，初始化方法有三个 1234567891011121314151617181920212223242526272829303132333435363738//指定大小初始化，默认非公平public ArrayBlockingQueue(int capacity) &#123; this(capacity, false);&#125;//指定大小和是否公平public ArrayBlockingQueue(int capacity, boolean fair) &#123; if (capacity &lt;= 0) throw new IllegalArgumentException(); this.items = new Object[capacity]; lock = new ReentrantLock(fair); notEmpty = lock.newCondition(); notFull = lock.newCondition();&#125;//同时向集合中添加数据public ArrayBlockingQueue(int capacity, boolean fair, Collection&lt;? extends E&gt; c) &#123; this(capacity, fair); final ReentrantLock lock = this.lock; lock.lock(); // Lock only for visibility, not mutual exclusion try &#123; int i = 0; try &#123; for (E e : c) &#123; checkNotNull(e); items[i++] = e; &#125; &#125; catch (ArrayIndexOutOfBoundsException ex) &#123; throw new IllegalArgumentException(); &#125; count = i; putIndex = (i == capacity) ? 0 : i; &#125; finally &#123; lock.unlock(); &#125;&#125; 通过源码可以看出，构造方法的第二个boolean参数，主要是用于创建ReentrantLock时指定锁是否为公平锁。如果锁是公平的，那么在锁竞争时就会按照先来先获取的顺序；如果是非公平锁，锁竞争时是随机的。我们举个例子来说明： 加入现在队列已满还有很多线程执行put操作，必然会有很多线程被阻塞，当有其他线程执行take操作时，会唤醒等待的线程，如果是公平锁，会按照阻塞等待的顺序依次唤醒等待的线程，如果是非公平锁，会随机唤醒等待的线程。队列空时也是一样的道理添加元素添加数据时都会按照putIndex的位置进行添加123456789101112131415161718192021222324252627282930313233343536public void put(E e) throws InterruptedException &#123; //检查添加元素是否为null，如果为null抛出异常 checkNotNull(e); final ReentrantLock lock = this.lock; //可响应中断锁 lock.lockInterruptibly(); try &#123; //如果数组已满，该线程等待 while (count == items.length) notFull.await(); //将元素入队 enqueue(e); &#125; finally &#123; lock.unlock(); &#125;&#125;“=================================”//检查nullprivate static void checkNotNull(Object v) &#123; if (v == null) throw new NullPointerException();&#125;“=================================”//添加方法private void enqueue(E x) &#123; final Object[] items = this.items; items[putIndex] = x; //实现循环队列 if (++putIndex == items.length) putIndex = 0; count++; //唤醒其他取数据的线程 notEmpty.signal();&#125; 从源码可以看出，该队列实现的是一个循环队列，当新增到队尾时，下次新增会从队头开始 取出元素123456789101112131415161718192021222324252627282930public E take() throws InterruptedException &#123; final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try &#123; //如果数组为空，该线程等待 while (count == 0) notEmpty.await(); return dequeue(); &#125; finally &#123; lock.unlock(); &#125;&#125;“=================================”//取数据方法private E dequeue() &#123; final Object[] items = this.items; E x = (E) items[takeIndex]; items[takeIndex] = null; //如果takeIndex已经到队尾，则下次从头开始拿 if (++takeIndex == items.length) takeIndex = 0; //元素个数-- count--; if (itrs != null) itrs.elementDequeued(); //唤醒其他等待添加数据的线程 notFull.signal(); return x;&#125; take方法的源码也比较简单，就是普通的对循环队列的操作 删除元素12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970public boolean remove(Object o) &#123; //如果指定参数为null，直接返回false if (o == null) return false; final Object[] items = this.items; final ReentrantLock lock = this.lock; //不可响应中断锁 lock.lock(); try &#123; if (count &gt; 0) &#123; final int putIndex = this.putIndex; int i = takeIndex; //从队头开始遍历，找到要删除元素 do &#123; if (o.equals(items[i])) &#123; removeAt(i); return true; &#125; //由于是循环队列，因此当遍历到数据末端时从开头继续 if (++i == items.length) i = 0; &#125; while (i != putIndex); &#125; return false; &#125; finally &#123; lock.unlock(); &#125;&#125;“==============================”//删除方法逻辑代码void removeAt(final int removeIndex) &#123; final Object[] items = this.items; //如果要删除的位置和takeIndex一样 //则直接将该位置置为null，将takeIndex后移，count-- if (removeIndex == takeIndex) &#123; items[takeIndex] = null; if (++takeIndex == items.length) takeIndex = 0; count--; if (itrs != null) itrs.elementDequeued(); &#125; //如果要删除元素的位置和takeIndex不同 else &#123; final int putIndex = this.putIndex; //从要删除位置循环向后遍历，直到遍历到putIndex为止 //将元素依次向前移一个位置 for (int i = removeIndex;;) &#123; int next = i + 1; if (next == items.length) next = 0; if (next != putIndex) &#123; items[i] = items[next]; i = next; &#125; else &#123; items[i] = null; this.putIndex = i; break; &#125; &#125; count--; if (itrs != null) itrs.removedAt(removeIndex); &#125; //唤醒添加方法上阻塞的线程 notFull.signal();&#125; 小结对于ArrayBlockingQueue，底层是一个数组组成了一个循环队列，线程安全并且不可扩容。由于是循环队列，因此当takeIndex和putIndex到达队尾时都会重新从0开始]]></content>
      <categories>
        <category>JDK源码</category>
      </categories>
      <tags>
        <tag>ArrayBlockingQueue集合</tag>
        <tag>源码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LinkedBlockingQueue源码详解]]></title>
    <url>%2F2019%2F11%2F16%2FLinkedBlockingQueue%E6%BA%90%E7%A0%81%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[队列，在我们平时使用的线程池、读写锁、消息队列等技术和框架使用的非常广泛，它是很多高级API的基础，因此今天就来介绍一下一种同步队列–LinkedBlockingQueue。(本文基于JDK1.8版本) 整体架构继承体系LinkedBlockingQueue中文名叫做链表阻塞队列，因此我们可以知道其底层数据结构是链表，并且队列是可阻塞的，首先我们看一看LinkedBlockingQueue的类图从类图中我们可以看出，该类的继承体系有两条路径 AbstractQueue-&gt;AbstractCollection-&gt;Collection-&gt;Iterable，这一条路径主要是想复用Collection和迭代器的一些操作 BlockingQueue-&gt;Queue-&gt;Collection，这里主要说一下BlockingQueue和Queue两个接口 Queue是最基础的接口，几乎所有的队列实现类都会实现这个接口，该接口定义了三大类操作 新增操作 add：队列满时抛出异常 offer：队列满时返回false 查看并删除操作 remove：队列空时抛出异常 poll：队列空时返回null 只查看不删除操作 element：队列空时抛出异常 peek：队列空时返回null 一共六种方法，也可以按照是否抛出异常分类 遇到队空或满时抛出异常，如add、remove、element 遇到队空或满时返回特殊值，如offer、poll、peek BlockingQueue在Queue的基础上加了阻塞的概念，结合上面的几个方法，我们通过一个表格来比较一下 操作类型 抛异常 返回特殊值 一直阻塞 阻塞一段时间 新增-&gt;队满 add offer返回false put offer超时时间后返回false 查看并删除-&gt;队空 remove poll返回null take poll超时时间后返回false 查看-&gt;队空 element peek返回null 无 无 注意：remove方法BlockingQueue类注释中定义的是抛异常，但是实际实现时返回false 类注释接下来我们看一看LinkedBlockingQueue的类注释 基于链表的阻塞队列，其底层数据结构为链表 链表维护FIFO，新元素被放在队尾，获取元素从头部拿 链表大小在初始化时可以设置，默认为Integer的最大值 可以使用Collection和Iterator连个接口的所有操作 成员属性我们来看一看LinkedBlockingQueue有哪些字段 1234567891011121314151617181920//链表节点static class Node&lt;E&gt; &#123; E item; Node&lt;E&gt; next; Node(E x) &#123; item = x; &#125;&#125;//默认容量，为Integer.MAX_VALUEprivate final int capacity;//使用原子类计算链表元素个数private final AtomicInteger count = new AtomicInteger();//链表头transient Node&lt;E&gt; head;//链表尾private transient Node&lt;E&gt; last;//锁结构private final ReentrantLock takeLock = new ReentrantLock();private final Condition notEmpty = takeLock.newCondition();private final ReentrantLock putLock = new ReentrantLock();private final Condition notFull = putLock.newCondition(); 从代码上来看，LinkedBlockingQueue结构很清晰，主要是链表存储+锁+迭代器。链表的作用是为了保存当前节点，锁有take锁和put锁，是为了保证操作时线程安全，设计两种锁是为了take和put两种操作可以同时进行，互不影响。 源码分析下面我们来看一看LinkedBlockingQueue的源码 初始化初始化有三种方式 指定容量初始化 默认初始化，默认大小为Integer.MAX_VALUE 对已有集合数据进行初始化 12345678910111213141516171819202122232425262728293031323334353637383940414243444546//默认初始化public LinkedBlockingQueue() &#123; this(Integer.MAX_VALUE);&#125;“=================================”//指定大小初始化public LinkedBlockingQueue(int capacity) &#123; if (capacity &lt;= 0) throw new IllegalArgumentException(); this.capacity = capacity; last = head = new Node&lt;E&gt;(null);&#125;“=================================”//指定数据初始化public LinkedBlockingQueue(Collection&lt;? extends E&gt; c) &#123; this(Integer.MAX_VALUE); final ReentrantLock putLock = this.putLock; //使用put锁进行同步，即同一时刻只能有一个线程put putLock.lock(); try &#123; int n = 0; for (E e : c) &#123; //集合中元素不能为空 if (e == null) throw new NullPointerException(); //元素个数不能超过指定容量 if (n == capacity) throw new IllegalStateException(&quot;Queue full&quot;); //将节点插入链表尾 enqueue(new Node&lt;E&gt;(e)); ++n; &#125; //修改size count.set(n); &#125; finally &#123; //释放锁 putLock.unlock(); &#125;&#125;“=================================”//插入方法private void enqueue(Node&lt;E&gt; node) &#123; last = last.next = node;&#125; 在上述第三种添加方法中，源码在检查容量是在for循环中，每添加一个元素就检查一次，这样不够好；最好是在for循环外(添加元素前)就检查容量是否足够，如果不够直接抛出异常。举个例子：如果当前容量为500，要添加600个元素进去，按照源码的实例，会在添加第501个元素时才抛出异常；如果在循环外面判断，则会直接抛出异常而不用添加这么多次。 辅助方法在正式介绍添加删除等方法时，先介绍几个后面会用到的辅助方法 12345678910111213141516171819202122232425262728293031323334353637383940//唤醒在notEmpty上阻塞的一个线程private void signalNotEmpty() &#123; final ReentrantLock takeLock = this.takeLock; takeLock.lock(); try &#123; notEmpty.signal(); &#125; finally &#123; takeLock.unlock(); &#125;&#125;//唤醒在notFull上阻塞的一个线程private void signalNotFull() &#123; final ReentrantLock putLock = this.putLock; putLock.lock(); try &#123; notFull.signal(); &#125; finally &#123; putLock.unlock(); &#125;&#125;//将元素添加到队尾private void enqueue(Node&lt;E&gt; node) &#123; // assert putLock.isHeldByCurrentThread(); // assert last.next == null; last = last.next = node;&#125;//删除队头元素private E dequeue() &#123; Node&lt;E&gt; h = head; Node&lt;E&gt; first = h.next; //后面迭代器时会讲到为什么这么做 h.next = h; head = first; E x = first.item; first.item = null; return x;&#125; 阻塞添加-put方法支持添加的方法不止一个，比如add、put、offer，三者的区别前面已经介绍过，我们下面以put方法为例，进行学习 123456789101112131415161718192021222324252627282930313233public void put(E e) throws InterruptedException &#123; //如果新增元素为null，抛出异常 if (e == null) throw new NullPointerException(); int c = -1; Node&lt;E&gt; node = new Node&lt;E&gt;(e); final ReentrantLock putLock = this.putLock; final AtomicInteger count = this.count; //使用put锁的可中断锁方法 putLock.lockInterruptibly(); try &#123; //如果队列已满，线程阻塞 while (count.get() == capacity) &#123; notFull.await(); &#125; //队列未满，添加元素到链表尾 enqueue(node); //使用的是getAndIncrement，即先获取后增加 //和incrementAndGet不同 //因此获取的c比添加后容量小1 c = count.getAndIncrement(); //如果此时链表大小小于容量，说明链表未满 //调用signal方法尝试唤醒一个put的等待线程 if (c + 1 &lt; capacity) notFull.signal(); &#125; finally &#123; putLock.unlock(); &#125; //c=0，代表队列里有一个元素 //则会尝试唤醒一个take的等待线程 if (c == 0) signalNotEmpty();&#125; 从源码中我们可以得到 添加数据之前，使用put锁加锁，所以添加数据是线程安全的 put方法简单地将数据添加到队尾 添加时，如果队满，当前线程是会被阻塞的。 新增数据成功后，在适当的时机会唤起put的等待线程(队列不满时)，或者take的等待线程。这样保证一旦满足put或take条件时立马就能唤起阻塞线程，继续运行。 阻塞添加-offer方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263//指定超时时间public boolean offer(E e, long timeout, TimeUnit unit) throws InterruptedException &#123; if (e == null) throw new NullPointerException(); long nanos = unit.toNanos(timeout); int c = -1; final ReentrantLock putLock = this.putLock; final AtomicInteger count = this.count; putLock.lockInterruptibly(); try &#123; while (count.get() == capacity) &#123; //如果nanos&lt;=0说明超过等待时间， //直接返回false if (nanos &lt;= 0) return false; nanos = notFull.awaitNanos(nanos); &#125; enqueue(new Node&lt;E&gt;(e)); c = count.getAndIncrement(); if (c + 1 &lt; capacity) notFull.signal(); &#125; finally &#123; putLock.unlock(); &#125; if (c == 0) signalNotEmpty(); return true;&#125;“=================================”//不指定时间的offer方法public boolean offer(E e) &#123; if (e == null) throw new NullPointerException(); final AtomicInteger count = this.count; //如果队列满，直接返回false if (count.get() == capacity) return false; int c = -1; Node&lt;E&gt; node = new Node&lt;E&gt;(e); final ReentrantLock putLock = this.putLock; putLock.lock(); try &#123; //双重检查，保证队列未满 //可能其他线程进行了put操作，导致队列满 if (count.get() &lt; capacity) &#123; enqueue(node); c = count.getAndIncrement(); if (c + 1 &lt; capacity) notFull.signal(); &#125; &#125; finally &#123; putLock.unlock(); &#125; if (c == 0) signalNotEmpty(); //如果添加成功返回true //否则返回false return c &gt;= 0;&#125; 指定等待时间的offer方法和put的区别只在于调用的阻塞方法不同，而不指定等待时间的offer方法如果队列满会直接返回false，不会进行等待。 阻塞删除-take方法删除的方法也有很多，我们以take方法为例进行学习 1234567891011121314151617181920212223242526public E take() throws InterruptedException &#123; E x; int c = -1; final AtomicInteger count = this.count; final ReentrantLock takeLock = this.takeLock; takeLock.lockInterruptibly(); try &#123; while (count.get() == 0) &#123; notEmpty.await(); &#125; //获取头节点值 x = dequeue(); //先获取后减1 c = count.getAndDecrement(); //如果此时队不为空，唤醒一个take的阻塞线程 if (c &gt; 1) notEmpty.signal(); &#125; finally &#123; takeLock.unlock(); &#125; //c==capacity说明队列还有一个空闲空间 //尝试唤醒一个put方法的阻塞线程 if (c == capacity) signalNotFull(); return x;&#125; take方法的流程很简单，在take锁的同步块内进行，整体思想和put方法类似，同样的poll方法和前面的offer方法也很类似。下面我们紧接着介绍一下查看方法 查看-peek方法123456789101112131415public E peek() &#123; if (count.get() == 0) return null; final ReentrantLock takeLock = this.takeLock; takeLock.lock(); try &#123; Node&lt;E&gt; first = head.next; if (first == null) return null; else return first.item; &#125; finally &#123; takeLock.unlock(); &#125;&#125; 可以看到，peek方法使用的也是take锁，这很容易理解。 迭代器不知道前面你注意到没有，在删除节点调用dequeue()方法删除节点时，使用的是h.next=h，而不是直接将h.next=null，这是什么原因呢？看完了迭代器你就会知道 辅助方法在介绍迭代器之前，先介绍三个个辅助方法 1234567891011121314151617181920212223//将take锁和put锁全部获得void fullyLock() &#123; putLock.lock(); takeLock.lock();&#125;//释放两锁void fullyUnlock() &#123; takeLock.unlock(); putLock.unlock();&#125;//删除方法void unlink(Node&lt;E&gt; p, Node&lt;E&gt; trail) &#123; p.item = null; trail.next = p.next; if (last == p) last = trail; //由于进行了删除，因此如果当前集合中还有一个容量 //则唤醒一个put方法上等待的线程 if (count.getAndDecrement() == capacity) notFull.signal();&#125; 这是可以理解的，在迭代过程中必须保证既不能添加也不能删除和查看。 迭代方法12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485//同样的，返回一个Iterator实现类对象public Iterator&lt;E&gt; iterator() &#123; return new Itr();&#125;“=========================”//迭代器实现类private class Itr implements Iterator&lt;E&gt; &#123; //下一次迭代节点 private Node&lt;E&gt; current; //上一次迭代节点 private Node&lt;E&gt; lastRet; private E currentElement; Itr() &#123; //进入同步区域 fullyLock(); try &#123; current = head.next; if (current != null) currentElement = current.item; &#125; finally &#123; fullyUnlock(); &#125; &#125; public boolean hasNext() &#123; return current != null; &#125; //获取下一个节点 private Node&lt;E&gt; nextNode(Node&lt;E&gt; p) &#123; for (;;) &#123; Node&lt;E&gt; s = p.next; //此时进行过take操作，并且current指向已经被删除的头节点 if (s == p) return head.next; if (s == null || s.item != null) return s; p = s; &#125; &#125; public E next() &#123; fullyLock(); try &#123; if (current == null) throw new NoSuchElementException(); //获取当前迭代节点值 E x = currentElement; //赋值上一次迭代节点 lastRet = current; //获取下一次迭代节点 current = nextNode(current); //此时说明链表为空 currentElement = (current == null) ? null : current.item; return x; &#125; finally &#123; fullyUnlock(); &#125; &#125; public void remove() &#123; //第一次迭代或者当前节点已经被删除 if (lastRet == null) throw new IllegalStateException(); fullyLock(); try &#123; Node&lt;E&gt; node = lastRet; lastRet = null; for (Node&lt;E&gt; trail = head, p = trail.next; p != null; trail = p, p = p.next) &#123; //找到上次迭代的节点进行删除 if (p == node) &#123; unlink(p, trail); break; &#125; &#125; &#125; finally &#123; fullyUnlock(); &#125; &#125;&#125; 以上就是迭代器方法源码，主要说以下一点 nextNode方法中为什么会存在if (s == p)分支？结合前面dequeue方法的源码我们可以得出结论，在dequeue方法中，删除第一个节点后，并不是将next域置为null，而是指向自身。关键就在这里，当删除节点为current指向的节点时，如果将next节点置为null，那么迭代将无法继续。因此将next指向自身，在迭代方法中进行额外判断。小结LinkedBlockingQueue队列使用带头节点的单向链表+ReentrantLick锁来实现阻塞队列，实现思想比较简单，但是其中同步的细节和迭代器的实现很棒，值得我们学习。]]></content>
      <categories>
        <category>JDK源码</category>
      </categories>
      <tags>
        <tag>源码</tag>
        <tag>LinkedBlockingQueue集合</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CopyOnWriteArrayList源码解析]]></title>
    <url>%2F2019%2F11%2F13%2FCopyOnWriteArrayList%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[在前面介绍ArrayList集合时，我们说过，ArrayList是一个非线程安全的集合，它的类注释推荐我们自己加锁或者使用Collections.synchronizedList方法来获取线程安全的集合。其实JDK还有另外一种线程安全的List，叫做CopyOnWriteArrayList。接下来将基于JDK1.8版本介绍该集合。 概述CopyOnWriteArrayList集合具有以下特征 线程安全的，多线程情况下无需加锁可以直接使用 通过锁+数组拷贝+volatile关键字保证了线程安全 每次数组操作，都会把数组拷贝一份出来，在新数组上进行操作，操作成功后再赋值回去 整体架构从整体架构上来说，CopyOnWriteArrayList数据结构和ArrayList是一致的，底层是个数组，只不过CopyOnWriteArrayList在对数组进行操作的时候，基本会走四步： 加锁 从原数组中拷贝出新数组 在新数组上进行操作，并将新数组赋给集合 解锁 除了加锁之外，CopyOnWriteArrayList地底层数组还被volatile修饰，意思是一旦数组被修改，其他线程立马能够感知到 1private transient volatile Object[] array; 整体来说，CopyOnWriteArrayList就是利用锁+数组拷贝+volatile关键字保证了List的线程安全。 源码学习类注释我们看看从CopyOnWriteArrayList的类注释上能得到哪些信息： 所有的操作都是线程安全的，因为操作都是在新拷贝的数组上进行的； 数组的拷贝虽然有一定的成本，但往往比一般的替代效率高 迭代过程中，不会影响原来的数组，也不会抛出ConcurrentModificationException异常。 新增方法新增方法有很多种重载形式，比如新增到数组尾部、新增到数组某个索引位置、批量新增等等，操作的思路还是前面说的四步，我们以新增到尾部为例 1234567891011121314151617181920public boolean add(E e) &#123; final ReentrantLock lock = this.lock; //获取锁 lock.lock(); try &#123; //得到原数组 Object[] elements = getArray(); int len = elements.length; //将所有数据拷贝到新数组中，长度为len+1，因为要添加一个元素进去 Object[] newElements = Arrays.copyOf(elements, len + 1); //在新数组中进行赋值 newElements[len] = e; //替换掉原来的数组 setArray(newElements); return true; //finally中释放锁 &#125; finally &#123; lock.unlock(); &#125;&#125; 从源码中我们发现，整个add()方法都是在持有锁的状态下进行的，通过加锁，来保证同一时刻只有一个线程对数组进行访问。除了加锁之外，还会从老数组中创建出一个新数组，然后将老数组中的值拷贝到新数组上。这时候就有一个问题了：既然已经加了锁，为什么还要拷贝一个新数组并且在新数组上操作而不直接在原来数组中进行操作呢？这样做是因为： volatile关键字修饰的是数组，如果简单地在原来数组上修改某几个元素的值，是无法触发可见性的，我们必须通过修改数组的内存地址才行，也就是说对数组进行重新赋值 在新的数组上进行拷贝，对老数组没有任何影响，只有新数组完全拷贝完成之后，外部才能访问到，降低了在赋值过程中老数组数据变动的影响 下面我们再看看指定位置添加元素的方法源码 12345678910111213141516171819202122232425262728293031public void add(int index, E element) &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; Object[] elements = getArray(); int len = elements.length; //校验参数是否越界 if (index &gt; len || index &lt; 0) throw new IndexOutOfBoundsException(&quot;Index: &quot;+index+ &quot;, Size: &quot;+len); Object[] newElements; int numMoved = len - index; //如果为0说明数据添加位置为数组末尾 if (numMoved == 0) newElements = Arrays.copyOf(elements, len + 1); else &#123; newElements = new Object[len + 1]; //第一次拷贝:将[0~index)的数据从原数组拷贝到新数组 System.arraycopy(elements, 0, newElements, 0, index); //第二次拷贝:将[index~len)的数据拷贝的新数组 //[index+1~len+1)位置 System.arraycopy(elements, index, newElements, index + 1, numMoved); &#125; //通过前两次拷贝，新数组中下标为index的位置为空，直接赋值 newElements[index] = element; setArray(newElements); &#125; finally &#123; lock.unlock(); &#125;&#125; 通过源码和注释我们可以很清楚的看到该方法的实现，先将原数组从插入位置一分为二，分别进行两次拷贝，最终将下标为index的位置空出来放置要插入的值 小结从add()方法源码可以看出，CopyOnWriteArrayList通过加锁+数组拷贝+volatile来保证了线程安全，每一个要素都有其独特的含义 加锁：保证同一时刻只能被一个线程操作 数组拷贝：保证数组的内存地址被修改，修改后立刻触发volatile可见性，其他线程立刻可以看到数组被修改后的值 volatile：值被修改后，其他线程能够立马感知最新值 三要素缺一不可，如果我们只是用1和3，去掉2，这样当我们修改数组中某个值时，并不会触发可见性，只有当数组内存地址被修改后，才能触发可见性 删除方法下面我们来看一看删除方法，删除方法也有不同的重载形式，这里介绍它其中一种，删除指定位置元素 123456789101112131415161718192021222324public E remove(int index) &#123; final ReentrantLock lock = this.lock; //加锁 lock.lock(); try &#123; Object[] elements = getArray(); int len = elements.length; //获取老值 E oldValue = get(elements, index); int numMoved = len - index - 1; if (numMoved == 0) setArray(Arrays.copyOf(elements, len - 1)); else &#123; Object[] newElements = new Object[len - 1]; System.arraycopy(elements, 0, newElements, 0, index); System.arraycopy(elements, index + 1, newElements, index, numMoved); setArray(newElements); &#125; return oldValue; &#125; finally &#123; lock.unlock(); &#125;&#125; 可以看到，删除方法和添加方法逻辑类似，从删除位置将将数组分成两部分，进行两次拷贝，具体分为三步 加锁 判断索引位置，从而进行不同的拷贝 解锁 批量删除数组的批量删除比较有意思，下面我们来看一看 12345678910111213141516171819202122232425262728293031323334public boolean removeAll(Collection&lt;?&gt; c) &#123; if (c == null) throw new NullPointerException(); final ReentrantLock lock = this.lock; lock.lock(); try &#123; Object[] elements = getArray(); int len = elements.length; //说明当前数组中有值，若当前集合没有元素直接返回false if (len != 0) &#123; //表示新数组的索引位置 int newlen = 0; Object[] temp = new Object[len]; //循环，把不包含在c里的元素拷贝到新数组中 for (int i = 0; i &lt; len; ++i) &#123; Object element = elements[i]; if (!c.contains(element)) temp[newlen++] = element; &#125; //拷贝新数组，变相删除了包含在c中的元素 if (newlen != len) &#123; setArray(Arrays.copyOf(temp, newlen)); return true; &#125; &#125; return false; &#125; finally &#123; lock.unlock(); &#125;&#125;“=================================”final void setArray(Object[] a) &#123; array = a;&#125; 从源码中可以看出，我们并不会直接对数组中的元素进行删除，而是先对数组中的值进行循环判断，把不需要删除的数据放到临时数组中，最后临时数组就是我们删除元素后的数组。可以和ArrayList的批量删除思想联系起来，所以我们在需要删除多个元素的时候，最好也采用这种批量删除的思想，而不是在for循环中单个删除；如果单个删除，那么每一次删除都会有拷贝操作；而如果批量删除，就只会有一次拷贝操作。 查找方法CopyOnWriteArrayList中的查找方法和普通ArrayList中查找方法一样，使用indexOf实现，并且不需要加锁。 12345678910111213141516171819202122232425/** * static version of indexOf, to allow repeated calls without * needing to re-acquire array each time. * @param 要查找的值 * @param 搜索的目标数组 * @param 搜索的开始位置 * @param 搜索的结束位置 * @return 返回搜索值得数组下标，未找到返回-1 */private static int indexOf(Object o, Object[] elements, int index, int fence) &#123; //如果要查找null值，则用==比较 if (o == null) &#123; for (int i = index; i &lt; fence; i++) if (elements[i] == null) return i; &#125; //如果要查找非空值，则使用equals方法 else &#123; for (int i = index; i &lt; fence; i++) if (o.equals(elements[i])) return i; &#125; return -1;&#125; 该方法是一个内部方法，实现了查找的逻辑代码。CopyOnWriteArrayList的内部使用比较广泛，各种重载形式的查找方法、contains内部都调用了该方法。 迭代方法在类注释中，明确的说明了在CopyOnWriteArrayList迭代过程中即使数组的原值被改变，也不会抛出ConcurrentModificationException异常。其根源在于数组每次变动，都会生成新的数组，并不会影响老数组，这样一来，在迭代过程中根本就不会发现迭代数组的变动。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public Iterator&lt;E&gt; iterator() &#123; return new COWIterator&lt;E&gt;(getArray(), 0);&#125;static final class COWIterator&lt;E&gt; implements ListIterator&lt;E&gt; &#123; private final Object[] snapshot; private int cursor; private COWIterator(Object[] elements, int initialCursor) &#123; cursor = initialCursor; snapshot = elements; &#125; public boolean hasNext() &#123; return cursor &lt; snapshot.length; &#125; public boolean hasPrevious() &#123; return cursor &gt; 0; &#125; public E next() &#123; if (! hasNext()) throw new NoSuchElementException(); return (E) snapshot[cursor++]; &#125; public E previous() &#123; if (! hasPrevious()) throw new NoSuchElementException(); return (E) snapshot[--cursor]; &#125; public int nextIndex() &#123; return cursor; &#125; public int previousIndex() &#123; return cursor-1; &#125; //不支持删除操作 public void remove() &#123; throw new UnsupportedOperationException(); &#125; //不支持修改操作 public void set(E e) &#123; throw new UnsupportedOperationException(); &#125; //不支持添加操作 public void add(E e) &#123; throw new UnsupportedOperationException(); &#125;&#125; 上面就是CopyOnWriteArrayList的迭代器源码，可以发现，内部迭代的数组直接持有原数组的引用。并且没有版本号。结合前面的添加删除方法，可以发现，每次操作后集合的内部数组就会改变，因此迭代器持有的数组也变成了无效数组，这也是该迭代器不支持删除、添加、修改操作的原因，因为如果迭代器创建后，如果集合结构发生了改变，那么在该数组上的任何修改操作都不会影响到集合中的数组。CopyOnWriteArrayList集合底层仍是数组，通过锁+拷贝数组+volatile实现线程安全，实现比较简单。]]></content>
      <categories>
        <category>JDK源码</category>
      </categories>
      <tags>
        <tag>源码</tag>
        <tag>CopyOnWriteArrayList集合</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅谈Java线程池(含常见面试题)]]></title>
    <url>%2F2019%2F11%2F13%2F%E6%B5%85%E8%B0%88Java%E7%BA%BF%E7%A8%8B%E6%B1%A0-%E5%90%AB%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98%2F</url>
    <content type="text"><![CDATA[线程池，从字面上看，是指管理一组同构工作线程的资源池。线程池是与工作队列密切相关的，其中在工作队列中保存了所有等待执行的任务。 概述在这篇文章中，将包含对线程池常见方法、线程池的内部实现、线程池的拒绝策略逐个进行介绍；除此之外，还包含一些常见的线程池面试题目。以上为Executor框架的继承体系结构 线程池常见方法获取方法获取一个线程池，我们有两种方法：一是通过Executor框架中Executors的静态方法来获取线程池对象。还可以通过直接创建ThreadPoolExecutor对象来直接创建线程池。这两种方法的差异以及如何选择这两种方法在后面会介绍。这里先介绍使用Executors的静态方法获取线程池对象。 1234public static ExecutorService newFixedThreadPool(int nThreads)public static ExecutorService newSingleThreadExecutor()public static ExecutorService newCachedThreadPool()public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) newFixedThreadPool(int nThreads)该方法返回一个固定线程数量的线程池。该线程池中的线程数量始终不变，当有一个新的任务提交时，若线程池中有空闲线程，则立即执行。若没有，则新的任务会被暂存在任务队列中，待有线程空闲时，就处理任务队列中的线程。 newSingleThreadExecutor()该方法返回一个只有一个线程的线程池。若多余一个任务被提交，同样的，该任务会被保存到任务队列中，待到线程空闲时，按先进先出的顺序执行队列中的任务 newCachedThreadPool()该方法返回一个可根据实际情况调整线程数量的线程池。线程池的线程数量不确定，但若有空闲线程可复用，则会优先使用可复用线程。若所有线程均在工作，又有新任务提交，则会创建新的线程处理任务。所有线程在当前任务执行完毕后，将返回线程池复用。 newScheduledThreadPool(int corePoolSize)该方法返回一个ScheduledExecutorService对象，该对象可以在给定时间执行任务，如在固定时间后执行任务、或者周期性执行执行某个任务 执行方法这里只介绍几个常用的方法 12public void execute(Runnable command)public Future&lt;?&gt; submit(Runnable task) execute()该方法是定义在Exector接口中的方法，用于执行一个任务，接受一个Runnable接口，无返回值 submit()该方法是ExecutorService接口中定义的方法，用于提交一个任务，接受一个Runnable接口，返回一个Future接口实现类，用于管理提交的任务。 线程池的内部实现对于核心的集合线程池，无论是newFixedThreadPool()方法、还是newCachedThreadPool()方法，虽然看起来创建的线程有着完全不同的功能特点，但其内部均使用了ThreadPoolExecutor类。下面给出这三个方法的源码 123456789101112131415161718192021222324public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;());&#125;public static ExecutorService newSingleThreadExecutor() &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()));&#125;public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;());&#125; 上述三个方法就是Executors类三个工厂方法的源码，通过原阿门可以看到，他们都是返回一个ThreadPoolExecutor对象，只是传递的参数不同。接下来就看看ThreadPoolExecutor类最重要的构造方法： 1234567public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) 该方法的参数如下： corePoolSize：指定线程池中线程的数量 maximumPoolSize：指定线程池中最大线程的数量 keepAliveTime：当线程池中线程数量超过corePoolSize时，多余空闲线程的存活时间，即超过corePoolSize的空闲线程，在多长时间内会被销毁 unit：keepAliveTime的时间单位 workQueue：任务队列，被提交但尚未被执行的任务 threadFactory：线程工厂，用于创建线程，一般使用默认的即可 handler：拒绝策略。当任务太多来不及处理时，如何拒绝任务 对于以上7个参数，大部分都比较简单，特别说明以下workQueue和handler两个参数 workQueue是指被提交但尚未执行的任务队列，它是一个BlockingQueue接口的对象，仅用于存放Runnable接口对象。根据队列功能分类，在ThreadPoolExecutor类的构造方法可以使用以下几种BlockingQueue接口 直接提交队列：该功能由SynchronousQueue对象提供SynchromousQueue是一个特殊的BlockingQueue。没有容量，每一个插入操作都要等待一个相应的删除操作，反之，每一个删除操作都要等待对应的插入操作。如果使用该队列，那么提交的任务不会被真实的保存，而是总将新任务提交给线程执行，如果没有空闲线程，则尝试创建新的线程，如果线程数量已经达到最大数量，则执行相应的拒绝策略。因此，在使用该队列时，通常要设置很大的maximumPoolSize。 有界的任务队列：有界的任务队列可以使用ArrayBlockingQueue类实现，ArrayBlockingQueue类的构造方法必须带一个容量参数，表示该队列的最大容量。使用有界的任务队列时，如有新的任务需要执行，如果线程池的实际线程数小于corePoolSize，则创建新的线程执行任务，若大于corePoolSize，则会将新的任务加入等待队列。若等待队列已满，无法加入，则在总线程数不大于maximumPoolSize的前提下，创建新的线程执行人物。若大于maximumPoolSize，则执行拒绝策略。可以发现，有界队列仅在任务队列装满时，才可能将线程数提升到corePoolSize以上。 无界的任务队列：无界的任务队列可以通过LinkedBlockingQueue类实现，与有界队列相比，除非资源耗尽，否则无界队列不存在入队失败的情况。当有新任务到来，系统线程数小于corePoolSize时，线程池创建新的线程执行任务，但当系统线程数达到corePoolSize后，就不会增加了。若后续仍有任务加入但是没有空闲线程，则任务直接进入队列等待。 解释了ThreadPoolExecutor的构造方法后，Executors的几个获取线程池的工厂方法获取的线程池参数也就很清楚了。 拒绝策略ThreadPoolExecutor类的最后一个参数指定了拒绝策略。也就是当任务数量超过系统实际承载能力时，就要用到拒绝策略了。拒绝策略可以说是系统超负荷运行时的补救措施。JDK内置了四种拒绝策略 AbortPolicy策略：该策略直接抛出异常，阻止系统正常工作 CallerRunsPolicy策略：只要线程池未关闭，该策略直接在调用者线程中，运行当前被丢弃的任务。显然这样做不会真的丢弃任务，但是提交线程的性能极有可能会急剧下降。 DiscardOldestPolicy策略：该策略将丢弃最老的一个请求，也就是即将被执行的一个任务(队头)，并尝试再次提交当前任务 DiscardPolicy策略：该策略默默丢弃一个无法处理的任务，不予以任何处理。如果允许任务丢失，这是最好的方案。 以上内置策略均实现了RejectedExecutionHandler接口，若以上策略仍无法实际满足需要，可以自己实现该接口，定义自己的方法。 1234public interface RejectedExecutionHandler &#123; void rejectedExecution(Runnable r, ThreadPoolExecutor executor);&#125; 该接口只有一个抽象方法rejectedExecution，其中r为请求执行的任务，executor为当前线程池。 123456789101112131415161718192021222324252627282930313233343536public class ThreadPoolExecutorTest implements Runnable &#123; @Override public void run() &#123; System.out.println(System.currentTimeMillis() + &quot; : Thread ID: &quot; + Thread.currentThread().getId()); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; ThreadPoolExecutorTest r = new ThreadPoolExecutorTest(); ExecutorService ex = new ThreadPoolExecutor( 5, 5, 0L, TimeUnit.SECONDS, new LinkedBlockingQueue&lt;Runnable&gt;(10), Executors.defaultThreadFactory(), new RejectedExecutionHandler() &#123; @Override public void rejectedExecution(Runnable r, ThreadPoolExecutor executor) &#123; System.out.println(&quot;任务提交过多&quot;); &#125; &#125;// (runnable,executor)-&gt; &#123;// throw new RuntimeException(&quot;任务提交过多&quot;);// &#125; ); for (int i = 0; i &lt; Integer.MAX_VALUE; i++) &#123; ex.execute(r); &#125; &#125;&#125; 如果，使用ThreadPoolExecutor构造方法创建线程池时，自己实现了rejectedExecution接口，并重写了rejectedExecution方法(设置自己的拒绝策略) ThreadFactory介绍了这么多关于线程池的知识，你可能会问：那线程池中的线程从哪里来呢？之前我们说过，线程池的作用主要是为了线程复用，也就是避免线程的频繁创建和销毁，但是最开始的线程又是哪里来的呢？答案就是ThreadFactory。Factory是一个接口，他只有一个用来创建线程的方法 1234public interface ThreadFactory &#123; Thread newThread(Runnable r);&#125; 当线程池需要新建线程时，就会调用该方法。自定义线程池可以帮助我们做不少事情。比如，我们可以跟踪线程究竟在何时创建了多少个线程，也可以自定义线程名称，组以及优先级等信息，甚至可以将所有线程设置为守护线程。 常见面试题1.什么是线程池？为什么要使用线程池线程池是一种多线程处理形式，处理过程将任务提交到线程池，任务的执行交由线程池来管理。创建和销毁线程的花销是比较大的，这些时间可能比线程执行的时间还要长。频繁的创建和销毁线程也会给GC造成很大的压力，延长GC停顿时间。为了避免频繁的创建和销毁线程，我们可以让线程复用，线程池正是实现了这个功能，当需要执行任务时，从线程池中取出一个线程，任务执行完毕后线程并不销毁而是返回给线程池用于执行下一个任务。 几种常见的线程池及使用场景 newSingleThreadExecutor:创建单个线程的线程池，它只会用唯一的线程来执行任务，并且保证公平性 newFixedThreadPool:创建定长线程池，可控制最大并发数，超出的线程会在队列中等待 newCachedThreadPool:创建一个可缓存的线程池，如果线程池长度超过处理需要，可回收灵活空闲线程，如果无可用线程，则会创建线程 newScheduledThreadPool:创建一个定长线程池，支持定时及周期性任务执行 线程池中几种重要的参数 corePoolSize:核心线程的数量，这些线程在空闲的时候也不会被回收 maxmumPoolSize:线程池最大可以容纳的线程数 keepAliveTime:除了核心线程外其他空闲线程最长可保留时间 unit:计算这个时间的单位 workQueue:任务队列，如果当前没有空闲线程，那么被提交的任务将被存储在队列中 ThreadFactory:创建线程的线程工厂，当线程池需要创建新的线程时，就会调用该对象的newThread()方法 handler:一种拒绝策略，当线程池超负荷运行时，可以拒绝执行某些任务 线程池的拒绝策略当任务不断地提交过来，而系统又处理不过来时，我们需要采取一定的拒绝策略来拒绝服务。前面介绍过JDK内置的四种拒绝策略以及自定义拒绝策略地方法，这里不做赘述。 线程池地关闭关闭线程池可以调用shutDownNow()和shutdown()两个方法来实现。shutDownNow方法对正在执行的任务全部发出interrupt()中断请求，停止执行，对还未开始执行的任务全部取消，并且返回还没开始的任务列表；shutdown()方法调用后不再接受新任务，但也不会去强制终止已经提交或正在执行中的任务。但是要注意的是，shutDownNow方法并不一定会终结线程，因为它调用的是线程的interrupt()方法，线程是否终止由线程自己来决定。]]></content>
      <categories>
        <category>Java并发编程</category>
      </categories>
      <tags>
        <tag>多线程</tag>
        <tag>线程池</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅谈Java同步工具类]]></title>
    <url>%2F2019%2F11%2F12%2F%E6%B5%85%E8%B0%88Java%E5%90%8C%E6%AD%A5%E5%B7%A5%E5%85%B7%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[前面相继介绍了两种锁、volatile关键字和FutureTask几种Java并发工具，现在继续介绍几种Java的同步工具类，分别是：CountDownLatch(闭锁)、Semaphore(信号量)、Condition。 CountDownLatch–闭锁这是一个非常实用的多线程控制工具类，闭锁的作用相当于一扇门：在闭锁到达结束状态之前，这扇门是一直关闭的，并且没有任何线程能够通过，当到达结束状态时，这扇门会打开并允许所有的线程通过。闭锁到达结束状态之后，将不会再改变状态，因此这扇门将永远保持打开状态。 1234567891011121314151617181920212223242526public class CountDownLatchTest implements Runnable &#123; public static CountDownLatch count = new CountDownLatch(10); @Override public void run() &#123; int i=1; while (true) &#123; try &#123; System.out.println(i++); count.countDown(); Thread.sleep(100); &#125; catch (InterruptedException e) &#123; System.out.println(&quot;任务结束&quot;); break; &#125; &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; CountDownLatchTest r = new CountDownLatchTest(); Thread t = new Thread(r); t.start(); count.await(); t.interrupt(); &#125;&#125; 在这段测试代码中，让一个线程从1打印到10，创建一个闭锁对象，传递参数为count=10。在t线程中，每打印一个数，就调用一次countDown()方法，闭锁对象内部的count就-1；调用await()方法阻塞主线程，当闭锁内部count为0时，主线程线程被唤醒，中断t线程。 Semaphore–信号量从广义上来说，信号量是对锁的扩展，无论是内置锁还是显式锁，一次都只允许一个线程访问一个资源，而信号量却可以指定多个线程同时访问某个资源 构造方法123public Semaphore(int permits)//第二个参数指定是否公平public Semaphore(int permits,boolean fair) 在创建信号量对象时，必须指定信号量准入数，即同时能申请多少个许可。当每个线程每次只申请一个许可时，这就相当于制定了同时可以有多少个线程访问某一资源。 主要方法让我们来看一看信号量有哪些主要方法 1234567public void acquire()public void acquireUninterruptibly()public boolean tryAcquire()public boolean tryAcquire(long timeout, TimeUnit unit)public void release() acquire()和acquireUninterruptibly()获取一个准入许可。每获取一个，信号量内部维护的许可就少一个，当许可数为0时，当前线程无法获取，则线程会等待，知道有线程释放许可或当前线程被中断。当使用acquireUninterruptibly()时不会响应中断，因此线程如果无法获取许可，那么会一直等到由许可为止。 tryAcquire()和tryAcquire(long timeout, TimeUnit unit)尝试获取一个许可，获取成功返回true，失败返回false。带参数的重载形式如果获取失败会等待一段时间，如果在超时时间内成功获取返回true，否则返回false。无参方法如果获取失败不会等待直接返回false。 release()用于线程在访问资源后释放一个许可，是其他等待许可的线程可以进行资源访问。 可以发现，该工具类的方法和显式锁的方法有一定的类似。 123456789101112131415161718192021222324252627282930public class BoundedHashSet&lt;T&gt; &#123; private final Set&lt;T&gt; set; private final Semaphore sem; public BoundedHashSet(int bound) &#123; this.set = Collections.synchronizedSet(new HashSet&lt;&gt;()); sem = new Semaphore(bound); &#125; public boolean add(T t) throws InterruptedException &#123; sem.acquire(); boolean wasAdded = false; try &#123; wasAdded = set.add(t); return wasAdded; &#125;finally &#123; if (!wasAdded) &#123; sem.release(); &#125; &#125; &#125; public boolean remove(T t) &#123; boolean wasremove = set.remove(t); if (wasremove) &#123; sem.release(); &#125; return wasremove; &#125;&#125; 这是一个简单地阻塞有界集合，底层使用synchronizedSet实现。当集合中的元素个数超过bound时，add()方法会被阻塞。 Condition–显式锁的好搭档Condition是与显式锁相关联的，通过Lock接口的new Condition()方法可以生成一个与当前重入锁绑定的Condition实例。 Condition成员方法12345void await() throws InterruptedExceptionvoid awaitUninterruptibly()void signal()void signalAll()boolean await(long time, TimeUnit unit) throws InterruptedException 可以将这些方法类比于和synchronized绑定的wait()、notify()方法。 await()方法和awaitUninterruptibly()使得当前线程等待，同时释放锁，当其他线程使用相同的Condition调用signal()方法或者signalAll()方法时，线程会获得锁重新执行，和wait()方法类似，但是该方法可以响应中断,awaitUninterruptibly()方法和awit()方法作用一样但是无法响应中断。 signal()signalAll()和notify()方法和notifiAll()方法类似，前者唤醒一个等待在该Condition对象上的线程，后者唤醒所有等待在该Condition对象上的线程。 测试Demo123456789101112131415161718192021222324252627282930313233public class ReentrantLockCondition implements Runnable &#123; public static ReentrantLock lock = new ReentrantLock(); public static Condition condition = lock.newCondition(); @Override public void run() &#123; try &#123; lock.lock(); //调用condition实例的awit()方法阻塞线程 condition.await(); System.out.println(&quot;Thread is going on&quot;); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;finally &#123; lock.unlock(); &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; ReentrantLockCondition r1 = new ReentrantLockCondition(); Thread t1 = new Thread(r1); t1.start(); Thread.sleep(1000); lock.lock(); //唤醒在该condition实例上阻塞的一个线程 condition.signal(); System.out.println(&quot;main&quot;); lock.unlock(); &#125;&#125; 上述代码中创建了一个与ReentrantLock对象绑定的Condition对象，有一点要注意：wait()方法和notify()方法只能在synchronized同步区域由锁对象调用；此处也一样，Condition对象只能在和其绑定的lock锁区域内调用awit()和signa()方法。在JDK的内部，显式锁和Condition对象被广泛使用，ArrayBlockingQueue类使用的即使这种方法实现线程安全(后面详细介绍该同步容器)]]></content>
      <categories>
        <category>Java并发编程</category>
      </categories>
      <tags>
        <tag>多线程</tag>
        <tag>CountDownLatch</tag>
        <tag>Semaphore</tag>
        <tag>CyclicBarrier</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发工具之显式锁]]></title>
    <url>%2F2019%2F11%2F12%2FJava%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E4%B9%8B%E6%98%BE%E5%BC%8F%E9%94%81%2F</url>
    <content type="text"><![CDATA[在JDK1.5后，增加了一种新的同步机制，那就是ReentrantLock。和synchronized不同，ReentrantLock并不是一种代替内置加锁的方式，而是当内置加锁机制不适用时，作为一种可选择的功能。Lock提供了一种无条件的、可轮询的、定时的以及可中断的锁获取操作。 概述我们知道，由synchronized锁造成的线程阻塞是无法被中断的，并且在内置锁中，死锁是一个很严重的问题，唯一恢复程序的方式就是重新启动程序，而防止死锁的唯一方法就是在构造程序时避免出现不一致的顺序。但是ReentrantLock中的可定时可轮询机制提供了另一种选择：避免死锁的发生。我们将在稍后进行介绍。本文不涉及源码方面的知识，仅介绍ReentrantLock不同枷加锁方法的介绍和演示。 ReentrantLock的使用下面将分别介绍ReentrantLock的一般加锁、可中断锁、定时锁和轮询锁几种不同的用法。 一般加锁1234567891011121314151617181920212223public class NormalLock implements Runnable &#123; public static ReentrantLock lock = new ReentrantLock(); @Override public void run() &#123; try &#123; //加锁，进入同步区域 lock.lock(); System.out.println(&quot;同步区域&quot;); Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;finally &#123; //退出同步区域 lock.unlock(); &#125; &#125; public static void main(String[] args) &#123; NormalLock r = new NormalLock(); new Thread(r).start(); &#125;&#125; 调用lock()方法，相当于进入了同步区，而调用unlock()方法，就相当于退出同步块。通俗的说，这两个方法之间的部分，就是一个synchronized同步块。但是要注意的是，当同步区域发生异常时，ReentrantLock并不会像synchronized一样释放锁，因此对于这种同步方法，解锁操作一定要放在finally语句中，保证线程无论出现什么情况都能够释放锁。 可中断锁对于synchronized来说，一个线程在等待锁，那么结果只有两种情况，要么获得锁继续执行，要么就保持等待，它是屏蔽中断的。而是用ReentrantLock，则提供另外一种可能，那就是可以响应中断。也就是说在等待锁的过程中，程序可以根据需要取消对锁的请求。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980public class IntLock implements Runnable &#123; public static ReentrantLock lock1 = new ReentrantLock(); public static ReentrantLock lock2 = new ReentrantLock(); int lock; /** * 通过参数控制加锁顺序 * @param lock */ public IntLock(int lock) &#123; this.lock = lock; &#125; @Override public void run() &#123; try &#123; if (lock == 1) &#123; lock1.lockInterruptibly(); try &#123; Thread.sleep(500); &#125; catch (InterruptedException e) &#123; System.out.println(&quot;lock1 Sleep Interrupted!&quot;); &#125; lock2.lockInterruptibly(); &#125; else &#123; lock2.lockInterruptibly(); try &#123; Thread.sleep(500); &#125; catch (InterruptedException e) &#123; System.out.println(&quot;lock2 Sleep Interrupted&quot;); &#125; lock1.lockInterruptibly(); &#125; &#125; catch (InterruptedException e) &#123; System.out.println(Thread.currentThread().getId()+&quot;: 响应中断&quot;); &#125; //在finally语句中进行锁的释放 finally &#123; //如果线程持有锁，返回true if (lock1.isHeldByCurrentThread()) &#123; System.out.println(Thread.currentThread().getId()+&quot; lock1 锁解锁&quot;); lock1.unlock(); &#125; if (lock2.isHeldByCurrentThread()) &#123; System.out.println(Thread.currentThread().getId()+&quot; lock2 锁解锁&quot;); lock2.unlock(); &#125; System.out.println(Thread.currentThread().getId() + &quot;: 线程退出&quot;); &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; IntLock r1 = new IntLock(1); IntLock r2 = new IntLock(2); Thread t1 = new Thread(r1); Thread t2 = new Thread(r2); t1.start(); t2.start(); Thread.sleep(1000); t2.interrupt(); &#125;&#125;“===============================”Output：t2: 响应中断t2 lock2 锁解锁t2: 线程退出t1 lock1 锁解锁t1 lock2 锁解锁t1: 线程退出 我们启动两个线程t1和t2 t1先占用lock1，再占用lock2 t2先占用lock2，再占用lock1 然后统一使用lockInterruptibly()方法进行加锁 在这种情况下，如果使用synchronized同步代码块，就造成了死锁，并且无法改变。但是在这里，我们使用ReentrantLock的lockInterruptibly()方法，这是一个可以对中断进行响应的锁申请动作，在等待锁的过程中，可以响应中断。即如果收到中断请求，该方法会抛出异常的方式来进行响应。在上述程序中，t1获取到了lock1后在等待lock2锁，而t2获得了lock2后在等待lock1，在主线程中调用了t2线程的中断方法，此时t2放弃对lock1锁的获取，中断执行任务，并在finally中释放了lock2锁；因此t1线程成功获取到lock2锁，最终成功执行完毕。因此虽然t1和t2都退出了，但是只有t1完成了任务，t2则放弃其任务直接退出。 定时锁除了等待外部通知以外，要避免死锁还有另外一种方法，那就是限时等待。通常，我们无法判断为什么一个线程迟迟拿不到锁，也许是因为死锁了，也许是因为产生了饥饿。如果给定一个等待时间，如果超时还无法获取到锁，让线程自动放弃，那么这么做对系统来说是有意义的。tryLock(long timeout,TimeUnit unit)方法可以做到这点。该方法给定一个等待时间，如果在给定时间内获得了锁，那么返回true；否则返回false。 1234567891011121314151617181920212223242526272829303132public class TimeLock implements Runnable &#123; public static ReentrantLock lock = new ReentrantLock(); @Override public void run() &#123; try &#123; if (lock.tryLock(5, TimeUnit.SECONDS)) &#123; Thread.sleep(6000); &#125;else &#123; System.out.println(&quot;get Lock failed&quot;); &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;finally &#123; if (lock.isHeldByCurrentThread()) &#123; lock.unlock(); &#125; &#125; &#125; public static void main(String[] args) &#123; TimeLock r1 = new TimeLock(); TimeLock r2 = new TimeLock(); new Thread(r1).start(); new Thread(r2).start(); &#125;&#125;“===============================”Output：get Lock failed 在上述代码中，线程1先拿到了锁，进入后调用sleep阻塞6s中，而之后线程2尝试获取锁时，在5s内无法获取到锁，因为此时锁正由线程1持有。所以tryLock返回false，线程2放弃获取锁，不执行if语句中内容。 轮询锁当使用不带参数的tryLock方法时，当前线程会尝试获得锁，如果获取成功则返回true。如果当前锁已经被占用，那么当前线程不会进行等待，而是立即返回false。相当于等待时间为0，和前面定时锁类似，不做赘述。 公平锁在ReentrantLock的构造方法中提供了两种公平性的选择： 创建一个非公平锁(默认情况下)在这种情况下，允许插队：当一个线程获取非公平锁时，如果在发出请求的同时该锁可用，那么这个线程可能跳过所有等待的线程并获取这把锁。 创建一个公平锁(传入true参数)线程按照它们发出请求的顺序来获得锁 在公平锁中，如果有另一个线程持有这个锁或者有其他线程在队列中等待这把锁，那么新发出的请求将被放在队列中，由于队列先进先出的特性，先发出请求的线程自然也就先入队，因而能够先获得锁。 1234567891011121314151617181920212223242526272829303132333435363738/** * 公平锁，可以避免饥饿问题 */public class FairLock implements Runnable &#123; public static ReentrantLock lock = new ReentrantLock(true); @Override public void run() &#123; while (true) &#123; try &#123; lock.lock(); System.out.println(Thread.currentThread().getName() + &quot;: 获得锁&quot;); &#125;finally &#123; lock.unlock(); &#125; &#125; &#125; public static void main(String[] args) &#123; ExecutorService exec = Executors.newCachedThreadPool(); for (int i = 0; i &lt; 3; i++) &#123; exec.execute(new FairLock()); &#125; &#125;&#125;“===============================”Output：pool-1-thread-1: 获得锁pool-1-thread-2: 获得锁pool-1-thread-3: 获得锁pool-1-thread-1: 获得锁pool-1-thread-2: 获得锁pool-1-thread-3: 获得锁pool-1-thread-1: 获得锁pool-1-thread-2: 获得锁pool-1-thread-3: 获得锁...... 可以看到，三个线程交替获取锁。公平锁不会产生饥饿现象，但是要实现公平锁必然要求系统维护一个有序队列，因此实现公平锁的成本比较高，性能比较低下，非公平锁是抢占式的，线程不必加入等待队列就可以获得锁，不仅免去了构造节点并加入队列的繁琐操作，也节省了线程阻塞唤醒的开销。因此如果没有特别需求，默认使用非公平锁 Synchronized和ReentrantLock介绍了ReentrantLock之后，我们又多了一种加锁的方式，那我们又该如何选择这两种方式呢？ReentrantLock在加锁和内存上提供的语义和内置锁相同，此外它还提供了一些其他的功能。但是内置锁也有它的优点：使用起来简洁紧凑，并且不用显式的加锁和释放锁，当出现异常后会自动释放锁，而显式锁却每次使用后要在finally语句中释放锁以保证后续线程能够重新获取锁，这对于开发人员来说无疑是个隐形的坑。因此，在一些内置锁无法满足需求的情况下，我们才去使用显式锁。这些需求包括：可定时的、可中断的与可轮询的获取操作、公平锁。否则还是应该优先使用synchronized内置锁。]]></content>
      <categories>
        <category>Java并发编程</category>
      </categories>
      <tags>
        <tag>多线程</tag>
        <tag>ReentrantLock</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅谈Java多线程中断机制]]></title>
    <url>%2F2019%2F11%2F11%2F%E6%B5%85%E8%B0%88Java%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%AD%E6%96%AD%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[在Java中，线程中断是一种重要的线程协作机制。从表面上理解，终端就是让目标线程停止执行的意思，实际上并非如此。对中断操作的正确理解是：它并不会真正的中断一个正在运行的线程，而只是发出中断请求，然后由线程在下一个合适的时刻中断自己。中断是实现取消的最好方式。 概述严格的讲，线程中断并不会使线程立即退出，而是给线程发送一个通知，告知目标线程，有人希望你退出了。至于目标线程接到通知后如何处理，则完全由目标线程自行决定！理解这点很重要。 中断方法有三个方法和中断有关，这三个方法看起来很像，很有可能会引起混淆和误用，稍后将会详细介绍这三个方法的作用 123456//实例方法，中断线程public void Thread.interrupt()//实例方法，判断线程是否被中断public boolean Thread.isInterrupted()//静态方法，判断是否被中断并清除当前中断状态public static boolean Thread.interrupted() 该方法是一个实例方法。它通知目标线程中断，也就是设置中断标志位。中断标志位表示当前线程已经被中断了。当发出中断请求时，该线程可通过不同的方式来响应中断 中断方式一12345678910111213141516171819class RunnableImpl implements Runnable&#123; @Override public void run() &#123; while (!Thread.currentThread().isInterrupted()) &#123; Thread.yield(); &#125; System.out.println(&quot;Interrupted&quot;); &#125;&#125;public class InterruptedTest &#123; public static void main(String[] args) &#123; RunnableImpl r = new RunnableImpl(); Thread t = new Thread(r); t.start(); t.interrupt(); &#125;&#125; 通过上述代码我们可以发现，线程可以通过判断当前中断状态来决定是否继续循环执行。 中断方式二12345678910111213141516171819202122232425class RunnableImpl implements Runnable&#123; @Override public void run() &#123; while (true) &#123; try &#123; Thread.sleep(1000); System.out.println(&quot;running......&quot;); &#125; catch (InterruptedException e) &#123; System.out.println(Thread.currentThread().isInterrupted()); break; &#125; &#125; &#125;&#125;public class InterruptedTest &#123; public static void main(String[] args) throws InterruptedException &#123; RunnableImpl r = new RunnableImpl(); Thread t = new Thread(r); t.start(); Thread.sleep(5000); t.interrupt(); &#125;&#125; 上述代码中，当线程调用sleep阻塞时，如果收到了中断请求，就会通过抛出异常的方式来处理中断请求。但是要注意的是，在抛出异常后，现成的中断请求会被复位，也就是说，如果在上述代码的catch语句中没有break语句的话，线程在处理完中断请求(执行catch语句后)将会继续循环下去。实际上break也是处理中断请求的一部分。 小结 在线程调用wait、sleep、join等方法(显式声明InterruptedException的方法)陷入阻塞时，会以异常的方式来处理外部的中断请求，相应的处理中断请求的逻辑代码在catch语句中编写。但是要注意的是，当抛出异常后，线程的中断请求相当于得到了处理，此时中断状态就会复位。如果想维持中断状态，应该在catch中再次调用interrupt()方法将中断状态复位。 可以结合isInterrupted()方法和interrupted()方法判断中断标志位来处理中断请求，但是要注意的是使用静态方法interrupted判断中断标志位时，判断过后会将中断标志位复位(类似于异常处理)。 如果线程没有处理中断请求的逻辑代码，那么中断请求并不能中断请求，只是改变了线程的中断标志位，线程仍将继续运行下去。 测试代码下面来写几段测试代码来验证上面的小结 中断请求并不总会中断线程12345678910111213141516171819class RunnableImpl implements Runnable&#123; @Override public void run() &#123; while (true) &#123; Thread.yield(); &#125; &#125;&#125;public class InterruptedTest &#123; public static void main(String[] args) throws InterruptedException &#123; RunnableImpl r = new RunnableImpl(); Thread t = new Thread(r); t.start(); t.interrupt(); &#125;&#125; 以上代码在调用线程的中断方法interrupt()时，由于线程的run方法并没有处理中断的逻辑代码，既没有阻塞方法异常处理，也没有使用isInterrupted()和interrupted()方法处理，所以此时中断请求相当于被线程屏蔽了，线程并不会停止，而是会无限期的执行下去。 静态方法interrupted自动恢复中断标志位12345678910111213141516171819202122232425class RunnableImpl implements Runnable&#123; @Override public void run() &#123; while (!Thread.interrupted()) &#123; Thread.yield(); &#125; System.out.println(&quot;线程使用interrupted()方法响应中断&quot;); System.out.println(&quot;此时中断标志位:&quot;+Thread.interrupted()); &#125;&#125;public class InterruptedTest &#123; public static void main(String[] args) throws InterruptedException &#123; RunnableImpl r = new RunnableImpl(); Thread t = new Thread(r); t.start(); t.interrupt(); &#125;&#125;”=========================“Output：线程使用interrupted()方法响应中断此时中断标志位:false 我们可以看到，t线程中使用Thread的静态方法interrupted()来响应中断，第一次调用该方法时，返回true，因此退出while循环，但当我们第二次再次调用该方法时，却返回false。这说明Thread.interrupted()在第一次判断中断标志位后将中断标志位恢复了。 使用异常处理中断后同样会将会将中断标志位恢复123456789101112131415161718192021222324252627282930class RunnableImpl implements Runnable&#123; @Override public void run() &#123; while (true) &#123; try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; System.out.println(&quot;线程被中断&quot;); System.out.println(&quot;此时中断标志位:&quot;+Thread.interrupted()); &#125; &#125; &#125;&#125;public class InterruptedTest &#123; public static void main(String[] args) throws InterruptedException &#123; RunnableImpl r = new RunnableImpl(); Thread t = new Thread(r); t.start(); Thread.sleep(2000); t.interrupt(); &#125;&#125;”=========================“Output：线程被中断此时中断标志位:false 通过输出可以很清楚的看到，在线程阻塞时，通过异常处理中断请求。在进入catch块中的语句后，调用interrupted()方法检查线程的中断状态，返回false。这说明当使用异常处理中断请求时，进入catch语句块后，相当于已经响应了中断请求，重新将线程的中断标志位恢复。 总结对于中断线程，通俗的说就是调用interruptt()方法将线程的中断标志位置为true(可以这么理解)，但是线程是否处理该终端是由线程自己决定，或者说是由编写线程的人决定。所谓的中断仅仅是改变线程的中断标志位而已，线程最终是否停止执行由线程自身的逻辑代码决定。]]></content>
      <categories>
        <category>Java并发编程</category>
      </categories>
      <tags>
        <tag>多线程</tag>
        <tag>中断</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[详解Runnable与Callable]]></title>
    <url>%2F2019%2F11%2F11%2F%E8%AF%A6%E8%A7%A3Runnable%E4%B8%8ECallable%2F</url>
    <content type="text"><![CDATA[在Java中，要想创建一个线程任务，有三种方式，分别是： 继承Thread类，重写run()方法 实现Runnable接口 实现Callable接口(后面详细说到) 实现Runnable接口如果我们选择该方法创建一个线程任务，那我们需要实现Runnable接口，重写run()方法。这样做只是创建了一个任务，那要怎样才能启动一个线程呢？具体有两种方法 构造Thread对象将实现类对象作为参数构造一个Thread对象，并调用Thread对象的start方法 12345678910111213141516//实现Runnable接口public class RunnableTest implements Runnable &#123; @Override public void run() &#123; System.out.println(&quot;run()&quot;); &#125; public static void main(String[] args) &#123; //创建实现类对象 RunnableTest r=new RunnableTest(); //作为参数构造Thread对象 Thread t = new Thread(r); //调用start方法开启一个线程 t.start(); &#125;&#125; 构造FutureTask对象将实现类对象作为参数构造一个TutureTask对象，再将FutureTask对象作为参数构造一个Thread对象，这样我们就能通过FutureTask来管理任务。前面讲过FutureTask实现了Runnable接口，因此可以被当作Runnable对象来使用。 12345678910111213141516171819//实现Runnable接口public class RunnableTest implements Runnable &#123; @Override public void run() &#123; System.out.println(&quot;run()&quot;); &#125; public static void main(String[] args) &#123; //创建实现类对象 RunnableTest r=new RunnableTest(); //作为参数构造FutureTask对象 FutureTask&lt;String&gt; futureTask = new FutureTask&lt;&gt;(r, &quot;hello&quot;); //构造Thread对象 Thread t = new Thread(futureTask); //调用start方法开启一个线程 t.start(); &#125;&#125; 通过前面的学习我们知道，FutureTask只有两个构造方法，一个是接收Callable对象，一个是接收Runnable对象和执行结果。 12345678910111213//接收Callable对象public FutureTask(Callable&lt;V&gt; callable) &#123; if (callable == null) throw new NullPointerException(); this.callable = callable; this.state = NEW; &#125;//接收Runnable对象 public FutureTask(Runnable runnable, V result) &#123; this.callable = Executors.callable(runnable, result); this.state = NEW; &#125; 我们可以发现，当我们使用Runnable构造方法时，该方法会将Runnable最终包装成一个Callable对象并赋值给成员属性callable，那么Runnable对象是怎样转换成Callable对象的呢？我们继续看 12345678910111213141516171819202122232425查看Executors类的callable方法public static &lt;T&gt; Callable&lt;T&gt; callable(Runnable task, T result) &#123; if (task == null) throw new NullPointerException(); return new RunnableAdapter&lt;T&gt;(task, result);&#125;”====================================“//Executors的私有嵌套类RunnableAdapter实现了Callable接口private static final class RunnableAdapter&lt;T&gt; implements Callable&lt;T&gt; &#123; private final Runnable task; private final T result; RunnableAdapter(Runnable task, T result) &#123; this.task = task; this.result = result; &#125; //重写call方法 public T call() &#123; task.run(); return result; &#125; public String toString() &#123; return super.toString() + &quot;[Wrapped task = &quot; + task + &quot;]&quot;; &#125;&#125; 通过以上源码我们发现，通过调用Executors的静态方法callable，返回Executors的私有嵌套类对象，该对象是一个适配器，它实现了Callable接口，将run()方法和返回值封装在call()方法里面，从而将Runnable对象转换成Callable对象。 通过线程池来执行12345678910111213141516//实现Runnable接口public class RunnableTest implements Runnable &#123; @Override public void run() &#123; System.out.println(&quot;run()&quot;); &#125; public static void main(String[] args) &#123; //创建实现类对象 RunnableTest r=new RunnableTest(); ExecutorService exec = Executors.newCachedThreadPool(); exec.execute(r); // Future&lt;?&gt; submit = exec.submit(r); &#125;&#125; 通过线程池可以使用两种方式，一种是调用execute方法直接执行，另一种是调用submit方法，该方法会返回一个FutureTask对象，可以用来管理任务。 实现Callable接口当你需要任务执行后的结果时候，可以使用这种方式。因为Thread构造方法不接受Callable对象，因此有两种方式开启线程 构造FutureTask对象12345678910111213141516public class CallableTest implements Callable&lt;Integer&gt; &#123; @Override public Integer call() &#123; System.out.println(&quot;call()&quot;); return 1; &#125; public static void main(String[] args) throws InterruptedException, ExecutionException &#123; CallableTest cal = new CallableTest(); FutureTask&lt;Integer&gt; futureTask = new FutureTask&lt;&gt;(cal); Thread t = new Thread(futureTask); t.start(); System.out.println(&quot;线程执行后的结果：&quot;+futureTask.get()); &#125;&#125; 将Callable包装成为FutureTask对象，因为该对象实现了Runnable接口，因此可以被用来构造Thread对象，并且FutureTask对象还能够用来管理任务，例如获取执行结果、取消线程等操作。 通过线程池来执行和Runnable一样的，该方式也可以通过线程池来执行，不过这时候就不能使用execute方法，因为该方法无法获取管理任务的FutureTask对象，也就无法获取任务执行后的结果。 12345678910111213141516171819public class CallableTest implements Callable&lt;Integer&gt; &#123; @Override public Integer call() &#123; System.out.println(&quot;call()&quot;); return 1; &#125; public static void main(String[] args) throws InterruptedException, ExecutionException &#123; CallableTest cal = new CallableTest(); FutureTask&lt;Integer&gt; futureTask = new FutureTask&lt;&gt;(cal); ExecutorService exec = Executors.newCachedThreadPool(); Future&lt;Integer&gt; submit = exec.submit(cal); //也可以使用execute方法，不过会比较麻烦 //并且没有任何其他作用 //exec.execute(futureTask); &#125;&#125; 总结到这里Runnable和Callable方法就介绍完了，结合前面FutureTask的源码学习我们不难发现，当我们实现Callable来执行任务的时候，最终执行的仍然是run()方法，只不过FutureTask通过重写run()，在run()方法中调用call()方法，并将call方法的返回值保存起来，当调用get()方法时将结果返回即可。你学会了么？]]></content>
      <categories>
        <category>Java并发编程</category>
      </categories>
      <tags>
        <tag>多线程</tag>
        <tag>Runnable</tag>
        <tag>Callable</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入剖析FutureTask]]></title>
    <url>%2F2019%2F11%2F11%2F%E6%B7%B1%E5%85%A5%E5%89%96%E6%9E%90FutureTask%2F</url>
    <content type="text"><![CDATA[Future模式可以这样来描述：我有一个任务提交给了Future，Future可以替我完成这个任务，期间我自己可以去做任何想做的事情。一段时间后，我可以从Future那取得结果。Future接口提供方法来检测任务是否被执行完，等待任务执行完获得结果，也可以设置任务超时时间。接下来，将依次介绍Runnable接口、Callable接口、Future接口和它的实现类FutureTask。 Runnable接口123456789101112131415public interface Runnable &#123; /** * When an object implementing interface &lt;code&gt;Runnable&lt;/code&gt; is used * to create a thread, starting the thread causes the object&apos;s * &lt;code&gt;run&lt;/code&gt; method to be called in that separately executing * thread. * &lt;p&gt; * The general contract of the method &lt;code&gt;run&lt;/code&gt; is that it may * take any action whatsoever. * * @see java.lang.Thread#run() */ public abstract void run();&#125; 该接口很简单，只有一个抽象方法run() Callable接口123456789public interface Callable&lt;V&gt; &#123; /** * Computes a result, or throws an exception if unable to do so. * * @return computed result * @throws Exception if unable to compute a result */ V call() throws Exception;&#125; 同样的，Callable接口也只有一个抽象方法call()，但是和run()方法不同的是，call()方法有异常声明 Future接口12345678910111213public interface Future&lt;V&gt; &#123; boolean cancel(boolean mayInterruptIfRunning); boolean isCancelled(); boolean isDone(); V get() throws InterruptedException, ExecutionException; V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;&#125; cancel()1boolean cancel(boolean mayInterruptIfRunning); 试图取消对此任务的执行。如果任务已完成、或已取消，或者由于某些其他原因而无法取消，则此尝试将失败。当调用 cancel 时，如果调用成功，而此任务尚未启动，则此任务将永不运行。如果任务已经启动，则 mayInterruptIfRunning 参数确定是否应该以试图停止任务的方式来中断执行此任务的线程。 参数：mayInterruptIfRunning - 如果应该中断执行此任务的线程，则为 true；否则允许正在运行的任务运行完成。 返回：如果无法取消任务，则返回 false，这通常是由于它已经正常完成；否则返回 true。 isCancelled()1boolean isCancelled(); 判断任务是否已经取消，如果任务正常完成前将其取消，返回true。 isDone()1boolean isDone(); 任务是否已经完成。需要注意的是，如果任务正常终止、异常或者被取消，都将返回true get()1V get() throws InterruptedException, ExecutionException; 等待任务执行结束，获取执行结果。如果如果任务已完成，则get()方法会返回一个结果或抛出异常；如果任务没有完成，那么get()方法将阻塞并直到任务完成。 get(long timeout, TimeUnit unit)12V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException; 和无参get()不同的是，该方法给定一个最多等待时间，如果在给定时间内任务仍没有完成，则抛出TimeoutException异常。 RunnableFuture接口在介绍FutureTask之前，最后再介绍一个接口，这个接口非常简单 1234567public interface RunnableFuture&lt;V&gt; extends Runnable, Future&lt;V&gt; &#123; /** * Sets this Future to the result of its computation * unless it has been cancelled. */ void run();&#125; 可以看到，该接口同时继承了Runnable接口和Future接口，因此也继承了两个接口所有的方法。 FutureTask类在做了这么多介绍之后，现在我们就来看一看FutureTask类吧 实现的接口1public class FutureTask&lt;V&gt; implements RunnableFuture&lt;V&gt; 通过源码可以发现，FutureTask并不是直接实现Future接口和Runnable接口，而是通过实现RunnableFuture接口来间接实现它们的方法。对于FutureTask类，在这里只介绍一些字段和常用的方法，并不会对所有的字段和方法进行介绍，有兴趣可以查看源码进行学习。 类的一些字段1234567891011121314151617181920212223//标识当前线程的状态private volatile int state;private static final int NEW = 0;private static final int COMPLETING = 1;private static final int NORMAL = 2;private static final int EXCEPTIONAL = 3;private static final int CANCELLED = 4;private static final int INTERRUPTING = 5;private static final int INTERRUPTED = 6;//被提交的任务private Callable&lt;V&gt; callable;//任务执行结果或任务异常private Object outcome;//执行任务的线程private volatile Thread runner; NEW表示刚刚创建的线程(调用start方法后)或者还没有执行完的任务 COMPLETING任务将要执行完毕(正常完毕或发生异常完毕)，但是还没有将结果存储到outcome中，是一个中间状态 NORMAL任务正常执行结束，已经将结果存储到outcome中 EXCEPTIONAL任务异常，异常信息已经存储到outcome中 CANCELLED任务取消，任务在创建之后，执行结束之前被取消，但是不要求中断正在执行的线程，也就是调用了cancel(false)，任务就是CANCELLED状态 INTERRUPTING任务已中断，任务在创建之后，执行结束之前被取消，并要求调用interrupt方法，即调用cancel(true)方法，这是一个中间状态，此时还没有调用线程的中断方法 INTERRUPTED已经调用了线程的interrupt方法 构造方法123456789101112public FutureTask(Callable&lt;V&gt; callable) &#123; if (callable == null) throw new NullPointerException(); this.callable = callable; this.state = NEW; &#125;public FutureTask(Runnable runnable, V result) &#123; //将Runnable对象包装为callable对象，下一篇会详细说 this.callable = Executors.callable(runnable, result); this.state = NEW; &#125; 通过构造方法我们可以看到，FutureTask既可以接收Runnable对象，也可以接受Callable对象，不过在接收到Runnable对象时，需要将该对象包装为一个Callable对象。并且最后将任务状态设置为NEW。对于如何将Runnable对象包装成为Callable对象在下一篇博客会详细介绍。 run()方法在多线程中，run()方法总是任何的核心，是执行业务逻辑的部分，因此我们先介绍run方法 1234567891011121314151617181920212223242526272829303132333435363738public void run() &#123; //检查当前任务状态是否为NEW并且runner是否被赋值 //如果没有直接返回，这也就导致了如果在任务开始前(start方法之前) //调用了cancel方法，后续调用start时任务将不会再执行 if (state != NEW || !RUNNER.compareAndSet(this, null, Thread.currentThread())) return; try &#123; Callable&lt;V&gt; c = callable; //双重检查 if (c != null &amp;&amp; state == NEW) &#123; V result; boolean ran; try &#123; //调用call方法获取方法返回值 //将ran标志位设置为true result = c.call(); ran = true; &#125; catch (Throwable ex) &#123; //如果业务逻辑发生异常 //将执行结果置位null，标志位置为false //调用setException方法(稍后介绍) result = null; ran = false; setException(ex); &#125; //如果标志位位true，说明任务正常结束，调用set方法 if (ran) set(result); &#125; &#125; finally &#123; //重置runner，一些收尾工作 runner = null; int s = state; if (s &gt;= INTERRUPTING) handlePossibleCancellationInterrupt(s); &#125;&#125; run()方法的逻辑介绍的在注释中已经介绍的很明白了，这里就不赘述。但我们应该明白，虽然FutureTask构造方法接收Callable对象，但实际上执行的仍是run()方法，在run方法中调用Callable对象的call方法。 set(V v)方法前面我们说过，当run方法正常结束，或者是任务正常执行完毕的时候，会调用set方法，并将call方法的返回值(也是我们想要通过get方法获取的执行结果)传递进去。让我们看一看set方法 1234567891011protected void set(V v) &#123; //状态从NEW-&gt;COMPLETING，在任务执行完毕但是 //还没有将执行结果赋值给outcome之前，是一个中间状态 if (STATE.compareAndSet(this, NEW, COMPLETING)) &#123; //将任务执行结果赋值给outcome属性 outcome = v; //状态从COMPLETING-&gt;NORMAL，即任务正常结束 STATE.setRelease(this, NORMAL); // final state finishCompletion(); &#125;&#125; setException(ex)方法当任务执行异常时，将调用setException方法，并将出现的异常作为参数传递进去，现在我们来看一看setException方法 12345678910protected void setException(Throwable t) &#123; //状态从NEW-&gt;COMPLETING if (STATE.compareAndSet(this, NEW, COMPLETING)) &#123; //将任务抛出异常赋值给outcome属性 outcome = t; //COMPLETING-&gt;EXCEPTIONAL，即任务异常 STATE.setRelease(this, EXCEPTIONAL); // final state finishCompletion(); &#125;&#125; 至此run方法已经全部介绍完了，接下来让我们看看get方法，看看Future是如何通过get方法来获取返回值的吧 get()方法1234567891011121314151617181920212223public V get() throws InterruptedException, ExecutionException &#123; int s = state; //如果任务没有结束，调用awaitDone方法等待 //这也是get方法一直阻塞直到回去结果的原因 if (s &lt;= COMPLETING) s = awaitDone(false, 0L); //当任务结束后，调用report()方法 return report(s);&#125;“=================================”private V report(int s) throws ExecutionException &#123; Object x = outcome; //如果任务正常结束，返回执行结果 if (s == NORMAL) return (V)x; //如果任务被取消或者被中断，抛出CancellationException异常 if (s &gt;= CANCELLED) throw new CancellationException(); //否则说明在任务执行过程中发生异常，抛出任务 //执行过程中产生的异常 throw new ExecutionException((Throwable)x);&#125; 通过上面的源码，我们可以发现，线程执行run方法，在run方法中调用Callable对象的call方法并保存call方法的返回结果(任务执行结果)到outcome属性中，最后调用get()方法返回该属性，这样就能够获取任务的返回值。 get(long timeout, TimeUnit unit)方法接着介绍一下get方法的重载形式，设置等待时间 123456789101112public V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException &#123; if (unit == null) throw new NullPointerException(); int s = state; //如果在指定时间内任务没有完成，抛出TimeoutException异常 //如果任务完成但是get指定的等待时间还没到，此时直接返回执行结果 if (s &lt;= COMPLETING &amp;&amp; (s = awaitDone(true, unit.toNanos(timeout))) &lt;= COMPLETING) throw new TimeoutException(); return report(s);&#125; 我们来一段简单地测试代码验证一下设置等待时间的get()方法 1234567891011121314151617181920212223242526272829class Cal implements Callable&lt;Integer&gt;&#123; @Override public Integer call() throws Exception &#123; System.out.println(&quot;正在计算&quot;); //在任务中睡眠2s Thread.sleep(2000); return 1; &#125;&#125;public class GetTest &#123; public static void main(String[] args) &#123; FutureTask&lt;Integer&gt; task = new FutureTask&lt;&gt;(new Cal()); new Thread(task).start(); try &#123; //将超时时间设置为3s System.out.println(&quot;任务执行结果：&quot;+task.get(3, TimeUnit.SECONDS)); //将超时时间设置为1s //System.out.println(&quot;任务执行结果：&quot;+task.get(1, TimeUnit.SECONDS)); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (ExecutionException e) &#123; e.printStackTrace(); &#125; catch (TimeoutException e) &#123; System.out.println(&quot;超时了&quot;); &#125; &#125;&#125; 我们在call方法中睡眠2s，在主线程中使用get()方法获取任务执行结果(可以复制上述代码运行验证) 当我们将超时时间设置为3s时，能够获取任务执行结果，并在任务结束后立即返回。 当我们将超时时间设置为1s时，并不能在1s内获取任务结果，因为在任务中我们使其睡眠了2s，因此将会抛出TimeoutException异常。 cancel()方法12345678910111213141516171819202122232425public boolean cancel(boolean mayInterruptIfRunning) &#123; //判断当前任务状态是否为NEW，如果不为NEW，说明任务已经结束或被取消，返回false //state==NEW时，判断mayInterruptIfRunning，如果为true，说明要中断任务的执行，NEW-&gt;INTERRUPTING //如果为false，不需要中断，将状态改为CANCELLED if (!(state == NEW &amp;&amp; STATE.compareAndSet (this, NEW, mayInterruptIfRunning ? INTERRUPTING : CANCELLED))) return false; try &#123; //如果参数为true，那么调用当前线程的interrupt()方法 if (mayInterruptIfRunning) &#123; try &#123; //获取当前线程对象，调用interrupt方法中断线程 Thread t = runner; if (t != null) t.interrupt(); &#125; finally &#123; /将任务状态改为中断状态 STATE.setRelease(this, INTERRUPTED); &#125; &#125; &#125; finally &#123; finishCompletion(); &#125; return true;&#125; 我们来分析以下该方法： 首先，对于前面介绍的线程状态，如果你忘了，要回头看一遍 判断state，保证state==NEW才能继续后面的操作，如果state!=NEW，通过前面的状态可以知道，此时线程要么执行完毕(正常完毕或异常完毕)，要么已经被取消，此时返回false。 如果state==NEW且mayInterruptIfRunning==true，此时任务状态NEW-&gt;INTERRUPTING，然后获取线程对象调用interrupt方法中断线程执行，任务状态INTERRUPTING-&gt;INTERRUPTED。 如果state==NEW且mayInterruptIfRunning==false，此时将线程状态改变为CANCELLED，但是并不会中断正在执行的线程。 我们用一个图来说明：如图我们可以得出 如果任务没有开始(没有调用start方法)，调用了cancel()方法，无论传递什么参数，该方法返回true，并且后面调用start方法执行任务时该线程不再执行 如果在任务结束后调用cancel()方法，无论传递什么参数，都返回false 如果在任务开始之后结束之前调用cancel()方法，cancel()方法返回true，线程是否中断分情况讨论 传递参数为true，调用线程的interrupt方法设置线程中断标志位。 传递参数为false，不会对线程产生影响。 cancel()方法测试代码对于cancel()方法，接下来针对不同的情况进行测试 任务开始前调用cancel()方法12345678910111213141516171819public class CallableTest implements Callable&lt;Integer&gt; &#123; @Override public Integer call() &#123; while (true)&#123; System.out.println(&quot;hello&quot;); &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; FutureTask&lt;Integer&gt; task = new FutureTask&lt;&gt;(new CallableTest()); Thread.sleep(100); System.out.println(&quot;cancel()：&quot;+task.cancel(false)); new Thread(task).start(); &#125;&#125;&quot;=============================&quot;Output:cancel()：true 上述代码中，在启动线程之前(调用start方法之前)调用了cancel()方法，并传递false进去。可以看到该方法返回true；在调用cancel()方法后启动线程，可以看到并不会有任何输出，也就是说run()方法并没有执行。(这里传递的是false，传递true是一样的) 任务结束后调用cancel()方法1234567891011121314151617181920public class CallableTest implements Callable&lt;Integer&gt; &#123; @Override public Integer call() &#123; System.out.println(&quot;执行线程的call()方法&quot;); return 1; &#125; public static void main(String[] args) throws InterruptedException &#123; FutureTask&lt;Integer&gt; task = new FutureTask&lt;&gt;(new CallableTest()); new Thread(task).start(); Thread.sleep(100); System.out.println(&quot;cancel()：&quot;+task.cancel(false)); &#125;&#125;&quot;=============================&quot;Output:执行线程的call()方法cancel()：false 可以看到，在线程结束后调用cancel()方法，这里传递的是false(传递true也是一样的)，cancel方法返回false，线程不受到影响。 任务执行过程中调用cancel()方法并传递true123456789101112131415161718192021222324252627282930public class CallableTest implements Callable&lt;Integer&gt; &#123; @Override public Integer call() &#123; while (!Thread.currentThread().isInterrupted())&#123; System.out.println(&quot;执行线程的call()方法&quot;); &#125; return 1; &#125; public static void main(String[] args) throws InterruptedException, ExecutionException &#123; FutureTask&lt;Integer&gt; task = new FutureTask&lt;&gt;(new CallableTest()); new Thread(task).start(); Thread.sleep(100); System.out.println(&quot;cancel()：&quot;+task.cancel(true)); System.out.println(task.get()); &#125;&#125;&quot;=============================&quot;Output:......执行线程的call()方法执行线程的call()方法执行线程的call()方法cancel()：trueException in thread &quot;main&quot; java.util.concurrent.CancellationException at java.base/java.util.concurrent.FutureTask.report(FutureTask.java:121) at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:191) at twentyoneth.runnableAndcallable.CallableTest.main(CallableTest.java:22) 在这段代码中，在线程执行过程中调用cancel()方法并传递true参数，可以看到cancel()方法返回true，任务被中断，并且抛出异常。(但是要注意，在这种情况下cancel()方法并不总能中断线程，后面会说到) 任务执行过程中调用cancel()方法并传递false1234567891011121314151617181920212223242526272829303132333435public class CallableTest implements Callable&lt;Integer&gt; &#123; @Override public Integer call() throws InterruptedException &#123; while (!Thread.currentThread().isInterrupted())&#123; System.out.println(&quot;执行线程的call()方法&quot;); Thread.sleep(1000); Thread.yield(); &#125; return 1; &#125; public static void main(String[] args) throws InterruptedException, ExecutionException &#123; FutureTask&lt;Integer&gt; task = new FutureTask&lt;&gt;(new CallableTest()); new Thread(task).start(); Thread.sleep(10); System.out.println(&quot;cancel()：&quot;+task.cancel(false)); System.out.println(task.get()); &#125;&#125;&quot;=============================&quot;Output：执行线程的call()方法cancel()：trueException in thread &quot;main&quot; java.util.concurrent.CancellationException at java.base/java.util.concurrent.FutureTask.report(FutureTask.java:121) at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:191) at twentyoneth.runnableAndcallable.CallableTest.main(CallableTest.java:24)执行线程的call()方法执行线程的call()方法执行线程的call()方法执行线程的call()方法...... 可以看到，在线程执行过程中调用cancel()方法并传递false参数，任务并不会终止，cancel()方法返回true。但是通过源码可知，此时该方法将任务的状态改变位CANCELED状态，在调用get()获取任务执行结果时只能得到CancellationException异常 cancel()方法并不总会中断线程通过cancel()方法源码我们发现，cancel()如果能够中断线程(在执行过程中调用cancel()并且传递true参数)，那么实际上调用的是线程的interrupt()方法。该方法只是给调用线程设置一个中断标志位，只有在遇到wait()、sleep()等方法阻塞时才会抛出异常，具体是否中断由线程内部逻辑决定。我们来看下面一段代码 123456789101112131415161718192021222324252627282930313233343536public class CallableTest implements Callable&lt;Integer&gt; &#123; @Override public Integer call() &#123; while (true)&#123; System.out.println(&quot;执行线程的call()方法&quot;); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; System.out.println(&quot;Interrupted&quot;); return 1; &#125; &#125; &#125; public static void main(String[] args) throws InterruptedException, ExecutionException &#123; FutureTask&lt;Integer&gt; task = new FutureTask&lt;&gt;(new CallableTest()); new Thread(task).start(); Thread.sleep(10); System.out.println(&quot;cancel()：&quot;+task.cancel(true)); System.out.println(task.get()); &#125;&#125;”======================================“Output：执行线程的call()方法Interruptedcancel()：trueException in thread &quot;main&quot; java.util.concurrent.CancellationException at java.base/java.util.concurrent.FutureTask.report(FutureTask.java:121) at java.base/java.util.concurrent.FutureTask.get(FutureTask.java:191) at twentyoneth.runnableAndcallable.CallableTest.main(CallableTest.java:28) 在上述代码中，能够成功的中断线程，任务在sleep阻塞时被cancel()方法中断，因此捕获异常，最后退出线程。你应该注意：虽然最后返回了执行结果1，但是调用get()方法获得到的仍是CancellationException。我们再看看下面一段测试代码 1234567891011121314151617181920212223242526272829303132public class CallableTest implements Callable&lt;Integer&gt; &#123; @Override public Integer call() &#123; while (true)&#123; System.out.println(&quot;执行线程的call()方法&quot;); &#125; &#125; public static void main(String[] args) throws InterruptedException, ExecutionException &#123; FutureTask&lt;Integer&gt; task = new FutureTask&lt;&gt;(new CallableTest()); new Thread(task).start(); Thread.sleep(10); System.out.println(&quot;cancel()：&quot;+task.cancel(true)); System.out.println(task.get()); &#125;&#125;”======================================“Output：执行线程的call()方法执行线程的call()方法执行线程的call()方法执行线程的call()方法执行线程的call()方法执行线程的call()方法执行线程的call()方法执行线程的call()方法...... 在这段代码中，任务逻辑代码没有任何阻塞，也没有任何相应中断的措施，因此即使调用了cancel()方法，改变了线程的中断标志位，线程仍然不会中断，而是会一直执行下去。(关于中断相关的方法会在后面陆续介绍) cancel()方法总结通过测试可以发现，只有在任务正常结束(最后处于NORMAL状态)时才能够得到任务执行结果，而调用cancel()方法后，如果调用get方法获取任务执行结果只能得到CancellationException异常。当任务执行过程中出现异常(编写的代码出现异常)，调用get方法能够获取到执行过程中出现的异常。并且cancel()并不一定能够中断线程]]></content>
      <categories>
        <category>Java并发编程</category>
      </categories>
      <tags>
        <tag>多线程</tag>
        <tag>Future</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[两整数之和]]></title>
    <url>%2F2019%2F11%2F10%2F%E4%B8%A4%E6%95%B4%E6%95%B0%E4%B9%8B%E5%92%8C%2F</url>
    <content type="text"><![CDATA[LeetCode第三百七十一题难度：简单题目：不使用运算符 + 和 - ​​​​​​​，计算两整数 ​​​​​​​a 、b ​​​​​​​之和。 思想分析看到不能使用+、-，我们应该第一时间想到位运算。我们来看一下二进制加减法的规律 12341+0=10+1=10+0=01+1=0(进位) 很明显的，可以看到二进制做加法，其实就是异或操作，只不过1+1时有溢出，那么如何解决溢出呢？通过加法的规律可以知道，当前位相加进位的部分和高一位的部分相加，因此我们将采用a&amp;b&lt;&lt;1操作 代码实现123456789101112public int getSum(int a, int b) &#123; int res; //b==0时说明无进位操作 while(b!=0)&#123; //将当前数字做&amp;运算得到需要进位的部分 //再见进位右移一位 res=(a&amp;b)&lt;&lt;1; a=a^b; b=res; &#125; return a;&#125; 不得不说，位运算有时候还是相当巧妙的。]]></content>
      <categories>
        <category>算法之美</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
        <tag>位运算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[有效的完全平方数]]></title>
    <url>%2F2019%2F11%2F10%2F%E6%9C%89%E6%95%88%E7%9A%84%E5%AE%8C%E5%85%A8%E5%B9%B3%E6%96%B9%E6%95%B0%2F</url>
    <content type="text"><![CDATA[LeetCode第三百六十七题难度：简单题目：给定一个正整数 num，编写一个函数，如果 num 是一个完全平方数，则返回 True，否则返回 False。(不使用内置方法) 思想分析解决这道题，有三种不同的思路。分别使用优化的暴力循环、二分法以及数学公式法 优化的暴力循环，创建一个变量i从1遍历到num/2 数学公式有：N^2=1+3+5+…+2*N-1。这样问题就会简单很多 二分法主要在于细节，思路就不赘述 代码实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647//优化的暴力循环public boolean isPerfectSquare(int num) &#123; //优化暴力循环 for(int i=1;i&lt;=num/2;i++)&#123; if(i*i==num) return true; if(i*i&gt;num) return false; &#125; //考虑num=1的特殊情况 return num==1;&#125;“===========================”//数学公式法public boolean isPerfectSquare(int num) &#123; //数学公式法：1+3+5+...+(2*N-1)=N^2 if(num==1) return true; int val=1; while(num&gt;0)&#123; num-=val; val+=2; &#125; return num==0;&#125;“===========================”//二分法public boolean isPerfectSquare(int num) &#123; //二分法 int left=0; int right=num; int mid; while(right&gt;=left)&#123; mid=left+(right-left)/2; //要转化为long类型，否则会溢出导致结果为负，进入死循环 if((long)mid*mid==num) return true; else if((long)mid*mid&gt;num)&#123; right=mid-1; &#125; else left=mid+1; &#125; return false;&#125; 对于二分法要注意的一点就是要考虑乘法溢出导致结果为负，最后陷入死循环，因此应该将值显式的转化为long类型。]]></content>
      <categories>
        <category>算法之美</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
        <tag>二分</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入剖析ThreadLocal]]></title>
    <url>%2F2019%2F11%2F10%2F%E6%B7%B1%E5%85%A5%E5%89%96%E6%9E%90ThreadLocal%2F</url>
    <content type="text"><![CDATA[当访问共享的可变数据时，通常需要使用同步。一种避免同步的方式就是不共享数据，如果仅在线程内访问数据，就不需要同步。这种技术被称为线程封闭。它是实现线程安全性的最简单方式之一。维持线程封闭性的方法不止一种，ThreadLocal就是其中一种。 概述ThreadLocal，很容易的就理解成为“本地线程”。其实，ThreadLocal并不是一个Thread，而是一个变量–线程局部变量。当使用ThreadLocal维护变量时，ThreadLocal为每个使用该变量的线程提供独立的变量副本，所以每个线程都可以独立地改变自己的副本，而不会影响其它线程的副本。 ThreadLocal整体结构在深入分析源码之前，先大体介绍以下ThreadLocal的类结构，方便后续学习。再来看一下ThreadLocal的嵌套类ThreadLocalMap从图中可以发现，ThreadLocal共有的方法(不包括构造方法)只有四个 1234get()set()remove()withInitial() ThreadLocalMap源码分析介绍了ThreadLocal的整体架构，现在来介绍以下它的内部类ThreadLocalMap。ThreadLocalMap也是一个哈希结构，内部维护一个Entry数组，每个Entry对象内存储这一对键值对。不过和HashMap不同的是，HashMap解决哈希冲突的方法是分离链接法，而ThreadLocalMap采用的则是开放定址法。 ThreadLocalMap的域来看一看ThreadLocalMap有哪些属性 1234567private static final int INITIAL_CAPACITY = 16;//底层数组private Entry[] table;//Map中元素个数private int size = 0;//扩容阈值private int threshold; 通过这些域我们发现，ThreadLocalMap和HashMap有一定的相似。接下来我们再看看ThreadLocalMap的嵌套类Entry 12345678static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125;&#125; 通过源码我们发现，Entry中键值对的键是一个ThreadLocal对象，而值则可以是任何类型。你可能会觉得奇怪，为什么Entry中的键是一个ThreadLocal对象呢？让我们带着疑问继续往下。 set()方法介绍一下ThreadLocalMap中set()方法的源码 123456789101112131415161718192021222324252627282930313233343536private void set(ThreadLocal&lt;?&gt; key, Object value) &#123; Entry[] tab = table; int len = tab.length; //将哈希值映射到数组下标(和HashMap类似) int i = key.threadLocalHashCode &amp; (len-1); //使用线性探测法找到合适的数组下标 for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) &#123; ThreadLocal&lt;?&gt; k = e.get(); 如果下标中已经存在相同的键，那么覆盖原来的值 if (k == key) &#123; e.value = value; return; &#125; //如果为空，说明外部强引用消失，ThreadLocal对象被回收 //那么新的值插入 if (k == null) &#123; replaceStaleEntry(key, value, i); return; &#125; &#125; //将键值对放入数组中 tab[i] = new Entry(key, value); int sz = ++size; //清理掉key为null的节点，使其能够被回收 if (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold) rehash();&#125;“=====================”//实际上就是一个取模运算private static int nextIndex(int i, int len) &#123; return ((i + 1 &lt; len) ? i + 1 : 0);&#125; 其中的replaceStaleEntry()方法和cleanSomeSlots()方法我们无需理会，只需要知道set方法是将一个键值对放到数组的合适位置即可。 getEntry()方法再来介绍一下getEntry()方法的源码 1234567891011121314private Entry getEntry(ThreadLocal&lt;?&gt; key) &#123; //通过映射找到相应数组下标 int i = key.threadLocalHashCode &amp; (table.length - 1); //取出数组中元素 Entry e = table[i]; //如果找到就返回 if (e != null &amp;&amp; e.get() == key) return e; //没找到说明发生了哈希冲突，当前节点被移动到另外的位置 //或者由于ThreadLocal被回收导致key==null(后面会说到) //调用getEntryAfterMiss继续找 else return getEntryAfterMiss(key, i, e);&#125; 如果进入了getEntryAfterMiss方法，有三种可能 e==null，之前发生了哈希冲突，想要找的节点被移动到其他位置，该位置节点被回收，继续寻找直到找到为止，最后返回相应entry e!=null&amp;&amp;e.get()!=key，发生了哈希冲突，继续寻找直到找到为止，最后返回相应entry e!=null&amp;&amp;e.get()==null，由于ThreadLocal被回收导致key为null，将key对应的value和entry都置为null使其能够得到回收，最后返回nullremove()方法最后介绍一下remove方法12345678910111213141516private void remove(ThreadLocal&lt;?&gt; key) &#123; Entry[] tab = table; int len = tab.length; //通过hash值映射数组下标 int i = key.threadLocalHashCode &amp; (len-1); for (Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) &#123; //找到相应元素后，将其删除并重新调整Map结构 if (e.get() == key) &#123; e.clear(); expungeStaleEntry(i); return; &#125; &#125;&#125; 小结对于ThreadLocalMap的分析就到这里，这里只是粗略的介绍了其中一些方法，目的是为了更好的理解后面的内容，对于其他方法，需要对开放定址法有一定的了解后才能学习(对于开放定址法参见我的另一篇博客:数据结构-哈希表)。 ThreadLocal源码分析介绍了ThreadLocalMap的部分源码，相信你对ThreadLocalMap也有了一定的了解，接下来我们学习一下ThreadLocal的部分源码 Thread中的域和方法为了能够更好的了解ThreadLocal、ThreadLocalMap三者之间的关系，需要对Thread中的部分源码有一定的了解，也不多，这里只介绍一个域和一个方法足够了。 123456789101112131415161718//域ThreadLocal.ThreadLocalMap threadLocals = null;//方法private void exit() &#123; if (group != null) &#123; group.threadTerminated(this); group = null; &#125; /* Aggressively null out all reference fields: see bug 4006245 */ target = null; /* Speed the release of some of these resources */ threadLocals = null; inheritableThreadLocals = null; inheritedAccessControlContext = null; blocker = null; uncaughtExceptionHandler = null;&#125; 我们先介绍ThreadLocal中一些方法，然后再详细说明三者之间的关系 ThreadLocal的域1234567891011private final int threadLocalHashCode = nextHashCode();private static AtomicInteger nextHashCode = new AtomicInteger(); private static final int HASH_INCREMENT = 0x61c88647;“==============================”private static int nextHashCode() &#123; return nextHashCode.getAndAdd(HASH_INCREMENT);&#125; 上面三个域，除了threadLocalHashCode是实例属性，其他两个都是类属性，还有一个类方法，也就是说是所有ThreadLocal对象共享的。前面介绍ThreadLocalMap的方法时，都是通过ThreadLocal对象的threadLocalHashCode属性来映射数组下标。通过上述源码我们可以发现，每个ThreadLocalMap对象的threadLocalHashCode都相差固定的值HASH_INCREMENT。这样做能够减少哈希冲突。 get()方法12345678910111213141516171819202122232425262728293031323334353637383940414243444546public T get() &#123; //获取当前线程 Thread t = Thread.currentThread(); //获取当前线程的threadlocals属性 ThreadLocalMap map = getMap(t); //如果属性不为空 if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; T result = (T)e.value; return result; &#125; &#125; return setInitialValue();&#125;&quot;==============================&quot;//该方法返回线程的threadLocals属性ThreadLocalMap getMap(Thread t) &#123; return t.threadLocals;&#125;&quot;==============================&quot;private T setInitialValue() &#123; T value = initialValue(); Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value); return value;&#125;&quot;==============================&quot;//获取初始value值，如果子类没有进行覆盖，默认为nullprotected T initialValue() &#123; return null;&#125;&quot;==============================&quot;//对线程的threadlocals属性进行初始化void createMap(Thread t, T firstValue) &#123; t.threadLocals = new ThreadLocalMap(this, firstValue);&#125; 现在来解析以下get()方法的逻辑 获取当前线程，调用ThreadLocal的getMap方法获取当前线程的threadLocals属性，即获取一个ThreadLocalMap对象。 如果该map对象不为空，转到3；否则转到5。 调用map的getEntry()方法，并将this(调用get方法的ThreadLocal对象)作为参数传递进去，获取该ThreadLocal对应的的Entry对象e。 如果e不为空，返回e的值即可 如果走到这一步，即执行了return setInitialValue();这一段代码，则有2种情况 该线程的threadlocals属性没有进行初始化，这时候调用createMap()方法进行初始化。最后返回value 通过getEntry()方法获取到的e为null，将this作为键，initialValue()方法获取到的初始值作为值的键值对添加到map中。最后返回value set()方法1234567891011public void set(T value) &#123; //获取当前线程并获取线程的threadlocals属性 Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); //如果map不为空，调用ThreadLocalMap的set方法将this作为键，value作为值添加进map中 if (map != null) map.set(this, value); //如果为空则调用createMap对其进行初始化 else createMap(t, value);&#125; 介绍完get()方法以及相应方法之后，set()方法就很容易理解，这里就不赘述了。 remove()方法12345public void remove() &#123; ThreadLocalMap m = getMap(Thread.currentThread()); if (m != null) m.remove(this);&#125; remove()方法源码也比较简单，直接调用ThreadLocalMap的remove方法，将当前ThreadLocal对象作为键传递进去即可。 三者的关系经过一系列铺垫之后，终于可以正式的介绍他们三者之间的关系了，也许你通过前面的介绍已经了解了三者之间的关系，也许你还不了解，但都没关系，我们接下类将通过几张图来详细的说明。上面这张图很直观很容易理解，通过前面的学习我们发现确实有这样的关系存在这张图表明了三者的关系：即每个线程中都有一个ThreadLocalMap对象，每个ThreadLocalMap对象内维护一个Entry数组，维护者若干个Entry对象；每个Entry存储着一对键值对，键值对的键就是ThreadLocal对象，值就是存储的共享变量的副本。简单地说，就是一个Thread对象只有一个ThreadLocalMap，而一个ThreadLocalMap中有多个键值对。每个键值对的键都是ThreadLocal对象。 ThreadLocal的内存回收了解了ThreadLocal实现以后，我们发现，这些数据的副本其实是维护在每个线程对象内部的(threadlocals属性内)，这也就意味着如果线程不退出，对象的引用就会一直存在。当一个线程退出时，Thread会进行一些清理工作，具体表现为在线程退出前，由系统回调exit()方法，进行资源清理。通过前面的Thread的exit()源码可以发现，Thread在推出时会将它的threadlocals属性置为null。这样ThreadLocalMap就能够被回收。在介绍threadLocalMap的嵌套类Entry时，我们发现Entry是继承自WeakReference&lt;ThreadLocal&lt;?&gt;&gt;的，WeakReference是一个弱引用，在JVM那篇博客中介绍过，弱引用对于GC没有任何影响，只是会在GC时收到一个通知。在这里，虽然Entry使用ThreadLocal作为Map的key，但实际上，它并不真的持有ThreadLocal的引用。当ThreadLocal的外部强引用被回收时，Entry中的key就会变为null。当系统进行ThreadLocalMap清理时(从ThreadLocalMap方法源码可以发现，每次put、get方法时都会进行清理)，就会将这些垃圾数据回收。 ThreadLocal导致的内存泄漏前面说过，当线程退出时，会将threadlocals属性置为空，这样该线程的所有变量都会被回收。但这样会存在一个问题，当我们使用线程池的时候，当前线程执行的任务结束后，线程并不会退出，而是会归还给线程池执行其他的任务，那这样一来，跟当前任务相关的变量数据并不会被回收，这样就导致了内存泄漏问题。如图所示此时，如果你希望能够及时的回收对象，最好使用ThreadLocal.remove()方法将这个变量移除。 设计思路通过学习我们发现，ThreadLocal的嵌套类ThreadLocalMap是作为Thread的成员属性使用，即数据存储在Thread对象中。那么我们不禁要问两个问题(以下内容均为个人理解，如有不对欢迎指正共同学习，感谢) 为什么ThreadLocalMap不直接定义在Thread中，而要定义在ThreadLocal中呢？看起来将ThreadLocalMap定义在Thread的内部更符合逻辑，但是ThreadLocalMap并不需要Thread的对象来操作，所以定义在Thread类中只会增加不必要的开销。定义在ThreadLocal类中的原因是ThreadLocal来负责ThreadLocalMap的创建，仅当线程中设置第一个ThreadLocal时，才为线程创建ThreadLocalMap对象。总的来说，ThreadLocalMap并不是Thread的必需属性，定义在ThreadLocal内会增加不必要的开销，而定义在ThreadLocal中可以按需创建。 ThreadLocalMap中的键值对为什么要使用ThreadLocal对象作为键，而不使用Thread对象作为键？可能一个线程需要的共享对象并不止一个，如果使用Thread作为键，由于哈希结构的特性，那么一个线程就只能持有一个共享变量的副本，这显然是不合理的。 总结通过学习，我们发现：ThreadLocal使得每个线程都持有共享资源的副本，从而可以独立的修改属于自己的副本而不会互相影响。 ThreadLocal并不存储任何数据，它只是用来操作当前线程的ThreadLocalMap和作为key而存在 ThreadLocalMap是线程内部属性，不同的线程拥有不同的ThreadLocalMap对象，这也是线程隔离的根本原因 线程中ThreadLocalMap变量的值是在ThreadLocal对象进行put或者get操作时添加的 线程中ThreadLocalMap是在第一次get或者set时创建的 一个ThreadLocal对象只能对应一个共享变量，如果一个线程需要多个共享变量，那么需要创建多个ThreadLocal对象 ThreadLocal模式实现了两个隔离： 纵向隔离：线程与线程之间ThreadLocalMap不同 横向隔离：不同的ThreadLocal对象对应不同的变量 线程退出时，线程局部变量会自动回收 当线程超过容量的2/3时，会涉及到ThreadLocalMap中Entry的回收 应用场景应用场景有很多，一个典型的应用场景就是在多线程下产生随机数 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677public class RndTask &#123; public static final int GET_COUNT=10000000; public static final int THREAD_COUNT=4; static ExecutorService exec = Executors.newFixedThreadPool(THREAD_COUNT); public static Random rand = new Random(123); public static ThreadLocal&lt;Random&gt; tRand=new ThreadLocal&lt;&gt;()&#123; @Override protected Random initialValue() &#123; return new Random(123); &#125; &#125;; static class Task implements Callable&lt;Long&gt; &#123; private int mode; public Task(int mode) &#123; this.mode = mode; &#125; public Random getRandom() &#123; if (mode == 0) &#123; return rand; &#125; else if (mode == 1) &#123; return tRand.get(); &#125;else &#123; return null; &#125; &#125; @Override public Long call() throws Exception &#123; long b = System.currentTimeMillis(); for (int i = 0; i &lt; GET_COUNT; i++) &#123; getRandom().nextInt(); &#125; long e = System.currentTimeMillis(); System.out.println(Thread.currentThread().getName() + &quot; spend &quot; + (e - b) + &quot; ms&quot;); return e - b; &#125; &#125; public static void main(String[] args) throws ExecutionException, InterruptedException &#123; Future&lt;Long&gt;[] futs = new Future[THREAD_COUNT]; for (int i = 0; i &lt; THREAD_COUNT; i++) &#123; futs[i] = exec.submit(new Task(0)); &#125; long totalTime = 0; for (int i = 0; i &lt; THREAD_COUNT; i++) &#123; totalTime += futs[i].get(); &#125; System.out.println(&quot;多线程访问同一个Random实例：&quot; + totalTime + &quot; ms&quot;); for (int i = 0; i &lt; THREAD_COUNT; i++) &#123; futs[i] = exec.submit(new Task(1)); &#125; totalTime=0; for (int i = 0; i &lt; THREAD_COUNT; i++) &#123; totalTime += futs[i].get(); &#125; System.out.println(&quot;使用ThreadLocal包装Random实例：&quot; + totalTime + &quot; ms&quot;); exec.shutdown(); &#125;&#125;”========================“Output：pool-1-thread-2 spend 2723 mspool-1-thread-4 spend 2860 mspool-1-thread-1 spend 2883 mspool-1-thread-3 spend 2885 ms多线程访问同一个Random实例：11351 mspool-1-thread-2 spend 136 mspool-1-thread-1 spend 136 mspool-1-thread-4 spend 136 mspool-1-thread-3 spend 138 ms使用ThreadLocal包装Random实例：546 ms 在多个线程共享一个Random实例的情况下，总耗时达到11s多，而使用ThreadLocal产生随机数，仅仅耗时0.5s ThreadLocal的学习就到这里，如有错误欢迎指正，本文基于JDK1.8版本。部分参考csdn]]></content>
      <categories>
        <category>Java并发编程</category>
      </categories>
      <tags>
        <tag>多线程</tag>
        <tag>ThreadLocal</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HashSet源码解析]]></title>
    <url>%2F2019%2F11%2F09%2FHashSet%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[对于Hash结构，我们还有最后一个没有介绍，那就是HashSet集合，HashSet是在Map的基础上组装起来的类，这里主要介绍Set是如何利用Map现有的功能进行创新从而实现新的功能。同样的，本文基于JDK1.8版本。 HashSet基础架构在开始学习之前，为了便于我们更好的理解，让我们先看一下HashSet的类注释 类注释 底层实现基于HashMap，所以迭代时不能保证插入顺序，获取其他顺序进行迭代 add、remove、contains、size等方法的耗时性能，是不会随着数据量增加为增加的，这个主要跟HashMap底层数据结构有关，不管数据量多大，在不考虑哈希冲突情况下，时间复杂度都是O(1) 线程不安全，如果需要线程安全自行加锁或者使用Collections.synchronizedSet 迭代过程中，使用的是快速失败策略。 联系之前学过了List和Map结构，发现它们也有2、3、4点信息。这是三者的共同点。 HashSet域前面介绍过，HashSet的实现基于HashMap的，在Java中，要基于基础类进行创新，有两种方法： 使用继承，复写基础类的方法 使用组合，通过调用基础类的方法，来复合基础类的能力 HashSet使用的就是组合，这样做有以下优点： 继承表示父子类是同一个事物，而Set和Map本来就是要表达两种事务，所以使用继承不妥当，而且Java中子类只能继承一个父类，后续难以扩展 组合更加灵活，可以任意组合现有的基础类，并且可以在基础类方法的基础上进行扩展、编排等，并且方法命名可以任意命名，不用和基础类方法名保持一致。 下面来看一下HashSet中的字段 1234//底层通过HashMap存储数据private transient HashMap&lt;E,Object&gt; map;//每个Node节点的value值都用PRESENT填充private static final Object PRESENT = new Object(); 从上面源码可以看出： 在使用HashSet时，比如add()方法。只有一个入参，但HashMap的put()方法却需要key和value两个参数。他的解决方法非常巧妙，在每次调用HashMap的put()方法时，都将PRESENT作为value填充进去来代替value。 如果HashMap是被共享的，当多个线程访问的时候，就会有线程安全问题，因为在后续的所有操作中，并没有加锁。 HashSet在以HashMap为基础进行实现时，首先选择组合方式，接着使用默认值来代替Map中的value值，设计非常巧妙。 HashSet源码方法介绍了关于HashSet的基础内容，现在来正式介绍一下HashSet方法的源码，其实都比较简单，因为HashSet的方法实际上调用的仍是HashMap的方法。 初始化方法1234public HashSet(Collection&lt;? extends E&gt; c) &#123; map = new HashMap&lt;&gt;(Math.max((int) (c.size()/.75f) + 1, 16)); addAll(c);&#125; HashSet的其他构造方法都是直接在里面调用相应的HashMap构造方法创建HashMap对象，只有这个方法做了特殊处理。Math.max((int) (c.size()/.75f) + 1, 16)，就是对HashMap的容量进行了计算，这段代码的意思是：取括号两个数的最大值(期望的值/0.75+1，默认值16)。 和16比较大小的意思是说，如果给定HashMap初始容量小于16，就按照默认的16初始化，如果大于16，就按照给定值初始化 HashMap扩容的阈值的计算公式为Map容量*0.75f，一旦达到阈值就会扩容，此处采用(int) (c.size()/.75f) + 1来表示初始化的值，这样我们的期望值正好比扩容的阈值大1，就不会扩容，设计的还是很巧妙的。 其他方法对于HashSet的其他方法，就比较简单了，只是简单地调用HashMap的方法而已 1234567public boolean add(E e) &#123; return map.put(e, PRESENT)==null;&#125;public boolean remove(Object o) &#123; return map.remove(o)==PRESENT;&#125; 从添加和删除方法来看，确实如此，那么HashSet的又是怎么迭代的呢？ 123public Iterator&lt;E&gt; iterator() &#123; return map.keySet().iterator();&#125; HashSet的迭代方法也非常简单，直接调用父类内部类keySet的迭代器进行迭代即可。 总结通过HashSet的源码我们能够学习不少，下面来总结几点 对组合还是继承的选择。 对复杂逻辑进行一些包装，使得吐出去的接口尽量简单好用 组合其他API时，尽量多对组合的API多一些了解，这样才能更好的使用API 对于HashSet的介绍就到这里]]></content>
      <categories>
        <category>JDK源码</category>
      </categories>
      <tags>
        <tag>源码</tag>
        <tag>HashSet集合</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Map源码常见面试题]]></title>
    <url>%2F2019%2F11%2F08%2FMap%E6%BA%90%E7%A0%81%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98%2F</url>
    <content type="text"><![CDATA[前面相继介绍了HashMap和LinkedHashMap集合，对于TreeMap集合，由于它的底层实现红黑树我不熟悉所以没有深入了解。现在就总结一下Map集合的一些常见面试题。 Map整体数据结构类 说一说HashMap底层数据结构HashMap底层是数组+链表+红黑树的数据结构，数组的主要作用是方便快速查找，时间复杂度为O(1)，默认大小为16，每次扩容保持为2的幂次方(通常以2倍扩容)。数组的下标索引是通过key的hashcode计算出来的，数组元素叫做Node，当多个key的hashcode一致，但是key值不同时(哈希冲突)，单个Node就会转化成为链表，链表的查询复杂度为O(n)，当链表的长度大于等于8并且数组大小超过64时，链表就会转化为红黑树，红黑树的查询复杂度是O(logN)。 HashMap、TreeMap、LinkedHashMap三者有什么相同点，有什么不同点 相同点： 三者在特定情况下都会使用红黑树 底层的Hash算法相同 在迭代过程中，如果Map的数据结构被改动，都会抛出ConcurrentModificationException异常。即快速失败策略 不同点： HashMap数据结构以数组为主，查询很快，TreeMap数据结构以红黑树为主，利用了红黑树左小右大的特点，可以实现key排序，LinkedHashMap在HashMap的基础上增加了链表的结构，实现了插入顺序访问和最少访问删除两种策略。 由于三种集合底层数据结构的差别，导致三者使用场景的不同。TreeMap适合需要根据key进行排序的场景，LinkedHashMap适合按照插入顺序访问或需要最少访问元素删除的场景，剩下的场景使用HashMap即可。HashMap是我们最常用的集合。 由于三种map的底层数据结构的不同，导致上层包装的API略有差别。 说一下HashMap的哈希算法123456789/** * 求键值对中键的哈希码 * @param key * @return */static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; 以上就是HashMap的哈希算法，这其实是一个数学问题，源码中首先通过key的hashCode()方法得到key的hashcode，在将该值的低16位和高16位做异或运算得到哈希值。这样做的好处是在大多数场景下，算出来的hash值比较分散。一般来说，hash值算出来之后，要计算当前key在数组索引下标位置时，可以采用取模的方式，就是索引下标位置=hash%数组大小。这样做的好处就是可以保证计算出来的索引下标值可以均匀的分布在数组的各个索引位置上，但由于取模操作计算比较慢，数学上有个公式：当b是2的幂次方时候，a%b=a&amp;(b-1)，因此可以用该公式计算key的下标位置。 为什么不用key值和数组大小做取模运算而要计算key的哈希值并与数组大小做取模运算如果key是数字，直接使用key%数组大小是完全没有问题的，但我们的key还有可能是字符串，是复杂对象，这时候用字符串或对象%数组大小是不行的，所以需要计算key的hash值 在计算hash值时，为什么要右移16位这样做是为了使计算出的hash值更加分散，减少碰撞的可能性(具体见HashMap源码解析博客) 为什么提倡数组大小是2的幂次方这样做有两个目的 当我们使用&amp;运算映射数组下标时，要保证(数组下标-1)用二进制表示时必须是全1，这样才能很好的利用hash值 12345678假设数组大小为10，那么9的二进制表示为1001；现假设有三个hash值，分别为...... 0010 1110 1010 0110...... 0110 0101 1010 0100...... 0011 0111 1111 0010使用这三个完全不同hash值和1001做&amp;运算时，就会发现结果都是0，这是因为和1001做&amp;运算时，不论中间两位是什么，&amp;出来都是0这样就无法很好的利用hash值 当数组大小为2的幂次方时，数组下标-1后二进制表示为全1，这样就能很好的利用hash值 只用数组大小是2的幂次方时，hash&amp;(length-1)==hash%length才成立。 为了解决哈希冲突，大概有哪些方法 好的hash算法 自动扩容，当数组大小快慢的时候，采取自动扩容，可以减少哈希冲突 当哈希冲突发生时，使用拉链法来解决(链表) 哈希冲突严重时，链表会自动转换为红黑树，提高遍历速度 HashMap源码细节类问题 HashMap是如何扩容的 扩容的时机： put时，发现数组为空，进行初始化扩容，默认扩容大小为16 put成功后，发现元素个数大于扩容阈值后，进行扩容，扩容为老数组的2倍 扩容的阈值是threshold，每次扩容时threshold都会被重新计算，阈值=数组大小*影响影子(0.75) 新数组初始化后，需要将老数组的值拷贝到新数组上。 Hash冲突时怎么办哈希冲突是指key值得hashcode计算相同，但是key值不同的情况。如果数组中元素已经有一个或已经是链表了，新增元素直接追加到链表尾部。如果数组中元素已经是链表，并且链表个数大于等于8时 如果此时数组大小小于64，数组再次扩容，链表不会转化为红黑树 如果此时数组大小大于等于64，链表转化为红黑树这样做主要是因为红黑树占用空间比链表大很多，转化也比较损耗时间，所以数组容量小的情况下冲突比较严重，可以先尝试扩容，看看能否通过扩容解决冲突的问题。 为什么链表个数大于等于8时，链表要转化为红黑树当链表个数太多了，遍历可能比较耗时，转化为红黑树可以使遍历的空间复杂度降低，但转化成红黑树有空间损耗和转化时成本，我们通过泊松分布得出，正常情况下链表个数出现8的概念不到千万分之一，因此正常情况下，链表都不会转化为红黑树。这样设计的目的是为了防止非正常情况下，比如hash算法出了问题，导致链表很轻易大于等于8时仍然能够快速遍历。 HashMap在put时，如果数组中已经有了这个key，我不想把value值覆盖怎么办？取值时如果得到的value是空，想返回默认值怎么办如果数组中有了key但是不想覆盖value，可以选择putIfAbsent()方法，这个方法会再调用putVal时将onlyIfAbsent置为true，这样就不会覆盖了；而我们使用的put方法，将onlyIfAbsent设置为false。取值时，若为空但是想返回默认值，可以使用getDefault方法，方法参数有两个：第一个是key，第二个为想要返回的默认值。 描述一下HashMap get、put的过程在前面源码解析中介绍过，可以详细描述源码的实现路径，最好画图说明。 其他面试题 LinkedHashMap中的LRU是什么意思，是如何实现的LRU，全称是Least recently used，即最近最少访问，在LinkedHashMap中，也叫做最少访问策略，我们可以通过removeEldestEntry()方法设定一定的策略，使最少访问的元素在适当的时候被删除，原理是在put方法执行的最后，LinkedHashMap会检查这种策略，如果满足策略，就删除头节点。 为什么推荐TreeMap的元素最好都实现Comparable接口？key是String的时候我们却没有额外的工作呢因为TreeMap的底层就是通过排序来比较两个key的大小的，所以推荐key实现Comparable接口，是为了往你所希望的排序上发展，而String本身已经实现了Comparable接口，所以在使用时不需要做额外的动作。不仅仅是String，其他包装类型也都实现了Comparable接口。 总结Map的面试题主要以HashMap为主，会问很多源码方面的东西，TreeMap和LinkedHashMap主要以功能和场景为主，作为加分项。只要弄懂了Map的源码，不管问题怎么变，问题都不大，所以说源码才是重点。本文摘自慕课网文贺老师专栏。]]></content>
      <categories>
        <category>JDK源码</category>
      </categories>
      <tags>
        <tag>源码</tag>
        <tag>集合</tag>
        <tag>面试题</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[4的幂]]></title>
    <url>%2F2019%2F11%2F08%2F4%E7%9A%84%E5%B9%82%2F</url>
    <content type="text"><![CDATA[LeetCode第三百四十二题难度：简单题目：给定一个整数 (32 位有符号整数)，请编写一个函数来判断它是否是 4 的幂次方。(不使用递归和迭代) 1234567示例 1:输入: 16输出: true示例 2:输入: 5输出: false 思想分析这道题和前面判断2的幂很相似，因为4也是2的幂，即4的幂一定是2的幂。通过观察4的幂次方数的二进制我们可以发现以下规律 4的幂次方数和2的幂次方数一样，二进制中只有一个1 4的幂次方数和0x55555555做&amp;运算还是他本身，和0xaaaaaaaa做&amp;运算为0。 有了这两条规律，那么解法就显而易见了 代码实现//解法一：和0xaaaaaaaa做&amp;运算，借助库方法实现 public boolean isPowerOfFour(int num) { return ((num&amp;0xaaaaaaaa)==0)&amp;&amp;Integer.bitCount(num)==1; } //解法二：不借助库方法，和0x55555555做&amp;运算。 //该方法需先确保num是2的幂次方，即保证转换为二进制只有一个1 public boolean isPowerOfFour(int num) { if(num&lt;=0) return false; if((num&amp;num-1)!=0) return false; if((num&amp;0x55555555)==num) return true; return false; }目前为止已经遇到了2、3、4次幂的问题，可以拿来对比以下它们的共同点和不同点。]]></content>
      <categories>
        <category>算法之美</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
        <tag>位运算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[猜数字游戏]]></title>
    <url>%2F2019%2F11%2F08%2F%E7%8C%9C%E6%95%B0%E5%AD%97%E6%B8%B8%E6%88%8F%2F</url>
    <content type="text"><![CDATA[LeetCode第二百九十九题难度：简单题目：你正在和你的朋友玩 猜数字（Bulls and Cows）游戏：你写下一个数字让你的朋友猜。每次他猜测后，你给他一个提示，告诉他有多少位数字和确切位置都猜对了（称为“Bulls”, 公牛），有多少位数字猜对了但是位置不对（称为“Cows”, 奶牛）。你的朋友将会根据提示继续猜，直到猜出秘密数字。请写出一个根据秘密数字和朋友的猜测数返回提示的函数，用 A 表示公牛，用 B 表示奶牛。请注意秘密数字和朋友的猜测数都可能含有重复数字。 1234567891011示例 1:输入: secret = &quot;1807&quot;, guess = &quot;7810&quot;输出: &quot;1A3B&quot;解释: 1 公牛和 3 奶牛。公牛是 8，奶牛是 0, 1 和 7。示例 2:输入: secret = &quot;1123&quot;, guess = &quot;0111&quot;输出: &quot;1A1B&quot;解释: 朋友猜测数中的第一个 1 是公牛，第二个或第三个 1 可被视为奶牛。说明: 你可以假设秘密数字和朋友的猜测数都只包含数字，并且它们的长度永远相等。 思想分析这道题可以使用由于题目确定了仅包括数字，那么可以用一个长度为10的数组来模拟哈希表。 同时遍历两字符串 如果相同位置字符相同，则公牛+1 如果不同，则secret中字符对应位置值+1，guess字符对应位置值-1。 最后统计哈希数组中大于0的个数sum 用secret字符串长度减去sum和公牛数就是母牛数 代码实现12345678910111213141516171819202122232425262728//在实现的过程中最好将字符串转换为字符数字，对字符数组进行操作//避免频繁使用charAt()方法public String getHint(String secret, String guess) &#123; int[] bucket = new int[10]; int bull = 0; int cow = 0; int len=secret.length(); char[] ss=secret.toCharArray(); char[] gg=guess.toCharArray(); for(int i=0;i&lt;len;i++)&#123; //如果相等，说明是公牛 if(ss[i]== gg[i])&#123; bull++; continue; &#125; bucket[ss[i] - &apos;0&apos;] += 1; bucket[gg[i] - &apos;0&apos;] -= 1; &#125; //计算bucket中正值的个数 for(int i=0;i&lt;10;i++)&#123; if(bucket[i] &gt; 0) cow+= bucket[i]; &#125; cow = len - cow - bull; return bull + &quot;A&quot; + cow + &quot;B&quot;;&#125;]]></content>
      <categories>
        <category>算法之美</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
        <tag>字符串</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[3的幂]]></title>
    <url>%2F2019%2F11%2F08%2F3%E7%9A%84%E5%B9%82%2F</url>
    <content type="text"><![CDATA[LeetCode第三百二十六题难度：简单题目：给定一个整数，写一个函数来判断它是否是 3 的幂次方。 123456789101112示例 1:输入: 27输出: true示例 2:输入: 0输出: false示例 3:输入: 9输出: true 思想分析和前面2的幂次方不同，3的幂次方在二进制位上没有明显的规律，仅有一点是二进制位中最后一位总是1。所以我们只能使用普通的取模加除法来解决问题。 代码实现12345678public boolean isPowerOfThree(int n) &#123; if(n&lt;1) return false; while(n%3==0)&#123; n/=3; &#125; return n==1;&#125;]]></content>
      <categories>
        <category>算法之美</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nim游戏]]></title>
    <url>%2F2019%2F11%2F08%2FNim%E6%B8%B8%E6%88%8F%2F</url>
    <content type="text"><![CDATA[LeetCode第二百九十二题难度：简单题目：你和你的朋友，两个人一起玩 Nim 游戏：桌子上有一堆石头，每次你们轮流拿掉 1 - 3 块石头。 拿掉最后一块石头的人就是获胜者。你作为先手 12345示例:输入: 4输出: false 解释: 如果堆中有 4 块石头，那么你永远不会赢得比赛； 因为无论你拿走 1 块、2 块 还是 3 块石头，最后一块石头总是会被你的朋友拿走。 思想分析这道题和小时候玩儿过的游戏很类似，如果石头的数目大于4，那么谁先拿谁就赢，因为谁先拿谁就能使得剩下的石头数为4的倍数，这样以来无论对面怎么拿，自己都能使得石头数保持为4的倍数。 代码实现12345public boolean canWinNim(int n) &#123; //(n-1)&amp;3和n%3的效果类似，但是比取模运算速度快 //仅当n为2的幂次方成立 return (n&amp;3)!=0;&#125;]]></content>
      <categories>
        <category>算法之美</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
        <tag>脑筋急转弯</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[移动零]]></title>
    <url>%2F2019%2F11%2F08%2F%E7%A7%BB%E5%8A%A8%E9%9B%B6%2F</url>
    <content type="text"><![CDATA[LeetCode第二百八十三题难度：简单题目：给定一个数组 nums，编写一个函数将所有 0 移动到数组的末尾，同时保持非零元素的相对顺序。 1234567示例:输入: [0,1,0,3,12]输出: [1,3,12,0,0]说明:必须在原数组上操作，不能拷贝额外的数组。尽量减少操作次数。 思想分析题目额外要求了必须在原数组上操作并且减少操作次数，我们可以使用一下方法解决 新建一个int型变量count，记录0的个数 从前往后遍历数组，如果当前元素为0，那么count++ 如果当前元素不为0，那么将当前元素向前移动count个单位(和i-count下标元素交换位置即可) 代码实现1234567891011public void moveZeroes(int[] nums) &#123; int count=0; for(int i=0;i&lt;nums.length;i++)&#123; if(count&gt;0&amp;&amp;nums[i]!=0)&#123; nums[i-count]=nums[i]; nums[i]=0; &#125; else if(nums[i]==0) count++; &#125; &#125; 对于数组这种数据结构，要能够熟练地掌握其各种操作。]]></content>
      <categories>
        <category>算法之美</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
        <tag>数组</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[缺失数字]]></title>
    <url>%2F2019%2F11%2F08%2F%E7%BC%BA%E5%A4%B1%E6%95%B0%E5%AD%97%2F</url>
    <content type="text"><![CDATA[LeetCode第二百六十八题难度：简单题目：给定一个包含 0, 1, 2, …, n 中 n 个数的序列，找出 0 .. n 中没有出现在序列中的那个数。(线性时间复杂度和常数空间复杂度) 1234567示例 1:输入: [3,0,1]输出: 2示例 2:输入: [9,6,4,2,3,5,7,0,1]输出: 8 思想分析提供两种解法 创建一个和参数数组一样大的新数组，对于参数数组中出现的每一个元素，新数组的相应下表设为true。最后遍历新数组，为false的元素下标即为缺失的数字，如果都为true，那么缺失的数字为n。 使用高斯公式计算n个数字之和，减去数组中的每一个元素，最后的值即为缺失数字。 使用异或运算解决问题，我们直到对一个数字亦或2次后得到的仍然是原数字，那么我们在遍历的过程中对每一个数组下标和数组元素进行异或运算 代码实现12345678910111213141516171819202122232425262728293031323334//使用额外数组实现public int missingNumber(int[] nums) &#123; int len=nums.length; boolean[] temp=new boolean[len]; for(int i=0;i&lt;len;i++)&#123; if(nums[i]!=len) temp[nums[i]]=true; &#125; for(int i=0;i&lt;len;i++) if(!temp[i]) return i; return len;&#125;“=======================”//使用高斯公式实现public int missingNumber(int[] nums) &#123; int len=nums.length; //计算和 int res=len*(len+1)/2; for(int i=0;i&lt;len;i++) res-=nums[i]; return res;&#125;“=======================”//位运算public int missingNumber(int[] nums) &#123; int missing = nums.length; for (int i = 0; i &lt; nums.length; i++) &#123; missing ^= i ^ nums[i]; &#125; return missing;&#125; 这是一道类似于脑筋急转弯的题目，很有意思。第二种和第三种方法比较巧妙，尤其是第三种。]]></content>
      <categories>
        <category>算法之美</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
        <tag>位运算</tag>
        <tag>数组</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[各位相加]]></title>
    <url>%2F2019%2F11%2F08%2F%E5%90%84%E4%BD%8D%E7%9B%B8%E5%8A%A0%2F</url>
    <content type="text"><![CDATA[LeetCode第二百五十八题难度：简单题目：给定一个非负整数 num，反复将各个位上的数字相加，直到结果为一位数。(不使用递归和循环，O(1)时间复杂度完成) 1234示例:输入: 38输出: 2 解释: 各位相加的过程为：3 + 8 = 11, 1 + 1 = 2。 由于 2 是一位数，所以返回 2。 思想分析对于这个题目，如果没有后面的时间复杂度要求，是非常简单的。但是由于题目的要求，我们只能另想办法解决问题。 对于一个数字n=875；我们可以写成875=81010+7*10+5的形式。那么8的权重为100，7的权重为10，5的权重为1 现在我们要将个位相加，也就是将各个位的权重都看作1。 因此875=81010+710+5=8(1010-1)+7(10-1)+5(1-1)=899+799 由上我们可以得到：875-899-79=8+7+5 同样的对于8+7+5=20也有：20-2*9=2 即875%9=2 代码实现123456public int addDigits(int num) &#123; //如果num是9的倍数，那么最后和为9 if(num&gt;0&amp;&amp;num%9==0) return 9; return num%9;&#125; 对于这类数字问题，了解了思路之后往往会很简单。]]></content>
      <categories>
        <category>算法之美</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
        <tag>位运算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二叉树的所有路径]]></title>
    <url>%2F2019%2F11%2F08%2F%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E6%89%80%E6%9C%89%E8%B7%AF%E5%BE%84%2F</url>
    <content type="text"><![CDATA[LeetCode第二百五十七题难度：简单题目：给定一个二叉树，返回所有从根节点到叶子节点的路径。 1234567891011示例:输入: 1 / \2 3 \ 5输出: [&quot;1-&gt;2-&gt;5&quot;, &quot;1-&gt;3&quot;]解释: 所有根节点到叶子节点的路径为: 1-&gt;2-&gt;5, 1-&gt;3 思想分析这道题的示例代码中，输出已经给了我们提示，可以使用一个集合来存储所有的路径。我们递归遍历链表 如果当前节点为空，什么都不做 将当前节点添加到当前路径中，如果当前节点为叶子节点，那么将当前路径添加到集合中 否则，递归遍历当前节点的左右子树 代码实现123456789101112131415161718public List&lt;String&gt; binaryTreePaths(TreeNode root) &#123; List&lt;String&gt; res=new ArrayList&lt;&gt;(30); getPaths(root,&quot;&quot;,res); return res;&#125;public void getPaths(TreeNode root,String path,List&lt;String&gt; res)&#123; if(root!=null)&#123; path+=root.val; if(root.left==null&amp;&amp;root.right==null) res.add(path); else&#123; path+=&quot;-&gt;&quot;; getPaths(root.left,path,res); getPaths(root.right,path,res); &#125; &#125;&#125;]]></content>
      <categories>
        <category>算法之美</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
        <tag>递归</tag>
        <tag>二叉树</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[有效的字母异位词]]></title>
    <url>%2F2019%2F11%2F08%2F%E6%9C%89%E6%95%88%E7%9A%84%E5%AD%97%E6%AF%8D%E5%BC%82%E4%BD%8D%E8%AF%8D%2F</url>
    <content type="text"><![CDATA[LeetCode第二百四十二题难度：简单题目：给定两个字符串 s 和 t ，编写一个函数来判断 t 是否是 s 的字母异位词。(假设只包含小写字符) 1234567示例 1:输入: s = &quot;anagram&quot;, t = &quot;nagaram&quot;输出: true示例 2:输入: s = &quot;rat&quot;, t = &quot;car&quot;输出: false 算法思想这道题可以使用两种方法来解决 排序思想，通过题意可知，排完序之后两字符串如果相等，那么返回true；否则返回true 哈希表思想，使用一个数组模拟哈希表，如果对于s上的字符，数组相应位置+1，对于t上的字符，数组相应位置-1；最后如果数组元素都为0，那么返回true 代码实现12345678910111213141516171819由于排序可以使用类库方法，这里就不做演示//哈希表思想public boolean isAnagram(String s, String t) &#123; if(s.length()!=t.length()) return false; int[] complate=new int[26]; char[] ss=s.toCharArray(); char[] tt=t.toCharArray(); int len=ss.length; for(int i=0;i&lt;len;i++)&#123; complate[ss[i]-&apos;a&apos;]++; complate[tt[i]-&apos;a&apos;]--; &#125; for(int c:complate) if(c!=0) return false; return true;&#125;]]></content>
      <categories>
        <category>算法之美</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
        <tag>字符串</tag>
        <tag>哈希表</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[删除当前节点]]></title>
    <url>%2F2019%2F11%2F08%2F%E5%88%A0%E9%99%A4%E5%BD%93%E5%89%8D%E8%8A%82%E7%82%B9%2F</url>
    <content type="text"><![CDATA[LeetCode第二百三十七题难度：简单题目：请编写一个函数，使其可以删除某个链表中给定的（非末尾）节点，你将只被给定要求被删除的节点。 123456789示例 1:输入: head = [4,5,1,9], node = 5输出: [4,1,9]解释: 给定你链表中值为 5 的第二个节点，那么在调用了你的函数之后，该链表应变为 4 -&gt; 1 -&gt; 9.示例 2:输入: head = [4,5,1,9], node = 1输出: [4,5,9]解释: 给定你链表中值为 1 的第三个节点，那么在调用了你的函数之后，该链表应变为 4 -&gt; 5 -&gt; 9. 思想分析要删除一个单链表的节点，我们一般的思路就是找到要删除的节点的前一个节点，利用前一个节点对当前节点进行删除。但是在这道题中，给出当前节点，要求删除当前节点。 代码实现123456public void deleteNode(ListNode node) &#123; //将后一个节点的值赋值给当前节点 node.val=node.next.val; //删除后一个节点 node.next=node.next.next;&#125; 方法比较巧妙，但是通过代码可以发小，该实现无法删除最后一个节点。]]></content>
      <categories>
        <category>算法之美</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
        <tag>链表</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AVL树的公共祖先]]></title>
    <url>%2F2019%2F11%2F08%2FAVL%E6%A0%91%E7%9A%84%E5%85%AC%E5%85%B1%E7%A5%96%E5%85%88%2F</url>
    <content type="text"><![CDATA[LeetCode第二百三十五题难度：简单题目：给定一个二叉搜索树, 找到该树中两个指定节点的最近公共祖先。 12345678示例 1:输入: root = [6,2,8,0,4,7,9,null,null,3,5], p = 2, q = 8输出: 6 解释: 节点 2 和节点 8 的最近公共祖先是 6。示例 2:输入: root = [6,2,8,0,4,7,9,null,null,3,5], p = 2, q = 4输出: 2解释: 节点 2 和节点 4 的最近公共祖先是 2, 因为根据定义最近公共祖先节点可以为节点本身。 思想分析又是一道递归题目，我们来分析一下流程 对于当前节点，判断p、q和当前节点值的大小 如果p和q都大于当前节点值，那么递归进入当前节点右子树 如果p和q都小于当前节点值，那么递归进入当前节点左子树 否则，当前节点就是p和q的公共祖先 代码实现12345678910public TreeNode lowestCommonAncestor(TreeNode root, TreeNode p, TreeNode q) &#123; int pval=p.val; int qval=q.val; int rval=root.val; if(pval&gt;rval&amp;&amp;qval&gt;rval) return lowestCommonAncestor(root.right,p,q); if(pval&lt;rval&amp;&amp;qval&lt;rval) return lowestCommonAncestor(root.left,p,q); return root;&#125;]]></content>
      <categories>
        <category>算法之美</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
        <tag>AVL树</tag>
        <tag>递归</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[回文链表]]></title>
    <url>%2F2019%2F11%2F08%2F%E5%9B%9E%E6%96%87%E9%93%BE%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[LeetCode第二百三十四题难度：简单题目：请判断一个链表是否为回文链表。(O(n)时间复杂度和O(1)空间复杂度) 1234567示例 1:输入: 1-&gt;2输出: false示例 2:输入: 1-&gt;2-&gt;2-&gt;1输出: true 思想分析判断一个链表是否为回文链表很简单，但是要实现复杂度要求并且以较好的方式来实现，就要用到快慢指针法 利用快慢指针，找到链表的中间节点 反转链表的前半部分 从链表头和链表中间节点开始往后遍历链表 代码实现12345678910111213141516171819202122232425262728293031public boolean isPalindrome(ListNode head) &#123; if(head==null||head.next==null) return true; //快慢指针法使slow指向链表的(n+1)/2位置的节点 ListNode slow=head; ListNode fast=head; while(fast!=null&amp;&amp;fast.next!=null)&#123; slow=slow.next; fast=fast.next.next; &#125; //反转前半部分链表 ListNode Pre=head; ListNode Next=head.next; while(Next!=slow)&#123; head.next=Next.next; Next.next=Pre; Pre=Next; Next=head.next; &#125; //如果链表个数为奇数，去掉中间节点 if(fast!=null) slow=slow.next; //比较 while(slow!=null)&#123; if(Pre.val!=slow.val) return false; Pre=Pre.next; slow=slow.next; &#125; return true;&#125; 可以发现，在解决链表问题时，快慢指针往往能够出其不意。]]></content>
      <categories>
        <category>算法之美</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
        <tag>链表</tag>
        <tag>快慢指针</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2的幂]]></title>
    <url>%2F2019%2F11%2F08%2F2%E7%9A%84%E5%B9%82%2F</url>
    <content type="text"><![CDATA[LeetCode第二百三十一题难度：简单题目：给定一个整数，编写一个函数来判断它是否是 2 的幂次方 12345678910111213示例 1:输入: 1输出: true解释: 20 = 1示例 2:输入: 16输出: true解释: 24 = 16示例 3:输入: 218输出: false 思路分析这道题，如果一上来就用普通的暴力遍历那就太简单了，我们可以通过2幂次方数的特点结合位运算来解决。首先，2的幂次方的数用二进制表示时只有一个1，其余都是0。并且有n&amp;(n-1)==0恒存在。知道了这点，这道题就更简单了 代码实现123456789public boolean isPowerOfTwo(int n) &#123; if(n&lt;=0) return false; if((n&amp;(n-1))==0) return true; return false; //一行代码解决 //return n&gt;0&amp;&amp;(n&amp;(n-1))==0;&#125; 深入理解二进制补码存储方式是很重要的，很多问题能够通过位运算得以大大简化。]]></content>
      <categories>
        <category>算法之美</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
        <tag>位运算</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[反转二叉树]]></title>
    <url>%2F2019%2F11%2F08%2F%E5%8F%8D%E8%BD%AC%E4%BA%8C%E5%8F%89%E6%A0%91%2F</url>
    <content type="text"><![CDATA[LeetCode第二百二十六题难度：简单题目：翻转一棵二叉树 123456789101112131415示例：输入： 4 / \ 2 7 / \ / \1 3 6 9输出： 4 / \ 7 2 / \ / \9 6 3 1 思想分析又是一道典型的递归解决的二叉树问题，而对于能使用递归解决的二叉树问题，通常也能够使用迭代来解决。递归思路： 递归出口：当前节点为null，返回null 遍历二叉树(我将使用先序遍历的方式) 遍历到二叉树的每一个节点，交换该节点的左右子树 递归遍历当前节点的左右子树 返回当前节点 迭代思路： 创建一个队列，将头节点入栈 如果队列不为空，取出队头节点，交换该节点的左右子树 如果该节点有左右子树，将其左右子树分别入栈 代码实现123456789101112131415161718192021222324252627282930313233//递归代码(先序遍历)public TreeNode invertTree(TreeNode root) &#123; //递归出口 if (root == null) &#123; return null; &#125; //交换节点左右子树 TreeNode temp=root.left; root.left=root.right; root.right=temp; //递归遍历当前节点左右子树 invertTree(root.right); invertTree(root.left); //返回当前节点 return root;&#125;“====================================”//迭代代码：public TreeNode invertTree(TreeNode root) &#123; if (root == null) return null; Queue&lt;TreeNode&gt; queue = new LinkedList&lt;TreeNode&gt;(); queue.add(root); while (!queue.isEmpty()) &#123; TreeNode current = queue.poll(); TreeNode temp = current.left; current.left = current.right; current.right = temp; if (current.left != null) queue.add(current.left); if (current.right != null) queue.add(current.right); &#125; return root;&#125;]]></content>
      <categories>
        <category>算法之美</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
        <tag>递归</tag>
        <tag>二叉树</tag>
        <tag>迭代</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LinkedHashMap源码解析]]></title>
    <url>%2F2019%2F11%2F06%2FLinkedHashMap%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[了解了HashMap之后，我们就会发现，插入HashMap中的元素是不保证顺序的，因为元素在数组中是通过映射找到具体位置的，所以不保证取出元素的顺序和插入时的相等。那如果有这方面的要求，就要用到LinkedHashMap集合了。接下来就介绍一下JDK1.8下的LinkedHashMap集合。 节点继承关系在介绍LinkedHashMap之前，我们先看一下节点的继承关系： 从图中可以看到，HashMap中的树节点TreeNode是继承自LinkedHashMap的Entry节点。至于TreeNode不继承自身的Node而去继承Entry，这是有原因的，我们后面说。 LinkedHashMap内部类Entry继承自HashMap内部类Node，并新增了两个引用，分别是before和after。这两个引用的用途不难理解，也就是用于维护双向链表。同时，TreeNode继承LinkedHashMap 的内部类Entry后，就具备了和其他Entry一起组成链表的能力。但是这里需要大家考虑一个问题。当我们使用HashMap时，TreeNode并不需要具备组成链表能力。如果继承LinkedHashMap内部类Entry ，TreeNode就多了两个用不到的引用，这样做不是会浪费空间吗？ TreeNode对象的大小约是普通Node对象的2倍，我们仅在桶（bin）中包含足够多的节点时再使用。当桶中的节点数量变少时（取决于删除和扩容），TreeNode 会被转成 Node。当用户实现的 hashCode 方法具有良好分布性时，树类型的桶将会很少被使用。 一般情况下，只要 hashCode 的实现不糟糕，Node 组成的链表很少会被转成由 TreeNode 组成的红黑树。也就是说 TreeNode 使用的并不多，浪费那点空间是可接受的。假如 TreeNode 机制继承自 Node 类，那么它要想具备组成链表的能力，就需要 Node 去继承 LinkedHashMap 的内部类 Entry。这个时候就得不偿失了，浪费很多空间去获取不一定用得到的能力。 LinkedHashMap新增属性LinkedHashMap集合能够维护插入顺序，继承自HashMap，所以它拥有HashMap的所有特性。在此基础上，还增加了两大特性 按照插入顺序进行访问； 实现了访问量最少最先删除的功能，其目的是把很久没有访问的key自动删除 12345678910111213141516//链表头transient LinkedHashMap.Entry&lt;K,V&gt; head;//链表尾transient LinkedHashMap.Entry&lt;K,V&gt; tail;//控制两种访问模式，默认false//true：按照访问顺序，把经常访问的key放到队尾//false：按照插入顺序提供访问final boolean accessOrder;//继承HashMap的内部类Node，为每个节点增加了before和after属性static class Entry&lt;K,V&gt; extends HashMap.Node&lt;K,V&gt; &#123; Entry&lt;K,V&gt; before, after; Entry(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; super(hash, key, value, next); &#125;&#125; 按照顺序访问LinkedHashMap通过新节点的head和tail指针，将各个节点都连接起来，形成一个链表，从而达到保证顺序的目的 按照插入顺序新增HashMap初始化时，默认accessOrder为false，就是会按照插入顺序提供访问，插入方法是使用父类的put方法，但是重写了父类put方法中的newNode/newTreeNode方法和afterNodeAccess方法。 newNode/newTreeNode方法。控制新增节点追加到链表尾部，这样每次新节点都追加到尾部，就可以保证插入顺序了，我们以newNode源码为例123456789101112131415161718Node&lt;K,V&gt; newNode(int hash, K key, V value, Node&lt;K,V&gt; e) &#123; LinkedHashMap.Entry&lt;K,V&gt; p = new LinkedHashMap.Entry&lt;K,V&gt;(hash, key, value, e); linkNodeLast(p); return p;&#125;”================================“private void linkNodeLast(LinkedHashMap.Entry&lt;K,V&gt; p) &#123; LinkedHashMap.Entry&lt;K,V&gt; last = tail; tail = p; if (last == null) head = p; else &#123; p.before = last; last.after = p; &#125;&#125; 从源码可以发现，LinkedHashMap通过新增头节点、尾节点，给每个节点增加before、after属性，在每次新增时，就已经维护了按照插入顺序的链表。 按照插入顺序访问LinkedHashMap只提供了单向访问，即按照插入顺序从头到尾进行访问，无法像LinkedList一样进行双向访问。我们主要通过迭代器进行访问，迭代器在初始化时默认从头节点开始，在迭代的过程中不断访问当前节点的after节点即可。Map对key、value和entry节点都提供了迭代的方法，假设我们现在对entry进行迭代，就可以使用LinkedHashMap.entrySet().iterator()来返回迭代器LinkedHashIterator，通过调用迭代器的nextNode方法就可以得到下一个节点。 123456789101112131415161718192021222324252627282930313233//获取entrySetpublic Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet() &#123; Set&lt;Map.Entry&lt;K,V&gt;&gt; es; return (es = entrySet) == null ? (entrySet = new LinkedEntrySet()) : es;&#125;”=====================================“//通过entrySet的iterator方法获取迭代器public final Iterator&lt;Map.Entry&lt;K,V&gt;&gt; iterator() &#123; return new LinkedEntryIterator();&#125;”=====================================“//LinkedEntryIterator迭代器类，继承自LinkedHashIterator final class LinkedEntryIterator extends LinkedHashIterator implements Iterator&lt;Map.Entry&lt;K,V&gt;&gt; &#123; public final Map.Entry&lt;K,V&gt; next() &#123; return nextNode(); &#125;&#125;”=====================================“//最终逻辑方法nextNode()返回节点final LinkedHashMap.Entry&lt;K,V&gt; nextNode() &#123; LinkedHashMap.Entry&lt;K,V&gt; e = next; //判断版本号，快速失败策略 if (modCount != expectedModCount) throw new ConcurrentModificationException(); if (e == null) throw new NoSuchElementException(); //返回当前接待你，next执行下一个节点 current = e; next = e.after; return e;&#125; 虽然迭代器next方法调用过程比较复杂，但是我们可以发现其逻辑代码却很简单，只是通过节点的after指针不断的访问下一个节点而已。 访问最少删除策略这种策略也叫做LRU(Least recently used)，大概意思就是经常访问的元素会被追加到队尾，这样不经常访问的数据自然就靠近队头，然后我们可以通过设置删除策略，比如当Map元素个数大于多少时把头节点删除。 元素被转移到队尾我们来看一下LinkedHashMap的get()方法源码 12345678910111213141516171819202122232425262728293031323334353637383940public V get(Object key) &#123; Node&lt;K,V&gt; e; if ((e = getNode(hash(key), key)) == null) return null; if (accessOrder) afterNodeAccess(e); return e.value;&#125;”========================“void afterNodeAccess(Node&lt;K,V&gt; e) &#123; // move node to last LinkedHashMap.Entry&lt;K,V&gt; last; if (accessOrder &amp;&amp; (last = tail) != e) &#123; LinkedHashMap.Entry&lt;K,V&gt; p = (LinkedHashMap.Entry&lt;K,V&gt;)e, b = p.before, a = p.after; p.after = null; //如果当前节点为头节点 if (b == null) head = a; else b.after = a; //如果当前节点不是尾节点 if (a != null) a.before = b; //如果当前节点是尾节点 else last = b; //如果当前链表只有一个节点 if (last == null) head = p; else &#123; p.before = last; last.after = p; &#125; //将当前节点移到链表尾部 tail = p; ++modCount; &#125;&#125; 通过源码可以发现，LinkedHashMap重写了父类HashMap的get()方法，通过afterNodeAccess()方法将当前访问节点移到队尾。 删除策略前面说过，LinkedHashMap可以设置在当插入元素超过一定数量时候删除队头元素。这是怎么实现的呢？首先LinkedHashMap并没有实现自己的put方法，调用的是HashMap的put方法。重写了HashMap的put方法中的afterNodeInsertion(evict)方法在每次添加元素后如果元素个数超过设置的阈值则会调用该方法删除链表头元素。 12345678910111213141516171819/** * 删除策略方法 * @param evict：HashMap的put方法中传递true值 */void afterNodeInsertion(boolean evict) &#123; LinkedHashMap.Entry&lt;K,V&gt; first; if (evict &amp;&amp; (first = head) != null &amp;&amp; removeEldestEntry(first)) &#123; K key = first.key; //调用HashMap的removeNode方法删除节点 removeNode(hash(key), key, null, false, true); &#125;&#125;&quot;=======================================&quot;//该方法用于设置阈值，当元素超过阈值时删除链表头元素//可通过继承LinkedHashMap类重写该方法修改阈值protected boolean removeEldestEntry(Map.Entry&lt;K,V&gt; eldest) &#123; return false;&#125; 上面代码中最终的删除方法调用的仍然是HashMap的删除方法，LinkedHashMap并没有重写该方法。但是重写了removeNode()方法中的afterNodeRemoval方法，使得在删除节点后调整链表。 1234567891011121314//删除节点后调整链表void afterNodeRemoval(Node&lt;K,V&gt; e) &#123; // unlink LinkedHashMap.Entry&lt;K,V&gt; p = (LinkedHashMap.Entry&lt;K,V&gt;)e, b = p.before, a = p.after; p.before = p.after = null; if (b == null) head = a; else b.after = a; if (a == null) tail = b; else a.before = b;&#125; 总结通过查看源码不难发现，LinkedHashMap继承自HashMap，主要重写了HashMap的Node类，实现了自己的Entry内部类(其实就是为每个节点增加了一个before和after指针)。LinkedHashMap的大多方法调用的仍是父类的方法。主要重写了四个方法，分别是 newNode/newTreeNode方法：用于在添加元素时维护一个链表 afterNodeRemoval方法，用于在删除节点时维护链表 afterNodeInsertion方法，在LRU模式下，设置元素阈值，当元素个数超过阈值时删除链表头元素 afterNodeAccess方法，设置LRU模式，将最少访问的节点放在链表头部 LinkedHashMap通过在HashMap的基础上增加一个双向链表来实现相应的功能，不得不说还是比较巧妙的。]]></content>
      <categories>
        <category>JDK源码</category>
      </categories>
      <tags>
        <tag>源码</tag>
        <tag>LinkedHashMap集合</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用队列实现栈]]></title>
    <url>%2F2019%2F11%2F05%2F%E7%94%A8%E9%98%9F%E5%88%97%E5%AE%9E%E7%8E%B0%E6%A0%88%2F</url>
    <content type="text"><![CDATA[LeetCode第二百二十五题难度：简单题目：使用队列实现栈的下列操作： push(x) – 元素 x 入栈 pop() – 移除栈顶元素 top() – 获取栈顶元素 empty() – 返回栈是否为空 思想分析我们知道队列具有FIFO，即先进先出的特点；而栈具有FILO-先进后出的特点。要想用队列实现栈的功能，有两种不同的思路。 使用两个队列，其中一个队列作为转换。 使用一个队列，再插入时做一些特殊操作。 代码实现前面介绍的比较简单，下面演示一下一个队列的实现，逻辑比较简单。 12345678910111213141516171819202122232425class MyStack &#123; private Queue&lt;Integer&gt; q=new LinkedList&lt;&gt;(); public MyStack() &#123; &#125; public void push(int x) &#123; q.add(x); for(int i=0;i&lt;q.size()-1;i++) //这个是插入的核心逻辑 q.add(q.poll()); &#125; public int pop() &#123; return q.poll(); &#125; public int top() &#123; return q.peek(); &#125; public boolean empty() &#123; return q.isEmpty(); &#125;&#125; 从代码可以看出，我们在每次插入时花费O(n)的时间复杂度，将队列中元素变成栈的顺序，而在其他操作时可以直接当作栈来处理，因此时间复杂度为O(1)。]]></content>
      <categories>
        <category>算法之美</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
        <tag>队列</tag>
        <tag>栈</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[反转链表]]></title>
    <url>%2F2019%2F11%2F05%2F%E5%8F%8D%E8%BD%AC%E9%93%BE%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[LeetCode第二百零六题难度：简单题目：反转一个单链表。(递归和迭代反转链表) 123示例:输入: 1-&gt;2-&gt;3-&gt;4-&gt;5-&gt;NULL输出: 5-&gt;4-&gt;3-&gt;2-&gt;1-&gt;NULL 思想分析迭代实现 判断临界情况，如果链表为空或只有一个元素，直接返回链表 需要创建两个临时指针next和pre。next初始化为head.next，pre初始化为null next指针指向需要反转的节点，pre指向反转后的第一个节点。 反转过程如图所示 递归实现代码比较简单，建议创建2个节点的链表，手动画一下递归过程中节点的变化。会更容易理解一些 代码实现1234567891011121314151617181920212223242526272829303132//迭代法public ListNode reverseList(ListNode head) &#123; //判断临界情况 if(head==null||head.next==null) return head; //初始化临时指针 ListNode Next=head.next; ListNode Pre=head; //遍历链表 while(Next!=null)&#123; head.next=Next.next; Next.next=Pre; Pre=Next; Next=head.next; &#125; //返回新头指针 return Pre;&#125;&quot;=================================&quot;//递归法public ListNode reverseList(ListNode head) &#123; //递归出口 if (head == null || head.next == null) return head; ListNode p = reverseList(head.next); //反转代码 head.next.next = head; //这个不能少，否则可能会产生循环链表 //当链表长度为2时 head.next = null; return p;&#125; 所有的迭代都能转化为递归，这里迭代的思路比较简单，递归解法就比较考验递归的思路是否清晰了。]]></content>
      <categories>
        <category>算法之美</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
        <tag>递归</tag>
        <tag>二分查找</tag>
        <tag>链表</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[同构字符串]]></title>
    <url>%2F2019%2F11%2F05%2F%E5%90%8C%E6%9E%84%E5%AD%97%E7%AC%A6%E4%B8%B2%2F</url>
    <content type="text"><![CDATA[LeetCode第二百零五题难度：简单题目：给定两个字符串 s 和 t，判断它们是否是同构的。如果 s 中的字符可以被替换得到 t ，那么这两个字符串是同构的。所有出现的字符都必须用另一个字符替换，同时保留字符的顺序。两个字符不能映射到同一个字符上，但字符可以映射自己本身。 1234567891011121314示例 1:输入: s = &quot;egg&quot;, t = &quot;add&quot;输出: true示例 2:输入: s = &quot;foo&quot;, t = &quot;bar&quot;输出: false示例 3:输入: s = &quot;paper&quot;, t = &quot;title&quot;输出: true说明:你可以假设 s 和 t 具有相同的长度。 思路分析 通用的解决方法是使用哈希表来解决这种映射问题，同时遍历两字符串，将两串对应位置的字符以键值对的形式存储进去。如果后面遇到值相同键不相同或者键相同值不相同的键值对，则说明这两个字符串不是同构的。 还有一种巧妙地方法，如果两字符串是同构字符串，那么两字符串中相同映射的字符第一次出现的位置相等。例如”add”和”egg”,对于”d-g”键值对，第一次出现的位置索引都是1。 代码实现12345678910111213141516171819202122232425262728293031323334//HashMap解决public boolean isIsomorphic(String s, String t) &#123; Map&lt;Character,Character&gt; map=new HashMap&lt;&gt;(); //方便遍历，将字符串转换为数组 char[] ss=s.toCharArray(); char[] tt=t.toCharArray(); for(int i=0;i&lt;ss.length;i++)&#123; if(map.containsKey(ss[i]))&#123; if(map.get(ss[i])!=tt[i]) return false; &#125; else if(map.containsValue(tt[i])) return false; else&#123; map.put(ss[i],tt[i]); &#125; &#125; return true;&#125;&quot;======================================&quot;//巧妙解法public boolean isIsomorphic(String s, String t) &#123; char[] ss=s.toCharArray(); char[] tt=t.toCharArray(); for(int i=0;i&lt;ss.length;i++)&#123; if(s.indexOf(ss[i])!=t.indexOf(tt[i])) return false; &#125; return true;&#125;]]></content>
      <categories>
        <category>算法之美</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
        <tag>字符串</tag>
        <tag>哈希表</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HashMap源码解析]]></title>
    <url>%2F2019%2F11%2F04%2FHashMap%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[介绍完了List集合，接下来就介绍一下Map集合中最常用的的HashMap集合，本文还是基于JDK1.8来介绍HashMap集合，由于HashMap集合比较复杂，这里只介绍一部分内容，对于红黑树部分跳过，本文基于JDK1.8版本。 整体架构在JDK1.8中，对HashMap进行了调整，1.8及其以后的数据结构主要是数组+链表+红黑树。其中当链表长度大于等于8并且数组长度大于等于64时，链表会转化为红黑树；当红黑树大小小于等于6时，红黑树会转化成链表，整体的数据结构如下图：左边竖着的就是HashMap的数组结构，数组的元素有三种情况 单个Node节点(存放键值对数据) 一个链表 一个红黑树 类注释从HashMap的类注释中，我们可以得知： HashMap允许存储null值 loadfactor(负载因子)默认为0.75，这时均衡了时间和空间损耗算出来的值。如果较高虽然节省了空间，但是增加了查找成本(hash冲突增加，链表长度边长) 扩容条件：当HashMap中元素的个数(size)&gt;=数组大小(Capacity)*负载因子(loadfactor)时，就要进行扩容。 如果有很多数据需要存储到HashMap中，建议HashMap一开始就设置成足够的大小，这样可以防止在使用过程中不断扩容。影响性能。 HashMap是非线程安全的，我们可以自己在外部加锁，或者使用Collections.synchronizedMap。该类和前面List集合一样，通过在每个方法上加锁来达到线程安全的目的。 HashMap是快速失败的，即在迭代过程中如果结构发生了变化，就会抛出异常。 类属性在介绍HashMap的方法之前，先了解一下HashMap的一些成员属性。 1234567891011121314151617181920212223242526272829303132333435数组初始容量为16static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4;//数组能扩容的最大容量static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;//默认负载因子为0.75static final float DEFAULT_LOAD_FACTOR = 0.75f;//当链表长度大于等于时，链表转化为红黑树static final int TREEIFY_THRESHOLD = 8;//当红黑树大小小于等于6时，红黑树转换为链表static final int UNTREEIFY_THRESHOLD = 6;//当数组大小大于64时，链表才会转换为红黑树static final int MIN_TREEIFY_CAPACITY = 64;//存放数据的数组transient Node&lt;K,V&gt;[] table;//HashMap元素的个数transient int size;//记录HashMap版本，用于快速失败transient int modCount;//扩容的门槛//如果初始化时给定数组大小，那么通过tableSizeFor计算，//数组大小永远接近于2的幂次方，如果给定19，那么实际上初始化大小为32。//如果是通过resize()方法进行扩容，那么threshold=数组大小*0.75int threshold;//负载因子final float loadFactor; 构造方法后面讲到的扩容和初始化方式有关，因此这里先介绍一下构造方法 123456789101112131415161718192021222324252627282930313233343536373839404142/** * 指定数组大小和负载因子构造方法 * @param 指定数组大小 * @param 指定负载因子 */public HashMap(int initialCapacity, float loadFactor) &#123; //如果参数小于0，抛出异常 if (initialCapacity &lt; 0) throw new IllegalArgumentException(&quot;Illegal initial capacity: &quot; + initialCapacity); //如果指定容量大于HashMap能扩容的最大值，就令其为最大值 if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; //如果负载因子为空或小于0，抛出异常 if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(&quot;Illegal load factor: &quot; + loadFactor); //前面讲过，使用tableSizeFor方法使得数组大小一直是一个接近2的幂次方的数 //关于tableSizeFor()方法一会儿介绍 this.loadFactor = loadFactor; this.threshold = tableSizeFor(initialCapacity);&#125;“==============================”/** * 空参构造方法 * 则负载因子为0.75 * 初始容量为0 */public HashMap() &#123; this.loadFactor = DEFAULT_LOAD_FACTOR;&#125;“==============================”/** * 一个参数构造方法 * 负载因子默认0.75 * @param 指定数组初始容量 */public HashMap(int initialCapacity) &#123; this(initialCapacity, DEFAULT_LOAD_FACTOR);&#125; 初始化方法源码下面我们首先来介绍一些HashMap中一些和初始化相关的方法源码。 hash()123456789/** * 求键值对中键的哈希码 * @param key * @return */static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; 该hash()方法将Key的哈希值高16位和低16位做异或运算。后面介绍这样做的好处 tableSizeFor(int cap)前面介绍过，HashMap会使数组大小尽量维持在2的幂次方，那么当使用指定大小初始化时，如果指定的初始大小不是2的幂次方，就会调用此方法，将数组大小变为接近指定参数的2的幂次方。例如指定大小为19，那么数组实际大小为32。 123456789static final int tableSizeFor(int cap) &#123; int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;&#125; 这个算法的思路很厉害，我们来分析一下：首先，这个方法是在指定大小初始化方法中被调用的。通过查看这两个构造方法可以保证传递进来的参数0&lt;=cap&lt;=MAXIMUM_CAPACITY。 当cap=0时，n=-1，那么经过5行移位和或运算之后n的仍为-1。我们再看最后一行返回代码，当n&lt;0时返回1(2的0次方) 当cap=1时，n=0，那么经过一系列操作之后n仍为0。同样的我们看最后一行返回语句，此时返回n+1=1(2的0次方) 当cap=2的幂次方(二进制表示就是只有一个1其余全是0，如1000)，那么最后运算得到的返回值仍为cap。 如果cap是其他值，那么经过移位运算和或运算之后得到的值一定是…1111(2的n次幂-1)，最后如果没有超出范围则返回2的n次幂。并且返回值是比cap大的最近的2的幂次方。 那么int n=cap-1有什么用呢？当cap=2的幂次方时，如果不采取这一步操作，最后得到的值就是2*cap，而不是cap。 hash()方法能够得到键值对的hash值，而tableSizeFor()方法在使用指定大小构造方法时能够将数组的大小指定为2的幂次方。 扩容方法前面说过，当哈希表中元素个数大于扩容门槛时，会对数组进行扩容。下面就来具体介绍一下扩容方法。 扩容源码分析123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109final Node&lt;K,V&gt;[] resize() &#123; //记录扩容前数组 Node&lt;K,V&gt;[] oldTab = table; //记录扩容前数组长度 int oldCap = (oldTab == null) ? 0 : oldTab.length; //记录扩容前数组的扩容门槛threshold int oldThr = threshold; //初始化新数组的大小和扩容门槛 int newCap, newThr = 0; //如果扩容前数组不为空 if (oldCap &gt; 0) &#123; //如果上一次已经将数组扩容为最大长度 //那么就将扩容门槛threshold调整为最大值 //此时并不进行扩容 if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; //先将新数组容量设置为老数组的二倍 //如果没有超过最大容量并且老数组大小大于初始容量 //则将新的扩容门槛也变为老数组扩容门槛的二倍 else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold &#125; //如果扩容前数组为空，但是扩容前数组的扩容门槛大于0，即创建对象时使用的带参构造方法 else if (oldThr &gt; 0) //将前面tableSizeFor()方法得到的数赋值给新数组大小 newCap = oldThr; //扩容前数组为空并且扩容门槛为0，即创建对象时使用的无参数初始化 else &#123; newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; //进入次if语句有两种可能 //1. 进入if(oldCap&gt;0)分支但是不满足里面两个if条件 //2. 进入了else if (oldThr &gt; 0)分支 //第一种情况说明此时是扩容，并且创建对象时使用的带参构造方法并且指定数组的大小小于16 //第二种情况说明此时是初始化，并且创建对象时使用的带参构造方法 if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; //创建新数组，修改扩容门槛threshold threshold = newThr; @SuppressWarnings(&#123;&quot;rawtypes&quot;,&quot;unchecked&quot;&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; //将数据拷贝到新数组中 if (oldTab != null) &#123; for (int j = 0; j &lt; oldCap; ++j) &#123; Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; //如果槽内是一个节点，直接重新映射 if (e.next == null) newTab[e.hash &amp; (newCap - 1)] = e; //如果槽内是红黑树，那么调用红黑树的方法进行映射 else if (e instanceof TreeNode) ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); //槽内是一个链表 else &#123; // preserve order Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; //将链表分为两部分，一部分仍在原来位置(lo) if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; //另外一部分重新映射(hi) else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab;&#125; 扩容总结根据源码，我们来对HashMap的扩容方法进行总结 首先判断本次操作是初始化还是扩容操作 如果是初始化，那么分三种情况 使用无参构造方法时：第一次扩容大小为16，扩容门槛为12 使用指定大小(cap)构造方法时，又分两种情况 cap&lt;最大容量(2的30次方)。此时数组大小为cap，扩容门槛为cap*0.75。 cap&gt;=最大容量，此时扩容门槛直接设为Integer.MAX_VALUE 如果是扩容操作，那么继续进行判断 如果此时数组大小已经大于等于最大容量，那么将扩容门槛设置为Integer.MAX_VALUE，并不进行扩容 否则新数组大小和新扩容门槛都是原来的2倍 如果上一步计算扩容门槛时溢出归零(当指定的扩容因子为2的幂次方时)，那么将扩容门槛设置为Integer.MAX_VALUE 最后得到新的数组和新的扩容门槛，然后将原来的数据重新映射到新数组上 遍历老数组，针对节点、链表和红黑树分别进行不同的操作 如果当前位置是节点，那么直接通过[hash&amp;(newcap-1)]将节点映射到新的位置 如果当前位置是链表，那么会将链表分成两部分，一部分在原位置不动，另一部分重新映射 如果当前位置是红黑树，那么同样的将红黑树分成两部分，一部分在原位置，一部分映射到新位置。并且对两部分的大小进行判断:如果小于等于6，则将该部分链化；反之，将该部分树化。 添加方法向哈希表中新增一个键值对，大概步骤如下 数组有无初始化，如果没有则先初始化 通过hash()方法计算得到的key的hash能够直接找到值，跳转到6，否则跳转到3 如果哈希冲突，有两种解决方案：链表或红黑树 如果是链表，递归循环，将新元素添加到队尾 如果是红黑树，调用红黑树的新增方法 通过2、4、5将新元素追加成功，再根据onlyAbsent()方法判断是否需要覆盖 判断是否需要扩容，结束 我们来看一下源码实现 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788public V put(K key, V value) &#123; return putVal(hash(key), key, value, false, true);&#125;”===================================“/** * Implements Map.put and related methods. * * @param 键的哈希值 * @param 键值对中键的值 * @param 键值对中值的值 * @param 如果是true，那么如果key有重复，不进行覆盖。默认为false * @param evict if false, the table is in creation mode. * @return previous value, or null if none */final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; //哈希表的底层结构之一：数组 Node&lt;K,V&gt;[] tab; //下标为i位置的Node值 Node&lt;K,V&gt; p; //数组长度 int n,i; //如果数组为空，那么先初始化数组 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; //如果数组中要插入的位置为空，那么直接插入 if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); //如果要插入的位置有值，即出现哈希冲突。 else &#123; //当前节点的临时变量 Node&lt;K,V&gt; e; K k; //如果要插入的节点的key和要插入位置的节点的key他们 //的hash和值都相等，直接将当前下标位置的Node赋值给e if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; //否则，判断如果是红黑树结构，使用红黑树的方式新增 else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); //如果是链表，将新节点放到链表尾端 else &#123; //自旋 for (int binCount = 0; ; ++binCount) &#123; //表示从头开始，遍历链表。p.next==null表明p是链表的尾节点 if ((e = p.next) == null) &#123; //把新节点放到链表的尾部 p.next = newNode(hash, key, value, null); //如果链表的长度大于8，链表转为红黑树 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; //链表遍历的过程中，发现有元素和新增元素相等，结束循环 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; //将p向后移 p = e; &#125; &#125; //找到了哈希冲突的点 if (e != null) &#123; // existing mapping for key V oldValue = e.value; //如果允许覆盖则覆盖原来的值 if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; //如果没有哈希冲突，就要向hashmap中添加新节点 //这样以来map的结构就发生了变化 ++modCount; //如果size超过扩容门槛，则进行扩容 if (++size &gt; threshold) resize(); afterNodeInsertion(evict); return null;&#125; 将hash值映射到数组介绍完了添加方法，就可以说明hash()方法以及如何将hash值映射到相应数组下标。 123456789//求哈希值static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125;//将哈希值映射到数组下标int n=tab.length;p = tab[(n - 1) &amp; hash] 从代码中可以发现映射函数为f(hash)=(length-1)&amp;hash。首先在前面说过，哈希表数组的长度都为2的幂次方，因此，length-1就能够得到一个一串连续二进制1组成的数。例如： 12316-1=15=111132-1=31=11111...... 因此可以发现，上面的移位方式和取模达到的效果是一样的，但是比取模运算高效很多。 hash值的原理介绍了如何将hash值映射到数组中，现在就介绍一下为什么要这样求hash值，它的道理在哪里？我们先看一组示例 123456789101112131415161718直接使用hashCode作为hash值对于下面两组明显不同的HashCode0101 0011 0010 1010 1101 1011 0101 10100101 1010 0000 1110 0001 0111 0010 1010此时数组容量为16如果直接使用hashCode作为hash值0101 0011 0010 1010 1101 1011 0101 10100000 0000 0000 0000 0000 0000 0000 1111——————————————————————————————————————0000 0000 0000 0000 0000 0000 0000 1010==&gt;数组下标:1010 0101 1010 0000 1110 0001 0111 0010 10100000 0000 0000 0000 0000 0000 0000 1111——————————————————————————————————————0000 0000 0000 0000 0000 0000 0000 1010==&gt;数组下标:1010 通过运算我们发现，这两个完全不同的hashCode被映射到了同一个数组下标1010。不仅如此，只要后四位相同的hashCode都会被映射到同一数组下标，这样的hash算法相当于只看hashCode的低位，高位完全不能产生影响，这是完全不合理的。因此，HashMap采用的hash算法将高位和低位取异或运算，使得高位也能够产生影响，从而使得分布更加均匀。 123456789101112131415161718192021222324252627282930使用hash算法求hash值对于下面两组明显不同的HashCode0101 0011 0010 1010 1101 1011 0101 10100101 1010 0000 1110 0001 0111 0010 1010求hash值0101 0011 0010 1010 1101 1011 0101 10100000 0000 0000 0000 0101 0011 0010 1010——————————————————————————————————————0101 0011 0010 1010 1000 1000 0111 00000101 1010 0000 1110 0001 0111 0010 10100000 0000 0000 0000 0101 0011 0010 1011——————————————————————————————————————0101 1010 0000 1110 0100 0100 0000 0001此时数组容量为16如果直接使用hashCode作为hash值0101 0011 0010 1010 1000 1000 0111 00000000 0000 0000 0000 0000 0000 0000 1111——————————————————————————————————————0000 0000 0000 0000 0000 0000 0000 0000==&gt;数组下标：0 0101 1010 0000 1110 0100 0100 0000 00010000 0000 0000 0000 0000 0000 0000 1111——————————————————————————————————————0000 0000 0000 0000 0000 0000 0000 0000==&gt;数组下标：1 具体的添加细节，向链表中添加比较简单，直接添加到链表末尾即可。由于对红黑树不太了解，因此向红黑树中添加就不赘述。 链表树化、红黑树链化和拆分链表树化我们知道，链表转化成红黑树需要连个条件 链表长度≥8 数组长度≥64 满足这两个条件，链表将会转化为红黑树。通过添加方法可以知道，在添加方法中，链表树化的方法是treeifyBin，我们来看一看这个方法 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/** * 将链表节点转化为红黑树节点 * @param tab 数组 * @param hash 转化红黑树的链表的哈希值 */final void treeifyBin(Node&lt;K,V&gt;[] tab, int hash) &#123; int n, index; Node&lt;K,V&gt; e; //如果此时桶长度小于64，那么进行扩容 if (tab == null || (n = tab.length) &lt; MIN_TREEIFY_CAPACITY) resize(); //如果当前位置不为空 else if ((e = tab[index = (n - 1) &amp; hash]) != null) &#123; //头节点和尾节点 TreeNode&lt;K,V&gt; hd = null, tl = null; //do-while循环将链表节点转换为树节点的同时 //也形成了一个双向链表 do &#123; //TreeNode有五个属性 //parent、color、left、right、prev、next TreeNode&lt;K,V&gt; p = replacementTreeNode(e, null); if (tl == null) hd = p; else &#123; p.prev = tl; tl.next = p; &#125; tl = p; &#125; while ((e = e.next) != null); //hd节点作为红黑树的根节点 if ((tab[index] = hd) != null) hd.treeify(tab); &#125;&#125;/** * 通过链表节点得到红黑树节点 * @param p * @param next * @return */TreeNode&lt;K,V&gt; replacementTreeNode(Node&lt;K,V&gt; p, Node&lt;K,V&gt; next) &#123; return new TreeNode&lt;&gt;(p.hash, p.key, p.value, next);&#125; 我们看到treeifyBin方法实际上是将链表节点转换成红黑树节点，并将这些红黑树节点组成双向链表(这些节点的顺序和之前一样)，然后调用treeify方法，将这些红黑树节点组成红黑树。但是，组成红黑树后，prev和next节点仍然存在，也就是说，此时即是双向链表又是红黑树 至于生成红黑树的方法这里不作赘述。只提一点，我们知道，红黑树在进行插入操作时，需要比较插入节点和红黑树上节点的大小从而将节点插入正确的位置，但是由于红黑树是JDK1.8才实现的，HashMap在此之前并没有实现Comparable接口，因此无法直接使用compareTo()方法来比较大小，它是这么做的： 比较节点的哈希值 如果哈希值相同，检测键类是否实现了Comparable接口，如果实现了则调用其compareTo()方法 如果还不行，那么就需要进行仲裁了，仲裁方法为 tieBreakOrde() 红黑树拆分扩容后，普通节点需要重新映射，红黑树节点也不例外。按照一般的思路，我们可以先把红黑树转成链表，之后再重新映射链表即可。这种处理方式是大家比较容易想到的，但这样做会损失一定的效率。不同于上面的处理方式，HashMap 实现的思路很是巧妙。如上节所说，在将普通链表转成红黑树时，HashMap 通过两个额外的引用next和prev保留了原链表的节点顺序。这样再对红黑树进行重新映射时，完全可以按照映射链表的方式进行。这样就避免了将红黑树转成链表后再进行映射，无形中提高了效率。在扩容方法中我们发现红黑树拆分的方法是split() 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172/** * Splits nodes in a tree bin into lower and upper tree bins, * or untreeifies if now too small. Called only from resize; * see above discussion about split bits and indices. * * @param 当前map集合 * @param 新数组 * @param 需要拆分的红黑树 * @param 原来数组的大小 */final void split(HashMap&lt;K,V&gt; map, Node&lt;K,V&gt;[] tab, int index, int bit) &#123; //当前红黑树的根节点 TreeNode&lt;K,V&gt; b = this; // 将红黑树拆分成两个双向链表lo和hi(但是红黑树结构不变，知识改变了prev和next) //分别定义其首尾节点 TreeNode&lt;K,V&gt; loHead = null, loTail = null; TreeNode&lt;K,V&gt; hiHead = null, hiTail = null; int lc = 0, hc = 0; for (TreeNode&lt;K,V&gt; e = b, next; e != null; e = next) &#123; next = (TreeNode&lt;K,V&gt;)e.next; e.next = null; //第一部分，位于原位置不变 if ((e.hash &amp; bit) == 0) &#123; if ((e.prev = loTail) == null) loHead = e; else loTail.next = e; loTail = e; ++lc; &#125; //第二部分，重新映射到距离当前位置bit的位置 else &#123; if ((e.prev = hiTail) == null) hiHead = e; else hiTail.next = e; hiTail = e; ++hc; &#125; &#125; //如果位于当前位置的部分红黑树不为空 if (loHead != null) &#123; //并且节点数目小于等于6，说明该部分红黑树 //应该转换为链表存储 if (lc &lt;= UNTREEIFY_THRESHOLD) //红黑树链化 tab[index] = loHead.untreeify(map); //如果该部分红黑树节点数目大于6，说明该部分 //仍需要以红黑树的方式存储 else &#123; tab[index] = loHead; //将该部分重新组成红黑树 if (hiHead != null) loHead.treeify(tab); &#125; &#125; //如果位于index+bit位置的部分不为空 //和前面一部分进行相同的操作 if (hiHead != null) &#123; if (hc &lt;= UNTREEIFY_THRESHOLD) tab[index + bit] = hiHead.untreeify(map); else &#123; tab[index + bit] = hiHead; if (loHead != null) hiHead.treeify(tab); &#125; &#125;&#125; 红黑树拆分与链表重映射细节前面说过，我们再进行扩容时，对于链表和红黑树，都是将其分成两部分，一部分仍在原位置，另一部分重新映射，那么这是怎么做到的呢？ 如果你认真看了resize()方法和split()方法的源码，会发现它们有相同之处 12345678910//resize()中将链表分成两部分的判断依据(e.hash &amp; oldCap) == 0)//split()中将红黑树分成两部分的判断依据(e.hash &amp; bit) == 0=====================不仅如此:链表的一部分仍在原位置index，另一部分在[index+oldCap]红黑树的一部分同样的原位置index，另一部分在[index+bit] 通过上面的比较你是不是觉得很相似？那我你查看resize()方法中调用split()方法传递进去的参数，你会发现实际上bit==oldCap。这样一来你会发现它们分割的依据都是一样的，那么这是什么原因呢？我们先回顾一下映射的过程 上图中，桶数组大小 n = 16，hash1 与 hash2 不相等。但因为只有后4位参与求余，所以结果相等。当桶数组扩容后，n 由16变成了32，对上面的 hash 值重新进行映射： 扩容后，参与模运算的位数由4位变为了5位。由于两个 hash 第5位的值是不一样，所以两个 hash 算出的结果也不一样。上面的计算过程并不难理解，继续往下分析。 假设我们上图的桶数组进行扩容，扩容后容量 n = 16，重新映射过程如下:依次遍历链表，并计算节点 hash &amp; oldCap 的值。如下图所示 如果值为0，将 loHead 和 loTail 指向这个节点。如果后面还有节点 hash &amp; oldCap 为0的话，则将节点链入 loHead 指向的链表中，并将 loTail 指向该节点。如果值为非0的话，则让 hiHead 和 hiTail 指向该节点。完成遍历后，可能会得到两条链表，此时就完成了链表分组： 最后再将这两条链接存放到相应的桶中，完成扩容。如下图： 从上图可以发现，重新映射后，两条链表中的节点顺序并未发生变化，还是保持了扩容前的顺序。 红黑树链化前面说过，即使链表转化成了红黑树，红黑树节点的prev和next指针仍然保留了原链表节点顺序。那么红黑树的链化就非常简单了 12345678910111213141516171819202122232425262728293031/** * 红黑树链化 * @param map * @return */final Node&lt;K,V&gt; untreeify(HashMap&lt;K,V&gt; map) &#123; Node&lt;K,V&gt; hd = null, tl = null; //通过next指针遍历红黑树 for (Node&lt;K,V&gt; q = this; q != null; q = q.next) &#123; //将每个树节点转化成红黑树节点，并重新进行连接 Node&lt;K,V&gt; p = map.replacementNode(q, null); if (tl == null) hd = p; else tl.next = p; tl = p; &#125; return hd;&#125;==========================/** * 通过红黑树节点生成链表节点 * @param p * @param next * @return */Node&lt;K,V&gt; replacementNode(Node&lt;K,V&gt; p, Node&lt;K,V&gt; next) &#123; return new Node&lt;&gt;(p.hash, p.key, p.value, next);&#125; 查找方法HashMap的查找主要分为三步 根据hash算法求出hash值，然后映射到数组的索引位置。equals()判断当前节点是否是需要查找的key。是就返回true，否则执行2 判断当前节点有无next节点，如果有判断是链表类型还是红黑树类型，并执行3；没有返回false 分别走链表和红黑树不同类型的查找方式 123456789101112131415161718192021222324252627282930public boolean containsKey(Object key) &#123; return getNode(hash(key), key) != null;&#125;final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; //如果数组不为空并且长度大于0并且要hash值映射的数组位置不为空 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; //如果当前节点的hash值和要查找的key的hash值相等 //并且两者也相等，直接返回当前节点 if (first.hash == hash &amp;&amp; ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; //判断当前节点是否有下一个节点 if ((e = first.next) != null) &#123; //如果是红黑树，调用红黑树查找方法 if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); //如果是链表则遍历链表查找 do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null;&#125; 对于红黑树的查找，可以大致介绍思路(类似AVL树) 从根节点开始查找 比较当前节点和要查找key的hash值，根据红黑树左小右大的特性 判断查找节点在第2步有没有找到节点，如果找到直接返回，没有重复2、3步 一直循环直到定位到节点位置为止。 删除方法最后再介绍一下删除方法的逻辑代码，和查找比较类似。remove方法有两种重载形式，下面分别介绍。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586//根据键删除节点public V remove(Object key) &#123; Node&lt;K,V&gt; e; return (e = removeNode(hash(key), key, null, false, true)) == null ? null : e.value;&#125;//根据键和值删除节点public boolean remove(Object key, Object value) &#123; return removeNode(hash(key), key, value, true, true) != null;&#125;”=======================================“/** * Implements Map.remove and related methods. * * @param 删除节点的hash值 * @param 要删除元素的键 * @param 如果只根据键删除，那么value传递null * @param 布尔值，如果为true那么说明要同时匹配键和值才能删除，否则只需要匹配键即可删除 * @param movable if false do not move other nodes while removing * @return 返回要删除的节点 */final Node&lt;K,V&gt; removeNode(int hash, Object key, Object value, boolean matchValue, boolean movable) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, index; //如果当前表中有数据并且通过哈希值映射的地方有数据 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (p = tab[index = (n - 1) &amp; hash]) != null) &#123; Node&lt;K,V&gt; node = null, e; K k; V v; //如果槽的第一个节点为删除节点 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) node = p; //如果槽内是一个链表或者红黑树 else if ((e = p.next) != null) &#123; //如果是红黑树，则通过红黑树的方法获取待删除节点 if (p instanceof TreeNode) node = ((TreeNode&lt;K,V&gt;)p).getTreeNode(hash, key); //如果是链表，则遍历找到待删除的节点 else &#123; do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) &#123; node = e; break; &#125; p = e; &#125; while ((e = e.next) != null); &#125; &#125; //如果找到键相同的待删除的节点，判断值是否相等 if (node != null &amp;&amp; (!matchValue || (v = node.value) == value || (value != null &amp;&amp; value.equals(v)))) &#123; //如果属于RBTree节点，则执行树的删除方法 if (node instanceof TreeNode) ((TreeNode&lt;K,V&gt;)node).removeTreeNode(this, tab, movable); //说明要删除的节点为链表的第一个节点 else if (node == p) tab[index] = node.next; //说明不是第一个节点，待删除节点的前一个节点为p else p.next = node.next; //修改版本号和元素个数 ++modCount; --size; //LinkedHashMap方法，这里不使用 afterNodeRemoval(node); return node; &#125; &#125; return null;&#125; 总结HashMap的内容比较多，这里仍还有很多部分没有涉及到，比如红黑树的增删操作等。但是对于我们来说没必要了解这么详细，毕竟我们只是使用它。HashMap的API大多都是对数组+链表+红黑树这种数据结构进行封装。参考文章：慕课网文贺老师专栏。HashMap 源码详细分析(JDK1.8)]]></content>
      <categories>
        <category>JDK源码</category>
      </categories>
      <tags>
        <tag>源码</tag>
        <tag>HashMap集合</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[List源码常见面试题]]></title>
    <url>%2F2019%2F11%2F04%2FList%E6%BA%90%E7%A0%81%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98%2F</url>
    <content type="text"><![CDATA[List集合在Java中用的非常多，在大多数情况下都可以使用List集合来代替数组。因此在面试中也是考察的重点，前面介绍了两种List集合的核心源码，现在就来介绍一下常见的面试题。同样的也是基于JDK1.8版本下。 对ArrayList的理解很多面试官喜欢这样开头，主要考察应聘者对ArrayList有没有总结经验，因为ArrayList内容很多，因此可以先回答总体架构。比如：ArrayList底层数据结构是一个数组，它的API都做了一层对数组底层访问的封装，就像add()方法的过程……。这样一来，如果回答得比较又没有漏洞，面试官就不会深究。对于LinkedList集合同样的道理。 扩容类问题对于ArrayList的扩容也是考察的重点，下面介绍几个常见的扩容类问题 ArrayList无参构造器构造，现在add一个值进去，此时集合中有多少元素，下次扩容前最大可用大小是多少？此时集合中有1个元素，下次扩容前最大可用大小是10。因为当使用无参初始化方法时，会在第一次添加元素时将数组扩容为10 如果我连续往list里面新增加值，增加到第11个时，数组的大小是多少？这里考察的就是扩容公式，当增加到11时，我们期望数组的大小为11，但是数组大小为10，因此需要进行扩容。集合每次以1.5倍进行扩容，因此此时数组大小被扩容到15 数组初始化，被加入一个值后，如果使用addAll方法，一下加入15个值，那么最终数组大小是多少当使用无参构造方法时，加入第一个值后数组的大小是10，如果还要一下加入15个值，我么们期望的的大小为16，因此需要对数组进行扩容。数组经过扩容后大小为15，此时我们发现数组大小仍不能满足要求。此时会直接将数组扩容为期望值16，而不是再次扩容。要记住，当需要扩容时，只会扩容一次，如果扩容一次仍不能满足要求，那么直接将数组扩容至期望值大小。 现在我有一个很大的数组需要拷贝，原数组大小是5k，如何能够快速拷贝因为原数组比较大，如果新建数组的时候不指定大小的话，就会频繁扩容，频繁扩容会造成性能低下，所以创建集合时应该指定大小为5000 为什么说扩容会消耗性能？扩容底层使用的是System.arraycopy方法，会把原数组的数据全部拷贝到新数组上，所以会有性能损耗 源码扩容有什么值得学习的地方 扩容的思想值得学习，通过自动扩容的方式，让使用者不用关心底层数据结构的变化，封装的很好，1.5倍的扩容速度，可以让扩容速度在前期缓慢上升，在后期增速比较快，大部分工作中要求数组的值并不多，因此在后期增速较快时也可快速扩容。 扩容的过程中，有数组大小溢出的意识，比如要求扩容后的数组大小不能小于0，不能超过Integer的最大值 删除类问题 对于ArrayList数组，能否通过增强for循环进行删除元素？不能，会抛出异常。因为增强for循环实际上就是通过迭代器实现的。当直接使用list.remove()方法进行删除时，ArrayList的版本modCount会发生变化，导致和迭代器期望的版本号不一致，就会抛出异常。 还是上面的题，能否使用Iterator.remove()方法进行删除？可以，因为Iterator.remove()方法在执行过程中会自动更新期望版本号expectedModCount，使得它和modCount一致 以上三个操作对于LinkedList也是同样的结果么？是的，虽然它们得底层实现不同，但是对于这两个问题，结果是一样的。 对比类问题 ArrayList和LinkedList有什么不同？可以先从底层数据结构开始说起，然后以某个方法为突破口深入。比如，最大的不同就是两者底层数据结构不同，ArrayList底层是数组，而LinkedList底层是双向链表，两者的不同也导致了一些差异。就拿新增操作来说，ArrayList会先计算并决定是否扩容，然后在进行赋值；而LinkedList仅仅需要改变插入节点何其前后节点的指向位置关系即可。 ArrayList和LinkedList应用场景有何不同？ArrayList更适合快速的匹配查找，不适合频繁的增删操作，而LinkedList更适合增删操作多，查询反而很少的情况。但如果是顺序插入的话(即调用add()方法插入)，ArrayList仅会为可能有的扩容操作花费时间，而LinkedList插入操作会繁琐一些。但如果是指定插入(add(int index))，ArrayList会比LinkedList慢。因此比较常用的还是ArrayList。 ArrayList和LinkedList两者有没有最大容量？ArrayList是有最大容量的，为Integer能表示的最大值；LinkedList理论上来说可以无限大，但是源码中使用int类型的size来表示LinkedList得大小，所以LinkedList也不能超过Integer得最大值。 ArrayList和LinkedList对于null值如何处理？从源码中可以发现在添加元素的时候并没有额外判断是否为null，因此ArrayList是允许存储null值的，如果要删除null值，那么从头开始遍历数组，删除第一个null值元素。LinkedList同样允许增删null值。 ArrayList和LinkedList是线程安全的么？当两者作为局部变量时，是线程安全的，当两者是共享变量时，会出现线程安全问题。主要原因在于多线程环境下，所有线程任何时刻都可以对数组和链表进行操作，这会导致一系列问题。如果有线程安全问题，在迭代过程中会频繁抛出ConcurrentModificationException异常。 如何解决线程安全问题？Java源码中推荐使用Collections.synchronizedList进行解决，该集合对List中每个方法都加了锁，保证同一时刻只有一个线程修改集合；或者采用CopyOnWriteArrayList来解决。 List集合用的比较多，熟悉了源码之后使用起来才能更加得心应手。]]></content>
      <categories>
        <category>JDK源码</category>
      </categories>
      <tags>
        <tag>源码</tag>
        <tag>集合</tag>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LinkedList源码解析]]></title>
    <url>%2F2019%2F11%2F03%2FLinkedList%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[上一节介绍了ArrayList集合，这次就接着介绍一下LinkedList集合。和ArrayList集合一样，该集合同样实现了List接口，和ArrayList集合不同的是，它们实现的抽象类不同。LinkedList集合适用于添加多查询少的场合。(本文基于JDK1.8版本) 整体架构LinkedList集合底层数据结构是一个双向链表，如下图所示如图所示，链表中的每一个节点都可以向前或者向后追溯 链表的每个节点叫做Node，是集合的私有嵌套类对象 123456789101112131415private static class Node&lt;E&gt; &#123; //存储数据 E item; //指向下一个节点 Node&lt;E&gt; next; //指向前一个节点 Node&lt;E&gt; prev; //构造方法 Node(Node&lt;E&gt; prev, E element, Node&lt;E&gt; next) &#123; this.item = element; this.next = next; this.prev = prev; &#125;&#125; 集合的四个域 1234567//记录链表中元素个数transient int size = 0;//指向链表头节点，它的prev为nulltransient Node&lt;E&gt; first;//指向链表为节点，它的next为nulltransient Node&lt;E&gt; last;(继承自abstractList抽象类)protected transient int modCount = 0; 由于是一个双向链表，因此只要内存足够，是没有大小限制的 源码解析同样的，通过对一些核心源码的分析来对LinkedList集合进行学习。 尾部添加元素(add())在添加节点时，我们可以选择将元素追加到链表头部或者链表尾部，add()方法默认是从尾部添加。addFirst()方法是从头部开始追加。下面我们分别介绍两种不同的追加方法 12345678910111213141516171819202122232425public boolean add(E e) &#123; linkLast(e); return true;&#125;&quot;==============================&quot;void linkLast(E e) &#123; //将尾节点数据保存在临时指针中 final Node&lt;E&gt; l = last; //创建新的节点 //数据域保存要插入的值 //prev指向当前链表的尾节点，next置null final Node&lt;E&gt; newNode = new Node&lt;&gt;(l, e, null); //将尾节点指针指向新的节点 last = newNode; //如果链表为空，那么将头部节点指向新建节点 if (l == null) first = newNode; //如果不为空，把之前尾节点的next域指向当前尾节点 else l.next = newNode; //更新大小和版本 size++; modCount++;&#125; 头部添加元素(addFirst())123456789101112131415161718192021222324public void addFirst(E e) &#123; linkFirst(e);&#125;&quot;==============================&quot;private void linkFirst(E e) &#123; //保存头节点数据到临时指针中 final Node&lt;E&gt; f = first; //新建节点 //数据域存储要插入的值 //prev置null，next指向原头节点 final Node&lt;E&gt; newNode = new Node&lt;&gt;(null, e, f); //头指针指向新节点 first = newNode; //如果当前链表为空，那么将尾节点指向新建节点 if (f == null) last = newNode; //将原头节点的prev指向新头节点 else f.prev = newNode; //更新大小和版本 size++; modCount++;&#125; 通过查看源码不难发现，LinkedList的插入操作就是双向链表的插入操作，较为简单 尾部删除节点同样的，删除节点也有两种选择方式，从头部删除或从尾部删除，删除操作会把节点的值、前后指针都置为null，以便GC操作能够顺利完成。 123456789101112131415161718192021222324252627282930public E removeLast() &#123; final Node&lt;E&gt; l = last; //如果当前链表为空抛出异常 if (l == null) throw new NoSuchElementException(); return unlinkLast(l);&#125;&quot;==============================&quot;private E unlinkLast(Node&lt;E&gt; l) &#123; //保存要删除节点的数据 final E element = l.item; //保存要尾节点的前一个节点 final Node&lt;E&gt; prev = l.prev; //将尾节点的数据域和指针域都置null，方便GC l.item = null; l.prev = null; //设置新的尾指针 last = prev; //如果删除后链表为空，那么first也置为空 if (prev == null) first = null; //将新尾节点的next置null else prev.next = null; //更新大小和版本以及返回被删除的节点 size--; modCount++; return element;&#125; 总结一下步骤 保存尾节点的数据和prev指针到临时变量中 将要删除的尾节点置空，便于GC 将链表尾指针last==prev 判断删除后链表是否为空，如果为空那么将first也置null，否则将新尾节点的next置null。 头部删除节点12345678910111213141516171819202122public E removeFirst() &#123; final Node&lt;E&gt; f = first; if (f == null) throw new NoSuchElementException(); return unlinkFirst(f);&#125;&quot;==============================&quot;private E unlinkFirst(Node&lt;E&gt; f) &#123; final E element = f.item; final Node&lt;E&gt; next = f.next; f.item = null; f.next = null; // help GC first = next; if (next == null) last = null; else next.prev = null; size--; modCount++; return element;&#125; 步骤和尾部删除节点镜像，就不赘述 普通删除节点前面两种是比较特殊的情况，下面介绍删除任意节点的方法无论是remove(int index)还是remove(T ele)都是通过下面方法实现 1234567891011121314151617181920212223242526272829303132333435E unlink(Node&lt;E&gt; x) &#123; //保存要删除节点的所有域 final E element = x.item; final Node&lt;E&gt; next = x.next; final Node&lt;E&gt; prev = x.prev; //如果prev==null，说明要删除头节点 //直接将first指向下一个节点 if (prev == null) &#123; first = next; &#125; //否则，将要删除节点的前一个节点的prev指向 //要删除节点的next域，并将要删除节点的prev置null else &#123; prev.next = next; x.prev = null; &#125; //同理，如果是尾节点，直接将尾指针指向前一个节点 if (next == null) &#123; last = prev; &#125; //将要删除节点的下一个节点的prev之前要删除节点的prev //将要删除节点的next置null else &#123; next.prev = prev; x.next = null; &#125; //到了这里节点已经从链表中删除，并且节点的指针域都为空 //执行收尾动作 x.item = null; size--; modCount++; return element;&#125; 总结一下步骤 保存要删除节点所有的域 如果节点的prev指针为空，说明是头节点。令first=next 如果prev不为空，那么将它前面节点的next指向它后一个节点，令该节点的prev=null 如果节点的next为空。说明是尾节点。令last=prev 如果next不为空，和第三步镜像操作。 节点查询链表的查询是比较慢的。需要挨个循环查找才行，我们来看看LinkedList有没有比较好的方法 12345678910111213141516171819//查找给定索引的节点//这是一个内部方法，其他成员方法调用该方法之前已经检查过index//能够确保index满足条件Node&lt;E&gt; node(int index) &#123; //如果inde处于队列的前半部分，从头开始找 if (index &lt; (size &gt;&gt; 1)) &#123; Node&lt;E&gt; x = first; for (int i = 0; i &lt; index; i++) x = x.next; return x; &#125; //如果处于后半部分，从后往前查找 else &#123; Node&lt;E&gt; x = last; for (int i = size - 1; i &gt; index; i--) x = x.prev; return x; &#125;&#125; 通过源码我们发现，LinkedList并没有采用从头循环到尾的做法，而是采用了简单地二分法 首先判断index在链表的前半部分还是后半部分 利用双向链表的特性进行查找。使循环次数至少降低了一半。 可能这也是LinkedList使用双向链表实现的原因吧。 迭代器因为LinkedList要实现双向的迭代访问，所以Iterator不能满足要求(但是由于继承了abstractList抽象类，仍可以使用Iterator迭代器)，因为Iterator只支持从头到尾单向遍历。Iterator有一个子接口叫ListIterator，这个接口支持双向迭代，这里介绍一下双向迭代。 1234从头到尾迭代hasNext、next、nextIndex从尾到头迭代hasPervious、previous、previousIndex LinkedList中一个私有内部类LisyItr实现了ListIterator接口，我们看一下该私有类的域和构造方法 123456789101112131415//上次之星next()或previous()方法时的节点位置private Node&lt;E&gt; lastReturned;//下一个节点private Node&lt;E&gt; next;//下一个节点的位置private int nextIndex;//期望版本号private int expectedModCount = modCount;“===============================”构造方法(如果不传递参数默认调用父类的无参构造方法，index=0)ListItr(int index) &#123; next = (index == size) ? null : node(index); nextIndex = index;&#125; 从头到尾迭代我们先看一下从头到尾迭代 12345678910111213141516171819public boolean hasNext() &#123; return nextIndex &lt; size;&#125;public E next() &#123; //首先判断版本号 checkForComodification(); if (!hasNext()) throw new NoSuchElementException(); //next是当前节点，在上一次执行next方法或构造方法中时被赋值的 lastReturned = next; //next指向下一个节点，为下一次迭代做准备 next = next.next; //next指向节点的索引位置 nextIndex++; return lastReturned.item;&#125; 可以看出，从头到尾迭代比较简单，直接取出当前节点的值，并将next指向下一个节点即可。 从尾到头迭代接着来看一下从尾到头迭代 1234567891011121314public boolean hasPrevious() &#123; return nextIndex &gt; 0;&#125;public E previous() &#123; //首先判断版本号 checkForComodification(); if (!hasPrevious()) throw new NoSuchElementException(); lastReturned = next = (next == null) ? last : next.prev; nextIndex--; return lastReturned.item;&#125; 在求lastReturned时候，需要判断next为空和不为空两种情况next不为空时说明已经发生过迭代了，直接取前一个节点即可next为空有两种情况： 第一次迭代并且传递参数index==size 上次操作将尾节点删除了 迭代器删除LinkedList在删除元素时，也推荐使用迭代器进行删除 12345678910111213141516171819202122232425public void remove() &#123; //判断版本号 checkForComodification(); //lastRuturned是本次迭代需要删除的值 //如果为空，说明调用者没有主动执行过next()或previous()方法，抛出异常 //如果不为空，是在上次执行next()或previous()赋的值 if (lastReturned == null) throw new IllegalStateException(); //将要删除的节点保存 Node&lt;E&gt; lastNext = lastReturned.next; //删除当前节点 unlink(lastReturned); //上一次迭代是从尾向头迭代(因为每次从尾向头迭代后next和lastReturned相等) if (next == lastReturned) //将next回到上一次迭代时位置 next = lastNext; //上一次是从头向尾迭代，此时只需改变nextIndex //使得nextIndex值总和next指向的节点索引相同 else nextIndex--; //避免重复删除，更新版本号 lastReturned = null; expectedModCount++;&#125; 总结LinkedList源码设计大量对于链表的操作，所以需要一定的数据结构基础才行，否则会比较难以理解。文章多数内容来自于慕课网文贺。]]></content>
      <categories>
        <category>JDK源码</category>
      </categories>
      <tags>
        <tag>源码</tag>
        <tag>LinkedList集合</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Iterator与Iteratable]]></title>
    <url>%2F2019%2F11%2F03%2FIterator%E4%B8%8EIteratable%2F</url>
    <content type="text"><![CDATA[在Java中，迭代器的使用是很常见的，比如我们使用的for-each循环，底层使用的就是迭代器。那到底什么是迭代器呢？今天就来介绍一下Java中的迭代器。 为什么要用迭代器你可能会想，为什么要使用迭代器呢？直接遍历集合不可以么？可以从多态这一方面回答这个问题，下面以List集合为例。对于List集合，无论是数组实现的ArrayList还是链表实现的LinkedList，我们常常将它们向上转型为List使用。当我们要遍历集合的时候，如果不使用迭代器，因为两种不同实现方式的集合遍历方式是不同的，我们如果不知道List的实际类型，那么就无法进行遍历。这样就造成了我们如果要遍历集合的时候必须要知道集合的内部结构，这样会使的遍历的代码和集合本身的耦合度很高！！在编程中我们应该尽量降低代码的耦合度，使代码方便日后管理，和适应需求变化。在JAVA中为了解决这个问题引入了Iterator，Iterator在遍历不同的集合的时候方式总是一样的。 12345678910为不同的List集合编写不同的代码//ArrayList实现for（int i=0;i&lt;array.size();i++）&#123;&#125;//LinkedList实现while （（linkedList =linkedList.next()）!=null）&#123;&#125; Iterator与Iteratable的关系下面分别查看两接口的部分源码来进行说明 1234567891011121314//Iteratable接口中的一个抽象方法/** * Returns an iterator over elements of type &#123;@code T&#125;. * @return an Iterator. */Iterator&lt;T&gt; iterator();”====================================“//Iterator接口中的三个方法boolean hasNext();E next();default void remove() &#123; throw new UnsupportedOperationException(&quot;remove&quot;);&#125; 通过观察源码不难发现，实现了Iteratable接口的类可以通过iterator()方法来获取一个Iterator接口的实现类对象，真正的迭代方法是在Iterator接口中实现的。 两者区别我们知道，Java中的集合都实现了Collection接口，除了map。而Collection接口有实现了Iteratable接口，那为什么不直接实现Iterator接口而要实现Iteratable接口通过该接口的iterator()方法来获取迭代器对象呢？如果Collection直接实现Iterator这个接口的时候，则当我们new一个新的对象的时候，这个对象中就包含了当前迭代位置的数据（指针），当这个对象在不同的方法或者类中传递的时候，当前传递的对象的迭代的位置是不可预知的，那么我们在调用next()方法的时候也就不知道是指到那一个元素。如果其中加上了一个reset()方法呢？用来重置当前迭代的位置这样Collection也只能同时存在一个当前迭代位置的对象。所有不能直接选择实现Iterator。实现Iteratable，里面的方法Iterator()可以在同一个对象每次调用的时候都产生一个新的Iterator对象。这样多个迭代器就不会互相干扰了。 参考文章sydMobile]]></content>
      <categories>
        <category>JDK源码</category>
      </categories>
      <tags>
        <tag>迭代器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ArrayList源码解析]]></title>
    <url>%2F2019%2F11%2F03%2FArrayList%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[在Java中，ArrayList集合我们用的非常多，但是对于ArrayList的底层实现，我一直不太了解。最近学习多线程的时候看到了线程安全集合，所以准备先回头把普通集合弄弄清除，再去看线程安全集合的底层实现会比较好一些。(本文基于JDK1.8源码进行分析) 整体架构ArrayList集合整体架构比较简单，底层就是一个数组结构，如图所示图中是一个长度为10的数组，展示了ArrayList底层存储数据的原理 源码中一些字段在学习ArrayList底层实现之前，我们先来认识一下源码中的一些字段，这在之后的方法中会用到 private static final int DEFAULT_CAPACITY = 10;默认初始容量为10，如果使用无参构造方法创建集合对象，那么第一次扩容时数组大小扩容为10 private static final Object[] EMPTY_ELEMENTDATA = {};默认空实例赋值，后面再扩容时会详细介绍 private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = {};含有默认值的空实例赋值，同样的，在扩容时介绍 transient Object[] elementData;实际存放数据的数组 private int size;集合中元素的个数 private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8;集合扩容的最大容量 protected transient int modCount = 0;从abstractList继承得到，集合的版本号，后面迭代时会详细介绍 1234567891011121314151617181920//从源码中Copy的代码，注释为自己添加private static final long serialVersionUID = 8683452581122892189L;//默认初始容量private static final int DEFAULT_CAPACITY = 10;//默认空实例赋值private static final Object[] EMPTY_ELEMENTDATA = &#123;&#125;;//含有默认值的空实例private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = &#123;&#125;;//存放实际元素的Object数组transient Object[] elementData; // non-private to simplify nested class access//集合中元素的个数private int size;//最大容量private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8; 类注释我们来看一下类注释都说了些什么 允许put null值，会自动扩容 size、isEmpty、get、set、add等方法时间复杂度都是O(1) 是非线程安全的，多线程情况下，推荐使用线程安全类：Collections#synchronizedList 增强for循环，或者使用迭代器迭代过程中，如果数组大小被改变，会快速失败抛出异常 源码解析介绍了一些基础内容，下面就从源码开始，分别对初始化、扩容、迭代器等进行解析 初始化ArrayList提供了三种初始化方法 无参直接初始化 指定大小初始化 指定初始数据初始化 源码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/** * 指定大小初始化 * @param 指定数组大小 * @throws IllegalArgumentException if the specified initial capacity * is negative */public ArrayList(int initialCapacity) &#123; //如果参数&gt;0，那么new一个指定大小的Object数组 if (initialCapacity &gt; 0) &#123; this.elementData = new Object[initialCapacity]; &#125; //如果参数等于0，那么elementData数组等于前面的默认空实例数组EMPTY_ELEMENTDATA else if (initialCapacity == 0) &#123; this.elementData = EMPTY_ELEMENTDATA; &#125; //如果小于0则抛出异常 else &#123; throw new IllegalArgumentException(&quot;Illegal Capacity: &quot;+ initialCapacity); &#125;&#125;“==============================”/** * 无参数直接初始化 */public ArrayList() &#123; this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA;&#125;“==============================”/** * 指定初始数据初始化 * @param c the collection whose elements are to be placed into this list * @throws NullPointerException if the specified collection is null */public ArrayList(Collection&lt;? extends E&gt; c) &#123; elementData = c.toArray(); //如果给定的集合(c)数据有值 if ((size = elementData.length) != 0) &#123; //如果集合元素类型不是Object类型，我们会转换成Object类型 if (elementData.getClass() != Object[].class) elementData = Arrays.copyOf(elementData, size, Object[].class); &#125; else &#123; //如果给定集合(c)无值，默认空数组 this.elementData = EMPTY_ELEMENTDATA; &#125;&#125; 对于上面三个构造方法，补充两点 集合存储数据的数组elementData指向有四种种情况(后面扩容和这个相关) 使用无参初始化，将数组elementData指向DEFAULTCAPACITY_EMPTY_ELEMENTDATA空数组 使用指定大小初始化并且指定大小为0，将数组elementData指向EMPTY_ELEMENTDATA空数组 使用指定大小初始化但参数不为0或者是使用指定数据初始化，将数组elementData指向一个新的数组 ArrayList使用无参初始化时，默认大小是空数组，并不是10，10是在第一次扩容时的数组大小 添加和扩容实现在向集合中添加元素时，主要分成两步 判断是否需要扩容，如果需要就执行扩容操作 直接赋值 我们来看一下添加方法代码和扩容代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465//添加方法add()public boolean add(E e) &#123; //确保数组大小是否足够，不够进行扩容，size为当前数组中元素的个数 ensureCapacityInternal(size + 1); //直接赋值，线程不安全 elementData[size++] = e; return true;&#125;”====================================“计算期望值//add()方法中调用此方法private void ensureCapacityInternal(int minCapacity) &#123; ensureExplicitCapacity(calculateCapacity(elementData, minCapacity));&#125;private static int calculateCapacity(Object[] elementData, int minCapacity) &#123; //如果elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA， //说明使用的是无参初始化，那么第一次初始化直接扩容为10 if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123; return Math.max(DEFAULT_CAPACITY, minCapacity); &#125; //如果使用的是指定大小初始化或指定数值初始化，那么普通扩容 return minCapacity;&#125;private void ensureExplicitCapacity(int minCapacity) &#123; //后面迭代器会说到 modCount++; //如果需要的大小超过了当前数组的长度，那么就进行扩容 //如果没超过说明就不进行扩容 if (minCapacity - elementData.length &gt; 0) grow(minCapacity);&#125;”====================================“扩容逻辑代码，将计算后的期望容量传递到grow方法中private void grow(int minCapacity) &#123; // 记录当前数组长度 int oldCapacity = elementData.length; //进行1.5倍扩容 int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); //如果扩容后还是小于期望值(使用addAll方法时有可能扩容一次后的容量仍不满足要求) 那么就令新的值等于期望值 if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; //如果扩容后的值&gt;JVM所能分配的数组最大值 //那么就用int能表示的最大值或者JVM所能分配的数组最大值进行扩容 //具体采用那个值视期望值而定 if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); //通过复制进行扩容 elementData = Arrays.copyOf(elementData, newCapacity);&#125;private static int hugeCapacity(int minCapacity) &#123; if (minCapacity &lt; 0) // overflow throw new OutOfMemoryError(); return (minCapacity &gt; MAX_ARRAY_SIZE) ? Integer.MAX_VALUE : MAX_ARRAY_SIZE;&#125; 对于扩容方法，进行以下总结 当添加元素时，我们需要首先确保数组的大小能够容纳新的元素，因此我们期望值是minCapacity=size+1 计算期望值的时候，我们需要根据当初构造对象使用的初始化方法来决定 如果当初使用的是无参初始化方法，那么我们直接令期望值为max(10,minCapacity)，这也就意味着我们在第一次添加元素的时候直接将集合扩容为10。 如果使用的其他的初始化方法，那么期望值为minCapacity，这也就意味着，我们第一次添加元素时仅仅将集合扩容为1； 当计算完期望值minCapacity后，我们需要根据期望值和当前数组大小来判断是否需要扩容 如果minCapacity&lt;elementData.length，说明数组还够用。因此不需要扩容 如果minCapacity&gt;elementData.length，说明数组不够用了，需要对数组进行扩容 扩容时，采用的扩容规则并不是翻倍，而是1.5倍速增长，即扩容后的大小newCapacity是原来大小的1.5倍。当得到扩容后大小newCapacity后，我们还不能直接对其进行扩容，因为这时候仍然存在一些问题 如果扩容后的大小newCapacity&lt;期望值minCapacity。这是完全有可能的：例如当前集合容量为10，集合中元素个数为10，这时候如果使用addAll()方法向集合中添加10个元素，那么就需要进行扩容。扩容后的newCapacity为15，但是我们期望值minCapacity=size+10=20，此时扩容一次后的大小仍然不够。此时采取的策略是不再进行下一次扩容(因为下一次扩容可能仍不够，反复扩容影响性能)，直接令扩容后的大小newCapacity==期望值minCapacity 如果扩容后的大小newCapacity超过了JVM能分配的最大值MAX_ARRAY_SIZE(Integer.MAX_VALUE-8)，此时就不能进行扩容要对newCapacity进行调整。调整的策略就是通过期望值minCapacity minCapacity &gt; MAX_ARRAY_SIZE，令newCapacity=Integer.MAX_VALUE minCapacity &lt; MAX_ARRAY_SIZE，令newCapacity=MAX_ARRAY_SIZE 这样添加和扩容的方法就介绍完毕了。通过分析，我们可以发现，源码在扩容的时候，有数组大小溢出的意识，即无论如何数组大小不能小于0，不能大于Integer.MAX_VALUE。这点值得我们学习！ 扩容的本质扩容是通过Arrays.copyOf(elementData, newCapacity);这一行代码实现的。这一行代码的本质是数组之间的拷贝，扩容会新建一个容量为newCapacity的新数组，然后将老数组的数据拷贝过去，我们通过System.arraycopy方法进行拷贝 1234567891011121314151617181920System.arraycopy源码 /** * @param src 被拷贝的数组. * @param srcPos 从数组哪里开始. * @param dest 目标数组. * @param destPos 从目标数组那个索引开始拷贝. * @param length 拷贝的长度. */ public static native void arraycopy( Object src, int srcPos, Object dest, int destPos, int length);这是一个本地方法“=====================”System.arraycopy( elementData, 0, newelementData, 0, Math.min(elementData.length, newCapacity));最终调用这行代码返回newelementData数组 删除ArrayList删除元素有很多种方式，根据索引删除、根据值删除、批量删除等，原理都比较类似，我们这里以根据值删除为例进行说明 1234567891011121314151617181920212223242526272829303132333435363738/** * 根据值删除元素 * @param 要删除的值 * @return 删除成功返回true，否则返回false */public boolean remove(Object o) &#123; //如果要删除的值是null，找到第一个值是null的删除并返回true if (o == null) &#123; for (int index = 0; index &lt; size; index++) if (elementData[index] == null) &#123; fastRemove(index); return true; &#125; &#125; //如果要删除的值不为null，使用equals比较， //找到第一个和要删除的值相等的删除 else &#123; for (int index = 0; index &lt; size; index++) if (o.equals(elementData[index])) &#123; fastRemove(index); return true; &#125; &#125; return false;&#125;//删除逻辑代码private void fastRemove(int index) &#123; modCount++; //表示删除index位置元素后，需要从index后移动多少个元素到前面去 //-1是因为size是从1开始算起，而index是从0开始算起 int numMoved = size - index - 1; if (numMoved &gt; 0) //从index+1位置开始拷贝，拷贝的起始位置为index，长度为numMoved System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; // clear to let GC do its work&#125; 从源码可以看出，删除方法中也使用的是System.arraycopy的方法进行实现，某一个元素删除后，会将后面的元素往前移动。如图所示 迭代器如果要自己实现迭代器，实现java.util.Iterator接口就可，ArrayList中用一个私有内部类实现了Iterator接口。关于Iterator接口和Iterable接口会在下一篇博客中介绍在ArrayList的私有内部类中，有以下几个重要的参数 1234567//迭代过程中，下一个元素的位置，初始值为0int cursor; //添加元素时：表示上一次迭代过程中索引的位置；//删除元素时：为-1int lastRet = -1; //表示迭代过程中，期望的版本号，modCount表示实际的版本号int expectedModCount = modCount; 迭代器一般来说有三个方法 123hashNext()：判断是否有值进行迭代next()：如果有，那么获取迭代的值remove()：删除当前迭代的值 下面来看以下ArrayList中三个方法的源码 hashNext() 1234public boolean hasNext() &#123; //cursor表示下一个元素的位置 return cursor != size;&#125; next() 1234567891011121314151617181920212223public E next() &#123; //迭代过程中，判断版本号是否被修改， //如果修改抛出ConcurrentModificationException异常 checkForComodification(); //本次迭代过程中元素的索引位置 int i = cursor; if (i &gt;= size) throw new NoSuchElementException(); Object[] elementData = ArrayList.this.elementData; if (i &gt;= elementData.length) throw new ConcurrentModificationException(); //下一次迭代时元素的位置 cursor = i + 1; //返回当前元素 return (E) elementData[lastRet = i];&#125;“=================================”检查版本号方法final void checkForComodification() &#123; if (modCount != expectedModCount) throw new ConcurrentModificationException();&#125; remove() 1234567891011121314151617181920public void remove() &#123; //不能重复删除 if (lastRet &lt; 0) throw new IllegalStateException(); //检查版本号 checkForComodification(); try &#123; ArrayList.this.remove(lastRet); //将cursor后移到上次迭代的位置 cursor = lastRet; //-1表示元素已经删除，防止重复删除同一个元素 lastRet = -1; //由于删除元素时modCount已经发生了变化 //所以要重新赋值给expectedModCount使得两者版本号一致 expectedModCount = modCount; &#125; catch (IndexOutOfBoundsException ex) &#123; throw new ConcurrentModificationException(); &#125;&#125; 在next()方法的源码中的这一行代码，为什么不直接操作外部类的elementData而要重新创建一个引用呢？ 1Object[] elementData = ArrayList.this.elementData; 这部分操作和String源码中replace()方法的很类似，一个是类变量，一个是局部变量，当操作类变量时每一次操作都会有一次getField操作，如果使用局部变量，那么仅仅在赋值的时候有一次getField操作，这样性能会好一些。 Fail-Fast策略ArrayList不是线程安全的，因此如果在使用迭代器的过程中如果有其他线程对集合进行了修改，那么就抛出ConcurrentModificationException异常，这就是Fail-Fast策略。这一策略在源码中就是通过版本号modCount实现的。每一次对ArrayList结构的修改(长度的变化、增加删除元素)都会增加这个值，在迭代器初始化过程中都会将这个值赋值给expectedModCount。在迭代过程中，如果expectedModCount和modCount不相等，说明ArrayList结构发生了变化，就抛出异常。 线程安全只有当ArrayList作为共享变量时，才会有线程安全问题，如果只是作为局部变量，那么就不存在线程安全问题。ArrayList线程安全问题的本质，是因为ArrayList自身的elementData、size、modCount在进行各种操作时没有加锁而且都不是volatile的。类注释中推荐我们使用Collections.synchronizedList来保证线程安全，该类是通过在每个方法上加锁来实现，性能较低。 总结这篇文章主要介绍了初始化，添加删除，迭代器等源码的实现，不难发现ArrayList的底层是一个数组，所谓子自动扩容是通过数组的拷贝来实现，ArrayList的各个API都是对数组操作进行封装。很大一部分参考慕课网文贺老师专栏。十分感谢]]></content>
      <categories>
        <category>JDK源码</category>
      </categories>
      <tags>
        <tag>源码</tag>
        <tag>ArrayList集合</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[详解synchronized关键字]]></title>
    <url>%2F2019%2F11%2F02%2F%E8%AF%A6%E8%A7%A3synchronized%E5%85%B3%E9%94%AE%E5%AD%97%2F</url>
    <content type="text"><![CDATA[这次来介绍另外一个关键字-synchronized关键字，接下来将对synchronized关键字的底层实现原理进行深度的介绍。 synchronized三种使用方式 修饰实例方法此时锁对象就是调用方法的实例对象 修饰静态方法此时锁对象就是该静态方法所属类的class对象 修饰代码块此时锁对象是自己指定的。 作用于实例方法来看一下下面这一段测试代码 1234567891011121314151617181920212223242526272829303132333435/** * 用两个线程，进行计数，每个线程加10000次 * 如果正确运行，结果应该是20000 */public class FunctionWithSyn implements Runnable &#123; int count; //先把synchronized注释掉，观察运行结果 public /*synchronized*/ void increase() &#123; count++; &#125; @Override public void run() &#123; for (int i = 0; i &lt; 10000; i++) &#123; increase(); &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; FunctionWithSyn f = new FunctionWithSyn(); Thread t1 = new Thread(f); Thread t2 = new Thread(f); t1.start(); t2.start(); t1.join(); t2.join(); System.out.println(f.count); &#125;&#125;=========================Output:10000多，(每次运行结果不确定，但是都达不到2w) 分析原因为了方便描述，我们假设两个线程分别为A线程和B线程，A和B两个线程分别执行自己的run方法。假设在某一时刻(假设此时count=100)A和B线程分别执行到了increase()方法里面的count++语句，那么会发生什么呢？通过查看反汇编指令，我们发现count分为四个指令123456789102: getfield #2 // Field count:I5: iconst_16: iadd7: putfield #2 // Field count:I=========================1. 取出字段count2. 从操作数栈中取出一个13. 执行count+14. 将操作后的count放回局部变量表 A线程取出count(此时count=100)进行操作，但是在A线程执行第四步回写操作之前，B线程也取出count(此时count还是100)。 A线程操作完后将101写回去，但是B线程最后也写回了101。 不难发现，虽然两个线程都进行了一个count++操作，按照预想count应该增加2，但是最后count却只增加了1。这就是最后得到的count远远小于20000的原因了。 解决方法解决的方法不止一种，但是既然讲的是synchronized，那就用synchronized来解决吧。用synchronized修饰increase()方法，就能够解决这个问题，代码如下。 1234567//其他不变，只在这个方法上加上synchronized关键字即可public synchronized void increase() &#123; count++;&#125;================Output:20000 分析原因在这里，synchronized修饰的就是实例方法，此时的锁对象就是调用方法的实例对象，即代码中的f。当加了synchronized关键字后，如果当前线程在访问该方法，那么其他线程就不能访问，因为锁只有一把，被当前线程拿到了，其他线程就不能拿了。这样以来，每次只有一个线程对count进行操作，只有该线程操作完了，将改变后的count写回去之后，另外的线程才有可能对count进行操作。保证了安全性。 但是要注意的是，如果是下面这种实现方式，仍然得不到正确的结果 12345678910111213141516public static void main(String[] args) throws InterruptedException &#123; FunctionWithSyn f = new FunctionWithSyn(); FunctionWithSyn f1 = new FunctionWithSyn(); Thread t1 = new Thread(f); Thread t2 = new Thread(f1); t1.start(); t2.start(); t1.join(); t2.join(); System.out.println(f.count);&#125;===================Output:10000 这是因为，两个线程的拿到的对象锁不是同一把锁，起不到同步的作用。两个线程仍然会同时对count进行操作，并且count的值始终是10000。这是因为，相当于两个线程分别对count加了10000次，最后将count=10000写回主内存。 作用于静态方法当synchronized作用于实例方法时，多个线程的锁对象必须是同一个才能起到同步作用。然而当synchronized修饰静态方法时，由于静态方法不属于对象而属于类，此时锁对象就是该静态方法所属类的class对象。此时无论实例多少个对象，锁都是唯一的，因为class对象只有一个。我们将increase变为静态方法，测试一下。 123456789101112131415161718192021222324252627282930313233public class FunctionWithSyn implements Runnable &#123; static int count; 将方法改为静态方法 public synchronized static void increase() &#123; count++; &#125; @Override public void run() &#123; for (int i = 0; i &lt; 10000; i++) &#123; increase(); &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; FunctionWithSyn f = new FunctionWithSyn(); FunctionWithSyn f1 = new FunctionWithSyn(); //传递进去的是两个对象 Thread t1 = new Thread(f); Thread t2 = new Thread(f1); t1.start(); t2.start(); t1.join(); t2.join(); System.out.println(f.count); &#125;&#125;====================Output:20000 上述代码中，我们将传递进去的是两个不同的FunctionWithSyn对象，最终仍然得到正确的结果。 作用于代码块有时候，我们并不需要对整个方法进行加锁，而是只需要对方法中的某些语句进行加锁也能达到线程安全的效果。这样的话性能会得到提高。我们来写一段测试代码 12345678910111213141516171819202122232425262728293031public class BlockWithSyn implements Runnable&#123; final Object o = new Object(); int count=0; @Override public void run() &#123; //......... //一些不需要加锁的其他逻辑代码 synchronized (o) &#123; for (int i = 0; i &lt; 10000; i++) &#123; count++; &#125; &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; BlockWithSyn b = new BlockWithSyn(); Thread t1 = new Thread(b); Thread t2 = new Thread(b); t1.start(); t2.start(); t1.join(); t2.join(); System.out.println(b.count); &#125;&#125;==============Output:20000 从上面代码不难发现，synchronized修饰代码块时，锁对象是需要自己指定的，你可以指定任意对象，但是关键要保证不同线程的锁对象是同一个。 synchronized底层原理前面说了synchronized的三种使用方式，下面说一下该关键字的底层原理。Java虚拟机中的同步是基于进入和退出管程(Monitor)对象实现。无论是显式同步(有明确的 monitorenter 和 monitorexit 指令,即同步代码块)还是隐式同步都是如此。在 Java 语言中，同步用的最多的地方可能是被synchronized修饰的同步方法。同步方法并不是由monitorenter和monitorexit指令来实现同步的，而是由方法调用指令读取运行时常量池中方法的 ACC_SYNCHRONIZED标志来隐式实现的。 对象头关于对象的组成部分在深入理解JVM虚拟机一已经介绍过，这里就不赘述。主要说一下对象头的组成，因为它是和synchronized息息相关的部分 轻量级锁和偏向锁是Java6对synchronized锁进行优化后新增加的，一会儿会说到。这里我们主要分析一下重量级锁也就是通常说synchronized的对象锁 锁标识位为10，其中指针指向的是monitor对象（也称为管程或监视器锁）的起始地址。每个对象都存在着一个 monitor 与之关联，对象与其 monitor 之间的关系有存在多种实现方式，如monitor可以与对象一起创建销毁或当线程试图获取对象锁时自动生成，但当一个 monitor 被某个线程持有后，它便处于锁定状态。在Java虚拟机(HotSpot)中，monitor是由ObjectMonitor实现的，其主要数据结构如下（位于HotSpot虚拟机源码ObjectMonitor.hpp文件，C++实现的）123456789101112131415161718ObjectMonitor() &#123; _header = NULL; _count = 0; //记录个数 _waiters = 0, _recursions = 0; _object = NULL; _owner = NULL; _WaitSet = NULL; //处于wait状态的线程，会被加入到_WaitSet _WaitSetLock = 0 ; _Responsible = NULL ; _succ = NULL ; _cxq = NULL ; FreeNext = NULL ; _EntryList = NULL ; //处于等待锁block状态的线程，会被加入到该列表 _SpinFreq = 0 ; _SpinClock = 0 ; OwnerIsThread = 0 ; &#125; ObjectMonitor中有两个队列，分别是_WaitSet和_EntryList。用来保存ObjectWaiter对象列表(每个等待锁的线程都会被封装成ObjectWaiter对象)_owner指向持有ObjectMonitor对象的线程 当多个线程同时访问一段同步代码时，首先会进入_EntryList集合 当线程获取到对象的monitor后进入_Owner区域 把monitor中的_owner变量设置为当前线程 monitor中的计数器count加1 若线程调用wait()方法，将释放当前持有的monitor owner变量恢复为null，count自减1 同时该线程进入WaitSet集合中等待被唤醒。 若当前线程执行完毕也将释放monitor(锁)并复位变量的值，以便其他线程进入获取monitor(锁)。 通过上述分析不难发现，monitor对象存在于每个Java对象的对象头中(存储的指针的指向)，synchronized锁便是通过这种方式获取锁的，也是为什么Java中任意对象可以作为锁的原因。 synchronized代码块原理下面定义一个同步代码块 123456789101112public class SynTest &#123; int count=0; //该同步代码块只有一行代码 public void SynFunction() &#123; synchronized (this) &#123; count++; &#125; &#125; public static void main(String[] args) &#123; &#125;&#125; 通过javap -verbose命令反汇编一下，主要查看SynFunction方法的指令 1234567891011121314151617181920212223242526272829public void SynFunction();descriptor: ()Vflags: (0x0001) ACC_PUBLICCode: stack=3, locals=3, args_size=1 0: aload_0 1: dup 2: astore_1 3: monitorenter //进入同步 4: aload_0 5: dup 6: getfield #2 // Field count:I 9: iconst_1 10: iadd 11: putfield #2 // Field count:I 14: aload_1 15: monitorexit //退出同步 16: goto 24 19: astore_2 20: aload_1 21: monitorexit //出现异常后退出同步，释放锁 22: aload_2 23: athrow 24: return Exception table: from to target type 4 16 19 any 19 22 19 any//省略一些其他属性 由此可知，同步语句块的实现使用的是monitorenter和monitorexit指令 其中monitorenter指令指向同步代码块的开始位置 monitorexit指令则指明同步代码块的结束位置 当执行monitorenter指令时，当前线程将试图获取 objectref(即对象锁) 所对应的 monitor 的持有权 当 objectref 的 monitor 的进入计数器为 0，那线程可以成功取得 monitor，并将计数器值设置为 1，取锁成功。 如果当前线程已经拥有 objectref 的 monitor 的持有权，那它可以重入这个 monitor (关于重入性稍后会分析)，重入时计数器的值也会加 1。 倘若其他线程已经拥有 objectref 的 monitor 的所有权，那当前线程将被阻塞，直到正在执行线程执行完毕，即monitorexit指令被执行，执行线程将释放 monitor(锁)并设置计数器值为0 ，其他线程将有机会持有 monitor 。 值得注意的是编译器将会确保无论方法通过何种方式完成，方法中调用过的每条 monitorenter 指令都有执行其对应 monitorexit 指令，而无论这个方法是正常结束还是异常结束。为了保证在方法异常完成时 monitorenter 和 monitorexit 指令依然可以正确配对执行，编译器会自动产生一个异常处理器，这个异常处理器声明可处理所有的异常，它的目的就是用来执行 monitorexit 指令。从字节码中也可以看出多了一个monitorexit指令，它就是异常结束时被执行的释放monitor 的指令。 synchronized方法原理方法的同步是隐式的，和同步块不同，它不需要通过字节码指令来完成，实现在方法调用和返回操作中。方法的访问标志有一个ACC_SYNCHRONIZED标志用于判断方法是否是同步方法。 当方法调用时，调用指令会检查方法的这个标志，如果该方法是同步方法 执行线程将先持有monitor，然后再执行方法。最后在方法退出(正常或非正常)时释放monitor 在方法执行期间，执行线程持有了monitor。其他任何线程都无法再获得，如果方法在执行期间抛出了异常，并且在方法内部无法处理，那同步方法的monitor将在异常抛出到同步方法之外时自动释放。对于下面这个同步方法，我们来查看一下它的字节码 123456789public class SynTest &#123; int count=0; public synchronized void SynFunction() &#123; count++; &#125; public static void main(String[] args) &#123; &#125;&#125; javap -verbose得到字节码指令 123456789101112131415161718public synchronized void SynFunction();descriptor: ()Vflags: (0x0021) ACC_PUBLIC, ACC_SYNCHRONIZED //同步方法的标志位Code: stack=3, locals=1, args_size=1 0: aload_0 1: dup 2: getfield #2 // Field count:I 5: iconst_1 6: iadd 7: putfield #2 // Field count:I 10: return LineNumberTable: line 6: 0 line 7: 10 LocalVariableTable: Start Length Slot Name Signature 0 11 0 this LblogTest/SynTest; 通过字节码指令可以发现，同步方法中是没有monitor指令的，但是方法的标志位出现了ACC_SYNCHRONIZED JVM对synchronized的优化HotSpot在1.6版本对synchronized实现了各种优化技术，如适应性自旋、锁消除、锁粗化、偏向锁和轻量级锁。接下来讲逐个进行介绍。 适应性自旋使用synchronized锁的时候，对性能最大的影响就是阻塞的实现，挂起和恢复线程的操作都需要转入内核态中完成，这给操作系统的并发性能带来了很大的压力。并且，在许多情境下，共享数据的锁定状态只会持续很短一段时间，为了这一段时间去挂起和恢复线程并不值得。这时候，我们可以让后面请求锁的那么线程“稍等一下”，但不放弃处理器执行时间，看看持有锁的线程是否很快就会释放锁。为了让线程等待，我们只需要让线程执行一个忙循环，这就是所谓的自旋锁。 自旋等待的时间自旋等待本身虽然避免了线程切换的开销，但它也是要占用处理器时间的。因此，如果锁被占用的时间很短，自选等待的效果就会非常好，反之，如果锁被占用的时间很长，那么自选等待的线程只会白白浪费处理器资源。因此，自旋等待的时间必须要有一定的限度。在JDK1.6引入了自旋锁，自旋的时间由前一次在同一个锁上的自旋时以及锁的拥有者的状态决定 如果在同一个锁对象上，自旋等待刚刚成功获得过锁，并且持有锁的线程赈灾运行中，那么虚拟机就会认为这一次自旋也很有可能再次成功，进而允许自旋等待的时间更长一点，如100个循环。 如果对于某个锁，自旋很少成功获得过，那么以后要获取这个锁时可能省略掉自旋过程。 这就是自适应自旋。 锁消除锁消除是指虚拟机在即时编译器运行时，对代码上要求同步，但是被检测到不可能存在共享数据竞争的锁进行消除。也许你会问，我们为什么要在明知道不会产生数据竞争的情况下还是用同步呢，如果我们不使用同步那么这项技术不就没用了么？这是因为，许多同步措施并不是我们在代码上自己加入的，同步的代码在Java程序中普遍程度较高，我们来看下面的例子 123public static String concatString(String s1, String s2, String s3) &#123; return s1 + s2 + s3;&#125; 我们知道，String是一个不可变的类，对字符串的连接操作总是通过生成新的String对象来进行的，因此Javac编译器会对String连接做优化。 在JDK1.5之前，会转化为StringBuffer对象的连续append()操作 在JDK1.5之后，会转化为StringBuilder对象的连续append()操作12345678//JDK1.5之前public static String concatString(String s1, String s2, String s3) &#123; StringBuffer sb = new StringBuffer(); sb.append(s1); sb.append(s2); sb.append(s3); return sb.toString();&#125; 我们知道StringBuffer是线程安全的，里面存在锁，现在你还认为这段代码没有锁么？当虚拟机执行这段代码时，发现sb对象的作用域被限制在方法内部，其他线程无法访问它，因此在即时编译时候，这段代码就会忽略掉所有的同步而直接执行。 锁粗化原则上，当我们在编写代码时，总是推荐讲同步块的作用范围限制的尽量小，只在共享数据的实际作用域中才进行同步，这样能够使得需要同步的操作数量尽可能变小，如果存在锁竞争，那么等待锁的线程也能尽快获得锁。大部分情况下，这样做是对的，但是如果一系列连续操作都对同一个对象反复加锁解锁，甚至加锁操作是出现在循环体中的，那即使没有锁竞争，频繁的互斥同步操作也会导致不必要的性能损耗。前面的连续的append()就属于这类情况。如果虚拟机发现有这样一串零碎的操作都是对同一个对象加锁，将会把加锁同步的范围扩大到整个操作序列外部。就拿上面来说，虚拟机会将加锁操作扩展到第一个append()之前和最后一个append()之后，这样只需要加锁一次即可。 偏向锁JDK1.6引入的一项锁优化，它的目的是消除数据在无竞争情况下的同步，进一步提高程序性能。它的核心思想是：如果一个线程获得了锁，那么锁就进入偏向模式。当这个线程再次请求锁时，无需任何同步操作，可以直接进入。对于没有锁竞争的场合，偏向锁有比较好的优化效果，因为连续多次极有可能是同一个线程请求相同的锁。对于锁竞争比较激烈的场合下，偏向模式就会失效，这时进入锁就升级为轻量级锁。 轻量级锁轻量级锁的操作也比较方便，它只是简单地讲对象头部作为指针指向持有锁的线程堆栈的内部，来判断一个线程是否持有对象锁。如果线程获得轻量级锁成功，就顺利进入临界区。如果轻量级加锁失败，则表示其他线程抢先争夺到了锁，那么当前线程的锁请求就会膨胀为重量级锁。轻量级锁提升性能的依据是“对于绝大部分的锁，整个同步周期都是不存在竞争的”。如果没有竞争，轻量级锁使用CAS操作避免的使用互斥量的开销。 重量级锁当轻量级锁失败后，JVM会做最后一次努力，线程并不会被真正挂起，而是采用前面介绍的适应性自旋的方式，看看能否再次获得锁。经过若干次循环后如果获得了锁，那么就进入同步区；否则，当前线程就会被真正挂起，变成重量级锁。 参考资料《深入理解JVM虚拟机》《Java并发编程实战》《Java编程思想》《实战Java高并发程序设计》大神博客]]></content>
      <categories>
        <category>Java并发编程</category>
      </categories>
      <tags>
        <tag>多线程</tag>
        <tag>synchronized</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计数质数]]></title>
    <url>%2F2019%2F11%2F02%2F%E8%AE%A1%E6%95%B0%E8%B4%A8%E6%95%B0%2F</url>
    <content type="text"><![CDATA[LeetCode第二百零四题难度：简单题目：统计所有小于非负整数 n 的质数的数量。 1234示例:输入: 10输出: 4解释: 小于 10 的质数一共有 4 个, 它们是 2, 3, 5, 7 。 思想分析首先，对于质数，我们首先想到的应该是大于1的数，最小的指数为2。对于这个题，我一开始想到的是优化的暴力解法，最后虽然通过了测试，但是速度感人，因此翻了评论区才发现有更好的思路，那就是厄拉多塞筛法。当我们遍历到一个数i(1&lt;i&lt;n)时，有这样一个隐藏条件，所有n以内的i的倍数都不是质数！！例如i=2，那么4、6、8、10……都不是指数，都可以排除。很巧妙吧，这就是厄拉多塞筛法的原理了。如图所示(图源LeetCode题解区) 代码实现123456789101112131415161718192021222324252627282930313233343536373839//优化的暴力解法public int countPrimes(int n) &#123; if(n&lt;=2) return 0; int res=1; //从奇数3开始遍历，偶数肯定不是质数，因此每次+2 for(int i=3;i&lt;n;i+=2)&#123; if(isPrime(i)) res++; &#125; return res;&#125;public boolean isPrime(int n)&#123; if(n==3) return true; //同样的道理，并且只遍历到sqrt(n)为止 for(int i=3;i*i&lt;=n;i+=2)&#123; if(n%i==0) return false; &#125; return true;&#125;”=====================================“//厄拉多塞筛法public int countPrimes(int n) &#123; boolean[] res=new boolean[n]; int count=0; for(int i=2;i&lt;n;i++)&#123; if(!res[i])&#123; count++; for(int j=i+i;j&lt;n;j+=i)&#123; res[j]=true; &#125; &#125; &#125; return count;&#125; 厄拉多塞筛法是求质数个数很实用高效的算法]]></content>
      <categories>
        <category>算法之美</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
        <tag>质数</tag>
        <tag>厄拉多塞筛法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[移除链表元素]]></title>
    <url>%2F2019%2F11%2F02%2F%E7%A7%BB%E9%99%A4%E9%93%BE%E8%A1%A8%E5%85%83%E7%B4%A0%2F</url>
    <content type="text"><![CDATA[LeetCode第二百零三题难度：简单题目：删除链表中等于给定值 val 的所有节点。 123示例:输入: 1-&gt;2-&gt;6-&gt;3-&gt;4-&gt;5-&gt;6, val = 6输出: 1-&gt;2-&gt;3-&gt;4-&gt;5 思想分析这道题看上去很简单，但是做起来却并不是那么简单。其中有一些细节是处理链表问题经常容易犯错的，因此才把这个题记录下来。 首先，对于链表问题，要保证不能有空指针异常 对于本题，要保证移动指针p始终在遍历的节点的前一个位置 代码实现1234567891011121314151617public ListNode removeElements(ListNode head, int val) &#123; //要使用while循环来保证head节点指向第一个值不为val的节点 //不能使用if！！！ while(head!=null&amp;&amp;head.val==val) head=head.next; ListNode p=head; //先判断p!=null再判断p.next!=null while(p!=null&amp;&amp;p.next!=null)&#123; if(p.next.val==val)&#123; p.next=p.next.next; &#125; else&#123; p=p.next; &#125; &#125; return head;&#125; 对于链表的题，如果思路比较简单，那么一定要注意细节问题不能出错。]]></content>
      <categories>
        <category>算法之美</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
        <tag>链表</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[快乐数]]></title>
    <url>%2F2019%2F11%2F01%2F%E5%BF%AB%E4%B9%90%E6%95%B0%2F</url>
    <content type="text"><![CDATA[LeetCode第二百零二题难度：简单题目：编写一个算法来判断一个数是不是“快乐数”。一个“快乐数”定义为：对于一个正整数，每一次将该数替换为它每个位置上的数字的平方和，然后重复这个过程直到这个数变为 1，也可能是无限循环但始终变不到 1。如果可以变为 1，那么这个数就是快乐数。 12345678示例: 输入: 19输出: true解释: 1*1 + 9*9 = 828*8 + 2*2 = 686*6 + 8*8 = 1001*1 + 0*0 + 0*0 = 1 思想分析通过题意可以发现 如果一个数是快乐数，那么经过若干次计算后最终会收敛为1。 如果一个数不是快乐数，那么经过若干次计算后会变回最开始的数 快慢指针法通过分析，可以发现这个题和判断链表是否有环较为类似，可以使用 设置一个fast变量和一个slow变量，初始值相等 fast每次循环计算两次，slow每次循环计算一次 当fast==slow时退出循环 如果fast==1，那么是快乐数，否则不是快乐数。 递归实现对于递归，我们首先要判断递归出口，对于10以内的数字，只有1和7是快乐数，其它的都不是快乐数，因此我们可以得到递归出口 如果n==1||n==7，返回true 否则如果n&lt;10，返回false 否则继续递归 代码实现下面将介绍两种实现思路 快慢指针法123456789101112131415161718192021public boolean isHappy(int n) &#123; int slow=n; int fast=n; do&#123; slow=cal(slow); fast=cal(fast); fast=cal(fast); &#125;while(slow!=fast); return slow==1;&#125;public int cal(int n)&#123; int res=0; while(n&gt;0)&#123; int temp=n%10; res+=temp*temp; n/=10; &#125; return res;&#125; 递归实现12345678910111213public boolean isHappy(int n) &#123; if(n==1||n==7) return true; if(n&lt;10) return false; int res=0; while(n&gt;0)&#123; int temp=n%10; res+=temp*temp; n/=10; &#125; return isHappy(res);&#125; 了解了规律，遇到这样的题就会迎刃而解。]]></content>
      <categories>
        <category>算法之美</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
        <tag>递归</tag>
        <tag>快慢指针法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java并发之先行发生原则]]></title>
    <url>%2F2019%2F11%2F01%2FJava%E5%B9%B6%E5%8F%91%E4%B9%8B%E5%85%88%E8%A1%8C%E5%8F%91%E7%94%9F%E5%8E%9F%E5%88%99%2F</url>
    <content type="text"><![CDATA[Java语言中有一个”先行发生“(heppens-before)原则，这个原则非常重要，它是判断数据是否存在竞争，线程是否安全的主要依据。依靠这个原则，我们可以通过几条规则一揽子的解决并发环境下两个操作是否可能存在冲突的所有问题。 下面就介绍Java内存模型下一些天然的先行发生关系，这些先行发生关系无需任何同步协助就已经存在，可以在编码中直接使用。如果两个操作的关系不在此列，并且无法从下列规则推导出来的话，他们就没有顺序性保障，虚拟机可以对它们随意的进行重排序。 程序次序规则在一个线程内，按照程序代码顺序，书写在前面的操作先行发生于书写在后面的操作。准确的说，应该是控制流顺序而不是程序代码顺序，因为要考虑循环、分支等结构。 管程锁定规则一个unlock操作先行发生于后面对同一个锁的lock操作。必须是同一个锁，并且这里的“先后”指的是时间上的顺序 volatile变量规则对一个volatile变量的写操作先行发生于后面对这个变量的读操作，这里的”后面“也是时间上的顺序 线程启动规则Thread对象的start()方法先行发生于此线程的每一个动作 线程终止规则线程中的所有操作都先行发生于对此线程的终止检测，我们可以通过Thread.join()方法结束、Thread.isAlive()的返回值等手段检测到线程是否已经终止执行 线程中断规则对线程的interrupt()方法先行发生于被中断线程的代码检测到中断事件的发生，可以通过Thread.interrupted()方法检测到是否有中断发生 对象终结规则一个对象初始化完成(构造方法执行结束)先行发生于它的finalized()方法的开始 传递性如果操作A先行发生于操作B，操作B先行发生于操作C，那么A先行与C。 下面就举例演示一下如何使用这些规则去判断线程是否安全 12345678private int value=0;public void setValue(int value)&#123; this.value=value;&#125;public void getValue()&#123; return value;&#125; 我们假设线程A先(时间上)调用了set方法，然后B调用了同一个对象的get方法。那么B收到的返回值是什么？我们依次分析一下先行发生规则里的各条规则 首先，A和B不再一个线程，因此不满足规则1 由于没有同步块，也就不会有lock和unlock操作，管程锁定规则不适用 value不是valotile变量，不满足第三条 同样的后面都不满足 因此，我们可以判定尽管A在时间上先于线程B，但是无法确定B中get方法的返回结果，即这里面的操作不是线程安全的。时间先后顺序于先行发生原则之间基本没有太大的关系。我们在衡量并发问题时不要受时间顺序的干扰，必须以先行发生原则为准]]></content>
      <categories>
        <category>Java并发编程</category>
      </categories>
      <tags>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[详解volatile关键字]]></title>
    <url>%2F2019%2F11%2F01%2F%E8%AF%A6%E8%A7%A3volatile%E5%85%B3%E9%94%AE%E5%AD%97%2F</url>
    <content type="text"><![CDATA[最近在学习Java并发方面的知识，对Java并发的基础知识有了初步的认识，会在接下来的几篇博客中就自己学到的部分进行介绍，这里就先介绍一下volatile关键字。 要想对volatile关键字有一个较为深入的了解，首先必须对JMM有一定的概念，如果你还不了解，翻看我前面的博客。这里只强调一点，每条线程都有自己的工作内存，线程的工作内存中保存了被该线程使用到的变量(实例字段、静态字段、构成数组对象的元素等)的主内存副本拷贝，线程对变量的所有操作都必须在工作内存中进行，包括volatile修饰的关键字。而不能直接读写主内存中的变量。 基本概念在介绍volatile之前，我们先了解三个基础的概念 原子性如果一个操作不能被线程调度机制中断，一旦操作开始，那么它一定可以在可能发生的“上下文切换之前”(切换到其他线程执行)执行完毕，那么该操作是一个原子性操作。一个原子性操作是不可分割的。由Java内存模型来直接保证的原子性变量操作包括read、load、assign、use、store和write，我们可以大致认为基本数据类型的访问读写是具备原子性的。我们经常会需要一个更大范围的原子性保证，JMM还提供了lock和unlock操作来满足这种需求。虚拟机没有把这两个操作直接开放给用户，它提供了更高层次的字节码指令monitorenter和monitorexit来隐式的使用这两个操作，这两个字节码指令反映到Java代码中就是同步块synchronized关键字(下一篇会介绍该关键字) 可见性可见性是指当一条线程修改了这个变量的值，新值对于其他线程来说是可以立即得知的，稍后会讲到，volatile修饰的变量是如何保证可见性的。 有序性对于单个线程的执行代码而言，我们总是习惯的认为代码是从前往后依次执行的。这样理解在单线程中不会出现错误，但是在多线程中，程序执行可能就会出现乱序，这给我们的直观感觉就是，写在前面的代码，会在后面执行。有序性问题的原因是程序在执行时，可能会进行指令重排序，重排后的指令与原指令的顺序未必一致。下面一段代码 123456789101112131415class OrderExample&#123; int a=0; boolean flag=false; public void writer()&#123; a=1; flag=true; &#125; public void reader()&#123; if(flag)&#123; int i=a+1; ..... &#125; &#125;&#125; 假设线程A首先执行writer()方法，接着线程B执行reader()方法。如果发生指令重排，那么”flag=true;”可能会在”a=1;”之前执行。那么线程B执行”int i=a+1”时a还没有被赋值为1。 内存屏障内存屏障(Memory Barrier)是一种CPU指令，它使CPU或编译器对屏障指令之前和之后发出的内存操作执行一个排序约束。这就意味着在屏障之前发布的操作被保证在屏障之后发布的操作之前执行。内存屏障共分为四种类型 LoadLoad屏障123Load1;LoadLoad;Load2; Load1和Load2代表两条读取指令。在Load2要读取的数据被访问前，保证Load1要读取的数据被读取完毕 StoreStore屏障123Store1;StoreStore;Store2; Store1和Store2代表两条写入指令。在Store2写入执行之前，保证Store1的写入操作对其他处理器可见 LoadStore屏障123Load;LoadStore;Store; Load代表读取指令，Store代表写入指令，在Store写入执行之前，保证Load要读取的数据被读取完毕 StoreLoad屏障123Store;StoreLoad;Load; Load代表读取指令，Store代表写入指令，在Load读取执行之前，保证Store写入对其他处理器可见。 volatile关键字作用volatile关键字是JVM提供的最轻量级的同步机制。当一个变量定义为volatile关键字后，它将具备两种特性 保证此变量对所有线程的可见性 禁止指令重排序优化 无法保证原子性 我们来看一段代码 123456789101112131415161718192021222324252627282930public class VolatileTest &#123; public static volatile int race = 0; public static void increase() &#123; race++; &#125; private static final int THREADS_COUNT = 20; public static void main(String[] args) throws InterruptedException &#123; //利用线程池开启20个线程，对volatile修饰的race进行增加操作 ExecutorService exec = Executors.newFixedThreadPool(THREADS_COUNT); for (int i = 0; i &lt; THREADS_COUNT; i++) &#123; exec.execute(()-&gt;&#123; for (int i1 = 0; i1 &lt; 10000; i1++) &#123; increase(); &#125; &#125;); &#125; //等所有线程都开始后调用shutdown方法， //该方法会使线程池完成已开启任务后关闭 TimeUnit.MILLISECONDS.sleep(100); exec.shutdown(); System.out.println(race); &#125;&#125;“==================”Output：130405 如果上述代码能够正确并发，那么最后的输出结果应该是200000，可以当我们运行时，每次运行的结果都不一样，但是都小于200000。这是什么原因呢？问题就处在race++中。我们使用Javap反编译后得到这行代码的指令 12345678910Code: stack=2, locals=0, args_size=0 0: getstatic #2 // Field race:I 3: iconst_1 4: iadd 5: putstatic #2 // Field race:I 8: return LineNumberTable: line 9: 0 line 10: 8 可以发现，这一行代码由四条字节码指令构成，那么我们很容易就能够分析出并发失败的原因：当getstatic指令将race的值取到操作数栈顶时，volatile关键字保证了race的值在此时是正确的，但是在执行了iconst_1，iadd这些指令的时候，其他线程可能已经将race的值加大了，而操作数栈顶的值就变成了过期数据。所以putstatic指令可能把较小的race值同步回主内存中。 使用volatile场景由于volatile关键字并不保证可见性，因此volatile关键字的使用需要格外小心，在以下两种情况下，我们可以使用volatile关键字 运算结果不依赖变量的当前值，或者能够确保只有单一线程修改变量的值。这一点很好理解，就向前面的race++一样，依赖于race当前的值，但是别的线程可能对当前值进行修改，那么该线程依赖的值就变成了无效值 变量不需要与其他的状态变量共同参与不变约束。我们来举例说明这一点1234567检查start&lt;end是否成立，在给start赋值之前不变式是有效的if(start&lt;end)&#123; start=newStart; ... //在给start赋值之后给end赋值之前，该不变式是有效的 end=newEnd; //给start和end赋值之后不变式重新变为有效&#125;这样一来，其他的线程在判断if条件的时候，就有可能得到不同的判断结果，导致并发的错误。 如果我们有更多的需求，那就要通过加锁来实现，而不能仅仅通过volatile来满足需求下面的场景就很适合volatile来控制并发 123456789101112volatile boolean shutdownReq;public void shutdown() &#123; shutdownReq = true;&#125;public void doWork() &#123; while (!shutdownReq) &#123; ...... &#125;&#125;//当shutdown方法被调用，shutdownReq被设置为true时//所有线程中执行的doWork()方法都立即停下来 禁止指令重排序优化普通的变量仅仅保证在该方法的执行过程中所有依赖赋值结果的地方都能获取到正确的结果，而不能保证变量赋值操作的顺序和程序代码中的执行顺序一致。我们来举例说明 12345678910111213141516volatile boolean initialized=false//假设以下代码在线程A中执行//模拟读取配置信息，读取完成后将initialized设置为true以通知其他线程配置可用dosomething()initialized=true;......//假设以下代码在线程B中执行//等待initialized为true，代表A已经把配置信息初始化完成while(!initialized)&#123; sleep();&#125;//使用A线程初始化好的配置信息useThreadA(); 以上是一段伪代码，如果我们在定义initialized关键字时没有使用volatile修饰，就可能由于指令重排序优化，导致位于线程A中最后一句代码“initialized=true;”被提前执行，这样在B线程中使用配置信息就会出现错误(因为实际上A线程还没有执行完配置操作)，而volatile关键字可以避免这一点。为什么说volatile能够禁止指令重排序呢？从硬件结构上讲，指令重排序是指CPU采用了允许讲多条指令不按程序规定的顺序分开发送给各相应的电路单元处理。但这并不是说指令任意重排，是在保证结果正确的情况下进行重排。在一个变量被volatile修饰之后，JVM会做两件事 在每个volatile写操作之前插入StoreStore屏障，写操作之后插入StoreLoad屏障 在每个volatile读操作之前插入LoadLoad屏障，读操作之后插入LoadStore屏障 这样就达到了禁止重排序的目的。 volatile变量的特殊规则我们假设T代表一个线程，V和W分别表示两个volatile型变量，那么在进行read、load、use、assign、store和write操作时需要满足一下规则 只有当线程T对V执行的前一个动作时load的时候，线程T才能对变量V执行use动作；同样的，只有当线程T对变量V执行的后一个动作是use的时侯，线程T才能对变量V执行load操作。简单地说就是线程T对变量V的read、load、use三个操作必须连续依次出现。这条规则要求在工作内存中，每次使用V前都必须先从主内存刷新最新的值，用于保证能看见其他线程对变量V所做的修改后的值。 只有当线程T对V执行的前一个动作时assign的时候，线程T才能对变量V执行store动作；同样的，只有当线程T对变量V执行的后一个动作是store的时侯，线程T才能对变量V执行assign操作。简单地说就是assign、store、write三个操作必须连续依次出现。这条规则要求在工作内存中，每次修改V后都必须立刻同步回主内存中，用于保证其他线程能看见自己对变量V所做的修改。 我们假定一下几个前提 假定动作A是线程T对变量V实施的use或assign操作，假定动作F是和动作A相关联的load和store操作，假定动作P是和动作F对应的对变量V的read和write操作； 类似的，假定动作B是线程T对变量W实施的use或assign操作，假定动作G是和动作B相关联的load和store操作，假定动作Q是和动作G对应的对变量W的read和write操作。 那么如果A先于B，那么P先于Q。这条规则要求volatile修饰的变量不会被指令重排序优化，保证代码执行顺序与程序的顺序相同。 前两条规则保证了volatile的可见性，第三条则保证了volatile变量不会被指令重排序优化 对volatile关键字的介绍就到这里，参考资料《Java并发编程实战》《实战Java高并发程序设计》和一些网络上查阅的资料。]]></content>
      <categories>
        <category>Java并发编程</category>
      </categories>
      <tags>
        <tag>多线程</tag>
        <tag>volatile</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[打家劫舍]]></title>
    <url>%2F2019%2F10%2F31%2F%E6%89%93%E5%AE%B6%E5%8A%AB%E8%88%8D%2F</url>
    <content type="text"><![CDATA[LeetCode第一百九十八题难度：简单题目：你是一个专业的小偷，计划偷窃沿街的房屋。每间房内都藏有一定的现金，影响你偷窃的唯一制约因素就是相邻的房屋装有相互连通的防盗系统，如果两间相邻的房屋在同一晚上被小偷闯入，系统会自动报警。给定一个代表每个房屋存放金额的非负整数数组，计算你在不触动警报装置的情况下，能够偷窃到的最高金额 123456789101112示例 1:输入: [1,2,3,1]输出: 4解释: 偷窃 1 号房屋 (金额 = 1) ，然后偷窃 3 号房屋 (金额 = 3)。 偷窃到的最高金额 = 1 + 3 = 4 。示例 2:输入: [2,7,9,3,1]输出: 12解释: 偷窃 1 号房屋 (金额 = 2), 偷窃 3 号房屋 (金额 = 9)，接着偷窃 5 号房屋 (金额 = 1)。 偷窃到的最高金额 = 2 + 9 + 1 = 12 。 思想分析考虑所有可能的抢劫方案过于困难。一个自然而然的想法是首先从最简单的情况开始。记： f(k) = 从前 k 个房屋中能抢劫到的最大数额，Ai=第 i 个房屋的钱数。 首先看 n = 1 的情况，显然 f(1) = A1。 再看 n = 2，f(2) = max(A1+A2)。 对于 n = 3，有两个选项: 抢第三个房子，将数额与第一个房子相加。 不抢第三个房子，保持现有最大数额。 显然，你想选择数额更大的选项。于是，可以总结出公式：f(k)=max(f(k–2)+A,f(k–1))使f(–1)=f(0)=0为初始情况，这将极大地简化代码。 代码实现123456789101112131415public int rob(int[] nums) &#123; //f(k-2) int prevMax = 0; //f(k-1) int currMax = 0; for (int x : nums) &#123; //保存当前最大值 int temp = currMax; //更新f(k-1)选择是否抢劫当前房子 currMax = Math.max(prevMax + x, currMax); //更新f(k-2) prevMax = temp; &#125; return currMax;&#125; 核心在于找到状态转换方程。]]></content>
      <categories>
        <category>算法之美</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
        <tag>动态规划</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[位1的个数]]></title>
    <url>%2F2019%2F10%2F31%2F%E4%BD%8D1%E7%9A%84%E4%B8%AA%E6%95%B0%2F</url>
    <content type="text"><![CDATA[LeetCode第一百九十一题难度：简单题目：编写一个函数，输入是一个无符号整数，返回其二进制表达式中数字位数为 ‘1’ 的个数（也被称为汉明重量）。 123456789101112131415示例 1：输入：00000000000000000000000000001011输出：3解释：输入的二进制串 00000000000000000000000000001011 中，共有三位为 &apos;1&apos;。示例 2：输入：00000000000000000000000010000000输出：1解释：输入的二进制串 00000000000000000000000010000000 中，共有一位为 &apos;1&apos;。示例 3：输入：11111111111111111111111111111101输出：31解释：输入的二进制串 11111111111111111111111111111101 中，共有 31 位为 &apos;1&apos;。 思想分析这道题有两种方法来解决 使用lowbit()公式:x&amp;-x，返回x的最后一个1 使用一个标记mark=1，通过对mark进行移位，并判断mark&amp;x是否为0。 代码实现1234567891011121314151617181920212223//lowbit公式public int hammingWeight(int n) &#123; int res=0; while(n!=0)&#123; res++; n-=(n&amp;-n); &#125; return res;&#125;”=========================“移位public int hammingWeight(int n) &#123; int res=0; int mark=1; for(int i=0;i&lt;32;i++)&#123; if((n&amp;mark)!=0)&#123; res++; &#125; mark&lt;&lt;=1; &#125; return res;&#125;]]></content>
      <categories>
        <category>算法之美</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
        <tag>二进制</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[旋转数组]]></title>
    <url>%2F2019%2F10%2F29%2F%E6%97%8B%E8%BD%AC%E6%95%B0%E7%BB%84%2F</url>
    <content type="text"><![CDATA[LeetCode第一百八十九题难度：简单题目：给定一个数组，将数组中的元素向右移动 k 个位置，其中 k 是非负数。 1234567891011121314示例 1:输入: [1,2,3,4,5,6,7] 和 k = 3输出: [5,6,7,1,2,3,4]解释:向右旋转 1 步: [7,1,2,3,4,5,6]向右旋转 2 步: [6,7,1,2,3,4,5]向右旋转 3 步: [5,6,7,1,2,3,4]示例 2:输入: [-1,-100,3,99] 和 k = 2输出: [3,99,-1,-100]解释: 向右旋转 1 步: [99,-1,-100,3]向右旋转 2 步: [3,99,-1,-100] 算法思想解决方法有很多，这里提供三种 暴力法 我们可以用一个额外的数组来将每个元素放到正确的位置上，也就是原本数组里下标为 ii 的我们把它放到 (i+k)%数组长度(i+k)%数组长度 的位置。然后把新的数组拷贝到原数组中。 当我们旋转数组 k 次， k%nk%n 个尾部元素会被移动到头部，剩下的元素会被向后移动。在这个方法中，我们首先将所有元素反转。然后反转前 k 个元素，再反转后面 n-kn−k 个元素，就能得到想要的结果。 代码实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849//暴力法public void rotate(int[] nums, int k) &#123; for(int i=0;i&lt;k;i++)&#123; int temp=nums[nums.length-1]; for(int j=nums.length-1;j&gt;0;j--)&#123; nums[j]=nums[j-1]; &#125; nums[0]=temp; &#125;&#125;时间复杂度：O(n*k)，每个元素被移动1步，k次空间复杂度：O(1)“=================================”//额外数组public void rotate(int[] nums, int k) &#123; int[] temp=new int[nums.length]; for(int i=0;i&lt;nums.length;i++)&#123; temp[i]=nums[(nums.length-k+i)%nums.length]; &#125; for(int i=0;i&lt;nums.length;i++)&#123; nums[i]=temp[i]; &#125; System.out.println(Arrays.toString(nums));&#125;时间复杂度：O(n)，每个元素被移动1步，k次空间复杂度：O(n)“=================================”//反转public void rotate(int[] nums, int k) &#123; k%=nums.length; reverse(nums,0,nums.length-1); reverse(nums,0,k-1); reverse(nums,k,nums.length-1);&#125;public static void reverse(int[] nums,int start,int end)&#123; while(start&lt;end)&#123; nums[start]+=nums[end]; nums[end]=nums[start]-nums[end]; nums[start]=nums[start]-nums[end]; start++; end--; &#125;&#125;时间复杂度：O(n)空间复杂度：O(1)]]></content>
      <categories>
        <category>算法之美</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
        <tag>数组</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[阶乘后的零]]></title>
    <url>%2F2019%2F10%2F29%2F%E9%98%B6%E4%B9%98%E5%90%8E%E7%9A%84%E9%9B%B6%2F</url>
    <content type="text"><![CDATA[LeetCode第一百七十二题难度：简单题目：给定一个整数 n，返回 n! 结果尾数中零的数量。 123456789示例 1:输入: 3输出: 0解释: 3! = 6, 尾数中没有零。示例 2:输入: 5输出: 1解释: 5! = 120, 尾数中有 1 个零. 思想分析这个题涉及到了数学数论方面的知识，具体的原理没弄明白。但是可以记录一种简单思路。 首先，只有因数中有2 *5，最后相乘的结果末尾才有0。 其次，在1* 2* 3…n的阶乘中，2的个数肯定比5多。 因此，我们只需要找到1~n中有多少个因子5即可。 重点就在于求1~n中所有的数有多少个因子5。 假设n=10，那么1~ 10中有10/5=2个因子5 假设n=25，那么1~25中有25/5=5，5/5=1；即有6个 假设n=37，那么1~37中有37/5=7，7/5=1，即有8个 假设n=125，那么1~125中有125/5=25，25/5=5，5/5=1，一共31个 ……以此类推，N!中5的个数count=N/5+N/25+N/125…… 代码实现12345678public int trailingZeroes(int n) &#123; int count=0; while(n&gt;0)&#123; count+=n/5; n/=5; &#125; return count;&#125;]]></content>
      <categories>
        <category>算法之美</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
        <tag>数学数论</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[求众数]]></title>
    <url>%2F2019%2F10%2F29%2F%E6%B1%82%E4%BC%97%E6%95%B0%2F</url>
    <content type="text"><![CDATA[LeetCode第一百六十九题难度：简单题目：给定一个大小为 n 的数组，找到其中的众数。众数是指在数组中出现次数大于 ⌊n/2⌋的元素(假设数组是非空的，并且给定的数组总是存在众数)。 12345678示例 1:输入: [3,2,3]输出: 3示例 2:输入: [2,2,1,1,1,2,2]输出: 2 思想分析有三种思路 结合哈希表来实现，以元素的值为键，以元素出现的次数为值。 先将数组排序，由于众数的定义，排序过后nums[nums.length-1]即为众数 使用Boyer-Moore投票算法。该算法是这样的：将众数设置为1，非众数设置为-1。因为众数的性质，可以得到将数组所有元素相加最后得到的值一定是大于0的。 我们维护两个变量，count(计数器)和res(众数) 遍历数组，当count为0时，将当前元素设置为众数 如果出现众数，那么计数器+1，如果出现非众数，计数器-1 如果计数器值小于0，那么将计数器清零，将下一个元素重新设置为众数。 当遍历完数组后，最后的res一定是众数。 代码实现1234567891011//使用Boyer-Moore投票算法来实现public int majorityElement(int[] nums) &#123; int res=0; int count=0; for(int num:nums)&#123; if(count==0) res=num; count+=(res==num?1:-1); &#125; return res;&#125; 这个算法比较巧妙，需要好好体会。]]></content>
      <categories>
        <category>算法之美</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
        <tag>数组</tag>
        <tag>Boyer-Moore投票算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[相交链表]]></title>
    <url>%2F2019%2F10%2F27%2F%E7%9B%B8%E4%BA%A4%E9%93%BE%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[LeetCode第一百六十题难度：简单题目：编写一个程序，找到两个单链表相交的起始节点。 如下面的两个链表：在节点 c1 开始相交。 示例 1：输入：intersectVal = 8, listA = [4,1,8,4,5], listB = [5,0,1,8,4,5], skipA = 2, skipB = 3输出：Reference of the node with value = 8输入解释：相交节点的值为 8 （注意，如果两个列表相交则不能为 0）。从各自的表头开始算起，链表 A 为 [4,1,8,4,5]，链表 B 为 [5,0,1,8,4,5]。在 A 中，相交节点前有 2 个节点；在 B 中，相交节点前有 3 个节点。 示例 2：输入：intersectVal = 2, listA = [0,9,1,2,4], listB = [3,2,4], skipA = 3, skipB = 1输出：Reference of the node with value = 2输入解释：相交节点的值为 2 （注意，如果两个列表相交则不能为 0）。从各自的表头开始算起，链表 A 为 [0,9,1,2,4]，链表 B 为 [3,2,4]。在 A 中，相交节点前有 3 个节点；在 B 中，相交节点前有 1 个节点。 示例 3：输入：intersectVal = 0, listA = [2,6,4], listB = [1,5], skipA = 3, skipB = 2输出：null输入解释：从各自的表头开始算起，链表 A 为 [2,6,4]，链表 B 为 [1,5]。由于这两个链表不相交，所以 intersectVal 必须为 0，而 skipA 和 skipB 可以是任意值。解释：这两个链表不相交，因此返回 null。 注意：如果两个链表没有交点，返回 null.在返回结果后，两个链表仍须保持原有的结构。可假定整个链表结构中没有循环。程序尽量满足 O(n) 时间复杂度，且仅用 O(1) 内存。 思想分析看到题第一时间，想到了哈希表来实现，利用哈希表存储一个链表的所有节点，然后遍历另一个链表，看是否有节点在哈希表中即可，但是空间复杂度较高，为O(m+n)。其实有一种更为简单巧妙地方法 设置两个指针pA和pB分别遍历A和B两链表， 如果pA遍历完了A链表，那就将pA指向B链表的头部继续遍历 同样的，pB遍历完B链表后，指向A链表的头部继续遍历 最后当pA和pB相等时，如果pA和pB为空，那么说明两链表不相交；反之，两链表相交。 代码实现1234567891011public ListNode getIntersectionNode(ListNode headA, ListNode headB) &#123; if(headA==null||headB==null) return null; ListNode pA=headA; ListNode pB=headB; while(pA!=pB)&#123; pA=(pA==null?headB:pA.next); pB=(pB==null?headA:pB.next); &#125; return pA;&#125; 不得不说，这个方法很是巧妙。]]></content>
      <categories>
        <category>算法之美</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
        <tag>链表</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅谈Java I/O系统]]></title>
    <url>%2F2019%2F10%2F27%2F%E6%B5%85%E8%B0%88Java-I-O%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[Java的I/O系统涉及了大量的类，本文只是简单的了解其中一些类的用法和分类，不涉及深层次的分析。 输入和输出Java的I/O库系统也使用流这个概念，它代表任何有能力产出数据源对象或是有能力接收数据的接收端对象。“流”屏蔽了实际I/O设备中处理数据的细节。Java类库中的I/O类分为输入和输出两部分，通过JDK可以查阅到，任何InputStream或Reader派生的子类都有read()方法，用于读取单个字节或者字节数组。同样的任何OutputStream或Writer派生的子类都有Write()方法，用于写单个字节或字节数组。 InputStream类型InputStream的作用是用来表示那些从不同数据源产生输入的类，这些数据源包括： 字节数组 文件 “管道”，工作方式与实际管道类似，即从一端输入，从另一端输出 一个由其他流组成的序列，以便我们可以将它们收集合并到一个流内 其他数据源，如网络等 每一种数据源都有相应的InputStream子类。另外FilterInputStreamu也属于一种InputStream，为“装饰器”类提供基类。 ByteArrayInputStream 构造方法传递一个字节数组作为其缓冲区ByteArrayInputStream(byte[] buf)ByteArrayInputStream(byte[] buf, int offset, int length) 作用将其缓冲区(构造参数的字节数组)作为数据源，从中读取数据进输入流。 常用方法 int available()在没有阻塞的情况下所能读取的字节数。对于文件来说，就是整个文件 void mark(int readAheadLimit)设置流中的当前标记位置。 void reset()将缓冲区的位置重置为标记位置。和mark()搭配使用。 boolean markSupported()测试此 InputStream 是否支持 mark/reset。 long skip(long n)从此输入流中跳过 n 个输入字节。 测试代码 1234567891011121314151617181920212223byte[] res = &quot;Hello ByteArrayInputStream&quot;.getBytes();//使用字节数组作为缓冲区ByteArrayInputStream bin = new ByteArrayInputStream(res);int count=0;//利用available()方法判断是否到数据源末尾while (bin.available() != 0) &#123; char ch = (char) bin.read(); count++; //在空格字符后面做标记 if(ch==&apos; &apos;) bin.mark(count+1); System.out.print(ch); //当第一次读到数据源末尾时将缓冲区位置重置到标记位置 if (bin.available() == 0&amp;&amp;count&lt;res.length+1) &#123; System.out.println(); bin.reset(); &#125;&#125;“===========================”Output：Hello ByteArrayInputStreamByteArrayInputStream FileInputStream将文件作为其数据源，通过构造方法绑定一个文件。方法和ByteArrayInputStream类似，比较常用也比较简单 PipedInputStream产生用于写入相关PipedOutputStream的数据，实现管道化概念 构造方法 PipedInputStream()创建尚未连接的 PipedInputStream。 PipedInputStream(PipedOutputStream src)创建 PipedInputStream，以使其连接到传送输出流 src。 作用多用于多线程环境。数据由某个线程从 PipedInputStream 对象读取，并由其他线程将其写入到相应的 PipedOutputStream。不建议对这两个对象尝试使用单个线程，因为这样可能会死锁该线程。传送输入流包含一个缓冲区，可在缓冲区限定的范围内将读操作和写操作分离开。 常用方法 void connect(PipedOutputStream src)使此传送输入流连接到传送输出流 src。如果使用无参构造方法创建了一个尚未连接的流，那么要先调用该方法和一个输出流连接 int available()返回可以不受阻塞地从此输入流中读取的字节数量。 测试代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556//创建一个接收线程public class Receiver implements Runnable &#123; public PipedInputStream in = new PipedInputStream(); @Override public void run() &#123; try &#123; 将管道中的数据读取出来 System.out.println(&quot;开始使用管道流&quot;); System.out.println(new String(in.readAllBytes())); System.out.println(&quot;数据接收完毕&quot;); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125;//创建一个发送线程public class Sender implements Runnable &#123; public PipedOutputStream out = new PipedOutputStream(); @Override public void run() &#123; String msg = &quot;Hello Receiver&quot;; try &#123; //将数据写入到输出流中 out.write(msg.getBytes()); out.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125;//主线程public class Piped &#123; public static void main(String[] args) throws IOException, InterruptedException &#123; Sender send=new Sender(); Receiver rece = new Receiver(); //连接管道 send.out.connect(rece.in); //rece.in.connect(send); 两种方式效果都一样 //先启动发送线程 new Thread(send).start(); Thread.sleep(100); new Thread(rece).start(); &#125;&#125;“=====================”Output：开始使用管道流Hello Receiver数据接收完毕 在本例中，是由一个线程使用管道输出流将数据写入到流中，另一个线程使用管道输入流将数据从流中读取到内存。 SequenceInputStream序列化流，将两个或多个InputStream对象传换成单一InputStream 构造方法SequenceInputStream(Enumeration&lt;? extends InputStream&gt; e)将多个输入流转换为单一输入流SequenceInputStream(InputStream s1, InputStream s2)将两个输入流转换为单一输入流 作用表示其他输入流的逻辑串联。它从输入流的有序集合开始，并从第一个输入流开始读取，直到到达文件末尾，接着从第二个输入流读取，依次类推，直到到达包含的最后一个输入流的文件末尾为止。 常用方法 int available()返回当前流中可用的字节数。 测试代码 12345678910111213ByteArrayInputStream bin1 = new ByteArrayInputStream(&quot;hello&quot;.getBytes());ByteArrayInputStream bin2 = new ByteArrayInputStream(&quot;SequenceInputStream&quot;.getBytes());//创建序列化流，将两个输入流转换成单一输入流SequenceInputStream in = new SequenceInputStream(bin1, bin2);int ch=0;//不能使用available()方法，否则只能读取第一个流的数据while ((ch = in.read()) != -1) &#123; System.out.print((char)ch);&#125;“=======================”Output：helloSequenceInputStream OutputStream类型和InputStream类型对应的，也有几种输出流类型 ByteArrayOutputStream 构造方法ByteArrayOutputStream()创建一个新的字节数组输出流。ByteArrayOutputStream(int size)创建一个新的字节数组输出流，它具有指定大小的缓冲区容量（以字节为单位）。 作用将数据写入到内部缓冲区中 常用方法 String toString(String enc)将缓冲区的内容转换为字符串，根据指定的字符编码将字节转换成字符 byte[] toByteArray()创建一个新分配的字节数组。 String toString()将缓冲区的内容转换为字符串，根据平台的默认字符编码将字节转换成字符。 示例代码 1234567891011121314151617ByteArrayOutputStream bou = new ByteArrayOutputStream();int read;//从将控制台输入的数据写入到缓冲区中while ((read=System.in.read())!=10)&#123; bou.write(read);&#125;//将缓冲区数据转换为字符串输出System.out.println(bou.toString());“=================”Input：qwertyuOutput：qwertyu FileOutputStream比较常用，和FileInputStream对应使用。 PipedOutputStream和管道输入流搭配使用，示例代码见前面PipedInputStream流 添加属性和有用的接口Jaav的I/O库需要多种不同功能的组合，这正是装饰器模式的理由所在。FilterInputStream和FilterOutputStream用于装饰InputStream和OutputStream字节流。它们分别继承自基类InputStream和OutputStream。 通过FilterInputStream从InputStream读取数据FilterInputStream有不同的子类，能够提供不同的功能 DataInputStream 构造方法传递一个InputStream实现类对象 作用和DataOutputStream搭配使用，允许应用程序以与机器无关方式从基础输入流中读取基本Java数据类型和String类型。与机器无关的方式也就是说在不同的机器上使用该流传递数据都是正确的。 常用方法 readxxx()readByte、readShort…一系列的read方法以相应的方式从流中读取数据。读取的方法要和写入的方法对应(如果使用writeBoolean()写入，那么就要用readBoolean()读取) readUTF读取字符串数据 当使用readByte()读取数据时，每一个字节都是有效的，不能使用返回值是否为-1来判断是否读取到文件末尾，可以使用处理异常的方法或者是available()方法 12345678910111213141516171819DataInputStream din = new DataInputStream(new ByteArrayInputStream( //这是自己写的一个类，read方法返回一个字符串，通过getBytes()得到byte数据传递给ByteArrayInputStream对象 BufferedInputFile.read(&quot;.\\src\\eighteenth\\formattedmemoryinput\\FormattedMemoryInput.java&quot;).getBytes()));//当使用readByte()方法一次一个字节的读取字符，那么任何字节的值都是合法效果//此时方法的返回值不能用来检测输入是否结束。这是我们有两种方法//这是第一种，使用捕获异常的方式来进行流控制(不是很推荐)// try &#123;// while (true) &#123;// System.out.println((char) din.readByte());// &#125;// &#125; catch (EOFException e) &#123;// System.out.println(&quot;End of Stream&quot;);// &#125;//第二种方法，使用available()方法，该方法的字面意思就是//“在没有阻塞情况下所能读取的字节数while (din.available() != 0) &#123; System.out.println((char) din.readByte());&#125; BufferedInputStream 构造方法传递一个InputStream子类对象。 作用对字节输入流进行缓冲，防止每次读写时都得进行实际操作，能够很好的加快读写速度。 常用方法基本上和InputStream提供的方法一样 通过FilterOutputStream从OutputStream读取数据和FilterInputStream对应的，FilterOutputStream也有一些子类，用于提供不同的功能 DataOutputStream 构造方法传递一个OutputStream实现类对象 作用和DataInputStream一起使用，将各种基本数据类型以及String类型格式化输出到流中，这样一来，任何机器上的任何DataInputStream都能够读取它们。 常用方法 writexxx()以不同的方式将数据格式化写入到流中，当使用DataInputStream读取这些数据时，要使用和写入对应的读取方法。 1234567891011121314151617181920212223242526//创建DataOutputStream对象，传递缓冲字节流DataOutputStream out = new DataOutputStream( new BufferedOutputStream( new FileOutputStream(&quot;.\\src\\eighteenth\\storingandrecoveringdata\\Data.txt&quot;)));out.writeDouble(3.1415926535);out.writeUTF(&quot;That was Pi&quot;);out.writeDouble(1.41413);out.writeUTF(&quot;Square root of 2&quot;);out.close();//创建DataInputStream对象，传递缓冲字节流DataInputStream in = new DataInputStream( new BufferedInputStream( new FileInputStream(&quot;.\\src\\eighteenth\\storingandrecoveringdata\\Data.txt&quot;)));System.out.println(in.readDouble());System.out.println(in.readUTF());System.out.println(in.readDouble());System.out.println(in.readUTF());“===============”Output：3.1415926535That was Pi1.41413Square root of 2 PrintStream 构造方法传递OutputStream子类对象或者直接传递文件对象或文件名 作用用于产生格式化输出，PrintStream会捕获所有的IOException(因此必须使用checkError()自行测试错误状态，如果出现错误返回true)，PrintStream不能以平台无关的方式处理换行动作(PrintWriter可以) 常用方法 println()将数据输出到流中并换行 append()向流中追加数据并返回该流 更多方法见API手册 BufferedOutputStream 构造方法传递一个OutputStream对象 作用对OutputStream进行了修改，对数据流使用了缓冲技术，因此每次向流写入时，不必每次都进行实际的物理写动作，因此它的速度更快。一般在进行输出时，使用该流更多一些。 Reader和Writer设计Reader和Writer继承层次结构主要是为了国际化，In/OutputStream只能处理8位字节流，并且不能很好的处理16位的Unicode字符。因此设计了Reader和Writer字符流与InputStream以及OutputStream对应的，Reader和Writer也有相应的子类 1234567891011121314151617181920212223242526272829&quot;========================================&quot;基类InputStream ReaderOutputStream Writer&quot;========================================&quot;文件流FileInputStream FileReaderFileOutputStream FileWriter&quot;========================================&quot;数组流ByteArrayInputStream CharArrayReaderByteArrayOutputStream CharArrayWriter&quot;========================================&quot;管道流PipedInputStream PipedReaderPipedOutputStream PipedWriter&quot;========================================&quot;转换流：字节流通向字符流的桥梁InputStreamReaderOutputStreamWriter&quot;========================================&quot;字符串流(字节流的已经废弃)StringReaderStringWriter 更改流的行为对于InputStream和OutputStream来说，我们会使用FilterInputStream和FilterOutputStream装饰器的子类来对流添加一些功能。对于Reader和Writer，也会使用一些装饰器来改变流的功能 1234567891011121314151617&quot;========================================&quot;过滤器FilterInputStream FilterReaderFilterOutputStream FilterWriter(抽象类，无子类)&quot;========================================&quot;缓冲流 直接继承自Reader和WriterBufferedInputStream BufferedReaderBufferedOutputStream BufferedWriter&quot;========================================&quot;打印流 直接继承自Reader和WriterPrintStream PrintWriter(构造参数技能接收Writer对象也能接收OutputStream对象)&quot;========================================&quot;数据流 DataInputStream DataInputStream(当需要使用readLine()方法时应该使用BufferedReader) 可以看出字符流装饰器的继承体系和字节流的有所不同(具体参考API类库)有一点要注意：当我们需要使用readLine()方法时，一定不能使用DataInputStream，而应该使用BufferedReader。除了这一点，DataInputStream仍是首选。 RandomAccessFle该流适用于由大小已知的记录组成的文件，我们可以使用seek()方法将记录从一处转移到另一处，然后读取和修改记录。RandomAccessFile不是InputStream或者OutputStream继承层次体系结构中的一部分。除了实现DataInput和DataOutput(DataInput/OutputStreamStream实现了这两个接口)之外，它和这两个继承层次结构没有任何关系。 构造方法RandomAccessFile(File file, String mode)RandomAccessFile(String name, String mode)传递文件对象或者文件路径名并指定模式(“r”随机读，”rw”既读由写) 作用支持对随机存取文件的读取和写入 常用方法 readxxx以各种形式读取数据(类似于DataInputStream) writexxx以各种形式写入数据(类似于DataOutputStream) read/writeUTF()对字符串进行读写操作 seek()将指针移到距离文件开头一定字节的偏移量，从此处开始读取数据(更多方法参见API) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859** * 使用RandomAccessFile对象，该对象类似于组合了DataInputStream和DataOutputStream * (因为它实现了DataOut和DataInput接口) * 该对象的seek()方法能够移动到文件的某个字节处。 * * 如下，因为double是8字节，因此使用seek方法，将指针移动到第5个double值并修改它 */public class UsingRandomAccessFile &#123; static String file = &quot;.\\src\\eighteenth\\usingrandomaccessfile\\UsingRandomAccessFile.dat&quot;; static void display() throws IOException &#123; RandomAccessFile rf = new RandomAccessFile(file, &quot;r&quot;); for (int i = 0; i &lt; 7; i++) &#123; System.out.println(&quot;Value &quot; + i + &quot;: &quot; + rf.readDouble()); &#125; System.out.println(rf.readUTF()); rf.close(); &#125; public static void main(String[] args) throws IOException &#123; RandomAccessFile rf = new RandomAccessFile(file, &quot;rw&quot;); for (int i = 0; i &lt; 7; i++) &#123; rf.writeDouble(i * 1.414); &#125; rf.writeUTF(&quot;The end of the file&quot;); rf.close(); display(); System.out.println(&quot;=================&quot;); rf = new RandomAccessFile(file, &quot;rw&quot;); //调用seek()方法 rf.seek(5 * 8); rf.writeDouble(47.0001); rf.close(); display(); &#125;&#125;”=====================“Output：Value 0: 0.0Value 1: 1.414Value 2: 2.828Value 3: 4.242Value 4: 5.656Value 5: 7.069999999999999Value 6: 8.484The end of the file=================Value 0: 0.0Value 1: 1.414Value 2: 2.828Value 3: 4.242Value 4: 5.656//使用seek()方法后指针移动到这里Value 5: 47.0001Value 6: 8.484The end of the file I/O的典型使用方式我们可以通过不同的方式组合I/O流，但是我们可能用到的组合不多，介绍几种典型的组合 缓冲输入文件如果要打开一个文件用于字符输入 可以使用String或者File对象作为文件名的FileReader。 为了提高速度，我们可以使用缓冲，因此可以将FileReader对象作为参数传递给BufferedReader构造器，得到一个BufferedReader对象。 并且该对象提供一个readLine()方法，当读取到文件末尾时，返回null。 12345678910111213//该read()方法传递一个文件名，返回文件的字符串表示public static String read(String filename) throws IOException &#123; //创建缓冲字符输入流对象 BufferedReader br = new BufferedReader(new FileReader(filename)); String s; StringBuilder sb = new StringBuilder(); //readLine()方法一次读取一行，但是不读取换行符，因此要自己加上&quot;\n&quot; while ((s = br.readLine()) != null) &#123; sb.append(s + &quot;\n&quot;); &#125; br.close(); return sb.toString();&#125; 从内存输入下面的示例中，从上面说的read方法中读入文件返回的String结果被用来创建一个StringReader，然后调用read()每次读取一个字符，并将它发送到控制台。 123456789101112131415/** * 从内存中读取数据，使用StringReader，构造参数传递一个字符串 * 使用StringReader对象的read方法从字符串中读取内容 */public class MemoryInput &#123; public static void main(String[] args) throws IOException &#123; //BufferedInputFile.read()即为上面介绍的从文件读取数据返回String对象 //利用String构造StringReader对象，从String中读取数据 StringReader sr = new StringReader(BufferedInputFile.read(&quot;.\\src\\eighteenth\\memoryinput\\MemoryInput.java&quot;)); int c; while ((c = sr.read()) != -1) &#123; System.out.println((char) c); &#125; &#125;&#125; 格式化内存输入要读取格式化数据，可以使用DataInputStream，这是一个面向字节的I/O类。因此我们要使用InputStream对象。 12345678910111213141516171819202122/** * 格式化内存输入 * 要读取格式化数据，可以使用DataInputStream，它是一个字节流。 * 构造方法传递一个InputStream子类对象 * 这里传递的是ByteArrayInputStream对象 * 构造BytrArrayInputStream对象时传递一个字节数组， * 该对象从字节数组中读取数据 */public class FormattedMemoryInput &#123; public static void main(String[] args) throws IOException &#123; //同样的，BufferedInputFile.read()方法返回一个字符串 DataInputStream din = new DataInputStream(new ByteArrayInputStream( BufferedInputFile.read(&quot;.\\src\\eighteenth\\formattedmemoryinput\\FormattedMemoryInput.java&quot;).getBytes())); //前面说过，DataInputStream的readByte()方法读取的每一个字节都是有效的 //因此无法根据返回值来判断是否到达文件末尾，应该使用available()方法 while (din.available() != 0) &#123; System.out.println((char) din.readByte()); &#125; &#125;&#125; 基本的文件输出FileWriter对象可以向文件写入数据。 创建一个与指定文件绑定的FileWriter对象 为了将快速度，我们一般使用缓存，因此将该对象传递给BufferedWriter构造器，创建一个缓冲字符流对象 有时候为了提供格式化机制，还可以包装成PrintWriter。 12345678910111213141516static String filename = &quot;.\\src\\eighteenth\\basefileoutput\\BasicFileOutput.out&quot;;//创建缓冲字符流，传递一个Reader流对象，这里传递的是StringReader对象//创建StringReader对象时构造参数传递一个String，流从String中读取数据BufferedReader bin = new BufferedReader(new StringReader( BufferedInputFile.read(&quot;.\\src\\eighteenth\\basefileoutput\\BasicFileOutput.java&quot;)));//创建FilterWriter流对象，传递一个Writer流对象，向文件中写入数据PrintWriter pw = new PrintWriter(new BufferedWriter(new FileWriter(filename)));int linecount = 1;String s;//使用该方法像文件中写入数据时，每写入一行数据会自动写入一个换行符while ((s = bin.readLine()) != null) &#123; pw.println(linecount++ + &quot;: &quot; + s);&#125;pw.close();bin.close(); 文件输出快捷方式在前面的示例中，为了使用带缓冲的PrintWriter，需要创建三各类来进行装饰，还有一种简单方法，直接给PrintWriter传递文件名或File对象，PrintWriter利用该构造器自己实现缓冲。 123456789101112131415BufferedReader bin = new BufferedReader( new StringReader(BufferedInputFile.read(srcfilename)));//直接传递文件名，船舰带缓存的打印流对象PrintWriter pou = new PrintWriter(desfilename);int linecount = 1;String res;while ((res = bin.readLine()) != null) &#123; pou.println(linecount++ + &quot;: &quot; + res);&#125;//使用完后关闭流pou.close();bin.close();System.out.println(BufferedInputFile.read(desfilename)); 存储和恢复数据PrintWriter可以对数据进行格式化，以便我们阅读。但是为了输出可供另一个流恢复的数据，我们需要使用DataOutputStream写入数据，并用DataInputStream恢复数据。 12345678910111213141516171819//创建DataOutputStream对象，传递缓冲字节流DataOutputStream out = new DataOutputStream( new BufferedOutputStream( new FileOutputStream(&quot;.\\src\\eighteenth\\storingandrecoveringdata\\Data.txt&quot;)));out.writeDouble(3.1415926535);out.writeUTF(&quot;That was Pi&quot;);out.writeDouble(1.41413);out.writeUTF(&quot;Square root of 2&quot;);out.close();//创建DataInputStream对象，传递缓冲字节流DataInputStream in = new DataInputStream( new BufferedInputStream( new FileInputStream(&quot;.\\src\\eighteenth\\storingandrecoveringdata\\Data.txt&quot;)));System.out.println(in.readDouble());System.out.println(in.readUTF());System.out.println(in.readDouble());System.out.println(in.readUTF()); 使用这一对流，在一台机器上写入，无论在哪一台机器上读取写入的结果，都是准确的，因为它们以和机器无关的方式读写数据。 标准I/O按照标准I/O模型，Java提供了Syatem.in、System.out、System.err。 System.out已经被事先包装成了PrintStream对象，可以进行格式化输出，将数据打印到控制台。 Systeam.err也是PrintStream对象 Syatem.in是一个未被包装过的未经加工的InputStream对象。 这意味着我们可以直接使用前两个输出流，但是在使用System.in时必须对其进行包装。 从标准输入中读取一般我们使用readLine()进行一行一行的读取，因此，我们将System.in包装成BufferedReader。由字节流转换为字符流，我们需要使用InputStreamReader。 123456789101112//利用System.in创建字符缓冲输入流对象BufferedReader stdin = new BufferedReader(new InputStreamReader(System.in));String s;//读取控制台输入的字符，并通过System.out回显到控制台中while ((s = stdin.readLine()) != null &amp;&amp; s.length() != 0) &#123; System.out.println(s);&#125;“=======================”Output：qwertqwert 将System.out转换为PrintWriterSystem.out是一个PrintStream，而PrintStream是一个OutputStream。PrintWriter有一个接收OutputStream对象的构造器 12345//使用两个参数的构造器，并将第二个设置为true，一边开启自动刷新功能，否则会看不到输出PrintWriter pw = new PrintWriter(System.out, true); pw.println(&quot;hello,world&quot;); //如果采用一个参数的构造器，那么在之后要关闭流，才能将pw中的数据刷新到控制台 //pw.close() 标准I/O重定向Java的System类提供了一些简单地静态方法，以支持我们对标准输入的、输出、错误I/O流进行重定向 setIn(InputStream) setOut(PrintStream) setErr(PrintStream) 123456789101112131415161718192021222324252627//保存控制台标准输出流的引用PrintStream console = System.out;//创建缓冲字节输入流BufferedInputStream in = new BufferedInputStream(new FileInputStream(&quot;.\\src\\eighteenth\\redirecting\\Redirceting.java&quot;));//创建格式化流PrintStream out = new PrintStream( new BufferedOutputStream( new FileOutputStream(&quot;.\\src\\eighteenth\\redirecting\\test.out&quot;)));//经标准输入流重定向到Redirceting.java//将标准输出流重定向到test.out// 将错误流也重定向到test.outSystem.setIn(in);System.setOut(out);System.setErr(out);//利用标准IO将一个文件的数据拷贝到另一个文件中BufferedReader br = new BufferedReader(new InputStreamReader(System.in));String s;while ((s = br.readLine()) != null) &#123; System.out.println(s);&#125;//关闭重定向的输出流out.close();//将标准输出流恢复到控制台System.setOut(console); I/O重定向操纵的是字节流，而不是字符流。 序列化流见Java编程思想和API类库]]></content>
      <categories>
        <category>Java编程思想</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>I/O</tag>
        <tag>Java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[买股票的最佳时机]]></title>
    <url>%2F2019%2F10%2F26%2F%E4%B9%B0%E8%82%A1%E7%A5%A8%E7%9A%84%E6%9C%80%E4%BD%B3%E6%97%B6%E6%9C%BA%2F</url>
    <content type="text"><![CDATA[LeetCode第一百二十一、二十二题难度：简单 第一百二十一题题目：给定一个数组，它的第 i 个元素是一支给定股票第 i 天的价格。如果你最多只允许完成一笔交易（即买入和卖出一支股票），设计一个算法来计算你所能获取的最大利润。注意你不能在买入股票前卖出股票。 1234567891011示例 1:输入: [7,1,5,3,6,4]输出: 5解释: 在第 2 天（股票价格 = 1）的时候买入，在第 5 天（股票价格 = 6）的时候卖出，最大利润 = 6-1 = 5 。 注意利润不能是 7-1 = 6, 因为卖出价格需要大于买入价格。示例 2:输入: [7,6,4,3,1]输出: 0解释: 在这种情况下, 没有交易完成, 所以最大利润为 0。 思想分析这道题用到了动态规划的思想，维护两个变量 当前元素前的最小元素值minprice 当前利润res 当遍历到当前节点时，判断当前元素值和minprice的差值是否大于当前利润，如果大于，更新利润。 代码实现12345678910111213141516171819 public int maxProfit(int[] prices) &#123; //首先考虑边界情况，当数组长度为0时 if(prices.length==0)&#123; return 0; &#125; //假设初始最小值是prices[0] int minprice=prices[0]; //初始利润为0 int res=0; for(int i=1;i&lt;prices.length;i++)&#123;//如果当前元素值小于最小值，更新最小值 if(minprice&gt;prices[i]) minprice=prices[i];//更新利润 else if(res&lt;prices[i]-minprice) res=prices[i]-minprice; &#125; return res; &#125; 第一百二十一题题目：给定一个数组，它的第 i 个元素是一支给定股票第 i 天的价格。设计一个算法来计算你所能获取的最大利润。你可以尽可能地完成更多的交易（多次买卖一支股票）。注意：你不能同时参与多笔交易（你必须在再次购买前出售掉之前的股票）。 12345678910111213示例 1:输入: [7,1,5,3,6,4]输出: 7解释: 在第 2 天（股票价格 = 1）的时候买入，在第 3 天（股票价格 = 5）的时候卖出, 这笔交易所能获得利润 = 5-1 = 4 。 随后，在第 4 天（股票价格 = 3）的时候买入，在第 5 天（股票价格 = 6）的时候卖出, 这笔交易所能获得利润 = 6-3 = 3 。示例 2:输入: [1,2,3,4,5]输出: 4解释: 在第 1 天（股票价格 = 1）的时候买入，在第 5 天 （股票价格 = 5）的时候卖出, 这笔交易所能获得利润 = 5-1 = 4 。 注意你不能在第 1 天和第 2 天接连购买股票，之后再将它们卖出。 因为这样属于同时参与了多笔交易，你必须在再次购买前出售掉之前的股票。 思想分析这道题和前一道题不同，它可以多次买卖一只股票，要求所得利润的总和最大。这时候，我们应该想到使用贪心算法。对于这道题，今天买，不管之后是否会赚的更多，只要明天能赚我就卖，这就是贪心。 代码实现12345678910111213public int maxProfit(int[] prices) &#123; int res = 0; //记录差值 int Dvalue = 0; for(int i = 0; i &lt; prices.length - 1; i++)&#123; Dvalue = prices[i+1] - prices[i]; if (Dvalue &gt; 0)&#123; res += Dvalue; &#125; &#125; return res;&#125;]]></content>
      <categories>
        <category>算法之美</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
        <tag>动态规划</tag>
        <tag>贪心算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[杨辉三角问题]]></title>
    <url>%2F2019%2F10%2F26%2F%E6%9D%A8%E8%BE%89%E4%B8%89%E8%A7%92%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[LeetCode第一百一十八、一十九题难度：简单 如图所示 12345678910示例:输入: 5输出:[ [1], [1,1], [1,2,1], [1,3,3,1], [1,4,6,4,1]] 第一百一十八题题目(第一百一十八)：给定一个非负整数 numRows，生成杨辉三角的前 numRows 行。 思想分析对于杨辉三角 每一行的第一个元素和最后一个元素为1 剩下的每一个元素都是它上一行正对元素及其前一个元素之和，即有(i,j)=(i-1,j-1)+(i-1,j)。 代码实现123456789101112131415161718192021public List&lt;List&lt;Integer&gt;&gt; generate(int numRows) &#123; List&lt;List&lt;Integer&gt;&gt; res=new ArrayList&lt;&gt;(numRows); //先将数组里的空引用初始化 for(int i=0;i&lt;numRows;i++)&#123; res.add(new ArrayList&lt;Integer&gt;()); &#125; for(int i=0;i&lt;numRows;i++)&#123; for(int j=0;j&lt;=i;j++)&#123; if(j==0||j==i) res.get(i).add(1); //(i,j)=(i-1,j-1)+(i-1,j); else res.get(i).add(res.get(i-1).get(j-1)+res.get(i-1).get(j)); &#125; &#125; return res;&#125; 第一百一十九题题目：给定一个非负索引 k，其中 k ≤ 33，返回杨辉三角的第 k 行(行数从0开始) 123示例:输入: 3输出: [1,3,3,1] 思想分析将每一行元素保存到集合中，求下一行元素时，利用集合中已有的元素求得当前行元素值，并存入集合中，覆盖上一行的元素。 代码实现123456789101112public List&lt;Integer&gt; getRow(int rowIndex) &#123; List&lt;Integer&gt; cur = new ArrayList&lt;&gt;(); cur.add(1); for (int i = 0; i &lt; rowIndex; i++) &#123; for (int j = i; j &gt; 0; j--) &#123; cur.set(j, cur.get(j - 1) + cur.get(j)); &#125; cur.add(1); &#125; return cur;&#125;]]></content>
      <categories>
        <category>算法之美</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
        <tag>迭代</tag>
        <tag>杨辉三角</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[路径总和]]></title>
    <url>%2F2019%2F10%2F25%2F%E8%B7%AF%E5%BE%84%E6%80%BB%E5%92%8C%2F</url>
    <content type="text"><![CDATA[LeetCode第一百一十二题难度：简单题目：给定一个二叉树和一个目标和，判断该树中是否存在根节点到叶子节点的路径，这条路径上所有节点值相加等于目标和。 1234567891011示例: 给定如下二叉树，以及目标和 sum = 22， 5 / \ 4 8 / / \ 11 13 4 / \ \ 7 2 1返回 true, 因为存在目标和为 22 的根节点到叶子节点的路径 5-&gt;4-&gt;11-&gt;2。 思想分析这道题思想比较简单，但是有两个点容易出错 目标和是根节点到叶子节点的路径和，一定是叶子节点。在递归的过程中如果到当前节点时路径和为sum，一定要判断当前节点是不是叶子节点 不能提前截断，如果遍历到当前节点时，路径和等于目标和，但是当前节点不是叶子节点，不要急着返回false，继续往下遍历。举个例子1234567891011对于这样一颗二叉树，目标和为-1 1 / \ -2 8 / / \ 1 13 4 / \ \ -1 2 1 当遍历到-2节点时，当前路径和为1-2=-1=sum，但是很明显，-2节点不是叶子节点，因此不能直接返回true但是也不能为了节省时间，直接返回false，因为从上面可以看到，继续往下遍历时，最终的路径和为1-2+1-1=-1=sum，仍然等于sum，因此返回true 代码实现123456789101112public boolean hasPathSum(TreeNode root, int sum) &#123; if(root==null) return false; sum-=root.val; if(sum==0&amp;&amp;root.left==null&amp;&amp;root.right==null) return true; //这里一定不能为了节省时间直接返回false // if(sum==0) // return false; return hasPathSum(root.left,sum)||hasPathSum(root.right,sum); &#125;]]></content>
      <categories>
        <category>算法之美</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
        <tag>递归</tag>
        <tag>二叉树</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二叉树的最小深度]]></title>
    <url>%2F2019%2F10%2F25%2F%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E6%9C%80%E5%B0%8F%E6%B7%B1%E5%BA%A6%2F</url>
    <content type="text"><![CDATA[LeetCode第一百一十一题难度：简单题目：给定一个二叉树，找出其最小深度。最小深度是从根节点到最近叶子节点的最短路径上的节点数量。(叶子节点是指没有子节点的节点) 12345678910示例给定二叉树 [3,9,20,null,null,15,7], 3 / \ 9 20 / \ 15 7返回它的最小深度 2. 思想分析前面做过了二叉树的最大深度题，这个会稍微难一点，对于当前节点，有三种情况 当前节点为空此时返回0 当前节点左右子树都不为空此时说明当前节点是叶子节点，返回1 当前节点左子树或右子树有一个为空此时，当前节点的最小深度就是它不为空的子树的最小深度！！这点很重要 当前节点左右子树都不为空当前节点的最小深度为它左右子树中较小的深度 代码实现有两种解法，一种是递归，一种类似于队列 递归解法12345678910111213141516public int minDepth(TreeNode root) &#123; //如果为空，返回0 if(root == null) return 0; //1.左孩子和有孩子都为空的情况，说明到达了叶子节点，直接返回1即可 if(root.left == null &amp;&amp; root.right == null) return 1; //2.如果左孩子和由孩子其中一个为空，那么需要返回比较大的那个孩子的深度 int m1 = minDepth(root.left); int m2 = minDepth(root.right); //这里其中一个节点为空，说明m1和m2有一个必然为0，所以可以返回m1 + m2 + 1; if(root.left == null || root.right == null) return m1 + m2 + 1; //3.最后一种情况，也就是左右孩子都不为空，返回最小深度+1即可 return Math.min(m1,m2) + 1;&#125; 递归的程序比较容易理解，最后测试时间1ms，内存消耗不太理想，为37.7M 队列解法将树节点和它的深度封装成一个类，当遇到叶子节点时，直接返回深度即可 12345678910111213141516171819202122232425262728293031323334353637//将树节点和它的深度封装成一个类class Node&#123; TreeNode t; int deepth; Node(TreeNode t,int deepth)&#123; this.t=t; this.deepth=deepth; &#125;&#125;public int minDepth(TreeNode root) &#123; if(root == null) return 0; int deepth=1; //使用List集合模仿队列 List&lt;Node&gt; list=new ArrayList(); list.add(new Node(root,1)); while(!list.isEmpty())&#123; Node DeepthNode=list.remove(0); TreeNode temp=DeepthNode.t; //如果当前节点为树节点，直接返回深度即可 if(temp.left==null&amp;&amp;temp.right==null)&#123; return DeepthNode.deepth; &#125; //如果当前节点含有子节点，将子节点和当前节点深度+1封装后加入集合中。 if(temp.left!=null)&#123; list.add(new Node(temp.left,DeepthNode.deepth+1)); &#125; if(temp.right!=null)&#123; list.add(new Node(temp.right,DeepthNode.deepth+1)); &#125; &#125; throw new RuntimeException();&#125; 这种方法算是宽度优先算法，按照层次遍历的方式，遍历每个节点并记录节点的深度，直到找到叶子节点为止。]]></content>
      <categories>
        <category>算法之美</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
        <tag>递归</tag>
        <tag>二叉树</tag>
        <tag>队列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[判断平衡二叉树]]></title>
    <url>%2F2019%2F10%2F24%2F%E5%88%A4%E6%96%AD%E5%B9%B3%E8%A1%A1%E4%BA%8C%E5%8F%89%E6%A0%91%2F</url>
    <content type="text"><![CDATA[LeetCode第一百一十题难度：简单题目：给定一个二叉树，判断它是否是高度平衡的二叉树。本题中，一棵高度平衡二叉树定义为：一个二叉树每个节点 的左右两个子树的高度差的绝对值不超过1。 123456789101112131415161718192021示例 1:给定二叉树 [3,9,20,null,null,15,7] 3 / \ 9 20 / \ 15 7返回 true 。示例 2:给定二叉树 [1,2,2,3,3,null,null,4,4] 1 / \ 2 2 / \ 3 3 / \ 4 4返回 false 。 思想分析这个题，和前面求二叉树最大深度有些相似，求出节点的左右子树高度，判断相差是否超过1，如果超过1，将标记设置为false。否则计算当前节点的深度，继续递归。 代码实现12345678910111213141516171819202122public class BalancedBinaryTree &#123; boolean res = true; public boolean isBalanced(TreeNode root) &#123; helper(root); return res; &#125; private int helper(TreeNode root) &#123; if (root == null) return 0; //左子树的高度 int left = helper(root.left) + 1; //右子树的高度 int right = helper(root.right) + 1; //在这里将res设置为false if (Math.abs(right - left) &gt; 1) res = false; //当前节点的高度 return Math.max(left, right); &#125;&#125; 还有一种实现方法较为巧妙，也贴一下吧 12345678910111213141516171819202122public boolean isBalanced(TreeNode root) &#123; return downToTop(root)!=-1;&#125;public int downToTop(TreeNode t)&#123; if(t==null) return 0; //求左子树的高度 int left=downToTop(t.left); //如果高度为-1，直接截断返回-1 if(left==-1) return -1; //求右子树的高度 int right=downToTop(t.right); //如果高度为-1，直接截断返回-1 if(right==-1) return -1; //这里很是巧妙，如果左右子树高度相差超过2，说明该树已经不平衡了 //将当前节点高度设为-1，否则说明当前节点仍然是平衡的，那就将当前节点 //高度设为正常高度。 return Math.abs(left-right)&lt;2?Math.max(left,right)+1:-1;&#125; 这个解法仔细想了想感觉很巧妙，很让人佩服。]]></content>
      <categories>
        <category>算法之美</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
        <tag>AVL树</tag>
        <tag>递归</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[有序数组转AVL树]]></title>
    <url>%2F2019%2F10%2F23%2F%E6%9C%89%E5%BA%8F%E6%95%B0%E7%BB%84%E8%BD%ACAVL%E6%A0%91%2F</url>
    <content type="text"><![CDATA[LeetCode第一百零八题难度：简单题目：将一个按照升序排列的有序数组，转换为一棵高度平衡二叉搜索树，本题中，一个高度平衡二叉树是指一个二叉树每个节点 的左右两个子树的高度差的绝对值不超过 1。 12345678910示例:给定有序数组: [-10,-3,0,5,9],一个可能的答案是：[0,-3,9,-10,null,5]，它可以表示下面这个高度平衡二叉搜索树： 0 / \ -3 9 / / -10 5 思想分析一开始看到这个题的时候，第一时间想到的是前面实现的一个AVL树，发现太麻烦了，每次插入一个数据要对节点进行平衡，而平衡又分为4种不同的情况….我的天，当时搞不懂为什么一个简单难度的题目会这么难。就想到可能是自己哪里思路有问题，一看解析才发现自己还是太年轻，居然完全没有利用(或者是忽略)有序数组这个性质。对于一个查找树，它的中序遍历就是有序的，更近一步，对于一个AVL树，它的根节点总是位于两边子树节点的中间。这就很明显了吧，对就是结合二分来实现就会变得异常简单。 代码实现在代码的开始部分，老规矩，总是要检查参数的边界条件，这是最起码的保证。 123456789101112131415161718public TreeNode sortedArrayToBST(int[] nums) &#123; if(nums==null||nums.length==0)&#123; return null; &#125; return toAVL(nums,0,nums.length-1);&#125;public TreeNode toAVL(int[] nums,int left,int right)&#123; if(left&gt;right)&#123; return null; &#125; int mid=(left+right)&gt;&gt;1; //将中间元素插入到根节点中。 TreeNode t=new TreeNode(nums[mid]); t.left=toAVL(nums,left,mid-1); t.right=toAVL(nums,mid+1,right); return t;&#125; 有序数组转AVL树的实现到这里就结束了，发现自己还是需要多练习，太年轻了。]]></content>
      <categories>
        <category>算法之美</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
        <tag>AVL树</tag>
        <tag>递归</tag>
        <tag>数组</tag>
        <tag>二分查找</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二叉树最大深度和层次遍历]]></title>
    <url>%2F2019%2F10%2F23%2F%E4%BA%8C%E5%8F%89%E6%A0%91%E6%9C%80%E5%A4%A7%E6%B7%B1%E5%BA%A6%E5%92%8C%E5%B1%82%E6%AC%A1%E9%81%8D%E5%8E%86%2F</url>
    <content type="text"><![CDATA[LeetCode第一百零四题/一百零七题难度：简单题目(一百零四)：给定一个二叉树，找出其最大深度，二叉树的深度为根节点到最远叶子节点的最长路径上的节点数。 二叉树最大深度思想分析对于一个二叉树中任意一个节点，它的最大深度等于它子树的最大深度+1。并且空节点的深度为0。也就是说，通过递归实现时，递归出口就是当节点为空时。 代码实现123public int maxDepth(TreeNode root) &#123; return root==null?0:Math.max(maxDepth(root.left),maxDepth(root.right))+1;&#125; 二叉树层次遍历题目(一百零七)：给定一个二叉树，返回其节点值自底向上的层次遍历。（即按从叶子节点所在层到根节点所在的层，逐层从左向右遍历） 123456789101112131415例如：给定二叉树 [3,9,20,null,null,15,7], 3 / \ 9 20 / \ 15 7返回其自底向上的层次遍历为：[ [15,7], [9,20], [3]] 思想分析可以使用List&lt; List&lt; Integer&gt;&gt;来实现，将相同层次的节点放到一个List集合中即可。 代码实现123456789101112131415161718192021public List&lt;List&lt;Integer&gt;&gt; levelOrderBottom(TreeNode root) &#123; List&lt;List&lt;Integer&gt;&gt; res=new ArrayList&lt;&gt;(); int deepth=0; //得到的结果是自定向下的层次遍历 levelOrderTree(root,res,deepth); //使用Collections工具类的reverse()方法 //将List反转即得到自下而上的层次遍历 Collections.reverse(res); return res;&#125;public void levelOrderTree(TreeNode t,List&lt;List&lt;Integer&gt;&gt; list,int deepth)&#123; if(t!=null)&#123; if(deepth&gt;=list.size())&#123; list.add(deepth,new LinkedList&lt;&gt;()); &#125; list.get(deepth).add(t.val); levelOrderTree(t.left,list,deepth+1); levelOrderTree(t.right,list,deepth+1); &#125;&#125;]]></content>
      <categories>
        <category>算法之美</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
        <tag>递归</tag>
        <tag>二叉树</tag>
        <tag>遍历</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[相同的树和镜像树]]></title>
    <url>%2F2019%2F10%2F23%2F%E7%9B%B8%E5%90%8C%E7%9A%84%E6%A0%91%E5%92%8C%E9%95%9C%E5%83%8F%E6%A0%91%2F</url>
    <content type="text"><![CDATA[LeetCode第一百题/一百零一题难度：简单题目(一百)：给定两个二叉树，编写一个函数来检验它们是否相同，如果两个树在结构上相同，并且节点具有相同的值，则认为它们是相同的。 相同的树1234567891011121314151617示例 1:输入: 1 1 / \ / \ 2 3 2 3 [1,2,3], [1,2,3]输出: true示例 2:输入: 1 1 / \ 2 2 [1,2], [1,null,2]输出: false 思想分析对于树的问题，尤其是二叉树，几乎都可以用递归进行解决(换个角度也是锻炼了我们的递归能力)。对于递归，很重要的一方面就是要找到递归出口，否则容易栈溢出。本题中，对于两个树的节点，有以下几种情况 都为空，说明当前分支遍历结束并且相等，返回true 只有一个为空，那说明两棵树必定不相等，返回false 都不为空但是值不相等，同上，返回false 都不为空且值相等，说明到当前为止两树相等，继续往下遍历比较。代码实现12345678910111213public boolean isSameTree(TreeNode p, TreeNode q) &#123; if(p==null&amp;&amp;q==null)&#123; return true; &#125; else if(p==null||q==null)&#123; return false; &#125; else if(p.val!=q.val)&#123; return false; &#125; else return isSameTree(p.right,q.right)&amp;&amp;isSameTree(p.left,q.left);&#125; 镜像树题目(一百零一)：给定一个二叉树，检查它是否是镜像对称的 1234567891011121314例如，二叉树 [1,2,2,3,4,4,3] 是对称的。 1 / \ 2 2 / \ / \3 4 4 3但是下面这个 [1,2,2,null,3,null,3] 则不是镜像对称的: 1 / \ 2 2 \ \ 3 3 思想分析可以使用递归和迭代两种方法，如果使用递归，那么和上面的思路一摸一样，只不过细节稍微有改动。 代码实现12345678910111213141516171819202122public boolean isSymmetric(TreeNode root) &#123; //边界条件 if(root==null)&#123; return true; &#125; return Judge(root.left,root.right);&#125;public boolean Judge(TreeNode p,TreeNode q)&#123; if(p==null&amp;&amp;q==null)&#123; return true; &#125; else if(p==null||q==null)&#123; return false; &#125; else if(p.val!=q.val)&#123; return false; &#125; else&#123; return Judge(p.left,q.right)&amp;&amp;Judge(p.right,q.left); &#125;&#125; 对于递归问题，尤其是树的递归，可以将通过个例来推导(例如将两层二叉树带入方法进行测试)，由于递归的性质，如果层数比较小的各种个例能够满足，那么递归应该没有问题。]]></content>
      <categories>
        <category>算法之美</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
        <tag>递归</tag>
        <tag>二叉树</tag>
        <tag>镜像树</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[爬楼梯]]></title>
    <url>%2F2019%2F10%2F23%2F%E7%88%AC%E6%A5%BC%E6%A2%AF%2F</url>
    <content type="text"><![CDATA[LeetCoode第七十题难度：简单题目：假设你正在爬楼梯。需要 n (n为正整数)阶你才能到达楼顶。每次你可以爬1或2个台阶。你有多少种不同的方法可以爬到楼顶呢？ 1234567891011121314示例 1：输入： 2输出： 2解释： 有两种方法可以爬到楼顶。1. 1 阶 + 1 阶2. 2 阶示例 2：输入： 3输出： 3解释： 有三种方法可以爬到楼顶。1. 1 阶 + 1 阶 + 1 阶2. 1 阶 + 2 阶3. 2 阶 + 1 阶 思想分析对于这道题，理解了思想之后其实非常简单。假设现在你站在第x阶(1&lt;=x&lt;=n)台阶上，那么你用了多少种方法爬到这里呢？因为爬上第x阶台阶只有两种方法 从第x-1阶台阶爬1个台阶上去 从第x-2个台阶爬2个台阶上去 如果我们假设爬上x阶台阶用了f(x)种方法，那么f(x)=f(x-1)+f(x-2)。很明显了，这就是一个斐波那契数列。 代码实现1234567891011121314public int climbStairs(int n) &#123; if(n==1)&#123; return 1; &#125; int f1=1; int f2=1; int sum=0; while(n--&gt;1)&#123; sum=f1+f2; f1=f2; f2=sum; &#125; return sum;&#125; 对于这种题目，理解了以后就会很简单，否则很有可能会将问题复杂化。]]></content>
      <categories>
        <category>算法之美</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
        <tag>递归</tag>
        <tag>斐波那契数列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[X的平方根]]></title>
    <url>%2F2019%2F10%2F23%2FX%E7%9A%84%E5%B9%B3%E6%96%B9%E6%A0%B9%2F</url>
    <content type="text"><![CDATA[LeetCode第六十九题难度：简单题目：实现 int sqrt(int x) 函数，计算并返回 x 的平方根，其中 x 是非负整数。由于返回类型是整数，结果只保留整数的部分，小数部分将被舍去。 12345678910示例 1:输入: 4输出: 2示例 2:输入: 8输出: 2说明: 8 的平方根是 2.82842..., 由于返回类型是整数，小数部分将被舍去。 思想分析又是一道二分算法的题，对于递归实现的二分算法，总是容易陷入死循环最后导致栈溢出。今天做了这个题，有一点二分算法的心得。二分算法，不管是左边二分还是右边二分，每一次二分后都要向递归出口逼近。根据题意，确定递归出口返回的值。 代码实现1234567891011121314151617public int mySqrt(int x) &#123; if(x==0||x==1) return x; return getRes(1,x,x);&#125;public int getRes(int left,int right,int n)&#123; if(left&gt;right)&#123; return left-1; &#125; int mid=(right+left)/2; //左递归 if(mid&gt;n/mid) return getRes(left,mid-1,n); //右递归 else return getRes(mid+1,right,n); &#125; 这道题不用递归也可以实现，但是为了熟悉，还是用了递归。主要的难点在于递归出口为什么是left&gt;right以及返回值为什么是left-1。当递归过程中left==right时，只有三种情况。 left* left==right*right==x向右递归，递归后，left&gt;right。并且left=left+1。因此最后返回left-1 left* left==right*right&lt;x向右递归，递归后，left&gt;right。并且left=left+1。因此最后返回left-1 left* left==right*right&gt;x向左递归，递归后，left&gt;right。并且right=right-1。因此最后返回left-1从两段向左向右递归的代码中可以发现，left最后的值一定是sqrt(x)+1。]]></content>
      <categories>
        <category>算法之美</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
        <tag>递归</tag>
        <tag>二分查找</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[报数]]></title>
    <url>%2F2019%2F10%2F22%2F%E6%8A%A5%E6%95%B0%2F</url>
    <content type="text"><![CDATA[LeetCode第三十八题难度：简单题目：报数序列是一个整数序列，按照其中的整数的顺序进行报数，得到下一个数。其前五项如下 12345678910111. 12. 113. 214. 12115. 1112211 被读作 &quot;one 1&quot; (&quot;一个一&quot;) , 即 11。11 被读作 &quot;two 1s&quot; (&quot;两个一&quot;）, 即 21。21 被读作 &quot;one 2&quot;, &quot;one 1&quot; （&quot;一个二&quot; , &quot;一个一&quot;) , 即 1211。给定一个正整数 n（1 ≤ n ≤ 30），输出报数序列的第 n 项。注意：整数顺序将表示为一个字符串。 思想分析题目说的很清楚，根据前一个字符串的读法的到下一个字符串，利用递归实现，但要注意递归的次数。 代码实现12345678910111213141516171819202122232425262728293031323334public String countAndSay(int n) &#123; //如果n为1，直接返回”1“ if(n==1)&#123; return &quot;1&quot;; &#125; //将”1“作为初始串，进行递归 //这里要传递n-1而不是n，因为”1“也算进去了 return getSeq(&quot;1&quot;,n-1);&#125;public String getSeq(String s,int n)&#123; //递归出口 if(n==0)&#123; return s; &#125; //用于拼接字符串 StringBuilder sb=new StringBuilder(); int i=0; //遍历当前字符串 while(i&lt;s.length())&#123; //用于记录相同字符的个数 int count=1; char ch=s.charAt(i++); while(i&lt;s.length()&amp;&amp;s.charAt(i)==ch)&#123; i++; count++; &#125; //前一个字符串各个字符的个数+字符就是下一个字符串 sb.append(count); sb.append(ch); &#125; return getSeq(sb.toString(),n-1);&#125;]]></content>
      <categories>
        <category>算法之美</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
        <tag>递归</tag>
        <tag>字符串</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搜索插入位置]]></title>
    <url>%2F2019%2F10%2F22%2F%E6%90%9C%E7%B4%A2%E6%8F%92%E5%85%A5%E4%BD%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[LeetCode第35题难度：简单题目：给定一个排序数组和一个目标值，在数组中找到目标值，并返回其索引。如果目标值不存在于数组中，返回它将会被按顺序插入的位置。(你可以假设数组中无重复元素) 123456789101112131415示例 1:输入: [1,3,5,6], 5输出: 2示例 2:输入: [1,3,5,6], 2输出: 1示例 3:输入: [1,3,5,6], 7输出: 4示例 4:输入: [1,3,5,6], 0输出: 0 解题思路很明显，这是一道二分查找的题目，对于二分查找，思想比较简单，但是实现起来却并不是那么容易，要特别注意边界条件。 代码实现1234567891011121314151617181920public int searchInsert(int[] nums, int target) &#123; return BinarySearch(nums,0,nums.length-1,target);&#125;public int BinarySearch(int[] nums,int left,int right,int target)&#123; if(left&gt;right)&#123; return left; &#125; else&#123; int mid=(right+left)/2; if(nums[mid]&lt;target)&#123; return BinarySearch(nums,mid+1,right,target); &#125; else if(nums[mid]&gt;target)&#123; return BinarySearch(nums,left,mid-1,target); &#125; else return mid; &#125;&#125; 递归出口当left&gt;right时说明数组已经遍历完，没有找到目标值，此时应该将目标值插入合适的位置。通过代码可以发现，left指向的元素是第一个大于目标值的元素，因此目标值应该插入到left下标位置。 递归过程在递归过程中，需要不断地逼近递归出口。这样mid+1和mid-1就很好理解了。]]></content>
      <categories>
        <category>算法之美</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
        <tag>递归</tag>
        <tag>数组</tag>
        <tag>二分查找</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[最长公共前缀]]></title>
    <url>%2F2019%2F10%2F21%2F%E6%9C%80%E9%95%BF%E5%85%AC%E5%85%B1%E5%89%8D%E7%BC%80%2F</url>
    <content type="text"><![CDATA[LeetCode第十四题难度：简单题目：编写一个函数来查找字符串数组中的最长公共前缀。如果不存在公共前缀，返回空字符串 “”。(只包含小写字母) 123456789示例 1:输入: [&quot;flower&quot;,&quot;flow&quot;,&quot;flight&quot;]输出: &quot;fl&quot;示例 2:输入: [&quot;dog&quot;,&quot;racecar&quot;,&quot;car&quot;]输出: &quot;&quot;解释: 输入不存在公共前缀。 思想分析首先判断边界条件，根据题意，当数组长度为0时，返回空串””。如果数组中存在一个””，那么也返回空串。解决了边界问题后，来看着这个题。解决方法有很多，介绍一种简单地，使用indexOf()方法来解决。 先选定数组的一个元素作为基准(这里选的是arr[0])， 依次遍历数组剩下的元素，判断该基准是否是其他元素的前缀 如果不是，基准长度-1，继续判断，直到基准为空(返回”“)或是当前元素前缀为止。 重复2，3步，遍历数组所有元素。 代码实现123456789101112131415161718192021public String longestCommonPrefix(String[] strs) &#123; //注意边界条件，如果数组长度为0，直接返回 if(strs.length==0)&#123; return &quot;&quot;; &#125; String prefix=strs[0]; for(int i=1;i&lt;strs.length;i++)&#123; //如果有任意元素为”“，直接返回 if(strs[i].equals(&quot;&quot;))&#123; return &quot;&quot;; &#125; while(strs[i].indexOf(prefix)!=0)&#123; prefix=prefix.substring(0,prefix.length()-1); if(prefix.equals(&quot;&quot;))&#123; return &quot;&quot;; &#125; &#125; &#125; return prefix;&#125;]]></content>
      <categories>
        <category>算法之美</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
        <tag>字符串</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[回文数]]></title>
    <url>%2F2019%2F10%2F21%2F%E5%9B%9E%E6%96%87%E6%95%B0%2F</url>
    <content type="text"><![CDATA[LeetCode第九题难度：简单题目：判断一个整数是否是回文数。回文数是指正序（从左向右）和倒序（从右向左）读都是一样的整数。 123456789示例一：输入: 10输出: false解释: 从右向左读, 为 01 。因此它不是一个回文数。示例二：输入: -121输出: false解释: 从左向右读, 为 -121 。 从右向左读, 为 121- 。因此它不是一个回文数。 思想分析这题思想很简单，一般的做法就是简单地将数字逆着算一遍然后比较是否相等。但这不是最优的解法，否则就没必要记录这一题了。其实，我们在将数字逆置到一半的时候就可以得到结论，并不需要完全逆置。另外，示例已经提示的很清楚，对于负数和10的倍数可以直接返回false，但是0要返回true。 代码实现1234567891011public boolean isPalindrome(int x) &#123; if(x&lt;0||x!=0&amp;&amp;x%10==0)&#123; return false; &#125; int res=0; while(x&gt;res)&#123; res=(res*10+x%10); x/=10; &#125; return x==res/10||x==res;&#125; 好的思想总是让人眼前一亮，忍不住要记录下来。]]></content>
      <categories>
        <category>算法之美</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[无重复字符的最长子串]]></title>
    <url>%2F2019%2F10%2F21%2F%E6%97%A0%E9%87%8D%E5%A4%8D%E5%AD%97%E7%AC%A6%E7%9A%84%E6%9C%80%E9%95%BF%E5%AD%90%E4%B8%B2%2F</url>
    <content type="text"><![CDATA[LeetCode第三题难度：中等题目：给定一个字符串，请你找出其中不含有重复字符的最长子串的长度。 示例12345678910示例一：输入: &quot;abcabcbb&quot;输出: 3 解释: 因为无重复字符的最长子串是 &quot;abc&quot;，所以其长度为 3。示例二：输入: &quot;pwwkew&quot;输出: 3解释: 因为无重复字符的最长子串是 &quot;wke&quot;，所以其长度为 3。 请注意，你的答案必须是 子串 的长度，&quot;pwke&quot; 是一个子序列，不是子串。 算法思想 定义一个HashMap&lt;K,V&gt;，其中key为字符，Value为字符的位置i+1； 定义不重复子串的开始位置为start，结束位置为end，长度为ans，并且都初始化为0 遍历字符串(end++)，随着end往后移动的过程中 如果[start,end]区间内出现重复字符，更新start，将start移动到重复字符的后一个位置 更新ans，将字符加入到HashMap中。 在整个过程中以[start,end]为边界的窗口在向后移动，最大子串的长度即为移动过程中窗口的最大长度 代码实现1234567891011121314151617public int lengthOfLongestSubstring(String s) &#123; //记录子串的最大长度 int ans=0; int length=s.length(); Map&lt;Character,Integer&gt; map=new HashMap&lt;&gt;(); for(int start=0,end=0;end&lt;length;end++)&#123; char ch=s.charAt(end); //当[start,end]区间出现重复字符， //将start移到重复字符后一个位置 if(map.containsKey(ch))&#123; start=Math.max(map.get(ch),start); &#125; ans=Math.max(ans,end-start+1); map.put(ch,end+1); &#125; return ans;&#125;]]></content>
      <categories>
        <category>算法之美</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
        <tag>滑动窗口</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构-哈希表]]></title>
    <url>%2F2019%2F10%2F20%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E5%93%88%E5%B8%8C%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[哈希表又称为散列表。散列表的实现常常叫做散列，散列是一种以常数平均时间执行插入、删除和查找的技术。但是对于散列，不支持那些需要元素间任何排序信息的操作。 对于散列的基础知识不做过多的介绍，主要介绍散列函数的选择以及解决冲突的方法，会以三个写的散列表作为演示。 散列函数如果输入的关键字是整数，则散列函数一般为f(Key)=Key mod TableSize。其中Key为关键字(整数)，TableSize为表的大小。f(Key)为该关键字应该在表中的下标。如果表的大小为10而关键字都以0为个位，那么上面的散列函数就不是一个好的选择，因为会将很多关键字映射到一个位置。比较好的办法就是保证表的大小为素数，这样当输入关键字是随机整数时，散列函数不仅计算起来简单而且分配也很均匀。在通常情况下，关键字是字符串，这时候散列函数就需要仔细地选择，这里提供两种方法 将字符串中字符的ASCII码值加起来1234567public static int hash(String key, int TableSize) &#123; int hashVal = 0; for (int i = 0; i &lt; key.length(); i++) &#123; hashVal += key.charAt(i); &#125; return hashVal % TableSize;&#125; 这种方法实现起来简单并且能够很快的计算出答案。不过缺点在于如果表很大，函数不会很好的分配关键字。例如设TableSize=10007(素数)，并假设所有关键字至多8个字符长，由于ASCII字符最大值为127，因此散列函数只能将关键字映射到127*8=1016以内，这显然不是一个好选择。 下面给出第二种尝试方法。123456789101112public static int hash(String key, int TableSize) &#123; int hashVal = 0; for (int i = 0; i &lt; key.length(); i++) &#123; hashVal += 37 * hashVal + key.charAt(i); &#125; hashVal %= TableSize; //溢出时进行补偿 if (hashVal &lt; 0) &#123; hashVal += TableSize; &#125; return hashVal;&#125; 该散列函数能够使得关键字分布的较好。并且允许溢出。当溢出时hashVal %= TableSize得到一个绝对值小于TableSize的负数，因此后面进行补偿。这种散列函数就表的分布而言不一定是最好的，但确实具有极其简单的优点而且速度也很快(书上原话)。 解决哈希冲突解决的散列函数的选择，剩下的问题就是如何解决哈希冲突，即当一个元素被插入时，与另一个已经插入的元素散列到相同的值，就会产生冲突，这个冲突需要消除。解决冲突的方法有很多种，这里介绍两种：分离链接法和开放定址法。 分离链接法解决冲突的第一种方法通常叫做分离链接法(也是HashMap和Set使用的方法)，其做法是将散列到同一个值的所有元素保留到一个表中。如图所示 代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144/** * 使用分离链接法构造哈希表 */public class SeparateChainingHashTable&lt;T&gt; &#123; //默认数组的长度 private static final int DEFAULT_TABLE_SIZE = 101; //记录元素个数 private int currentSize; //用于存储数据 private List&lt;T&gt;[] theList; /** * 默认构造方法 */ public SeparateChainingHashTable() &#123; this(DEFAULT_TABLE_SIZE); &#125; /** * 指定初始大小 * @param size 初始值 */ public SeparateChainingHashTable(int size) &#123; theList = new LinkedList[nextPrime(size)]; for (int i = 0; i &lt; theList.length; i++) &#123; theList[i] = new LinkedList&lt;&gt;(); &#125; &#125; /** * 清空表 */ public void clear() &#123; for (int i = 0; i &lt; theList.length; i++) &#123; theList[i].clear(); &#125; currentSize = 0; &#125; /** * 判断表中是否包含指定值 * @param ele 元素的值 * @return 包含返回true，否则返回false */ public boolean contains(T ele) &#123; List&lt;T&gt; whichList = theList[myhash(ele)]; return whichList.contains(ele); &#125; /** * 插入方法 * @param ele 要插入的元素 */ public void insert(T ele) &#123; List&lt;T&gt; whichList = theList[myhash(ele)]; //如果链表中不包含要插入元素，则将元素插入，否则不做任何操作 if (!whichList.contains(ele)) whichList.add(ele); /** * 定义散列表的装填因子Lambda为散列表中元素个数比该表的大小 * 在这里，如果Lambda超过1，那么就调用rehash方法扩大散列表的大小 */ if (++currentSize &gt; theList.length) rehash(); &#125; /** * 删除方法 * @param ele 要删除的节点 */ public void remove(T ele) &#123; List&lt;T&gt; whichList = theList[myhash(ele)]; if (whichList.contains(ele)) &#123; whichList.remove(ele); currentSize--; &#125; &#125; /** * 重新散列方法 */ private void rehash() &#123; List&lt;T&gt;[] oldlist = theList; theList = new List[nextPrime(2 * theList.length)]; for (int i = 0; i &lt; theList.length; i++) &#123; theList[i] = new LinkedList&lt;&gt;(); &#125; currentSize = 0; for (int i = 0; i &lt; oldlist.length; i++) &#123; for (T t : oldlist[i]) &#123; insert(t); &#125; &#125; &#125; /** * hash函数，将元素映射到指定链表上 * @param x 传入参数 * @return 参数应该映射的下标 */ private int myhash(T x) &#123; int hashVal = x.hashCode(); hashVal %= theList.length; if (hashVal &lt; 0) hashVal += theList.length; return hashVal; &#125; /** * 获取当前值的下一个素数 * @param n 当前值 * @return 当前值的下一个参数 */ private int nextPrime(int n) &#123; if (n % 2 == 0) &#123; n++; &#125; for (; !isPrime(n); n += 2); return n; &#125; /** * 判断由nextPrime()方法传递的参数是否为素数 * @param n 由nextPrime()方法传递的参数 * @return 是素数返回true，不是返回false */ private boolean isPrime(int n) &#123; if (n == 2 || n == 3) return true; if (n == 1 || n % 2 == 0) return false; for (int i = 3; i * i &lt;= n; i += 2) if (n % i == 0) return false; return true; &#125;&#125; 分离链接法思想不是很难，主要说一下insert()方法。 1234567891011121314151617/** * 插入方法 * @param ele 要插入的元素 */public void insert(T ele) &#123; List&lt;T&gt; whichList = theList[myhash(ele)]; //如果链表中不包含要插入元素，则将元素插入，否则不做任何操作 if (!whichList.contains(ele)) whichList.add(ele); /** * 定义散列表的装填因子Lambda为散列表中元素个数比该表的大小 * 在这里，如果Lambda超过1，那么就调用rehash方法扩大散列表的大小 */ if (++currentSize &gt; theList.length) rehash();&#125; 我们定义散列表的装填因子Lambda为散列表中元素个数于该表大小的比值。在上面的代码中，Lambda=1。当Lambda=1时，如果链表的长度为Lambda，执行查找工作大概需要1+(Lambda)/2个节点的查找代价。散列表的大小实际上并不重要，装填因子才是最重要的。分离链接法的一般法则是使得表的大小与预料元素的个数大致相等(即让Lambda=1)。如果Lambda &gt; 1，那么用rehash()方法扩大散列表的大小。 线性探测法分离链接法的缺点是使用一些链表，由于给新单元分配地址需要时间，因此这就导致算法的速度有些缓慢，同时算法实际上还要求对第二种数据结构的实现。下面介绍探测散列表，它的装填因子约为0.5。对于线性探测法，解决冲突的方法一般为f(i)=i。如图所示，将关键字{89，18，49，58，69}一次插入到一个散列表中，此时解决冲突的方法就是f(i)=i。第一个冲突在插入关键字49时产生，它被放到下一个空闲地址，即0地址。关键字58先与18冲突，再与89冲突，然后又和49冲突，试选三次后才找到空闲单元。69同样也是这样解决冲突。这样一来，只要表足够大，总能找到一个自由单元，但是花费的事件也是相当多的。更不幸的是，即使表相对较空，这样占据的单元也会形成一些区块，其结果称为一次聚集，也就是说，散列到区块的任何关键字都需要多次试选单元才能够解决冲突。线性探测法代码就不上了，下面介绍一种能够解决线性探测法中一次聚集问题的探测方法–平方探测法 平方探测法平方探测法，就是冲突函数为二次的探测方法，流行的选择是f(i)=i*i。如图，同样使用关键字{89，18，49，58，69}插入链表中当插入49时发生冲突，f(i)=f(1)=1；并且下一个位置是空的，因此49就放到0位置。插入58是第一次和18发生冲突，f(i)=f(1)=1，但是下一个位置不为空，因此进行第二次探测，f(2)=4，下一个单元在距位置8为4的地方也就是2。因此58就放在2处。对于线性探测，让当散列表几乎填满元素时性能会降低。对于平方探测更为严重，一旦表被填充超过一半，当表的大小不是素数时甚至在表被填充一半之前就不能保证一次找到空的单元了。可以证明，如果表有一半是空的，并且表的大小是素数，那么就能保证总能插入一个新的元素。即使表被填充的位置仅比一半多一个，那么插入都有可能失败。 代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199package 哈希表结构;/** * 平方探测法 * 冲突解决方法：f(i)=i*i * 即 f(i)=f(i-1)+2*i-1=f(i-1)+2*(i-1)+1 */public class QuadraticProbingHashTable&lt;T&gt; &#123; private static final int DEFAULT_TABLE_SIZE = 101; private int currentSize; private HashEntry&lt;T&gt;[] array; public QuadraticProbingHashTable1() &#123; this(DEFAULT_TABLE_SIZE); &#125; /** * 私有嵌套类作为节点存储数据和记录存活状态 * @param &lt;T&gt; */ private static class HashEntry&lt;T&gt;&#123; private T ele; private boolean isAlive; public HashEntry(T ele) &#123; this(ele, true); &#125; public HashEntry(T ele, boolean isAlive) &#123; this.ele = ele; this.isAlive = isAlive; &#125; &#125; /** * 删除表中所有数据项 */ public void clear() &#123; currentSize = 0; for (int i = 0; i &lt; array.length; i++) &#123; array[i] = null; &#125; &#125; public QuadraticProbingHashTable1(int size) &#123; allocateArray(size); clear(); &#125; /** * 在表中查找指定元素 * @param ele 要查找的元素 * @return 找到返回true，否则返回false */ public boolean contains(T ele) &#123; int currentPos = findPos(ele); return isAlive(currentPos); &#125; /** * 插入方法 * @param ele */ public boolean insert(T ele) &#123; int currentPos = findPos(ele); //说明当前表中已有该元素并且并没有被删除，不做操作 if (isAlive(currentPos)) &#123; return false; &#125; //将元素插入 array[currentPos] = new HashEntry&lt;&gt;(ele, true); //表中元素数+1并判断是否超过数组长度一半 if (++currentSize &gt; array.length / 2) &#123; rehash(); &#125; return true; &#125; /** * 删除方法 * @param ele */ public boolean remove(T ele) &#123; int currentPose = findPos(ele); if (isAlive(currentPose)) &#123; array[currentPose].isAlive = false; currentSize--; return true; &#125; return false; &#125; public int size() &#123; return currentSize; &#125; /** * 再散列方法 * */ private void rehash() &#123; HashEntry&lt;T&gt;[] oldarray = array; //创建一个新数组 allocateArray(2 * array.length); //将占有数和存活数都初始化0值 currentSize = 0; //将原数组元素拷贝到新数组上 for (HashEntry&lt;T&gt; hashEntry : oldarray) &#123; //只拷贝存活的元素 if (hashEntry != null &amp;&amp; hashEntry.isAlive) &#123; insert(hashEntry.ele); &#125; &#125; &#125; /** * 判断给定数组下标中是否存在元素，如果存在是否被删除 * @param currentPos * @return 如果存在且未被删除，返回true */ private boolean isAlive(int currentPos) &#123; return array[currentPos] != null &amp;&amp; array[currentPos].isAlive; &#125; /** * 找到一个合适的位置 * @param ele 传入参数 * @return 返回数组下标元素要么值等于ele，要么为空 */ private int findPos(T ele) &#123; int offest = 1; int currentPos = myhash(ele); while (array[currentPos] != null &amp;&amp; !array[currentPos].ele.equals(ele)) &#123; currentPos += offest; offest += 2; if (currentPos &gt;= array.length) &#123; currentPos -= array.length; &#125; &#125; return currentPos; &#125; /** * 散列函数，将元素映射到指定数组下标中 * @param ele * @return */ private int myhash(T ele) &#123; int hashVal = ele.hashCode(); hashVal %= array.length; if (hashVal &lt; 0) &#123; hashVal += array.length; &#125; return hashVal; &#125; /** * 创建一个指定大小的数组用来存储数据 * @param arraySize */ private void allocateArray(int arraySize) &#123; array = new HashEntry[nextPrime(arraySize)]; &#125; /** * 找到n后面的素数 * @param n * @return */ private int nextPrime(int n) &#123; if (n % 2 == 0) &#123; n++; &#125; for (; !isPrime(n); n += 2) ; return n; &#125; /** * 判断素数 * @param n * @return */ private boolean isPrime(int n) &#123; if (n == 1 || n % 2 == 0) &#123; return false; &#125; if (n == 2 || n == 3) &#123; return true; &#125; for (int i = 3; i * i &lt; n; i += 2) &#123; if (n % i == 0) &#123; return false; &#125; &#125; return true; &#125;&#125; 在探测散列表中不能使用真正的删除操作，因为相应的单元可能已经引起过冲突，元素绕过它存在了别处。例如，如果我们删89，那么实际上剩下的contains操作都将失败。所以我们使用惰性删除，即将要删除的元素做一个标记而不是真的删除它。在本例中，没有使用链表数组，而是使用散列表项单元的数组，定义了一个HashEntry类用于存储数据 12345678910111213141516171819/** * 私有嵌套类作为节点存储数据和记录存活状态 * @param &lt;T&gt; */private static class HashEntry&lt;T&gt;&#123; //保存数据 private T ele; //记录元素状态，如果已被删除该boolean值为false private boolean isAlive; public HashEntry(T ele) &#123; this(ele, true); &#125; public HashEntry(T ele, boolean isAlive) &#123; this.ele = ele; this.isAlive = isAlive; &#125;&#125; 用了上面的类作为节点，那么一个HashEntry引用数组的每一项是下面三种情况之一 null，说明当前单元为空，可以直接插入 非null，并且isAlive为true，当前单元存在数据且未被删除，不能直接插入，需要使用冲突函数绕过该节点 非null，但是isAlive为false，当前单元存在数据但是已经被删除(懒惰删除)，可以直接插入覆盖 再散列前面无论是线性探测法还是平方探测法都是用到了rehash()方法，即再散列。下面就来介绍一下再散列前面说过，对于平方探测法，如果元素散列表太满，那么操作的运行时间会变长，并且插入操作可能失败。为了解决这种问题，我们建立一个另外约大两倍的表(且使用一个新的散列函数)，扫描整个原始散列表，计算每个(未删除)元素的新散列值并将其插入到新散列表中。这就是再散列。 123456789101112131415161718192021222324252627282930313233343536/** * 平方探测法的 * 再散列方法 */private void rehash() &#123; HashEntry&lt;T&gt;[] oldarray = array; //创建一个新数组 allocateArray(2 * array.length); //将占有数和存活数都初始化0值 currentSize = 0; //将原数组元素拷贝到新数组上 for (HashEntry&lt;T&gt; hashEntry : oldarray) &#123; //只拷贝存活的元素 if (hashEntry != null &amp;&amp; hashEntry.isAlive) &#123; insert(hashEntry.ele); &#125; &#125;&#125;“====================================================================================”对于前面说的使用一个新的散列表并且使用新的散列函数，这里使用的是hashVal mod array.length。因此当新的表建立时，array.length也会改变，自动得就会使用新的散列函数/** * 散列函数，将元素映射到指定数组下标中 * @param ele * @return */private int myhash(T ele) &#123; int hashVal = ele.hashCode(); hashVal %= array.length; if (hashVal &lt; 0) &#123; hashVal += array.length; &#125; return hashVal;&#125; 关于散列表的部分就介绍到这里，可以看到散列表主要解决的就是散列函数和冲突解决方法两大问题。]]></content>
      <categories>
        <category>DataStructure</category>
      </categories>
      <tags>
        <tag>哈希表</tag>
        <tag>数据结构</tag>
        <tag>分离链接法</tag>
        <tag>开放定址法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java编程思想之浅谈反射机制]]></title>
    <url>%2F2019%2F10%2F20%2FJava%E7%BC%96%E7%A8%8B%E6%80%9D%E6%83%B3%E4%B9%8B%E6%B5%85%E8%B0%88%E5%8F%8D%E5%B0%84%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[运行时类型信息使得你可以在程序运行时发现和使用类型信息。在Java中，有两种方式让我们在运行时识别对象和类的信息。 传统的“RTTI”(运行时，识别一个对象的类型)它假定我们在编译时已经知道了所有的类型 反射机制它允许我们在运行时发现和使用类的信息 RTTI运行时类型信息使得我们可以在程序运行时发现和使用类型信息。RTTI的含义：在运行时，识别一个对象的类型。 关于Class类对象Java中有一个特殊的对象–Class对象，该对象包含了与类有关的信息。事实上，Class对象就是用来创建类的所有“常规”对象的。Java中使用Class对象来执行RTTI。每当编写并且编译了一个新类，就会产生一个Class对象(被保存在同名的.class文件中)。主要有三种RTTI形式 传统的类型转换，由RTTI来确保类型转换的正确性，如果执行了一个错误的类型转换，就会抛出一个ClassCastException异常 代表对象类型的Class对象，通过查询Class对象可以获取运行时所需的信息 关键字instanceof，告诉我们对象是不是某个特定类型的实例 但是无论是三种方法中的哪一种，在使用RTTI时都要求这个类型在编译时必须已知。也就是说，在编译时，编译器必须知道所有要通过RTTI来处理的类(类名)。但是现在，假设运行期间你获取了一个不在你程序空间中的对象的引用，通过RTTI是没有办法知道这个对象到底是属于哪个类，因为编译器根本就不知道这个类的名字。假设你从磁盘或者网络中获取了一串字节，并且被告知这是一个类(假设该类名为A)。那你要怎样使用这个类呢？正常情况下是没办法使用的，就比如你要产生这个类的对象，是做不到的。因为你的代码中根本就没有A a=new A()这样的代码，那你说我提前在写一个A a=new A()，这样也不行，代码是通不过编译的，因为编译器检查这段代码发现程序空间中根本就没有A这个类，因为这个类是你运行时候从别的地方加载进来的，编译器根本就不知道会有A这个类，同样的你要调用类的字段方法统统都做不到。对于这种类似的情况，就要用到反射。 四种获取Class对象的方法既然说到Class类对象，就来谈一谈如何获取该对象吧 Class.forName(String name)通过Class类的静态方法获取，传递参数为类的全限定名(包名.类名)。 通过类字面常量.class获取使用类名.class来获取Class类对象，当使用这种方法时，不会引发类的初始化(通俗的说，类的静态代码块不会被执行)。 通过类对象来获取如果你已经有了一个对象，那么可以使用对象名.getClass()来获取该对象的Class对象 通过类加载器获取如果有了一个类加载器对象classLoader，那么可以使用classLoader.loadclass(String name)方法获取指定名称的Class对象，参数类的全限定名1234//通过一个Class对象获取类加载器ClassLoader classLoader = son2Class.getClassLoader();//通过类加载器获取另一个类的Class对象Class&lt;?&gt; cl = classLoader.loadClass(&quot;想要获取哪个类的Class对象，就传递该类的全限定名&quot;); 反射Class类和java.lang.reflect类库一起对反射机制进行了支持，该类库包含Field、Method以及Constructor(这些类都实现了Member接口)。这些类型的对象是由JVM在运行时创建的，用来表示未知类里对应的成员。这样你就可以用Constructor创建对象(而不必使用对象名)，用get()和set()方法读写与Field对象相关联的字段，使用invoke()方法调用与Method对象相关联的方法……这样以来，未知对象的类信息就完全确定了，即使在编译时根本不知道这个类。或者在运行期间从网路中获取了一个类，可以使用反射来创建该类的对象，调用对象的方法，即使根本不知道类的名字，没有也不可能在代码中使用new，来创建对象。 当通过反射与一个未知类型的对象打交道时，JVM只是简单地检查这个对象，看他属于哪一个特定的类(就像传统的RTTI那样)。在用它做其他事情之前必须先加载那个类的Class对象(加载类的.class文件)，因此这个类的.class文件对于JVM来说必须是可以获得的(要么在本地机器，要么从网络中获取)。所以RTTI与反射之间真正的区别只在于 对于RTTI，编译器在编译时打开和检查.class文件。(我们知道类的名字，在代码中使用普通的方式创建对象，调用对象的方法) 对于反射机制，.class文件在编译时是不可获取的，是在运行期间(程序运行到代码的某个部分)获取到的。所以在运行时打开和检查.class文件。 总结一下Java反射机制在运行状态中，对于任意一个类，都能够知道这个类的所有属性和方法，对于任意一个对象，都能够调用它任意的方法。这种动态获取类的内容以及动态调用对象的方法称为反射机制。 Java反射APIClass对象相关方法Class对象的方法有很多，这里只介绍获取类的字段、方法、构造器三类 获取字段 getField(String name)获取指定名称的字段，只能是public的字段，该字段可以来自父类和接口 getFields()获取所有的public修饰的字段，包括从父类继承得到的public字段和接口定义的常量。前面说过字段是不存在多态的，让我们来测试一下下面这种情况 1234567891011121314151617181920212223242526272829303132//子类中有字段value，父类中也有字段value，并且接口中也有字段value，那么子类的Class对象到底能获取几个字段呢？class Father&#123; public int value;&#125;class Son extends Father implements Inter &#123; public int value;&#125;interface Inter&#123; int value = 0;&#125;public class getFieldTest &#123; public static void main(String[] args) throws Exception&#123; Class&lt;?&gt; cl = Class.forName(&quot;fourteen.reflectTest.Son&quot;); Field[] fields = cl.getFields(); for (Field field : fields) &#123; System.out.println(field); &#125; &#125;&#125;“============================”Output：public int Son.valuepublic static final int Inter.valuepublic int Father.value通过测试我们发现，子类中包含了从接口和父类继承的同名字段，并且接口中字段默认为常量，并不会发生多态行为 getDeclaredField(String name)获取指定字段，该字段可以是任意权限但只能是本类定义的字段 getDeclaredFields()获取类自身定义的所有权限的字段，但是不会获取父类或者接口的任何字段。 获取方法 getMethod(String name,Class…args)获取指定名称方法的指定重载形式，只能获取本类的public方法参数 String name：方法名称 Class…args：方法参数的Class对象(因为方法的重载，所以仅凭方法名无法确定一个方法) getMethods()获取所有public修饰的方法，包括从父类继承的方法。如果发生重写，那么只获取子类的方法。如果发生重载那么父类和子类的方法都会被获取 getDeclaredMethod(String name,Class…args)获取指定名称方法的指定重载形式，能获取本类定义的任何权限的方法，无法获取任何父类或接口的方法 getDeclaredMethods()获取本类定义的所有方法，无法获取父类继承的方法。 获取构造器 getConstructor(Class…args)获取指定重载形式的public修饰的构造器，因为构造器和类同名因此无需name参数参数 Class…args方法参数的Class对象(因为方法的重载，所以仅凭方法名无法确定一个方法) getConstructors()获取所有public修饰的构造器。不会获取父类构造器 getDeclaredConstructor(Class…args)获取指定重载形式的构造器，能够类任何权限的构造器。 getDeclaredConstructor()获取类所有权限的构造器 reflect类库对象方法前面的Class对象的三类方法主要是获取reflect类库的三个类对象，分别是Field对象，Method对象以及Constructor类对象 Field对象方法 get(Object obj)参数：obj–字段所属对象获取字段的值 set(Object obj1,Object obj2)参数： obj1：字段所属对象 obj2：想要给字段设置的新值设置字段的值 Method对象方法 Object invoke(Object obj，Object…args)参数： Object obj:方法所属的类对象 Object…args:方法所需要的参数返回值：方法如果不为void，那么返回方法执行的结果传入指定参数，执行获取的方法。 Constructor对象方法 T newInstance(Object…args)参数： 构造方法需要的参数返回值：执行构造方法创建出来的对象 对于一些getName()类似的方法没有介绍，但是查看API文档可以很轻易地学习到。另外，如果想要对获取到的私有的(或者是本来权限不够无法操作的)字段、方法或者构造器进行操作，要先调用setAccessible(true)方法。]]></content>
      <categories>
        <category>Java编程思想</category>
      </categories>
      <tags>
        <tag>Java基础</tag>
        <tag>反射机制</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构-树]]></title>
    <url>%2F2019%2F10%2F18%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E6%A0%91%2F</url>
    <content type="text"><![CDATA[前面说过，数组查询快而增删满，链表增删快而查询慢，那么有没有一种查询和增删修改都比较快的数据结构呢？这里主要介绍两种树，即二叉查找树和AVL树。值得一提的是，二叉查找树对于大部分操作的运行时间平均为O(logN)。 对于树的基本知识就不做赘述，这里主要通过手写一个二叉查找树和AVL树并实现其一些必要功能来学习这两种数据结构。 二叉查找树代码实现先上代码，然后再对每一个方法的实现进行介绍 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185public class BinarySearchTree&lt;T extends Comparable&lt;? super T&gt;&gt;&#123; //私有嵌套类表示树节点 private static class BinaryNode&lt;T&gt; &#123; T ele; BinaryNode&lt;T&gt; left; BinaryNode&lt;T&gt; right; BinaryNode(T ele) &#123; this(ele, null, null); &#125; BinaryNode(T ele, BinaryNode&lt;T&gt; left, BinaryNode&lt;T&gt; right) &#123; this.ele = ele; this.left = left; this.right = right; &#125; &#125; //BinarySearchTree成员属性，表示树的根节点 private BinaryNode&lt;T&gt; root; //无参构造方法 public BinarySearchTree() &#123; root = null; &#125; /** * 判断树空 * @return 为空返回true，否则返回false */ public boolean isEmpty() &#123; return root == null; &#125; /** * 判断树中是否含有指定元素 * @param ele 指定元素 * @return 包含返回true，否则返回false */ public boolean contains(T ele) &#123; return contains(ele, root); &#125; /** * 获取树中节点的最小值 * @return 最小节点值 */ public T findMin() &#123; if (isEmpty()) &#123; throw new NullPointerException(); &#125; return findMin(root).ele; &#125; /** * 获取树中最大节点的值 * @return 最大节点值 */ public T findMax() &#123; if (isEmpty()) &#123; throw new NullPointerException(); &#125; return findMax(root).ele; &#125; /** * 向树种插入节点 * @param ele 插入元素的值 */ public void insert(T ele) &#123; root = insert(ele, root); &#125; /** * 删除指定节点 * @param ele 删除节点值 */ public void remove(T ele) &#123; root = remove(ele, root); &#125; /** * 先序遍历树并打印 */ public void infixPrintTree() &#123; infixPrintTree(this.root); &#125; /** * 中序遍历树并打印 */ public void InOrderPrintTree() &#123; InOrderPrintTree(this.root); &#125; /** * 后序遍历树并打印 */ public void SufixPrintTree() &#123; SufixPrintTree(this.root); &#125; private void SufixPrintTree(BinaryNode&lt;T&gt; t) &#123; if (t != null) &#123; SufixPrintTree(t.left); SufixPrintTree(t.right); System.out.println(t.ele); &#125; &#125; private void InOrderPrintTree(BinaryNode&lt;T&gt; t) &#123; if (t != null) &#123; System.out.println(t.ele); InOrderPrintTree(t.left); InOrderPrintTree(t.right); &#125; &#125; private void infixPrintTree(BinaryNode&lt;T&gt; t) &#123; if (t != null) &#123; infixPrintTree(t.left); System.out.println(t.ele); infixPrintTree(t.right); &#125; &#125; private BinaryNode&lt;T&gt; remove(T ele, BinaryNode&lt;T&gt; t) &#123; if (t == null) &#123; return t; &#125; int res = ele.compareTo(t.ele); if (res &lt; 0) &#123; t.left = remove(ele, t.left); &#125; else if (res &gt; 0) &#123; t.right = remove(ele, t.right); &#125; else if (t.left != null &amp;&amp; t.right != null) &#123; t.ele = findMin(t.right).ele; t.right = remove(t.ele, t.right); &#125;else &#123; t = (t.left != null) ? t.left : t.right; &#125; return t; &#125; private BinaryNode&lt;T&gt; insert(T ele, BinaryNode&lt;T&gt; t) &#123; if (t == null) &#123; return new BinaryNode&lt;&gt;(ele, null, null); &#125; int res = ele.compareTo(t.ele); if (res &lt; 0) &#123; t.left = insert(ele, t.left); &#125; else if (res &gt; 0) &#123; t.right = insert(ele, t.right); &#125; else; return t; &#125; private BinaryNode&lt;T&gt; findMax(BinaryNode&lt;T&gt; t) &#123; if (t.right == null) &#123; return t; &#125; return findMax(t.right); &#125; private BinaryNode&lt;T&gt; findMin(BinaryNode&lt;T&gt; t) &#123; if (t.left == null) &#123; return t; &#125; return findMin(t.left); &#125; private boolean contains(T ele, BinaryNode&lt;T&gt; t) &#123; if (t == null) &#123; return false; &#125; int res = ele.compareTo(t.ele); if (res &lt; 0) &#123; return contains(ele, t.left); &#125; else if (res &gt; 0) &#123; return contains(ele, t.right); &#125; else &#123; return true; &#125; &#125;&#125; 实现细节 节点类1234567891011121314151617private static class BinaryNode&lt;T&gt; &#123; //节点值 T ele; //指向该节点的左子树 BinaryNode&lt;T&gt; left; //指向该节点的右子树 BinaryNode&lt;T&gt; right; //无参构造方法 BinaryNode(T ele) &#123; this(ele, null, null); &#125; BinaryNode(T ele, BinaryNode&lt;T&gt; left, BinaryNode&lt;T&gt; right) &#123; this.ele = ele; this.left = left; this.right = right; &#125;&#125; 就像前面的链表结构、哈希表结构，它们的每一个节点也都是一个类，这里定义了一个树节点类，使用了泛型。节点类类有三个属性、一个无参构造方法和一个含餐构造方法。实现比较简单，就不多说 contains(T ele)方法123456789101112131415161718192021222324/** * 判断树中是否含有指定元素 * @param ele 指定元素 * @return 包含返回true，否则返回false */public boolean contains(T ele) &#123; return contains(ele, root);&#125;“=================================================”private boolean contains(T ele, BinaryNode&lt;T&gt; t) &#123; if (t == null) &#123; return false; &#125; int res = ele.compareTo(t.ele); if (res &lt; 0) &#123; return contains(ele, t.left); &#125; else if (res &gt; 0) &#123; return contains(ele, t.right); &#125; else &#123; return true; &#125;&#125; 调用的是contains(T ele)的重载方法contains(T ele,BinaryNode t)，将根节点root作为参数传递进去。该方法使用递归查询 将待查找值和当前节点值进行比较 如果大于当前节点值，递归查询当前节点的右子树 如果小于当前节点值，递归查询当前节点的左子树 如果等于当前节点值，说明树中包含该节点，返回true 递归出口：当前节点为空时，说明树中不包含查找值，返回false findMax()和findMin() 1234567891011121314151617181920212223242526272829303132333435363738394041/** * 获取树中节点的最小值 * @return 最小节点值 */public T findMin() &#123; if (isEmpty()) &#123; throw new NullPointerException(); &#125; return findMin(root).ele;&#125;“================================================”private BinaryNode&lt;T&gt; findMin(BinaryNode&lt;T&gt; t) &#123; if (t.left == null) &#123; return t; &#125; return findMin(t.left);&#125;“================================================”“================================================”/** * 获取树中最大节点的值 * @return 最大节点值 */public T findMax() &#123; if (isEmpty()) &#123; throw new NullPointerException(); &#125; return findMax(root).ele;&#125;“================================================”private BinaryNode&lt;T&gt; findMax(BinaryNode&lt;T&gt; t) &#123; if (t.right == null) &#123; return t; &#125; return findMax(t.right);&#125; 分别获取树中节点最大值和最小值。思想很简单，对于二叉查找树的每一个节点，其左子树一定小于右子树。因此该树的最右叶子节点就是最大节点，同样的，最左叶子节点即为最小节点。 insert(T ele)12345678910111213141516171819202122/** * 向树种插入节点 * @param ele 插入元素的值 */public void insert(T ele) &#123; root = insert(ele, root);&#125;“================================================”private BinaryNode&lt;T&gt; insert(T ele, BinaryNode&lt;T&gt; t) &#123; if (t == null) &#123; return new BinaryNode&lt;&gt;(ele, null, null); &#125; int res = ele.compareTo(t.ele); if (res &lt; 0) &#123; t.left = insert(ele, t.left); &#125; else if (res &gt; 0) &#123; t.right = insert(ele, t.right); &#125; else; return t;&#125; 向树中插入节点，要保证插入后仍是二叉查找树。使用递归实现比较简单。 比较待插入值和当前节点值大小 如果待插入值大于当前节点值，说明该值应该插入在当前节点的右子树中 如果待插入值小于当前节点值，说明该值应该插入在当前节点的左子树中 如果待插入值等于当前节点值，由二叉查找树的定义可知节点值不能重复，因此不做插入操作 递归出口，有两个递归出口 找到合适的插入位置，插入后return 待插入值等于当前节点值，递归结束。返回当前节点 树的前中后序遍历 123456789101112131415161718192021222324252627282930313233343536373839404142434445/** * 先序遍历树并打印 */public void infixPrintTree() &#123; infixPrintTree(this.root);&#125;/** * 中序遍历树并打印 */public void InOrderPrintTree() &#123; InOrderPrintTree(this.root);&#125;/** * 后序遍历树并打印 */public void SufixPrintTree() &#123; SufixPrintTree(this.root);&#125;“================================================”private void SufixPrintTree(BinaryNode&lt;T&gt; t) &#123; if (t != null) &#123; SufixPrintTree(t.left); SufixPrintTree(t.right); System.out.println(t.ele); &#125;&#125;private void InOrderPrintTree(BinaryNode&lt;T&gt; t) &#123; if (t != null) &#123; System.out.println(t.ele); InOrderPrintTree(t.left); InOrderPrintTree(t.right); &#125;&#125;private void infixPrintTree(BinaryNode&lt;T&gt; t) &#123; if (t != null) &#123; infixPrintTree(t.left); System.out.println(t.ele); infixPrintTree(t.right); &#125;&#125; 思想较为简单，算是树的基础操作，不多说 remove(T ele)123456789101112131415161718192021222324252627/** * 删除指定节点 * @param ele 删除节点值 */public void remove(T ele) &#123; root = remove(ele, root);&#125;“================================================”private BinaryNode&lt;T&gt; remove(T ele, BinaryNode&lt;T&gt; t) &#123; if (t == null) &#123; return t; &#125; int res = ele.compareTo(t.ele); if (res &lt; 0) &#123; t.left = remove(ele, t.left); &#125; else if (res &gt; 0) &#123; t.right = remove(ele, t.right); &#125; else if (t.left != null &amp;&amp; t.right != null) &#123; t.ele = findMin(t.right).ele; t.right = remove(t.ele, t.right); &#125;else &#123; t = (t.left != null) ? t.left : t.right; &#125; return t;&#125; 删除操作是二叉查找树最困难的操作，对于以恶搞要删除的节点，需要考虑几种可能的情况 1. 如果节点是一个叶子节点，那么可以直接删除 2. 如果节点有一个子节点(左右都可以)，那么可以可以将该节点的父节点指向它的子节点来达到删除该节点的目的，如图 3. 比较复杂的是，待删除节点具有两个孩子节点，一般的策略是用待删除节点的右子树中最小的子节点代替该节点的数据并递归的删除那个最小的节点。因为右子树中最小的节点不可能有左儿子，因此第二次remove时要容易。如图 AVL树二叉查找树在大多数情况下能够提高我们的访问速度，但是对于下面这样已经退化为链表的二叉排序树，并不能提高我们的访问速度。因此在二叉查找树的基础上又引进了AVL树对于AVL树结构，要求它的每一个节点的左右子树的高度最多相差1。 平衡调整策略当执行插入操作时，我们需要更新通向根节点路径上的哪些节点的所有平衡信息。但是，插入一个节点可能会破坏AVL树的特性。如图破坏平衡的插入情况一共有4种，下面将对这四种情况进行分别说明 LL形调整如图所示 RR形调整和LL形类似，可以推导一下 LR形调整如图所示 RL形调整同样的，和LR形类似，可以推导一下 以上就是四种破坏平衡的情况对应的调整策略，下面来看一下代码实现 代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223public class AVLtree&lt;T extends Comparable&lt;? super T&gt;&gt;&#123; private static final int ALLOW_IMBALANCE = 1; private AvlNode&lt;T&gt; root; public AVLtree() &#123; root = null; &#125; //私有嵌套类，树节点类 private static class AvlNode&lt;T&gt; &#123; T ele; AvlNode&lt;T&gt; left; AvlNode&lt;T&gt; right; int height; public AvlNode(T ele) &#123; this(ele, null, null); &#125; private AvlNode(T ele, AvlNode&lt;T&gt; lt, AvlNode&lt;T&gt; rt) &#123; this.ele = ele; right = left; left = lt; height = 0; &#125; &#125; /** * 向AVL树中插入节点 * @param x 插入的节点值 */ public void insert(T x) &#123; root=insert(x, root); &#125; /** * 从AVL树中删除节点 * @param x 删除的节点值 */ public void remove(T x) &#123; root = remove(x, root); &#125; private AvlNode&lt;T&gt; remove(T ele,AvlNode&lt;T&gt; t) &#123; //如果当前节点为空，说明树中不存在要删除的节点值，直接返回 if (t == null) return t; //将当前节点值和删除值比较 int res = ele.compareTo(t.ele); //删除值大于当前节点值，向节点的右子树查询 if (res &lt; 0) &#123; t.left = remove(ele, t.left); &#125; //删除值小于当前节点值，向节点的左子树查询 else if (res &gt; 0) &#123; t.right= remove(ele, t.right); &#125; //找到要删除的节点 //如果要删除的节点左右子树都不为空， //那么就将该节点右子树中最小的值代替当前节点的值并递归删除右子树中最小的值 else if (t.left != null &amp;&amp; t.right != null) &#123; t.ele = finMin(t.right).ele; t.right = remove(t.ele, t.right); &#125; //如果要删除的节点左右子树有一个或两个不存在，直接删除 else t = (t.left != null) ? t.left : t.right; //每次删除后重新对AVL树进行调整 return balance(t); &#125; private AvlNode&lt;T&gt; finMin(AvlNode&lt;T&gt; t) &#123; if (t.left == null) &#123; return t; &#125; return finMin(t.left); &#125; /** * 先序遍历AVL树 */ public void preOrder() &#123; preOrder(this.root); &#125; /** * 中序遍历AVL树 */ public void InOrder() &#123; InOrder(this.root); &#125; private void InOrder(AvlNode&lt;T&gt; t) &#123; if (t != null) &#123; InOrder(t.left); System.out.println(t.ele); InOrder(t.right); &#125; &#125; private void preOrder(AvlNode&lt;T&gt; t) &#123; if (t != null) &#123; System.out.println(t.ele); preOrder(t.left); preOrder(t.right); &#125; &#125; //获取节点高度 private int height(AvlNode&lt;T&gt; t) &#123; return t == null ? -1 : t.height; &#125; private AvlNode&lt;T&gt; insert(T x, AvlNode&lt;T&gt; t) &#123; if (t == null) return new AvlNode&lt;T&gt;(x, null, null); int CompareResult = x.compareTo(t.ele); if (CompareResult &lt; 0 ) &#123; t.left = insert(x, t.left); &#125; else if (CompareResult &gt; 0) &#123; t.right = insert(x, t.right); &#125; return balance(t); &#125; private AvlNode&lt;T&gt; balance(AvlNode&lt;T&gt; t) &#123; if (t == null) &#123; return t; &#125; //如果节点左子树的高度高于右子树的高度 if (height(t.left) - height(t.right) &gt; ALLOW_IMBALANCE) &#123; //当前节点t左子树的左子树高度大于左子树的右子树的高度 //属于LL形，需要一次单旋转 if (height(t.left.left) &gt;= height(t.left.right)) &#123; //LL形调整 t=rotateWithLeftChild(t); &#125; //LR形，需要一次双旋转 else &#123; t=doubleWithLeftChild(t); &#125; &#125; if (height(t.right) - height(t.left) &gt; ALLOW_IMBALANCE) &#123; //RR形 if (height(t.right.right) &gt;= height(t.right.left)) &#123; //RR形式调整 t=rotateWithRightChild(t); &#125; //RL形 else &#123; t=doubleWithRightChild(t); &#125; &#125; t.height = Math.max(height(t.left), height(t.right)) + 1; return t; &#125; /** * RL调整 * @param k3 不平衡的节点 * @return 调整后的新节点 */ private AvlNode&lt;T&gt; doubleWithRightChild(AvlNode&lt;T&gt; k3) &#123; AvlNode&lt;T&gt; k1 = k3.right; AvlNode&lt;T&gt; k2 = k1.left; k3.right = k2.left; k1.left = k2.right; k2.left = k3; k2.right = k1; k1.height = Math.max(height(k1.left), height(k1.right)) + 1; k3.height = Math.max(height(k3.left), height(k3.right)) + 1; k2.height = Math.max(height(k2.left), height(k2.right)) + 1; return k2; &#125; /** * LR调整 * @param k3 不平衡的节点 * @return 调整后的新节点 */ private AvlNode&lt;T&gt; doubleWithLeftChild(AvlNode&lt;T&gt; k3) &#123; AvlNode&lt;T&gt; k1 = k3.left; AvlNode&lt;T&gt; k2 = k1.right; k1.right = k2.left; k3.left = k2.right; k2.left = k1; k2.right = k3; k1.height = Math.max(height(k1.left), height(k1.right)) + 1; k3.height = Math.max(height(k3.left), height(k3.right)) + 1; k2.height = Math.max(height(k2.left), height(k2.right)) + 1; return k2; &#125; /** * RR调整 * @param k2 不平衡的节点 * @return 调整后新的节点 */ private AvlNode&lt;T&gt; rotateWithRightChild(AvlNode&lt;T&gt; k2) &#123; AvlNode&lt;T&gt; k1 = k2.right; k2.right = k1.left; k1.left = k2; k2.height = Math.max(height(k2.left), height(k2.right)) + 1; k1.height = Math.max(height(k1.left), height(k1.right)) + 1; return k1; &#125; /** * LL调整 * @param k2 不平衡的节点 * @return 调整后新的节点 */ private AvlNode&lt;T&gt; rotateWithLeftChild(AvlNode&lt;T&gt; k2) &#123; AvlNode&lt;T&gt; k1 = k2.left; k2.left = k1.right; k1.right = k2; k2.height = Math.max(height(k2.left), height(k2.right)) + 1; k1.height = Math.max(height(k1.left), height(k1.right)) + 1; return k1; &#125;&#125; 实现细节 节点类对于二叉查找树中的简单方法入isEmpty等这里就不实现了。1234567891011121314151617181920212223//私有嵌套类，树节点类private static class AvlNode&lt;T&gt; &#123; //节点值 T ele; //指向节点左子树 AvlNode&lt;T&gt; left; //指向节点右子树 AvlNode&lt;T&gt; right; //记录节点的高度 int height; //空参数构造方法 public AvlNode(T ele) &#123; this(ele, null, null); &#125; private AvlNode(T ele, AvlNode&lt;T&gt; lt, AvlNode&lt;T&gt; rt) &#123; this.ele = ele; right = left; left = lt; height = 0; &#125;&#125; 由于AVL树要求节点的左右子树高度最多相差1，因此就需要每一个节点记录自身的高度，如果是叶子节点，那么高度为0，空节点高度为-1。 height(AvlNode t)1234//获取节点高度private int height(AvlNode&lt;T&gt; t) &#123; return t == null ? -1 : t.height;&#125; 在介绍插入删除操作之前，先介绍两个方法，这是其中一个。思想很简单，如果当前节点不为空，就返回节点的高度，如果为空，返回-1。 balance(AvlNode t)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103private AvlNode&lt;T&gt; balance(AvlNode&lt;T&gt; t) &#123; if (t == null) &#123; return t; &#125; //如果节点左子树的高度和右子树的高度相差超过1 if (height(t.left) - height(t.right) &gt; ALLOW_IMBALANCE) &#123; //当前节点t左子树的左子树高度大于等于左子树的右子树的高度 //属于LL形，需要一次单旋转 if (height(t.left.left) &gt;= height(t.left.right)) &#123; //LL形调整 t=rotateWithLeftChild(t); &#125; //LR形，需要一次双旋转 else &#123; t=doubleWithLeftChild(t); &#125; &#125; //如果右子树的高度和左子树的高度相差超过1 if (height(t.right) - height(t.left) &gt; ALLOW_IMBALANCE) &#123; //RR形 if (height(t.right.right) &gt;= height(t.right.left)) &#123; //RR形式调整 t=rotateWithRightChild(t); &#125; //RL形 else &#123; t=doubleWithRightChild(t); &#125; &#125; t.height = Math.max(height(t.left), height(t.right)) + 1; return t;&#125;“=================================================================”/** * RL调整 * @param k3 不平衡的节点 * @return 调整后的新节点 */private AvlNode&lt;T&gt; doubleWithRightChild(AvlNode&lt;T&gt; k3) &#123; AvlNode&lt;T&gt; k1 = k3.right; AvlNode&lt;T&gt; k2 = k1.left; k3.right = k2.left; k1.left = k2.right; k2.left = k3; k2.right = k1; //先重新确定子树的高度，最后确定k2的高度，k2一定在最后确定 k1.height = Math.max(height(k1.left), height(k1.right)) + 1; k3.height = Math.max(height(k3.left), height(k3.right)) + 1; k2.height = Math.max(height(k2.left), height(k2.right)) + 1; return k2;&#125;/** * LR调整 * @param k3 不平衡的节点 * @return 调整后的新节点 */private AvlNode&lt;T&gt; doubleWithLeftChild(AvlNode&lt;T&gt; k3) &#123; AvlNode&lt;T&gt; k1 = k3.left; AvlNode&lt;T&gt; k2 = k1.right; k1.right = k2.left; k3.left = k2.right; k2.left = k1; k2.right = k3; //先重新确定子树的高度，最后确定k2的高度，k2一定在最后确定 k1.height = Math.max(height(k1.left), height(k1.right)) + 1; k3.height = Math.max(height(k3.left), height(k3.right)) + 1; k2.height = Math.max(height(k2.left), height(k2.right)) + 1; return k2;&#125;/** * RR调整 * @param k2 不平衡的节点 * @return 调整后新的节点 */private AvlNode&lt;T&gt; rotateWithRightChild(AvlNode&lt;T&gt; k2) &#123; AvlNode&lt;T&gt; k1 = k2.right; k2.right = k1.left; k1.left = k2; //先确定子树k2的高度，后确定k1的高度 k2.height = Math.max(height(k2.left), height(k2.right)) + 1; k1.height = Math.max(height(k1.left), height(k1.right)) + 1; return k1;&#125;/** * LL调整 * @param k2 不平衡的节点 * @return 调整后新的节点 */private AvlNode&lt;T&gt; rotateWithLeftChild(AvlNode&lt;T&gt; k2) &#123; AvlNode&lt;T&gt; k1 = k2.left; k2.left = k1.right; k1.right = k2; //先确定子树k2的高度，后确定k1的高度 k2.height = Math.max(height(k2.left), height(k2.right)) + 1; k1.height = Math.max(height(k1.left), height(k1.right)) + 1; return k1;&#125; 以上balance()平衡方法和平衡被破坏后四种调整策略的代码是AVL树中的核心部分。对于LR调整和RL调整最后重新确定高度的时候，由于将k2作为根节点，所以一定要注意确定的顺序。先确定k2的左右子树高度，最后确定k2高度。LL调整和RR调整同理，最后确定调整后根节点的高度。 insert(T x)123456789101112131415161718192021/** * 向AVL树中插入节点 * @param x 插入的节点值 */public void insert(T x) &#123; root=insert(x, root);&#125;“=============================================”private AvlNode&lt;T&gt; insert(T x, AvlNode&lt;T&gt; t) &#123; if (t == null) return new AvlNode&lt;T&gt;(x, null, null); int CompareResult = x.compareTo(t.ele); if (CompareResult &lt; 0 ) &#123; t.left = insert(x, t.left); &#125; else if (CompareResult &gt; 0) &#123; t.right = insert(x, t.right); &#125; return balance(t);&#125; 对于AVL树的插入，和二叉查找树的插入过程一摸一样，只是每插入一个节点，要对插入节点到根节点路径上的所有节点进行平衡调整。 remove(T x)1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/** * 从AVL树中删除节点 * @param x 删除的节点值 */public void remove(T x) &#123; root = remove(x, root);&#125;&quot;==============================================================&quot;private AvlNode&lt;T&gt; remove(T ele,AvlNode&lt;T&gt; t) &#123; //如果当前节点为空，说明树中不存在要删除的节点值，直接返回 if (t == null) return t; //将当前节点值和删除值比较 int res = ele.compareTo(t.ele); //删除值大于当前节点值，向节点的右子树查询 if (res &lt; 0) &#123; t.left = remove(ele, t.left); &#125; //删除值小于当前节点值，向节点的左子树查询 else if (res &gt; 0) &#123; t.right= remove(ele, t.right); &#125; //找到要删除的节点 //如果要删除的节点左右子树都不为空， //那么就将该节点右子树中最小的值代替当前节点的值并递归删除右子树中最小的值 else if (t.left != null &amp;&amp; t.right != null) &#123; t.ele = finMin(t.right).ele; t.right = remove(t.ele, t.right); &#125; //如果要删除的节点左右子树有一个或两个不存在，直接删除 else t = (t.left != null) ? t.left : t.right; //每次删除后重新对AVL树进行调整 return balance(t);&#125;“===========================================================”private AvlNode&lt;T&gt; finMin(AvlNode&lt;T&gt; t) &#123; if (t.left == null) &#123; return t; &#125; return finMin(t.left);&#125; 对于删除节点，无疑更为麻烦。但是就像插入方法一样。我们使用二叉查找树的删除方法，最后不直接返回t，而是对删除节点到根节点上的每一个节点进行平衡调整后再返回，即返回balance(t)，这是可行的！为了证明可行，下面推导一种删除后需要LL调整的情形：对于需要RR调整和另外两种调整的情形类似。 二叉查找树和AVL树介绍告一段落，对于树要学的还有很多。另外可以发现，树相关的问题大多可以用递归来解决，因此能够理解并运用递归非常重要。(参考书籍：数据结构和算法分析(Java语言描述)》)]]></content>
      <categories>
        <category>DataStructure</category>
      </categories>
      <tags>
        <tag>AVL树</tag>
        <tag>递归</tag>
        <tag>读书笔记</tag>
        <tag>数据结构</tag>
        <tag>二叉查找树</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java编程思想之内部类]]></title>
    <url>%2F2019%2F10%2F14%2FJava%E7%BC%96%E7%A8%8B%E6%80%9D%E6%83%B3%E4%B9%8B%E5%86%85%E9%83%A8%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[可以将一个类的定义放在另一个类的定义内部，这就是内部类，Java的内部类用者很多妙用和特性。但对于内部类，总是有一些不明白的地方，最近看了书，算是有所收获，来记录一下内部类相关知识。 内部类主要分为一下几种(还有一些接口内部类省略) 非静态内部类 普通内部类 局部内部类 匿名内部类(前面介绍工厂模式用过，这里不赘述) 静态内部类(嵌套类) 非静态内部类 非静态内部类的创建非静态内部类的创建必须依赖于其外部类(稍后会说到为什么)，对于非静态内部类而言，在拥有外部类对象之前是不可能创建内部类对象的。 创建内部类对象格式外部类名.内部类名 内部类对象名=外部类对象.new 内部类名() 指向外部类的引用在内部类中，使用外部类.this可以获取对外部类对象的引用。直接使用this就是对自身的引用 123456789101112131415161718192021222324//外部类public class DoThis &#123; void f() &#123; System.out.println(&quot;DoThis.f()&quot;); &#125; //DoThis类的内部类 public class Inner&#123; //返回对外部类对象的引用 public DoThis outer() &#123; //通过外部类名.this获取外部类对象的引用 return DoThis.this; &#125; &#125; public static void main(String[] args) &#123; //先创建外部类对象 DoThis dt=new DoThis(); 通过外部类对象创建内部类对象 DoThis.Inner inner = dt.new Inner(); DoThis outer = inner.outer(); System.out.println(outer == dt); //两个引用指向同一个对象，因此返回true &#125;&#125; 内部类对象和外部类对象的关系当生成一个内部类对象时，该对象与制造它的外部类对象之间存在着一种联系，它能够无条件的访问其外部类对象的所有成员。内部类自动拥有对其外围类所有成员的访问权，这是如何做到的呢？当某个外部类对象创建了一个内部类对象时，该内部类对象会自动获取一个指向该外部类对象的引用。然后在使用内部类来访问外部类的成员时，就会使用那个引用来操作。因为内部类中会有一个指向外部类对象的引用，因此内部类对象的创建必须依靠外部类对象，否则无法获取到该引用。 局部内部类在一个方法的作用域内(而不是在类内)创建一个完整的类，这被称为局部内部类。 123456789101112131415161718192021222324252627282930313233public class Parcel6 &#123; private void inter(boolean b) &#123; if (b) &#123; //该类被嵌入在if语句的作用域内，这并不是说该类的创建是有条件的，它其实和别的类一起编译过了， // 然而在定义该类的作用域之外，他是不可用的。除此之外，它与普通的类一样 class Tracking&#123; private String id; Tracking(String s) &#123; id = s; &#125; String get() &#123; return id; &#125; &#125; Tracking t = new Tracking(&quot;局部内部类&quot;); System.out.println(t.get()); &#125; &#125; //在方法之外无法访问Tracking类 //Tracking t = new Tracking(&quot;局部内部类&quot;); public void track() &#123; inter(true); &#125; public static void main(String[] args) &#123; Parcel6 p=new Parcel6(); p.track(); &#125;&#125; 注意，上面代码中Tracking类是一个局部内部类，它是inter(boolean b)方法的一部分，而不是Parcel6类的一部分。所以，在方法之外不能访问该内部类。 静态内部类(嵌套类)如果不需要内部类对象和其外部类对象之间的引用关系，可以将类声明为static，这通常称为嵌套类。需要牢记：普通内部类(包括局部内部类)对象隐式的保存了一个引用，指向创建它的外部类对象，而static不存在这个引用。这也就是说，嵌套类的创建不需要依赖于外部类的对象。 嵌套类创建外部类名.内部类名 对象名=new 内部类名() 1234567891011121314//外部类public class Practice18 &#123; //内部类 protected static class Inner&#123; public void show() &#123; System.out.println(&quot;你好，嵌套类&quot;); &#125; &#125; public static void main(String[] args) &#123; //对于嵌套类(静态内部类)，不需要创建其外围类对象啊，通过外围类名可以直接调用 Practice18.Inner inner = new Inner(); inner.show(); &#125;&#125; 多层类的嵌套一个内部类被嵌套多少层并不重要，他能透明的访问所有它嵌入的外围类的所有成员 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253//最外围类public class Practice20 &#123; //创建内部类对象 Practice20.Innerclass1 innerclass1=new Innerclass1(); //创建内部类的内部类对象 Practice20.Innerclass1.Innerclass2 innerclass2=innerclass1.new Innerclass2(); private void show() &#123; System.out.println(&quot;Practice20.show()&quot;); &#125; //内部类 private class Innerclass1&#123; //创建内部类对象 Innerclass1.Innerclass2 innerclass2 = new Innerclass2(); private void show() &#123; //对外围类的引用 Practice20.this.show(); System.out.println(&quot;Innerclass1.show()&quot;); &#125; //内部类的内部类 private class Innerclass2&#123; private void show() &#123; //对最外围类的引用 Practice20.this.show(); //对外围类的引用 Innerclass1.this.show(); System.out.println(&quot;Innerclass2.show()&quot;); &#125; &#125; &#125; public static void main(String[] args) &#123; //创建最外部类对象 Practice20 p=new Practice20(); p.show(); System.out.println(&quot;===============&quot;); //通过最外部类对象创建其内部类对象 Practice20.Innerclass1 innerclass1 = p.new Innerclass1(); innerclass1.show(); System.out.println(&quot;===============&quot;); //通过内部类对象创建内部类的内部类对象 Practice20.Innerclass1.Innerclass2 innerclass2=innerclass1.new Innerclass2(); innerclass2.show(); &#125;&#125; 当出现下列情况，即子类和父类不在一个包下时，子类如果想创建父类内部类的对象，那么父类的内部类构造器必须为public，否则子类无法访问到父类内部类的构造器。 12345678910111213141516171819202122232425262728//Pricitice6有一个protected修饰的内部类，如果不显式指明，其构造方法也是protected的public class Pricitice6 &#123; protected class Inner implements inter&#123; //显式指明public构造方法 public Inner() &#123; &#125; @Override public void show() &#123; System.out.println(&quot;内部类实现的接口&quot;); &#125; &#125;&#125;=========================================================================//在另一个包下，有Pricitice6的一个子类Pricitice6Testpublic class Pricitice6Test extends Pricitice6 &#123; public inter geta() &#123; //在另一个包下，如果想要创建其父类的内部类对象，那么要求该内部类的构造方法必须是public //否则子类无法访问到其父类内部类的构造器(因为不在一个包下) return new Inner(); &#125; public static void main(String[] args) &#123; Pricitice6Test p=new Pricitice6Test(); Pricitice6Test.Inner inner=p.new Inner(); &#125;&#125;]]></content>
      <categories>
        <category>Java编程思想</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>Java基础</tag>
        <tag>内部类</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之工厂模式]]></title>
    <url>%2F2019%2F10%2F14%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[本文主要介绍工厂模式的两种实现方式：即接口实现和匿名内部类实现。在介绍工厂模式之前，会先对接口的一些细节性知识做一个记录和小结。 接口 接口的访问权限 public公共接口，所有类都能访问 default包访问权限，只有同一个包内的类可以访问 接口的变量可以含有变量，但是接口中的变量默认都是sttaic final public修饰，即接口中只有常量。 接口的方法对于接口中的方法可以显式的声明为public，也可以不声明，接口中的方法默认是public的。因此当实现一个接口时，在接口中被定义的方法必须为public，否则会报错。接口中可以有三种方法 默认方法(default修饰) 123456789101112131415161718192021222324251. 接口方法和父类方法参数列表和返回值一样，那么&quot;类优先原则&quot;，使用父类方法interface inter3&#123; default void show() &#123; System.out.println(&quot;接口方法&quot;); &#125; &#125;class sub extends classDefault implements inter3 &#123;&#125;public class classDefault &#123; public void show() &#123; System.out.println(&quot;父类方法&quot;); &#125; public static void main(String[] args) &#123; sub s=new sub(); s.show(); &#125;&#125;=============Output：父类方法2. 接口方法和父类方法参数列表不同时，构成重载3. 接口方法和父类方法参数列表一样，返回值不一样时，报错，因为返回值不同不构成重载。 抽象方法(没有方法体) 静态方法 12345678910111213141516171819JDK8中，添加了静态方法 interface inter3&#123; static void show() &#123; System.out.println(&quot;接口方法&quot;); &#125; &#125;class sub extends classDefault implements inter3 &#123;&#125;public class classDefault &#123; public void show() &#123; System.out.println(&quot;父类方法&quot;); &#125; public static void main(String[] args) &#123; sub s=new sub(); s.show(); &#125;&#125;同样的，也是类优先原则。不同的是，接口中的静态方法和类一样，可以使用接口直接调用。 工厂模式(接口) 需要两个接口，一个是工厂接口，一个是想要的实现类接口(比如这里最后想要得到Animal对象，那就创建一个Animal接口) 创建不同的类来实现Animal。这里我想要一个狗和一个猫，那我就分别创建两个类来实现Animal接口。如果还想要别的动物，那就创建再创建类来实现Animal接口。 为每一个实现类创建一个单独的工厂类，每一个工厂类都实现工厂接口。这样通过不同的工厂类就能够得到不同的动物实现类。 最后只需要传入相应的工厂类即可得到不同的Animal实现类，即得到不同的动物。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263//Animal接口interface Animal&#123; void eat();&#125;//工厂接口interface AnimalFactory&#123; Animal getAnimal();&#125;//Animal接口实现类--Dogclass Dog implements Animal &#123; @Override public void eat() &#123; System.out.println(this.getClass().getSimpleName() + &quot; eat meet&quot;); &#125;&#125;//Animal接口实现类--Catclass Cat implements Animal&#123; @Override public void eat() &#123; System.out.println(this.getClass().getSimpleName() + &quot; eat fish&quot;); &#125;&#125;//相应实现类的工厂实现类class DogFactory implements AnimalFactory &#123; @Override public Animal getAnimal() &#123; return new Dog(); &#125;&#125;//相应实现类的工厂实现类class CatFactory implements AnimalFactory &#123; @Override public Animal getAnimal() &#123; return new Cat(); &#125;&#125;public class Factories &#123; //静态方法，返回Animal接口的实现类(多态) public static Animal CreateAnimal(AnimalFactory factory) &#123; return factory.getAnimal(); &#125; public static void main(String[] args) &#123; Factories.CreateAnimal(new DogFactory()).eat(); Factories.CreateAnimal(new CatFactory()).eat(); &#125;&#125;=============Output：Dog eat meetCat eat fish 工厂模式(匿名内部类+Lambda表达式)12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849//Animal接口interface Animal&#123; void eat();&#125;//工厂接口interface AnimalFactory&#123; Animal getAnimal();&#125;//Animal接口实现类--Dogclass Dog implements Animal &#123; @Override public void eat() &#123; System.out.println(this.getClass().getSimpleName() + &quot; eat meet&quot;); &#125; //使用匿名内部类实现工厂接口 public static AnimalFactory factory = () -&gt; new Dog();&#125;//Animal接口实现类--Catclass Cat implements Animal&#123; @Override public void eat() &#123; System.out.println(this.getClass().getSimpleName() + &quot; eat fish&quot;); &#125; //使用匿名内部类实现工厂接口 public static AnimalFactory factory = () -&gt; new Cat();&#125;public class Factories &#123; //静态方法，返回Animal接口的实现类(多态) public static Animal CreateAnimal(AnimalFactory factory) &#123; return factory.getAnimal(); &#125; public static void main(String[] args) &#123; //调用不同Animal实现类的类变量作为参数传入 Factories.CreateAnimal(Dog.factory).eat(); Factories.CreateAnimal(Dog.factory).eat(); &#125;&#125;==============Dog eat meetCat eat fish 这种方式不同为每一个Animal实现类单独创建一个工厂实现类，而是以匿名内部类的方式实现工厂接口并作为相应动物类的静态变量，看起来更为优雅简单。]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>接口</tag>
        <tag>设计模式</tag>
        <tag>匿名内部类</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[手写简单的LinkedList集合]]></title>
    <url>%2F2019%2F10%2F13%2F%E6%89%8B%E5%86%99%E7%AE%80%E5%8D%95%E7%9A%84LinkedList%E9%9B%86%E5%90%88%2F</url>
    <content type="text"><![CDATA[前面介绍了一个简单了AyyayList集合，现在来继续整个复杂一点的，那就是双向链表组成的LinkedList集合。 实现功能集合底层是一个带头节点和尾节点的双向链表，主要步骤和完成的功能 创建一个节点类，可以是一个私有的嵌套类 创建一个链表类 一个私有的内部类实现了Iterator接口，作为迭代器 实现的接口方法 isEmpty()、clear()、size()等基础方法 add()方法几种重载形式、get()方法 set()方法、remove()方法 内部方法我们知道，当我们在使用链表进行操作的时候，输入的总是值或者是index位置，但是实际上我们需要通过位置来定位到链表中具体的节点从而对链表进行操作。 代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233import java.util.ConcurrentModificationException;import java.util.Iterator;import java.util.NoSuchElementException;public class MyLinkedList&lt;T&gt; implements Iterable&lt;T&gt; &#123; //记录元素个数 private int size = 0; //分为指向头节点和为尾节点 private Node&lt;T&gt; first; private Node&lt;T&gt; last; //用于判断迭代器是否过时 private int modeCount = 0; //节点类 private static class Node&lt;T&gt;&#123; private Node&lt;T&gt; pre; private Node&lt;T&gt; next; private T d; //构造方法 public Node(T ele, Node p, Node n) &#123; d = ele; this.pre = p; this.next = n; &#125; &#125; //以下为接口方法 /*=========================================*/ /** * 构造方法 */ public MyLinkedList() &#123; doclear(); &#125; /** * 清空集合 */ public void clear() &#123; doclear(); &#125; /** * 创建带头节点的链表 */ public void doclear() &#123; size = 0; first = new Node&lt;&gt;(null, null, null); last = new Node&lt;&gt;(null, first, null); first.next = last; modeCount++; &#125; /** * 判断是否为空 * @return */ public boolean isEmpty() &#123; return size() == 0; &#125; /** * 返回集合元素个数 * @return */ public int size() &#123; return this.size; &#125; /** * 移除指定位置元素 * @param index * @return */ public T remove(int index) &#123; return remove(getNode(index)); &#125; /** * 修改指定位置元素的值 * @param index * @param val * @return */ public T set(int index, T val) &#123; Node&lt;T&gt; p = getNode(index); T oldValue = p.d; p.d = val; return oldValue; &#125; /** * 指定位置添加元素 * @param index * @param x */ public void add(int index, T x) &#123; addBefore(getNode(index, 0, size()), x); &#125; /** * 默认尾添加 * @param ele */ public void add(T ele) &#123; add(size(), ele); &#125; /** * 获取指定位置的元素 * @param index * @return */ public T get(int index) &#123; return getNode(index).d; &#125; /** * 返回一个迭代器，用于遍历链表 * @return */ @Override public Iterator&lt;T&gt; iterator() &#123; return new LinkedListIterator(); &#125; //以下为内部方法 /*===========================================*/ /** * 内部方法 * @param p * @return */ private T remove(Node&lt;T&gt; p) &#123; T ele = p.d; p.pre.next = p.next; p.next.pre = p.pre; size--; modeCount++; return ele; &#125; /** * 获取指定索引元素值 * @param index * @return */ private Node&lt;T&gt; getNode(int index) &#123; return getNode(index, 0, size() - 1); &#125; /** * 返回指定索引元素节点 * @param index * @param lower * @param upper * @return */ private Node&lt;T&gt; getNode(int index, int lower, int upper) &#123; Node&lt;T&gt; p; if (index &lt; lower || index &gt; upper) &#123; throw new IndexOutOfBoundsException(); &#125; if (index &lt; size() / 2) &#123; p = first.next; for (int i = 0; i &lt; index; i++) &#123; p = p.next; &#125; &#125; else &#123; p = last; for (int i = size(); i &gt; index; i--) &#123; p = p.pre; &#125; &#125; return p; &#125; /** * 插入到指定节点前面 * @param p * @param ele */ private void addBefore(Node&lt;T&gt; p, T ele) &#123; p.pre = p.pre.next = new Node(ele, p.pre, p); size++; modeCount++; &#125; //私有内部类，实现Iterator接口，用作迭代器 private class LinkedListIterator implements Iterator&lt;T&gt; &#123; private Node&lt;T&gt; current = first.next; private int expCount = modeCount; private boolean canRemove = false; @Override public boolean hasNext() &#123; return current!=last; &#125; @Override public T next() &#123; if (modeCount != expCount) &#123; throw new ConcurrentModificationException(); &#125; if (!hasNext()) &#123; throw new NoSuchElementException(); &#125; T ele = current.d; current = current.next; canRemove = true; return ele; &#125; @Override public void remove() &#123; if (expCount != modeCount) &#123; throw new ConcurrentModificationException(); &#125; if (!canRemove) &#123; throw new IllegalStateException(); &#125; MyLinkedList.this.remove(current.pre); expCount++; canRemove = false; &#125; &#125; &#125; 一个简单地双向链表实现的LinkedList集合就完成了，其实难度并不高，但是在上手之前，最好先明确自己要实现什么功能(也就是实现几个接口方法)，有了大方向之后在动手实现就会事半功倍。]]></content>
      <categories>
        <category>DataStructure</category>
      </categories>
      <tags>
        <tag>集合</tag>
        <tag>链表</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java编程思想之final和多态]]></title>
    <url>%2F2019%2F10%2F13%2FJava%E7%BC%96%E7%A8%8B%E6%80%9D%E6%83%B3%E4%B9%8Bfinal%E5%92%8C%E5%A4%9A%E6%80%81%2F</url>
    <content type="text"><![CDATA[多态是Java语言面向对象的三大特征之一，也是Java很有特色的部分。这里对于多态的基本知识不做赘述，主要关注多态的一些细节知识。 final关键字final通常指的是”这是不可变的”，它可以用来修饰数据、方法、类，下面就分别谈谈这三种用法 final数据 final修饰基本数据类型表示该变量不可改变，在对这个常量定义的时候，必须对其进行赋值。一个既是final又是static的字段只占据一块不可改变的空间，通常被称为编译期常量。 final修饰对象引用表示该对象引用不能再指向其他的对象，即引用指向不可变，但是对象自身数据却是可以改变的。 final数据的初始化对于final字段(成员变量)，要么在定义时初始化，要么在构造器中对其进行初始化。这保证了final字段在使用前总被初始化 final参数Java允许在方法的参数列表中以声明的方式将参数指明为final，这就表示无法在方法中改变参数的值或参数引用所指向的对象12345public static void f(final int i) &#123; //无法对i重新赋值 //i = 0; System.out.println(i); &#125; final方法使用final方法主要是为了把方法锁定，以防止任何继承类修改它的含义，即确保在继承中使方法的行为保持不变，且不会被覆盖 final和private关键字类中所有的private关键字都隐式的指定为final。因为你无法取用private方法，自然也就无法覆盖它。对于final和private，稍后会在多态提到 final类当一个类整体定义为final时，该类就不可被继承，但是final类的字段可以不是final。对于final类中的方法，因为final类是不可被继承的，因此final类的所有方法都不能被覆盖，因此这些方法都隐式的被指定为final。 多态Java中除了static和final方法(private属于final方法)，其他所有方法都是后期绑定。由于static和final方法在编译期进行了解析，那么也就不存在多态，因此可以得出结论：static、private、final修饰的方法不存在多态。 static方法是属于类的方法，对于所有的对象不会有不同的行为 final方法和private方法不能被重写覆盖，自然也就不会产生多态了 不能覆盖私有方法下面一段代码123456789101112131415161718192021class BB extends PrivateTest&#123; public void show() &#123; System.out.println(&quot;privateOverride&quot;); &#125;&#125;public class PrivateTest &#123; private void show() &#123; System.out.println(&quot;private f()&quot;); &#125; public static void main(String[] args) &#123; PrivateTest p = new BB(); p.show(); BB b=new BB(); b.show(); &#125;&#125;============Output：private f()privateOverride 测试可以看出，private方法并没有被覆盖，即父类的private修饰的show()方法对子类是屏蔽的，子类的show()方法相当于是一个全新的方法。 不能覆盖字段下面一段代码123456789101112131415161718192021222324252627282930313233class Div extends FinalField&#123; public int field = 1; public int getField() &#123; return field; &#125;&#125;public class FinalField &#123; public int field = 0; public int getField() &#123; return field; &#125; public static void main(String[] args) &#123; FinalField f = new Div(); //父类的field字段 System.out.println(f.field); //子类的getField方法，返回子类的field字段 System.out.println(f.getField()); Div d=new Div(); //子类的field字段 System.out.println(d.field); //子类的getField方法 System.out.println(d.getField()); &#125;&#125;==============Output：0111 当Div对象(子类对象)向上转型为父类对象时，任何字段访问操作都将由编译器解析，因此不是多态的。可以这么理解，在子类对象中，为父类和子类的field字段分配了两块不同的空间。所以在使用时，不建议给父类和子类字段取相同的名字。 构造器内部的多态下面一段代码12345678910111213141516171819202122232425262728293031323334353637383940class AAA &#123; void draw() &#123; System.out.println(&quot;father.draw()&quot;); &#125; AAA() &#123; System.out.println(&quot;father.draw() before&quot;); //父类构造器调用了draw()方法 draw(); System.out.println(&quot;father.draw() after&quot;); &#125;&#125;class BBB extends AAA&#123; private int i = 1; BBB(int i) &#123; //子类构造器首先执行父类构造器 this.i = i; System.out.println(&quot;BBB+&quot;+i); &#125; void draw() &#123; System.out.println(&quot;son.draw():&quot; + i); &#125;&#125;public class PolyConstructors &#123; public static void main(String[] args) &#123; BBB b = new BBB(5); &#125;&#125;===============Output：father.draw() beforeson.draw():0father.draw() afterBBB+5 在上面这段测试中，子类BBB重写了父类的draw方法。在创建子类对象时，会先执行父类的构造器。那么在父类构造器中调用的肯定是子类的draw方法(多态)，这没有问题。但是我们在创建子类对象时期望的是son.draw():5而不是son.draw():0，因为我们传递的i的参数为i=5，这就出现了错误。这是因为，在所有代码执行之前，虚拟机会将分配给对象的空间初始化成二进制0(JVM虚拟机中讲到过)，而父类构造器中执行draw方法时，子类对i的赋值还没有进行，此时i仍是初始化的0，这样就出现了问题。]]></content>
      <categories>
        <category>Java编程思想</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>Java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java编程思想之复用类]]></title>
    <url>%2F2019%2F10%2F12%2FJava%E7%BC%96%E7%A8%8B%E6%80%9D%E6%83%B3%E4%B9%8B%E5%A4%8D%E7%94%A8%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[这次主要介绍一下访问权限修饰符的一些细节和复用类的几种方法 访问权限控制我们都知道，Java中有四种访问权限修饰符，它们从大到小依次为public-&gt;protected-&gt;包访问权限(没有关键字)-&gt;private。 为什么要设置访问权限控制？当你编写一个代码给别人用的时候(例如写一个类库，后面假设就是类库)，你可能会发现类库中的某些代码或者方法有更好的实现方式，因此你可能需要对代码进行反复修改。举个例子，JDK7中的HashMap使用的是数据+链表实现，后来发现链表较长时效率不高，因此就改成了数组+链表+红黑树实现。但是你在修改代码的过程中，你需要确保使用你类库的人不会因为你改动的这些代码而受到影响。这很容易理解，别人可能正在用你的一些方法，而你把这个方法删掉了，那么别人的代码就用不了了。这时候，你就需要确认那些地方是类库使用者用不到的，那些地方是使用者正在使用的。因此Java就提供了访问权限控制，供类库开发人员向使用者指明哪些是可用的，哪些是不可用的。这样就很容易的知道你能够改动哪些部分而不会影响别人的使用。 总的来说，控制对成员的访问权想有两个原因 1. 为了使用户不要触碰那些它们不该触碰的部分，这些部分对类的内部操作是必要的，但是并不属于使用者所需要接口的一部分 2. 也是最重要的，为了让类库设计者可以更改类的内部工作方式而不必担心这样会对使用者产生重大影响 复用类 组合语法(has-a关系)实现很简单，只需要在新的类中产生现有类的对象，由于新的类是由现有类的对象组成，所以这种方法成为组合。例如 12345678class ClassTest&#123;&#125;public class combimation &#123; //在新类中产生ClassTest类对象和String类对象 private ClassTest c = new ClassTest(); private String s = &quot;abc&quot;;&#125; 继承语法(is-a关系)子类继承父类时，会自动得到父类所有的字段和方法(即得到父类所有的部分)，这里也包括private修饰的字段和方法，只是子类不能够直接访问这些private字段和方法。但是可以通过反射来访问。 初始化父类当创建一个子类对象时，该子类对象包含了一个父类的子对象，这个子对象和你直接用父类创建的对象是一摸一样的。两者的区别在于直接用父类创建的对象在外部，而子对象被包裹在子类对象的内部。因此，在初始化子类对象时，对子类对象中的父类子对象的初始化是至关重要的。即在子类构造器中调用基类构造器来执行对子对象的初始化，如果没有写，编译器会自动在子类构造器第一行加上对父类无参构造器的调用(super())。 注意：在构造器中，super和this关键字不能同时使用，因为两者都必须位于第一行。但是如果只写this来调用子类其他构造方法，编译器会自动添加对父类无参构造方法的调用。 12345678910111213141516171819202122class ClassTest&#123; ClassTest() &#123; System.out.println(&quot;父类构造器&quot;); &#125;&#125;class ClassSon extends ClassTest&#123; ClassSon() &#123; System.out.println(&quot;子类构造器&quot;); &#125; ClassSon(int i) &#123;// super(); 同时写super和this会编译报错 this(); //只写一个this，编译器会隐式的添加对父类无参构造方法的调用// super(); &#125;&#125;=============Output：父类构造器子类构造器]]></content>
      <categories>
        <category>Java编程思想</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>Java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java编程思想之初始化与清理]]></title>
    <url>%2F2019%2F10%2F12%2FJava%E7%BC%96%E7%A8%8B%E6%80%9D%E6%83%B3%E4%B9%8B%E5%88%9D%E5%A7%8B%E5%8C%96%E4%B8%8E%E6%B8%85%E7%90%86%2F</url>
    <content type="text"><![CDATA[为了巩固基础，特意找来了”Java圣经”之称的《Java编程思想》(第四版)来看，准备一边学习一边做笔记，虽然会慢一点，但是感觉会扎实一点。 方法重载方法重载以及其底层原理在前面已经介绍过，就不多说。只需要记住，区分重载方法的规则很简单：每个重载方法都必须有一个独一无二的参数类型列表。 涉及基本类型的重载基本类型能从一个”较小”的类型自动提升至一个”较大的类型”。即byte-&gt;short-&gt;int-&gt;long-&gt;float-&gt;double。对于char类型，会自动提升至int类型而不是short类型如果传递的实际参数大于方法要求的参数，就必须进行显式类型转换，否则编译不通过。 在构造器中调用构造器一个类有多个不同的构造器，如果想要在一个构造器中调用另外一个构造器，可以使用this(通过传递参数调用不同的构造器)。但是，this()部分必须位于构造器的第一行，这也就意味着尽管可以用this调用以恶搞构造器，但是只能调用一个。并且，除了构造器外，不能在任何其他方法中调用构造器。 12345678910111213public class initTest &#123; public initTest() &#123; this(10); //this代码必须位于第一行 this(1, 9); //只能调用一次 &#125; public initTest(int i) &#123; &#125; public initTest(int a, int b) &#123; &#125;&#125; 成员初始化初始化顺序： 父类静态部分(静态代码块和静态成员变量初始化顺序取决于代码上的顺序) 子类静态部分(静态代码块和静态成员变量初始化顺序取决于代码上的顺序) 父类非静态代码块和父类成员变量(初始化顺序取决于代码上的顺序) 父类构造方法 子类非静态代码块和子类成员变量(初始化顺序取决于代码上的顺序) 子类构造方法 类是在其任何static成员被访问时加载的(构造器是隐式的static)，静态变量和静态代码块只有在第一次创建对象时初始化一次。这是因为静态部分在类加载过程中进行初始化(前面介绍过)，而类只加载一次，因此静态部分也就只初始化一次。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859class staticfield&#123; public staticfield(String s) &#123; System.out.println(s); &#125;&#125;class Father&#123; static &#123; System.out.println(&quot;父类静态代码块&quot;); &#125; private static staticfield s=new staticfield(&quot;父类静态变量&quot;); public Father() &#123; System.out.println(&quot;Father 构造方法&quot;); &#125; &#123; System.out.println(&quot;Father 普通代码块&quot;); &#125; private staticfield f=new staticfield(&quot;父类成员变量&quot;);&#125;class Son extends Father&#123; private static staticfield s=new staticfield(&quot;子类静态变量&quot;); static &#123; System.out.println(&quot;子类静态代码块&quot;); &#125; public Son() &#123; System.out.println(&quot;Son 构造方法&quot;); &#125; private staticfield f=new staticfield(&quot;子类成员变量&quot;); &#123; System.out.println(&quot;Son 普通代码块&quot;); &#125;&#125;public class staticinit &#123; public static void main(String[] args) &#123; Son s=new Son(); &#125;&#125;=================Output：父类静态代码块父类静态变量子类静态变量子类静态代码块Father 普通代码块父类成员变量Father 构造方法子类成员变量Son 普通代码块Son 构造方法]]></content>
      <categories>
        <category>Java编程思想</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>Java基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[手写简单ArrayList集合]]></title>
    <url>%2F2019%2F10%2F11%2F%E6%89%8B%E5%86%99%E7%AE%80%E5%8D%95ArrayList%E9%9B%86%E5%90%88%2F</url>
    <content type="text"><![CDATA[ArrayList集合是Java中最常用的集合类之一，是一个能够扩容的集合，它的底层维护的是一个数组。闲来无事，今天就手写一个简单地ArrayList集合吧。 实现功能 可以自动进行扩容，并允许回收老数组 实现get()和set方法 提供size()、isEmpty()和clear()方法以及remove()方法、两种不同的add()方法 能够使用迭代器Iterator 代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156public class MyArrayList&lt;T&gt; implements Iterable&lt;T&gt;&#123; //初始容量，默认为10 private final int DEFAYLT_VALUE = 10; //集合中元素个数 private int size; //底层数组 private T[] Array; /** * 构造方法 */ public MyArrayList() &#123; //无参构造方法，默认创建大小为10的集合 grow(10); &#125; /** * 清空集合 */ public void clear() &#123; size=0; grow(DEFAYLT_VALUE); &#125; /** * 获取元素个数 * @return */ public int size() &#123; return size; &#125; /** * 判断是否为空 * @return */ public boolean isEmpty() &#123; return size == 0; &#125; /** * 获取指定元素 * @param index * @return */ public T get(int index) &#123; //判断参数正确性 if (index &lt; 0 || index &gt;= size) &#123; throw new ArrayIndexOutOfBoundsException(); &#125; return Array[index]; &#125; /** * 修改指定元素 * @param index * @param newValue */ public void set(int index, T newValue) &#123; if (index &lt; 0 || index &gt;= size) &#123; throw new ArrayIndexOutOfBoundsException(); &#125; Array[index] = newValue; &#125; /** * 添加方法 * @param value */ public void add(T value) &#123; //默认将元素添加到末尾 add(size, value); &#125; /** * 添加方法 * @param index * @param value */ public void add(int index, T value) &#123; //如果参数小于0，默认插到头部 if (index &lt; 0) &#123; index = 0; &#125; //如果参数大于当前集合中元素个数，默认插到尾部 if (index &gt;= size) &#123; index = size; &#125; //如果集合满，那么就以2倍扩容 //+1是为了防止出现0*2==0的情况 if (size == Array.length) &#123; grow(Array.length * 2 + 1); &#125; for (int i = size; i &gt; index; i--) &#123; Array[i] = Array[i - 1]; &#125; Array[index] = value; size++; &#125; public T remove(int index) &#123; if (index &lt; 0 || index &gt;= size) &#123; throw new ArrayIndexOutOfBoundsException(); &#125; T removeEle = Array[index]; for (int i = index; i &lt; size; i++) &#123; Array[i] = Array[i + 1]; &#125; size--; return removeEle; &#125; /** * 数组扩容 * @param newSize */ private void grow(int newSize) &#123; if (newSize &lt; size) &#123; return; &#125; T[] oldArr = Array; Array = (T[]) new Object[newSize]; for (int i = 0; i &lt; size; i++) &#123; Array[i] = oldArr[i]; &#125; &#125; //由于容器实现了Iterable接口，所以要重写该方法，返回一个迭代器 @Override public Iterator&lt;T&gt; iterator() &#123; return new ArrayListIterator(); &#125; //该类实现了Iterator接口，重写hasNext()、next()、remove()方法 private class ArrayListIterator implements Iterator&lt;T&gt; &#123; private int cur=0; @Override public boolean hasNext() &#123; return cur &lt; size(); &#125; @Override public T next() &#123; if (!hasNext()) &#123; throw new NoSuchElementException(); &#125; return Array[cur++]; &#125; @Override public void remove() &#123; MyArrayList.this.remove(--cur); &#125; &#125;&#125; 这样，一个极其简化的ArrayList集合就写出来了。]]></content>
      <categories>
        <category>DataStructure</category>
      </categories>
      <tags>
        <tag>数组</tag>
        <tag>集合</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[最大子序列和问题]]></title>
    <url>%2F2019%2F10%2F11%2F%E6%9C%80%E5%A4%A7%E5%AD%90%E5%BA%8F%E5%88%97%E5%92%8C%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[题目：给定一个数组，在数组所有的子序列中找到和最大的子序列。我将用4中解法来对该题进行求解 暴力求解 算法思想思路很简单，遍历数组所有的子序列，对每个子序列进行求和，找到最大的和并返回 代码实现 1234567891011121314151617181920212223/** * 暴力求解 * @param arr * @return */public static int maxSubSum(int[] arr) &#123; int maxsum=0; //遍历以数组中所有元素开头的子序列 for (int i = 0; i &lt; arr.length; i++) &#123; //对于每个元素，以该元素开头的所有长度序列都要计算一次 for (int j = i; j &lt; arr.length; j++) &#123; int thissum = 0; //计算序列和 for (int k = i; k &lt;= j; k++) &#123; thissum += arr[k]; &#125; if (maxsum &lt; thissum) &#123; maxsum = thissum; &#125; &#125; &#125; return maxsum;&#125; 时间复杂度三重循环，所以时间复杂度为O(N3) 优化暴力求解 算法思想我们需要知道，f(k+1)=k+f(k)，即对于一个子序列，该子序列的和，等于它前一个子序列的和加上一个元素得到。借此可以消除一层循环 代码实现 1234567891011121314151617181920/** * 优化暴力解法 * @param arr * @return */public static int maxSubSum1(int[] arr) &#123; int maxsum=0; //同样的，遍历以每个元素开头的序列 for (int i = 0; i &lt; arr.length; i++) &#123; int thissum = 0; //找到以arr[i]开头的所有序列中最大和序列 for (int j = 0; j &lt; arr.length; j++) &#123; thissum += arr[j]; if (maxsum &lt; thissum) &#123; maxsum = thissum; &#125; &#125; &#125; return maxsum;&#125; 时间复杂度双重循环，时间复杂度为O(N2) 分治算法 算法思想分治的思想就是把问题分成两个大致相等的子问题，然后递归对它们进行求解这就是”分”；”治”阶段将两个子问题的解修补到一起并可能再做一些少量步骤的附加工作，最后得到整个问题的解。对于这个题，最大子序列可能在三处出现 该子序列全部位于数组的左边 改子序列全部位于数组的右边 该子序列跨越数组中部，即一部分在左边一部分在右边 因此我们可以进行分治递归求解 代码实现 1234567891011121314151617181920212223242526272829303132333435363738394041424344/** * 分治算法 * @param arr * @param left 初始值为0 * @param right 初始值为arr.length-1 * @return */public static int maxSubRec(int[] arr, int left, int right) &#123; //递归出口，当左边界等于右边界时只有一个数，直接返回 if (left == right) &#123; return arr[left]; &#125; int center = (left + right) / 2; //左递归，求出数组左边部分最大子序列 int leftsum = maxSubRec(arr, left, center); //右递归，求出数组右边部分最大子序列 int rightsum = maxSubRec(arr, center + 1, right); //求出跨越数组中部的子序列左边部分的最大值 int leftbordersum = arr[center]; int maxleftborder = arr[center]; for (int i = center - 1; i &gt;= left; i--) &#123; maxleftborder += arr[i]; if (leftbordersum &lt; maxleftborder) &#123; leftbordersum = maxleftborder; &#125; &#125; //求出跨越数组中部的子序列右边部分的最大值 int rightbordersum = arr[center + 1]; int maxrightborder = arr[center + 1]; for (int i = center +2; i &lt;= right; i++) &#123; maxrightborder += arr[i]; if (rightbordersum &lt; maxrightborder) &#123; rightbordersum = maxrightborder; &#125; &#125; //leftbordersum+rightbordersum即为数组中间部分的最大值 //返回三者最大值，即为最大子序列和 return Math.max(Math.max(leftsum, rightsum), leftbordersum + rightbordersum);&#125; 时间复杂度O(NlogN) 动态规划我们需要知道，负数不可能是最大子序列的前缀，这不难理解，因为一个负数对于序列和没有任何增益效果反而会使得序列和变小。那么可以推广的到任何负序列也不可能是最大子序列的前缀。由此可以得到动态规划解法 123456789101112131415161718192021222324/** * 动态规划 * 时间复杂度：O(n) * @param arr * @return */public static int maxSubSumdyn(int[] arr) &#123; int maxsum=0; int thissum = 0; for (int i = 0; i &lt; arr.length; i++) &#123; thissum += arr[i]; //当前最大子序列和小于当先序列和时，更新最大子序列和 if (maxsum &lt; thissum) &#123; maxsum = thissum; &#125; //当thissum&lt;0时，说明当前子序列和为负，丢弃该子序列 else if (thissum &lt; 0) &#123; thissum = 0; &#125; &#125; return maxsum;&#125;//该算法中加了一个可以得到最大子序列左右边界的实现 时间复杂度很明显的。只有一重循环，复杂度为O(N)，是线性的 四种解法，动态规划法最优，个人感觉分治算法较为考验细节部分]]></content>
      <categories>
        <category>算法之美</category>
      </categories>
      <tags>
        <tag>数组</tag>
        <tag>动态规划</tag>
        <tag>分治算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[自顶向下之计算机网络和因特网-运输层]]></title>
    <url>%2F2019%2F10%2F09%2F%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B%E4%B9%8B%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%92%8C%E5%9B%A0%E7%89%B9%E7%BD%91-%E8%BF%90%E8%BE%93%E5%B1%82%2F</url>
    <content type="text"><![CDATA[运输层位于应用层和网络层之间，是分层网络体系结构的重要部分。该层为运行在不同主机上的应用进程提供直接的通信服务起着至关重要的作用。其中两个运输层协议TCP和UDP是本次介绍的重点。 概述和运输层服务运输层介绍运输层协议为运行在不同主机上的应用进程提供了逻辑通信功能。运输层协议是在端系统中而不是在路由器中实现的。 在发送端，运输层将从应用程序接收到的报文转换成运输层分组(报文段) 实现的方法是将应用报文划分为较小的块，并为每块加上一个运输层首部从而生成运输层报文段 然后，在发送端系统中，运输层将这些报文段传递到网络层，网络层将其封装为网络层分组(数据报)并向目的地发送 在接收端，网络层从数据报中提取运输层报文段，并将该报文段上交给运输层 运输层则处理接收到的报文段，最后将其中的数据交给应用程序 通过上述过程可以明确：网络路由器仅作用于该数据报的网络层字段，即它们不检查封装在该数据报的运输层报文段的字段。事实上网络路由器并没有实现运输层协议。 运输层和网络层的关系 在协议栈中，运输层位于网络层上面，网络层提供了主机之间的逻辑通信，而运输层为运行在不同主机上的进程之间提供了逻辑通信 在端系统中，运输层协议将来自应用进程的报文移动到网络边缘(网络层)，反之亦然。但对有关这些报文在网络核心如何移动不做任何规定。中间路由器既不处理也不识别运输层加载应用层报文上的任何信息。 运输层能够提供的服务常常受制于网络层协议的服务模型。如果网络层协议无法为主机之间发送的运输层报文段提供延时或带宽保证的话，那么运输层协议也就无法为进程之间发送的应用程序提供延时和带宽保证。 然而，即使底层网络协议不能再网络层提供相应的服务，运输层协议也能提供某些服务。例如，网络层IP协议是不可靠的，然而应用层协议TCP却是可靠的传输协议。 因特网运输层概述因特网运输层为应用层提供两种不同的运输层协议 UDP协议，它提供了一种无连接的、不可靠的的服务 TCP协议，提供了一种可靠的、面向连接的服务 在对UDP和TCP进行介绍之前，先简要介绍一下因特网网络层，因特网网络层协议中有一个IP协议(网际协议)，IP协议为主机提供了逻辑通信。IP协议的服务模型是尽力而为交付服务。也就是说，IP尽它最大的努力在通信主机之间交付数据，但它并不做任何保证。他不确保报文段的交付、不保证报文段的按序交付，不保证报文段中数据的完整性(可以理解为三无产品…)。即IP为不可靠服务。初步了解了IP服务模型之后，来总结一下TCP和UDP所提供的服务模型 TCP和UDP最基本的责任是，将两个端系统间IP的交付服务扩展为运行在端系统上的两个进程之间的交付服务。 将主机间的交付扩展到进程间的交付被称为运输层的多路复用和多路分解 UDP和TCP还可以通过在其报文段首部中包括差错检查字段来提供完整性检查 以上两种服务是最低限度的运输层服务，同时也是UDP仅能提供的两种服务。 UDP和IP一样，UDP提供了是一种不可靠服务(不止一次提到过)，它不能保证数据能够完整的从一个进程发送到另外一个进程。 TCPTCP为应用程序提供了几种附加服务 可靠数据传输通过使用流量控制、序号、确认和定时器TCP能够确保正确的、有序的将数据交付给接收进程(后面将会具体说到) 拥塞控制服务前面说到过，该服务是一种提供给因特网的服务，它防止任何一条TCP连接用过多的流量来淹没通信主机之间的链路和交换设备。(后面会着重介绍) 多路分解和多路复用多路复用和多路分解，即将网络层提供的主机间的交付服务扩展到运行在主机上的进程间的交付服务。在发送主机中，发送主机将应用层报文推进套接字，在套接字中为应用层报文加上运输层报文首部字段形成运输层报文段，然后将报文段交付给运输层。同样的在接收主机中，运输层实际上并没有直接将数据交付给进程，而是将数据交付给中间的套接字。 多路分解将运输层报文段中的数据交付到正确的套接字 多路复用在源主机从不同套接字中收集数据块，并为每个数据块封装上首部信息(用于后面的多路分解)从而生成报文段，然后将报文段传递到网络层。 无连接的多路复用和多路分解如下图在主机A(客户主机)和主机B(服务主机)中各有3个进程，假设每个进程分配了一个套接字(实际上一个进程可能分配多个)。现在A主机的进程1(端口号为7777)，要向B主机上的进程1(端口号为4567)发送一个应用层报文 将应用层报文推进进程1对应的套接字中，形成如图所示的应用层报文段，该报文段中有这样两个字段。然后将该报文段交付给运输层 目的端口号发送进程的端口号 源端口号接受进程的端口号 运输层将接收到的报文段传递给网络层 网络层将接收到的报文段封装为IP数据报，并尽力的交付给B主机(目的主机)。 主机B有多个进程，每个进程都有一个UDP套接字和端口号，当报文段从应用层到达时，主机B通过检查该报文段中的目的端口号，将报文段定向(分解)到对应的套接字中。在本例中，报文段的目的端口号为4567，那么最终会被交付给B主机的进程1套接字 套接字将报文段数据取出并交付给B中的接收进程1。 以上就是无连接的多路分解和多路复用 注意：一个UDP套接字是由一个二元组全面标识的，该二元组包含一个目的IP地址和一个目的端口号。因此，如果两个UDP报文段有不同的源IP地址或源端口号，但是具有相同的目的IP地址和目的端口号，那么这两个报文段会被定向到同一个目的套接字(目的进程)如下图所示 面向连接的多路复用和多路分解前面说过，UDP的套接字是由一个二元组标识，而TCP的套接字是由一个四元组标识(源IP地址，源端口号，目的IP地址，目的端口号)来标识的。因此，当一个TCP报文段到达一台主机时，该主机使用4个值来将报文段定向(分解)到相应的套接字。和UDP不同的是，两个具有不同的源IP地址或源端口号的TCP报文段将被定向到两个不同的套接字。如图所示 报文段中源端口号的作用：假设A向B发送数据，报文段中的源端口号就是运行在A上的进程的端口号。当B要向A发送数据时，B发送的报文段的目的端口号就从这里取值。 无连接运输：UDPUDP做了运输协议能够做的最少工作。UDP从应用进程得到数据，附上用于多路复用/分解的源和目的端口号，以及两个其他的小字段形成了UDP报文段。然后将报文段交付给网络层。其中，使用UDP时，在发送报文段之前，发送方和接收方的运输层实体之间没有进行握手，正因为如此，UDP被称为无连接运输协议。我们前面说过的DNS应用层协议就是基于UDP运输协议的。当一台主机的DNS应用程序想要进行以恶搞查询时，它构造一个DNS查询报文并将其交给UDP。UDP为此报文添加首部字段封装为UDP报文段并交付给网络层。 UDP的优点 采用UDP时，只要应用进程将数据传递给UDP，UDP就会将数据封装成UDP报文段并立即交付给网络层。而TCP并非如此，TCP有一个拥塞控制机制，当源和目的主机间的一条或多条通信链路变得极为拥塞时来遏制TCP发送方。这样会导致报文段的延时发送。 无需建立连接：TCP在开始数据传输之前会经历三次握手。而UDP却并不需要任何准备即可进行数据传输。因此UDP不会引入建立连接的时延。这也是DNS建立在UDP而非TCP上的原因 无连接状态：TCP需要在端系统中维护连接状态。该连接状态包括接收和发送缓存、拥塞控制参数以及序号和确认号参数。而对于UDP而言，不需要维护连接状态，也不需要跟踪这些参数 分组首部开销小：每个TCP报文段首部为20字节，而UDP报文段首部只有8个字节。 另外，虽然UDP是不可靠的数据传输协议，但这并不意味着使用UDP的应用不能实现可靠数据传输，可以通过在应用程序自身建立可靠性机制来完成。例如谷歌的Chrome浏览器使用的QUIC协议在UDP之上的应用层协议中是西安了可靠性。 UDP报文段的结构如图，一个UDP报文段的结构及其首部字段的作用： UDP检验和UDP提供了差错检验功能。它的检验和字段用于确定当UDP报文段从源到目的地移动时，其中的bit是否发生了变化。发送方的UDP对报文段中所有16bit字的和进行反码运算，求和时遇到的任何溢出都被回卷。得到的结果放在UDP报文段中的检验和字段中。例如假定有3个16bit的字 1234567891011121314151617180110 0110 0110 00000101 0101 0101 0101 1000 1111 0000 1100前两个16bit字的和：0110 0110 0110 00000101 0101 0101 0101 ————————————————————1011 1011 1011 0101再加上第三个16bit字1011 1011 1011 01011000 1111 0000 1100————————————————————(在这次加法中有溢出，它要被回卷)0100 1010 1100 0010将该结果进行反码运算得到1011 0101 0011 1101==&gt;这就是检验和 在接收方，将全部的4个16bit字(包括检验和)加在一起。如果该UDP报文段没有差错，那么在接收方的和应该是1111 1111 1111 1111。 可靠数据传输原理《计算机网络自顶向下方法》p134-144，转换图很多很详细，就不赘述了。归纳一下可靠数据传输协议的要点 检验和用于判断报文段是否有差错，如果有差错则重传 序号 定时器当发生丢包或者接收方确认超时时进行重传 肯定和否定确认分组对检验和无误的分组返回肯定ACK确认，对有误的分组返回否定NAK确认。 流水线可靠数据传输协议rdt3.0是一个正确的可靠数据传输协议(见书p141)，但是由于他是一个停等协议，所以性能不能够令人满意。停等协议，即发送方发送一个分组后，只有等到接收方的肯定确认才能发送下一个分组，性能较低。解决的方法就是不以停等方式运行，允许发送方发送多个分组而无需等待确认。即流水线技术如图，如果要使用流水线技术，那么就不得不考虑： 每个输送中的分组(不包括重传的)必须有一个唯一的序号。 协议的发送方和接收方两端不得不缓存多个分组，对于接收方，至少应该缓存哪些已发送但没有收到接收方确认的分组，接收方也需要缓存正确接收的分组(后面会说到)。 怎样处理丢失、损坏以及延时过大(超时)的分组 回退N步(Go-Back-N，GBN)解决流水线的差错回复有两种基本方法是：回退N步和选择重传。现在就介绍一下回退N步。在回退N步协议中，允许发送发发送多个分组而不需等待确认。但是在流水线中未确认的分组数不能超过某个最大允许数N。如图，显示了发送方看到的GBK协议的序号范围。可以将分组序号范围分成4段 [0，base-1]段内的序号对应已经发送并被确认的分组(收到接收方的ACK)。 [base，nextseqnum-1]段内的序号对应已经发送但没有被确认的分组(没有收到接收方的ACK) [nextseqnum，base+N-1]段内的序号能用于立即要被发送的分组。 [base+N，~]的序号处于窗口外面，不能被分组使用 随着协议的运行，分组被确认后base向前移动，该窗口在序号空间向前滑动。因此N被称为窗口长度，GBN协议也被称为滑动窗口协议。那么问题来了，为什么要限制这些已发送但未被确认的分组数目为N而不允许这些分组无限制数目(即N无穷大)呢？后面会说到TCP的流量控制和拥塞控制机制是限制窗口长度不能为无限大的的原因。 对于GBN协议，GBN发送方必须响应三种类型的事件 上层的调用当上层调用rdt_send()时(可以理解为应用层将数据交付给GBN协议)，发送方首先检查发送窗口是否已满，即是否有N个已发送但未被确认的分组。 如果窗口未满，则产生一个分组并将其发送，相应的更新变量 如果窗口已满，将数据返回上层，隐式的指示上层该窗口已满，上层可能过会儿再试。 收到一个ACK在GBN协议中，对序号n的分组采取累计确认的方式。表明接收方以正确接收序号在n之前(包括n)的所有分组。 超时事件协议的名字”回退N步”来源于出现丢失和延时过长分组时发送方的行为。当发送分组时，定时器开始计时，如果超时，则发送方重传所有已发送但还没确认的分组。 对于GBN协议，GBN接收方的动作 如果一个序号为n的分组被正确接收到，并且按序(即上一次收到的分许序号为n-1)，则接收方为分组n发送一个ACK分组，并将分组中的数据交付给上层。 在其他情况下，接收方丢弃该分组，并为最近按序接收的分组重新发送ACK。 从接收方的动作可以发现，当分组k已接收并被交付时，所有序号比k小的分组必然已经接收并交付。因此说GBK使用累计确认。如图给出一个长度为4的GBN协议运行情况 向上面给出的运行情况一样，GBN协议中，接收方丢弃所有失序的分组。 优点：接收方不缓存任何失序的分组，需要维护的唯一信息就是下一个按序接收分组的序号。 缺点：丢弃一个正确分组，后续对该分组的重传可能会丢失或出错，从而导致更多的重传。 选择重传对于GBN协议，当窗口长度和带宽延时较大时，单个分组的差错会引起大量分组的重传，但是许多分组并没有重传的必要。这样会导致更大的时延。顾名思义，选择重传(SR)协议通过让发送方仅重传那些它怀疑在接收方出错的分组而避免了不必要的重传。SR接收方将确认一个正确接受的分组而不管其是否按序。失序的分组n将被缓存，直到n之前的所有分组都被收到。这时才可以将这一批分组按序交付给上层。SR发送方事件和动作 从上层收到数据。从上层收到数据后，SR发送方检查下一个可用于该分组的序号。如果序号位于发送方窗口内，则将该数据打包并发送；否则和GBN一样，返回给上层。 超时。每个分组都有自己的逻辑定时器，和GBN不同(GBN公用一个定时器)，因为超时后只能发送一个分组。 收到ACK。 如果收到ACK，倘若该分组序号在窗口内，则SR发送方将那个被确认的分组标记为已接收。 如果该分组序号等于send_base(发送方基序号)，则窗口向前移动到最小的已发送但未确认分组序号处。 如果窗口移动了并且有未发送的分组序号位于窗口内，则发送这些分组。 SR接收方事件和动作 序号在[rec_base，rec_base+N-1]内的分组被正确接收。此时，收到的分组落在接收方窗口内，给发送方回一个ACK。 如果该分组以前没有收到过，缓存该分组。 如果该分组序号等于接收窗口的基序号(rec_base)，则将从该分组开始(包括该分组)的连续的缓存的分组交付给上层(例如之前收到了3，4，5，这一次收到了2，那么就将2，3，4，5一起交付给上层，并将rec_base移动到6)。 序号在[rec_base-N,rec_base+N-1]内的分组被正确收到。此时，必须产生一个ACK，即使该分组是接受方以前已经确认过的分组。因为可能虽然接收方确认了该分组，但是发送方并没有收到(ACK丢失)，如果不再次确认，这就导致发送方的send_base一直停在该分组序号处，窗口无法移动 其他情况，忽略该分组。 另外，由于分组的序号取模运算。因此窗口的长度必须小于序号空间的一半。假设序号空间为[0~3]，窗口长度为3(大于序号空间的一半) 123//有可能会出现这种情况：当收到分组0时，无法判断该分组是新的分组还是重传的分组。0，1，2，3，0，1，2，3如图8所示 面向连接的传输：TCP前面已经介绍了可靠数据传输的基本原理，现在就可以学习TCP了 TCP连接TCP在两个进程发送数据之前，这两个进程必须先相互”握手”，即它们必须相互发送一些预备报文段，以建立确保数据传输的参数。 双全工服务如果一台主机中的进程A和另一台主机上的进程B存在一条TCP连接，那么应用层数据就可在从A流向B的同时，也从B流向A。 点对点TCP连接是点对点的，即在单个接收方和单个发送方之间的连接。对于TCP而言，两个主机是一对。 TCP连接建立的大致过程 客户端首先发送一个特殊的TCP报文段，该报文段不承载数据 服务器用另一个特殊的TCP报文段来响应，该报文段不承载数据 客户端再用第三个特殊报文段作为响应，该报文段可以承载数据 建立起TCP连接后，两进程就能够互相发送数据。如图所示发送进程将数据推进套接字，TCP将数据导入TCP的发送缓存，发送缓存是三次握手期间设置的缓存之一。接下类TCP就会不时的从发送缓存中取出一块数据，并传递到网络层。TCP可从缓存中取出并放入报文段中的数据数量受限于最大报文段长度(MSS)，MSS通常根据本地发送主机发送的最大链路层帧长度(最大传输单元，MTU)来设置。设置该MSS要保证一个TCP报文段加上TCP/IP首部长度(通常40字节)将适合单个链路层帧。注意，MSS是指报文段里应用层数据的最大长度，而不是包括首部的TCP报文段的最大长度。 TCP报文段结构TCP报文段结构如图所示 目的端口号和源端口号用于多路复用和多路分解 检验和字段用于报文段的差错检验 序号字段和确认号字段被TCP发送方和接收方用来实现可靠数据传输 接收窗口字段用于流量控制，指示接收方愿意接受的字节数量 首部长度以32bit的字为单位，一般为10个字(20字节) 标志字段 ACK用于指示确认字段中的值是有效的，即该报文包含一个对已被成功接收报文段的确认 RST\SYN\FIN用于连接的建立和拆除 CWR\ECE明确拥塞通告中用到这两个字段 序号和确认号 序号TCP首部字段中最重要的两个字段。TCP把数据看成是一个有序的字节流。一个报文段的序号就是该报文段首字节的字节流编号。如图所示 确认号前面说过，TCP是双全工的，因此A在向B发送数据的同时，也许在接收B的数据。从B到达的每一个报文段中都有一个序号用于从B流向A的数据。主机A发送的报文中的确认号就是主机A期望从主机B接收到的下一个字节的序号(也就是下一个报文段的序号)。假设A已经收到了来自B的编号为0-535的所有字节，同时它打算给B发送一个报文段。那么该报文段的确认号就是A期望从B接收到的下一个字节的序号，也就是536。此外如果TCP收到了来自B的数据流0-535和900-1000。此时A到B的下一个报文段的确认号仍然是536而不是1001。即TCP只确认该流中第一个丢失的字节，所以TCP被称为提供累计确认。可靠数据传输前面说过，IP是不可靠的，TCP在IP不可靠的尽力而为服务上创建了一种可靠数据传输服务。TCP的可靠数据传输服务保证一个进程从其接收缓存中接收到的数据和发送进程发送的数据一模一样。为了简化讨论，先假设数据只从A到B，TCP发送方的动作 从应用程序接收数据从应用程序接收数据，生成具有序号seq的TCP报文段，如果定时器没有运行那么启动定时器 定时器超时重传序号最小的未收到确认的报文，重启定时器 收到ACK收到ACK，ACK的确认号为y，如果y&gt;sendBase，那么sendBase==y。其中sendBase为发送方为最早未被确认的字节序号。如果仍有未被确认的报文段，TCP还要重启定时器以上是TCP过程中两种特殊情况，还有一种情况和第二种类似，如果主机B的ACK=100和ACK=120没有超时，但是ACK=100丢失，即只有ACK=120按时到达了主机A，那么主机A不会重传任何报文，因此TCP的累计确认机制，发送方收到ACK=120后，就能够知道B已经收到了119以及之前的所有字节。 超时间隔加倍这是大多TCP实现中的一种改进，每当超时事件发生时，就像前面提到的，TCP发送方重传具有最小序号但还未被确认的报文段。但是每次TCP重传时都会将下次的超时间隔设为先前值得两倍。例如假设初始的TCP超时间隔为0.75s，那么第一次超时事件发生后，TCP重传报文段，并将超时间隔设置为1.5秒，以此类推……这样修改是因为，定时器过时很可能是因为网络拥塞引起的，分组并没有真的丢失。在拥塞的时候，如果发送方持续的重传分组，会导致拥塞更为严重，所以TCP采用超时间隔加倍的方式使延时的分组尽可能少的被重传。 快速重传前面说到的超时间隔加倍也可能存在一个问题，当一个分组真的丢失时，超时间隔过长就会导致端到端的时延，因此TCP设计了快速重传机制。TCP发送方通常可在超时事件发生之前通过冗余ACK来较好的检测到丢包的情况。冗余ACK就是对同一个报文段重复确认的ACK。如果TCP发送方接收到对相同数据的3个冗余ACK(即一共接收到4个ACK)，它就认为跟在这个已经被确认3次之后的报文段之后的报文段已经丢失(即序号为冗余ACK报文段确认号的报文段)。此时TCP进行快速重传，即在该报文段的定时器过期之前重传丢失的报文段。 流量控制前面提到过，TCP连接的两侧主机都为该连接设置了一个缓存，当TCP接收到正确按序的字节后，就将数据放入缓存，相应的进程会从缓存中读取数据。事实上，接收方应用也许正忙于其他任务，甚至要很长时间后才去读取该数据，如果某些应用程序读取数据时相对缓慢，而发送方发送的太多太快，发送的数据很容易使得接收缓存溢出而导致数据丢失。流量控制服务就是用来消除发送方使接收方缓存溢出得可能性。TCP通过让发送方维护一个称为接收窗口的变量来提供流量控制(即TCP报文段中接收窗口字段)。通俗的说，接收窗口是一个变量，用于给发送方一个指示–该接收方还有多少可用的缓存空间。由于TCP是双全工通信，因此连接连端各有一个接收窗口。现假设A通过TCP连接向B发送一个大文件。主机B为该连接分配了一个TCP接收缓存(用RcvBuffer表示其大小)。主机B上的进程不断地从该缓存中读取数据。我们定义一下变量 LastByteRead主机B上的进程从缓存中读取的最后一个字节的编号 LastByteRcvd从网络到达并放入B接收缓存中的数据流最后一个字节的编号。 由于TCP不允许缓存溢出，因此必须有(LastByteRcvd-LastByteRead)&lt;=RcvBuffer接收窗口用rwnd表示，根据缓存可用空间来设置：rwnd=RcvBuffer-(LastByteRcvd-LastByteRead)如图所示主机B通过把当前的rwnd的值放入它发给主机A的报文段接收窗口字段中，通知A它在该连接的接收缓存中还有多少可用空间，开始时rwnd=RcvBuffer在主机A中，主机A跟踪两个变量，LastByteSent和LastByteAcked，这两个变量的差LastByteSent-LastByteAcked就是A发送到连接中但未被确认的数据量，通过将该差值控制在rwnd以内，就可以保证B中接收缓存不会溢出。因此，主机A在该连接的整个生命周期保证LastByteSent-LastByteAcked&lt;=rwnd。 以上的流量控制还存在一个小问题：即当主机B的接收缓存已满，使得rwnd为0。再将rwnd=0发送给A之后，假设B没有任何数据要发送给主机A，那么当B的应用进程将接收缓存中的数据读取完之后，主机A并不知道B的接收缓存已经有新空间了。即主机A被阻塞而不能在发送数据。为了解决这个问题，TCP规范中要求：当主机B的接收窗口rwnd=0时，主机A继续发送只有一个字节数据的报文段。这些报文段将会被接收方确认。最终缓存开始清空，并且确认报文中将包含一个非0的rwnd值。这样主机A就能够知道B的接收窗口有空闲空间从而继续发送数据。 TCP连接管理下面主要介绍TCP连接是如何建立和拆除的，即三次握手、四次挥手是如何进行的。 三次握手 客户端TCP首先向服务器发送一个特殊的TCP报文段。该报文段不包含数据内容，但是报文段首部的SYN字段(回顾TCP报文段结构)被置1，因此该报文段又被称为SYN报文段。另外，客户端会随机选择一个初始序号(client_isn)，放在SYN报文段的序号字段中 服务器接收到客户端的SYN报文段后，就为该TCP连接分配TCP缓存和变量，并向客户端TCP发送允许连接的报文段。这个报文段也不包含应用层数据，SYN字段也被置为1(该报文段被称为font color=red&gt;SYNACK报文段)。服务器也会选择一个初始序号sever_isn，放在该SYNACK报文段的序号字段中。另外，该SYNACK报文段的确认号字段放的是client_isn+1。这个报文段实际上表明了：我收到了你的SYN分组，该分组的初始序号为client_isn，我同意建立连接。我的序号为sever_isn。 在收到SYNACK报文段后，客户端给该TCP连接分配缓存和变量。并且向服务器发送另外一个报文段；该报文段对服务器的SYNACK报文段进行了确认(将sever_isn+1放到确认号字段中)，因为连接已经建立，因此该报文段SYN置0，并且该报文段可以携带应用层数据。 四次挥手当TCP连接结束后，主机中的资源(缓存和变量)将被释放(来自网络) 客户的应用进程要关闭此连接，那么客户TCP发送一个FIN标志位置1的FIN报文段，并进入FIN_WAIT_1状态。等待一个来自服务器对FIN报文段的ACK报文段 服务器接收到来自客户端的FIN报文段，发出确认报文段ACK，进入CLOSE_WAIT状态。此时客户端向服务器方向的连接就释放了。该连接处于半关闭状态，即客户端已经没有数据要发送了，但服务器若发送数据，客户端依然要接受。 客户端收到来自服务器的ACK报文段后进入FIN_WAIT_2状态，等待来自服务器的FIN报文段 处于CLOSE_WAIT状态服务器如果仍有数据要发送，就继续发送数据。当服务器将该发送的数据发送完后，发送一个FIN报文段并进入LAST_ACK状态 处于FIN_WAIT_2状态的客户端收到来自服务器的FIN报文段后，发送一个ACK报文段进行确认并进入TIME_WAIT状态，该状态持续一段时间后自动退出，之后客户端释放资源 服务器收到来自客户端的ACK之后，直接释放资源。从图上可以看出，服务器释放资源要比客户端早一些 以上就是四次挥手的过程(由于书上描述的不够详细，从网上查阅资料结合书本得出) 关于”三次握手、四次挥手”的一些问题 为什么连接时三次握手，而关闭时却需要四次回收？ 在建立连接时，服务器收到客户端的SYN报文段时，发送的是SYNACK报文段，即SYN+ACK，该报文段即包含了对客户端SYN报文段的应答也包含了自己的连接请求SYN。 在关闭连接时，当服务器收到客户端的FIN报文段后，可能还有数据没有发送完毕仍然需要发送，并不能立刻关闭。因此并不会发送一个类似于SYNACK的FINACK，而是先发送ACK报文段对客户端的FIN报文段进行确认(告诉客户端你的FIN我收到了，此时客户端到服务器方向连接关闭)，然后发送需要发送的数据，等到数据发送完毕之后，再发送自己的FIN报文段(请求关闭到客户端方向的连接)。 为什么客户端在发送完对服务器的FIN报文段的ACK后需要一个TIME_WAIT状态而不能直接关闭？这是因为，有可能该ACK在网络中丢失，而服务器没有收到来自客户端的ACK报文段，那么服务器将重新发送FIN报文段，客户端需要对该重传的FIN再次进行ACK确认。 为什么不能用两次握手？这是为了防止已失效的连接请求报文段突然又到达了服务器。 客户端向服务器发送一个请求连接的SYN报文段1，但是该报文段由于网络延时较长，导致客户端认为该报文段丢失，然后重新发送SYN报文段2 SYN报文段2成功到达了服务器，最后成功的建立了TCP连接 客户端和服务器在完成数据传输后关闭了该TCP连接。 但是问题来了，前面延时的SYN报文段1经过较长一段时间后又到达了服务器。服务器会认为这是客户端新发起的TCP连接，因此向客户端发送一个ACK报文段，如果没有第三次握手，那么连接就已经建立了，但是事实上客户端并没有任何数据要发送给服务器，因为SYN报文段1对于客户端来说是一个过期的报文段。这样就白白浪费了资源。 拥塞控制原理在介绍拥塞控制原理之前，先简要介绍一下拥塞的原因和代价 拥塞的代价 如果网络中发生拥塞，那么路由器中会形成分组队列，首先会导致延时。 当分组队列过长时，由于路由器缓存有限，进而会造成分组丢失。 由于TCP是可靠数据传输服务，因此必须对丢失的分组进行重传。 当分组在路由器中延时过长导致超时，即使分组没有丢失那么TCP发送方也会重传分组，这就会导致路由器转发不必要的重复分组。 如果一个分组经过了很多个路由器后，在之后的路由器中因为超时或者路由器缓存溢出而丢失导致发送方对该分组进行重传，那么这就意味着该分组经过的每个上游路由器所用的资源都浪费了。 TCP拥塞控制TCP使用的是端到端的拥塞控制，这是因为IP层不向端系统提供显式的网络拥塞反馈。TCP所采用的方法是让每一个发送方根据所感知到的网络拥塞程度来限制其向连接发送流量的速率。如果发送方感知到从它到目的地之间没什么拥塞，就加快发送速率，反之，就抑制发送速率。那么问题来了 TCP发送方如何限制它向连接发送数据的速率呢？ TCP发送方如何感知从他到目的地之间的路径上存在拥塞呢？ 当发送方感知到拥塞时，采用什么算法来改变发送速率呢？ TCP限制向其连接发送流量的方式在前面提到过，TCP连接的每一端都是由一个接收缓存、一个发送缓存和几个变量组成。运行在发送方的TCP拥塞控制机制跟踪一个额外的变量，即拥塞窗口(cwnd)，它对一个TCP发送方能像网络中发送流量的速率进行了限制。一个发送方中未被确认的数据量不会超过cnwd和rnwd中的最小值，即(LastByteSent-LastByteAcked)&lt;=min{cwnd，rndw}在这里为了和流量控制区分开，我们假设接收窗口无限大(这样就不存在缓存溢出，也就不存在流量控制了)，因此在发送方未被确认的数据量就受限于cwnd，还假设发送方总是有数据要发送。这样的约束控制了发送方未被确认的数据量，间接的控制了发送方的发送速率。 TCP发送方感知网络拥塞的方式我们将TCP丢包事件定义为：要么出现超时，要么收到来自接收方的三个冗余ACK。 当出现过度拥塞时，在沿着这条路径上的一台或多台路由器缓存溢出，引发一个数据报(网络层分组，包含TCP报文段)丢失。丢失的分组接着会引起丢包事件，发送方就认为在网络中(发送方到接收方的网络路径)出现了拥塞。 当网络没有拥塞时，即没有出现丢包事件。在此情况下，TCP发送方将收到对未确认报文段的ACK。TCP将这些确认的到达作为网络正常的指示，并使用确认来增加窗口长度(发送速率)，(这不难理解，当发送方觉得网络很好的时候，理所当然的就会尝试提高发送速率)。注意，窗口增大的速率取决于ACK确认报文到达的速率。TCP使用确认来触发增大它拥塞窗口长度的被称为自计时方式。 那么TCP又是怎样确定发送速率呢？如果发送速率太快，会导致拥塞，太慢又导致带宽不能充分得到利用。TCP使用下列三种指导性原则 一个丢失的报文段意味着拥塞，因此当丢包事件发生时应当降低TCP发送方的速率 一个确认报文段(ACK报文段)意味着网络中一切顺利，因此对先前未确认的确认到达时，能够增加发送方速率 带宽检测。TCP调节其传输速率的策略是增加其速率以影响到达的ACK，除非出现丢包事件，此时才减小传输速率。该行为类似于一个要求并得到越来越多糖果的孩子，知道最后告知他不行。孩子后退一点，然后过一会儿再次开始要糖果。 概述了TCP拥塞控制后，现在开始介绍TCP拥塞控制算法细节，该算法主要包括3个部分： 慢启动 拥塞避免 快速恢复 前两种是TCP的强制部分 慢启动一条TC连接开始时，cwnd初始值同设置为一个MSS(最大传输单元)，这使得初始发送速率大约为MSS/RTT(平均往返时间)。对于TCP发送方而言，可用带宽可能远远大于该速率，因此发送方希望希望迅速找到可用带宽的数量cwnd的值以1个MSS开始并且每当传输的报文段首次被确认就增加一个MSS。如图所示从图中可以看出，没过一个RTT，发送速率就会翻倍。因此TCP发送速率起始满，但在慢启动阶段以指数增长。那么这种指数增长什么时候结束呢？有三种方式分别对应三种情况 出现由超时指示的丢包事件时(拥塞)TCP发送方将cwnd重新置为1，将ssthresh(慢启动阈值标记)设置cwnd/2(这里的cwnd是置1之前的值)，并重新开始慢启动过程。 当cwnd&gt;=sshthresh时当cwnd一直翻倍增长，超过ssthresh时，直接进入到拥塞避免模式(后面会说到)，这是因为，在第一种情况检测到拥塞时将sshthresh设置为拥塞时cwnd的一半，当cwnd再次达到ssthresh时，如果继续翻倍，那么很有可能继续造成拥塞，因此应采取更为缓慢的增长方式，即拥塞避免模式。 快速恢复如果检测到3个冗余的ACK，这时TCP将执行快速重传，并进入快速回复模式 拥塞避免一旦进入拥塞避免，cwnd的值大约是上次拥塞值得一半，即距离拥塞并不远。因此TCP使用一种较为保守的方式增加cwnd，每个RTT将cwnd的值增加一个MSS。如何结束拥塞避免模式得线性增长呢？ 出现由超时指示的丢包事件时(拥塞)和慢启动一样，将MSS设置为1个MSS，ssthresh设置为cwnd/2，重新进入慢启动模式 收到3个冗余ACK包将ssthresh设置为cwnd/2，然后将cwnd增加3个MSS(可以理解为3个冗余ACK各增加一个)，进入快速回复模式 快速回复在此状态下，对收到的每一个冗余ACK，cwnd值增加一个MSS。如何结束拥塞避免模式得线性增长呢？ 收到对未确认报文段的ACK将cwnd设置为ssthresh值，进入到拥塞避免模式 出现由超时指示的丢包事件时(拥塞)和慢启动一样，将ssthresh设置为cwnd/2，将cwnd置为1个MSS，重新进入慢启动模式 TCP拥塞控制的状态转换如图所示我们不难发现一些规律 引起状态转换一共有四种事件，分别是 超时 窗口长度超过阈值 收到正常ACK 收到累计3个冗余ACK 当累计收到3个冗余ACK时，必定会转换到快速回复模式，并有ssthresh=cwnd/2和cwnd=ssthresh+3 MSS操作 关于运输层的简要学习就到这里，主要介绍了多路复用/分解，滑动窗口协议、选择重传、TCP的可靠数据传输、超时间隔加倍以及快速重传、流量控制和拥塞控制机制等。下次介绍网络层相关知识。]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>计算机网络自顶向下方法</tag>
        <tag>传输层</tag>
        <tag>TCP</tag>
        <tag>UDP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[查找算法之二分查找]]></title>
    <url>%2F2019%2F10%2F08%2F%E6%9F%A5%E6%89%BE%E7%AE%97%E6%B3%95%E4%B9%8B%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE%2F</url>
    <content type="text"><![CDATA[查找在日常生活中的应用也非常广泛，除了一般的线性查找，还有专门针对有序数组得二分查找、插值查找、斐波那契查找等查找算法。今天介绍的就是著名的二分查找算法。 算法思路二分查找要求待查找数据是有序的。每次取出数据的中间项midValue，和要查找的数searchValue相比较 如果midValue&lt;searchValue，那么就在midValue得左边继续查找 如果midValue&gt;searchValue，那么就在midValue得右边继续查找 如果midValue==searchValue，返回midValue下标。 算法使用递归实现，当left(左边界)&gt;right(有边界)时，说明数据得每一个元素都已经被访问过仍然没有找到，返回-1。 代码实现 只查找一个值，找到后就返回，无论是否有重复值 123456789101112131415161718192021222324252627282930313233/** * 二分查找 * 找到一个就返回，不管是否重复 * @param arr 待查找数组 * @param left 左边界索引，初始值为0 * @param right 右边界索引，初始值为length-1 * @param value 要查找的值 * @return 返回值得下标，没找到返回0 */public static int binarySearch(int[] arr, int left, int right, int value) &#123; //递归出口当left&gt;right时说明说明数组每一个元素都已经遍历完但是没有找到，直接返回-1 if (left &gt; right) &#123; return -1; &#125; int mid = (right + left) / 2; int midValue = arr[mid]; //向右递归 if (value &gt; midValue) &#123; return binarySearch(arr, mid + 1, right, value); &#125; //向左递归 else if (value &lt; midValue) &#123; return binarySearch(arr, left, mid - 1, value); &#125; else &#123; return mid; &#125;&#125; 查找数据中所有值为value的下标，返回一个下标集合 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/** * 二分查找 * 找出所有值为value的下标 * @param arr 带查找数组 * @param left 左边界索引，初始值为0 * @param right 右边界索引，初始值为length-1 * @param value 要查找的值 * @return 值得下标集合 */public static List&lt;Integer&gt; binarySearch1(int[] arr, int left, int right, int value) &#123; //当left&gt;right时说明说明数组每一个元素都已经遍历完但是没有找到，直接返回-1 if (left &gt; right) &#123; return null; &#125; int mid = (right + left) / 2; int midValue = arr[mid]; //向右递归 if (value &gt; midValue) &#123; return binarySearch1(arr, mid + 1, right, value); &#125; //向左递归 else if (value &lt; midValue) &#123; return binarySearch1(arr, left, mid - 1, value); &#125; else &#123; //再找到mid值时不马上返回，向mid索引值的两边扫描 //将所有值为value的下标值添加到ArrayList集合中，最后返回集合 //向左查找 int goLeft=mid-1; List&lt;Integer&gt; list = new ArrayList&lt;&gt;(); while (left &gt; 0 &amp;&amp; arr[goLeft] == value) &#123; list.add(goLeft); goLeft--; &#125; //向右查找 while (mid &lt; arr.length &amp;&amp; arr[mid] == value) &#123; list.add(mid); mid++; &#125; return list; &#125;&#125; 插值查找请注意，当我们需要在数组{1,2,3….100}中查找1或100时，用二分会查找次数相对多一些，这时候可以用到插值查找插值查找思路也非常的简单，和二分查找唯一的区别在于mid(每次查找分界点)的选用不同。 二分查找每次都去中间的数据作为分界点即mid=left+(right-left)/2 而插值查找mid的选取是自适应的，和要查找的值findValue有关mid=left+(right-left)*{(findValue-arr[left])/(arr[right]-arr[left])} 代码实现12345678910111213141516171819202122232425/** * 插值查找 * @param arr 待查找数组 * @param left 左边界索引 * @param right 有边界索引 * @param findValue 待查找的值 * @return 数组下标，没找到返回-1 */public static int insertValueSearch(int[] arr, int left, int right, int findValue) &#123; //必须确保findValue在数组最大值和最小值中间，否则会导致数组越界 if (left &gt; right || findValue &lt; arr[left] || findValue &gt; arr[right]) &#123; return -1; &#125; int mid = left + (right - left) * (findValue - arr[left]) / (arr[right] - arr[left]); int midValue = arr[mid]; if (midValue &lt; findValue) &#123; return insertValueSearch(arr, mid + 1, right, findValue); &#125; else if (midValue &gt; findValue) &#123; return insertValueSearch(arr, left, mid - 1, findValue); &#125;else &#123; return mid; &#125;&#125; 算法分析这样一来，当要查找的数位于数据靠两边的位置时，查找次数会相对少一些。该算法适用于待查找数据较为连续时。当数不连续时有时甚至比二分查找次数更多一些。]]></content>
      <categories>
        <category>算法之美</category>
      </categories>
      <tags>
        <tag>递归</tag>
        <tag>二分查找</tag>
        <tag>查找</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[排序算法之基数排序]]></title>
    <url>%2F2019%2F10%2F07%2F%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E4%B9%8B%E5%9F%BA%E6%95%B0%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[这次要介绍的是最后一种排序算法，个人觉得也是最一种神奇的排序算法、当然更是最典型的空间换时间排序算法。它就是基数排序 算法思路 首先要额外申请10个桶(一维数组，和待排序数组arr一样大)，可以用二维数组来实现。 取出arr的每个元素个位数字m，根据元素的个位数字将元素放到下标为m的桶中(例如：123个位数为3，就将123放到下标为3的桶中) 将10个桶中的数依次再放回arr数组中 取出arr的每个元素十位数字，继续进行以上操作 知道最大元素的每个位都遍历完为止。 该算法按照个、十、百位等依次将元素进行排序，最终得到有序数组。 代码实现123456789101112131415161718192021222324252627282930313233343536373839/** * 基数排序 * @param arr 待排序数组 */public static void radixSort(int[] arr) &#123; //用作桶的数组 int[][] temp = new int[10][arr.length]; //计数数组，用于记录每个桶中有多少个数 int[] count = new int[10]; //找到最大的元素 int max = arr[0]; for (int i = 1; i &lt; arr.length; i++) &#123; if (arr[i] &gt; max) &#123; max = arr[i]; &#125; &#125; //获取最大元素的位数，即循环次数 int maxLength = (max + &quot;&quot;).length(); for (int r = 0, i = 1; r &lt; maxLength; r++, i *= 10) &#123; for (int j = 0; j &lt; arr.length; j++) &#123; //取出每个元素相应位的数 int digitElement = (arr[j] / i) % 10; //放到对应的桶中 temp[digitElement][count[digitElement]++] = arr[j]; &#125; //每一轮开始将arr下标置0 int index = 0; //遍历10个桶，将桶中元素放回arr数组中 for (int k = 0; k &lt; 10; k++) &#123; int countIndex = 0; //将每个桶中的元素依次放回arr数组中 while (count[k] &gt; 0) &#123; arr[index++] = temp[k][countIndex++]; count[k]--; &#125; &#125; &#125;&#125; 分析 时间复杂度 O(n*k) 空间复杂度 O(n+k) 稳定性 基数排序是稳定的 算法速度既然说基数排序是典型的空间换时间，那么它的性能究竟如何呢？来测试一下 12345678910111213141516171819//生成了一个800w的随机数组进行排序public static void main(String[] args) &#123; //随机生成一个数组，对其进行排序 int[] arr = new int[8000000]; Random random = new Random(); for (int i = 0; i &lt; arr.length; i++) &#123; arr[i] = random.nextInt(800000); &#125; System.out.println(&quot;====================&quot;); long start = System.currentTimeMillis(); radixSort(arr); long ends = System.currentTimeMillis(); System.out.println(&quot;插入排序共花费：&quot; + (ends - start) + &quot;毫秒&quot;);&#125;=============Output：500毫秒左右 在800w时，速度仅为快排的一半。但是由于该算法空间复杂度过高，因此在8000w时就OOM了。]]></content>
      <categories>
        <category>算法之美</category>
      </categories>
      <tags>
        <tag>排序</tag>
        <tag>基数排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[自顶向下之计算机网络和因特网-应用层]]></title>
    <url>%2F2019%2F10%2F07%2F%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B%E4%B9%8B%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%92%8C%E5%9B%A0%E7%89%B9%E7%BD%91-%E5%BA%94%E7%94%A8%E5%B1%82%2F</url>
    <content type="text"><![CDATA[应用层是五层协议中的最顶层，网络应用是计算机网络存在的理由，如果我们不能构想出来任何有用的应用，也就没必要去设计支持他们的网络协议了。接下来就介绍一些应用层的一些相关知识。 应用层协议原理开发网络应用的核心在于能够写出运行在两个不同的端系统和通过网络彼此通信的程序。例如，在WEB应用中，有两个相互通信的不同的程序：一个是运行在用于主机上的浏览器程序，另一个是运行在服务主机上的WEB服务器程序。 网络应用程序体系结构应用程序体系结构由研发者设计，规定了如何在各种端系统上组织该应用程序。有两种主流的体系结构 客户-服务器体系结构在该体系中，有一个总是打开的主机被称为服务器，它服务于来自许多被称为客户端主机的请求。该体系有两个特点 客户端和客户端不直接通信 服务器具有周知的固定的IP地址 P2P体系结构对专用服务器有最小的或者没有依赖，应用程序在间断连接的主机对直接直接通信，这些主机对称为对等方。 进程通信用操作系统的术语来说，进程通信的实际上是进程而不是程序 进程可以被认为是运行在端系统上的一个程序。 当多个进程运行在相同的端系统上时，它们使用进程通信机制相互通信。进程通信的规则由端系统上的操作系统确定。在这里，我们主要关注运行在不同端系统上的进程间通信。在两个不同端系统上的进程，通过跨越计算机网络交换报文而相互通信： 发送进程生成并向网络中发送报文 接收进程接受这些报文并可能通过回送报文进行相应 客户和服务器进程网络应用程序由成对的进程组成，这些进程通过网络相互发送报文。对于每一对通信进程，我们称其中一个为客户，另一个为服务器 客户在一对进程之间的会话通信中，发起通信的进程被标识为客户 服务器在会话开始时等待联系的进程被标识为服务器 进程和计算机之间的接口前面说过，多数应用程序是由通信进程对组成，每对两个进程间相互发送报文。从一个进程到另一个进程发送报文必须通过下面的网络。进程通过一个称为套接字的软件接口像网络发送报文和从网络接收报文。 套接字是同一台主机内应用层和运输层之间的接口(关于套接字在前面一篇文章已介绍过)，又被称为应用程序和网络之间的应用程序编程接口。 进程寻址为了向特定目的地发送邮件，需要一个地址。类似的，在一台主机上运行的进程为了向另一台主机上运行的进程发送分组，接收进程需要有一个地址，这样发送方才能通过这个地址找到接收进程。为了标识该进程，需要定义两种信息 主机的地址在因特网中，主机地址由IP地址标识。现在，只需要了解IP地址是一个32bit的数并且能唯一标识该主机。 目的主机中指定接收进程的标识符知道了主机的地址后，分组就能够到达改主机。但是，主机中运行着不止一个进程，发送进程还必须指定运行在接受主机上的接收进程。我们用目的端口号来标识进程。 发送进程通过IP地址和目的端口号，就能准确地将定位运行在目的主机上的接收进程。 可供应用程序使用的运输服务前面说了，套接字是应用程序和运输层协议之间的接口。在发送端的应用程序将报文推进该套接字，在套接字的另一侧，运输层协议负责从接收进程的套接字得到该报文。运输层协议不止一种，当开发一个应用时，要选择一种可用的运输层协议。一个运输层协议能够为调用它的应用程序提供呢？接下来将从四个方面对应用程序服务要求进行分类 可靠数据传输前面说过，分组在计算机网络中可能丢失。有时候，数据丢失会带来巨大的损失，如金融应用程序，文件传输等。为了支持这些应用，必须做一些工作以确保由应用程序的一端发送的数据正确、完全的交给另一端。如果一个列协议提供了这样的确保数据交付服务，就认为提供了可靠数据传输。运输层协议能够潜在的想应用程序提供的一个重要服务是进程到进程的可靠数据传输服务。当一个运输层协议不提供可靠数据传输时，由进程发送的某些数据就可能到达不了接收进程。像多媒体应用如视频音乐等应用是允许少量数据丢失的。 吞吐量可用吞吐量就是发送进程能够向接收进程交付比特的速率。运输层协议能够以某种特定的速率提供确保的可用吞吐量，使用这种服务，该应用程序能够请求r bit/s的确保吞吐量，并且该运输协议能够确保可用吞吐量总是至少为r bit/s。这对一些即时应用如视频会话很有吸引力。具有吞吐量要求的应用被称为带宽敏感应用。相对的，弹性应用能够根据当时可用的带宽或多或少的利用可供使用的吞吐量，如电子邮件等。 定时运输层协议也能提供定时保证。这种服务对于交互式应用很有吸引力，在多方游戏和虚拟互动环境中，在做出动作并看到来自环境的相应之间，较长的延迟极大的影响体验。 安全性在发送主机中，运输协议能够加密由发送进程传输的所有数据，在接受主机中，运输层协议能够在将数据交付给接收进程之前解密这些数据。这样就能够防止数据在发送的过程中被观察到。 因特网提供的运输服务上面考虑了计算机网络能够提供的通用运输服务，现在就具体介绍由因特网提供的运输层服务类型。因特网(或者说TCP/IP网络)为应用程序提供了两个运输层协议，即TCP和UDP TCPTCP服务包括面向连接和可靠数据传输服务。当某个应用程序调用TCP作为运输协议时，该应用程序就能获得来自TCP的这两种服务。 面向连接的服务在应用层数据报文开始流动之前，TCP让客户端和服务器相互交换控制层信息(握手过程)。握手阶段后，一个TCP连接就在连个进程的套接字之间建立了。这是一条双全工连接，即连接双方的进程可以在连接上同时进行报文收发。当应用程序结束报文发送时，该连接被拆除。 可靠的数据传输服务通信进程能够依靠TCP，无差错、按适当顺序交付所有发送的数据。 TCP协议具有拥塞控制协议，该服务不一定能贵进程带来直接好处，但能为互联网带来整体好处。当发送方和接收方之间的网络出现拥塞时，TCP的拥塞控制机制会抑制发送进程。 UDPUDP是无连接的，提供一种不可靠数据传输服务，也就是说，当进程将一个报文发送进UDP套接字时，UDP协议并不保证该报文将到达接收进程。并且接收进程的报文也有可能是乱序到达的。 前面说了四种运输协议的服务，那么对因特网运输协议来说，TCP提供了可靠数据传输并且能通过SSL提供安全性服务(后面会说到)。然而对于定时和吞吐量，因特网协议虽然没有提供任何保证，但是却能够为时间敏感应用提供满意的服务。 应用层协议应用层协议是网络应用的一部分(很重要的一部分)。前面介绍了通过把报文发送进套接字实现网络进程间的相互通信，但是如何构造这些报文？报文中字段的含义是什么等等问题……应用层协议定义了运行在不同端系统上的应用程序进程如何相互传递报文。特别是应用层协议定义了如下： 交换的报文类型，如请求报文和响应报文等 各种报文类型的语法 字段的含义 确定一个进程何时以及如何发送这些报文，对报文进行响应的规则 Web和TTTPWeb具有按需操作，当我们需要时，就能得到想要的内容。这不同于广播和电视，它们迫使用户只能收听观看它们提供的内容。 HTTP概况Web的应用层协议是超文本传输协议(Hyper Text Transfer Proyocol，即HTTP)，它是Web的核心。HTTP由两个程序实现：一个客户端程序和一个服务器程序。客户程序和服务器程序运行在不同的端系统中，通过交换HTTP报文进行会话。HTTP定义了这些报文的结构以及客户和服务器进行报文交换的方式。在介绍HTTP之前，先来了解几个Web术语 Web页面是由对象构成的，一个对象只是一个文件。诸如一个HTML文件、一个图片等等。且它们可以通过一个URL地址寻址。 URL地址每个URL地址包括两部分：存放对象的服务器主机名和对象地址。 HTTP定义了Web客户向Web服务器请求Web页面的方式以及服务器向客户传送Web页面的方式。HTTP使用TCP作为它的支撑运输协议。HTTP客户首先发起一个与服务器的TCP连接，一旦连接建立，该浏览器和服务器进程就可以通过套接字访问TCP。客户向它的套接字发送HTTP请求报文并从它的套接字接口接收HTTP响应报文。一旦客户向它的套接字发送了一个请求报文，该报文就脱离了客户控制并进入TCP控制。 无状态协议服务器向客户发送被请求的文件，而不存储任何关于该客户的状态信息，即HTTP是一个无状态协议。同时Web服务器总是打开的并且拥有一个固定的IP地址。 非持续连接和持续连接在许多因特网应用程序中，客户和服务器在很长的时间范围内通信，其中客户发出一系列请求并且服务器对每个请求进行响应。那么问题来了，每个请求/响应对是经一个单独的TCP连接发送还是所有的请求/响应对经同一个TCP连接发送呢？前面的方法被称为非持续连接，后面的被称为持续连接。 非持续连接对于非持续连接，每一次请求响应都要维持一个新的TCP连接。即一个请求/响应对对应着一个TCP连接。假设有一个Web页面包含一个HTML文件和10个png文件，那么发送该页面就要创建11个TCP连接。这种方式有一些缺点 必须为每一个请求/响应对建立和维护一个全新的TCP连接，对于每一个TCP连接，在客户端和服务器端中都要分配TCP缓冲区和保持TCP变量(后面会说到)，这给Web服务器带来了严重的负担 对于每个TCP连接的都要经历”三次握手”的过程，因此响应时间变长。 持续连接HTTP1.1使用了持续连接。服务器在发送响应后保持TCP连接打开。在相同的客户和服务器之间，后续的请求和响应报文能够通过相同的连接进行传送。一般来说，如果一条TCP连接经过一段时间间隔(可设置该间隔)仍未被使用，HTTP服务器就关闭该连接。 HTTP报文格式HTTP报文有两种：请求报文和响应报文 请求报文 请求行 方法字段：包括GET、POST等 URL字段 HTTP版本字段 请求头由一系列键值对组成(具体键值对在HTTP协议概述大致介绍过) 请求空行就是一个空行，用于分隔请求头和请求体 请求体 使用GET方法时请求体为空，此时请求参数跟在URL后面 使用POST方法时，请求参数被封装在请求体中。 响应报文和请求报文类似，响应报文也有4部分 响应行(状态行) 协议版本字段 状态码 对应状态信息 响应头同样的，由一系列键值对组成 响应空行用于分隔响应头和响应体 响应体包含了客户请求的对象。如HTML文档、jpg图片以及视频等 Web缓存Web缓存器也叫Web代理服务器。它能够代表初始服务器来满足HTTP请求的网络实体。Web缓存器有自己的磁盘空间，并在存储空间中保存最近请求过的对象的副本。如图，当浏览器正在请求对象http://www.aaa.com/campas.gif时 浏览器会创建一个到Wen缓存器的TCP连接，并向Web缓存器中对象发送一个HTTP请求 Web缓存器进行检查，查看本地是否存储了该对象的副本。如果有，Web缓存器就像客户浏览器用响应报文返回该对象 如果Web缓存器中没有该对象，它就创建一个与该对象初始服务器(www.aaa.com )的TCP连接。并在这个连接上发送一个该对象的HTTP请求。在接收到该请求后，初始服务器向Web缓存器发送具有该对象的响应报文。 Web缓存器收到来自初始服务器的对象时，在本地存储空间存储一份副本，并通过客户-缓存器的TCP连接向客户的浏览器用HTTP响应报文发送该副本。 通过上面的描述可以发现，Web缓存器既是客户又是服务器。 在因特网上部署Web缓存器的原因 Web缓存器可以大大减少对客户请求的响应时间，特别是客户与服务器之间的瓶颈带宽远低于客户与Web缓存器之间的瓶颈带宽时。 Web缓存器能够大大减少一个机构的接入链路到因特网的通信量。减少通信量，该机构就不必增加带宽，减少了成本。 Web缓存器能够从整体上大大降低因特网上的wen流量，从而改善了所有应用的性能。 条件GET方法前面说了Web缓存的一系列好处，但是也引入了一个新的问题：即存放在缓存器中的对象副本可能是陈旧的。换句话说，保存在服务器中的对象自改副本缓存在客户上以后可能已经被修改了。好在，HTTP协议有一种机制，允许缓存器证实它的对象是新的。这就是条件GET方法。如果 请求报文中使用GET方法 并且请求报文中包含一个”If-Modified-Since”请求头字段 那么该HTTP请求就是一个条件GET请求报文。 前面说过，当缓存器将对象转发到浏览器时，也在本地缓存了该对象。重要的是，缓存器缓存对象的同时也缓存了最后修改日期。 下次再次请求该对象时，该对象仍然在缓存器中。由于该对象再这期间可能被修改，所以该浏览器发送一个条件GET执行最新检查。 该请求里面有一个If-Modified-Since字段，该字段的值，正是上次缓存的最后修改日期。该条件GET报文告诉服务器，仅当自指定日期之后该对象没有被修改过，才发送该对象。 如果没有修改过，Web服务器向缓存器发送一个响应报文(该响应报文中响应体为空)，状态行为304 Not Modified。告诉缓存器可以使用该对象 缓存器将本地缓存的对象发送给浏览器。 DNS(Domain Name System)域名系统因特网上的主机和人类一样，可以用多种方式进行标识。主机的一种标识方法是用它的主机名，也可以用IP地址进行标识 DNS提供的服务主机名是一种方便人们记忆的标识方式，而路由器则更喜欢定长的、有结构层次的IP地址。为了折中这些偏好。我们需要一种能进行主机名到IP地址转换的目录服务，这就是域名系统的主要任务。DNS是： 一个由分层的DNS服务器实现的分布式数据库 一个使得主机能够查询分布式数据库的应用层协议 DNS是基于UDP协议的应用层协议，端口号为53。通常是由其他应用层协议所使用的，包括HTTP、SMTP和FTP，将用户提供的主机名解析为IP地址。当用户访问一个主机名时 将主机名发送给DNS应用的客户端 DNS客户端向DNS服务器发送一个包含主机名的请求 DNS客户最终会收到一份回答报文，其中包含主机名对应的IP地址 浏览器收到IP地址后，它能够向位于该IP地址的80端口的HTTP服务器进程发起一个TCP连接 从上面可以看到，DNS的使用会带来额外的网络时延，有时可能时延很长。但是幸运的是，我们想获得的IP地址通常就缓存在一个”附近”的DNS服务器中，这有助于减少DNS的网络流量和DNS平均时延。除了进行主机名到IP地址的转换以外，DNS还提供了一些其他的服务 主机别名有着复杂主机名的主机能拥有一个或多个别名。主机别名通常比主机规范名更加容易记忆。应用程序可以调用DNS来获得主机别名对应的主机规范名以及IP地址。 负载分配DNS也用于再冗余的服务器(如冗余的Web服务器)之间进行负载分配。繁忙的站点被冗余分布在多个服务器上，每台服务器运行在不同的端系统上，都有不同的IP地址。这些IP地址集合同一个主机名相联系。DNS数据库中存储着这些IP地址集合。当客户对映射到某地址集合的名字发出一个DNS请求时，该服务器用IP地址集合进行响应，但在每个回答中循环这些地址次序。因为这些客户通常总时向IP地址排在最前面的服务器发送HTTP请求报文，所以DNS就在所有这些冗余的Web服务器之间循环分配了负载。 DNS工作机理概述下面主要讨论DNS的主机名到IP地址转换服务。假设运行在用户主机上的某应用程序(Web浏览器等)需要将主机名转换为IP地址。 这些应用程序将调用DNS的客户端，并指明需要被转换的主机名 用户主机上的DNS接收到后，向网络中发送一个DNS查询报文。所有的DNS请求和回答报文使用UDP协议经53号端口发送 用户主机上的DNS接收到一个提供所希望映射的DNS回答报文。 这个映射结果被传递到调用DNS的应用程序。 从用户主机上调用应用程序的角度看，DNS是一个提供简单地直接转换的黑盒子。事实上，这个黑盒子相当复杂，它由分布在全球的大量DNS服务器以及定义了DNS服务器与查询主机通信方式的应用层协议组成。 分布式、层次数据库DNS使用了大量的DNS服务器，它们以层次的方式组织，并且分布在全世界范围内。没有一台服务器拥有因特网上所有主机的映射。DNS服务器分为三种 根DNS服务器有400多个根服务器分布在全世界，用于提供TLD服务器的IP地址 顶级域DNS(TLD)服务器每一个顶级域(如com、org、net等)和所有的国家顶级域(如cn、uk等)都有TLD服务器，用于提供权威服务器的IP地址 权威DNS服务器在因特网上具有公共可访问主机(例如Web服务器、邮件服务器等)的每个组织都必须提供公共可访问的DNS记录，这些记录将这些主机的名字映射为IP地址。 另外，还有一种很重要的DNS服务器，即本地服务器。它并不属于DNS服务器层次结构，但是它很重要。每个ISP都有一个本地DNS服务器，当主机和某个ISP连接时，该ISP提供一台主机的IP地址，该主机具有一台或多台其本地DNS服务器的IP地址。主机的本地DNS服务器通常”邻近”本主机。如图请求主机如果要得到服务器主机的IP地址，假设服务器主机名为( aaa.bbb.com) 主机向本地服务器发送一个DNS查询报文，该报文含有被转换的主机名 本地服务器将该报文转发到根服务器 根服务器注意到其com前缀并向本地服务器返回负责com得TLD得IP地址列表 本地服务器再向这些TLD服务器之一发送查询报文 该TLD服务器注意到bbb.com前缀，并用权威DNS服务器的IP地址进行响应，该权威服务器是bbb.com 最后，本地服务器直接向bbb.com重发查询报文,bbb.com用aaa.bbb.com的IP地址进行响应。这样就得到了服务器主机的IP地址。 DNS缓存在上述映射中，为了得到一台主机名的映射，共发送了8份DNS报文，这无疑是增加了查询流量和查询时延。实际上，为了改善时延性能并减少DNS报文数量，DNS广泛使用了缓存技术。DNS缓存的原理很简单，在一个请求链中，当某DNS服务器接收到一个DNS回答(如包含某主机名到IP的映射)时，它能将映射缓存在本地服务器中。如果DNS服务器缓存了一台主机名/IP对，另一个对相同主机名的查询到达该DNS服务器时，该DNS服务器就能够提供所要求的IP地址，即使它不是该主机名的权威服务器。 要注意的是，主机名和IP地址之间的映射不是永久的，DNS服务器会在一段时间后(一般设置为2天)丢弃该缓存信息 本地服务器也能够缓存TLD服务器的IP地址，因而允许本地DNS绕过查询链中的根DNS服务器。事实上，除了少数DNS查询外，根服务器被绕过了。 DNS记录和报文DNS记录共同实现DNS分布式数据库的所有DNS服务器存储了资源记录(Resource Record，简称RR)，RR提供了主机名到IP地址的映射。每个DNS回答报文包含了一条或多条RR。资源记录是一个包含了{Name，Value，Type，TTL}这些字段的四元组。 TTL是该记录的生存时间，它决定了资源记录应当从缓存中删除的时间 Name和Value的值取决于Type Type=A那么Name是主机名，Value是该主机名对应的IP地址。即一条A类型的资源记录提供了标准主机名到IP地址的映射。 Type=NS那么Name是一个域，而Value是一个权威服务器的主机名，该权威服务器能够获取该域中主机IP地址的。 Type=CNAME则Value是一个别名为Name的主机对应的规范主机名。 Type=MX则Value是一个别名为Name的邮件服务器的规范主机名。 如果一台DNS服务器是用于某特定主机名的权威DNS服务器，那么该DNS服务器会包含一条用于该主机名的类型A记录。 如果DNS服务器不是用于主机名的权威服务器 那么该服务器将包含一条NS记录，该记录对应包含主机名的域； 它还将包含一条类型A记录，该记录提供了上面NS记录中Value字段(权威服务器主机名)的IP地址 DNS报文前面说到了DNS查询和回答报文，DNS只有这两种报文并且两种报文格式相同。 前12个字节是首部区域 标识符(16比特)用于标识该查询。这个标识符会被复制到对查询的回答报文中，以便让客户用它来匹配发送的请求和收到的回答 问题区域包含正在进行的查询信息，该区域包括 名字字段包含正在被查询的主机名字 类型字段指出有关名字的正被询问的问题类型，如主机地址是一个和名字相关(类型A)还是和邮件服务器相关(类型给MX) 回答区域包含了对最初请求的名字的资源记录，在回答区域可以包含多条RR，因此一个主机名能够有多个IP地址的(前面讨论的冗余Web服务器) 权威区域包含了其他权威服务器的记录 应用层大致介绍到这里就结束了，主要介绍了HTTP和DNS两个应用层协议，至于书中的P2P、SMTP等其他协议就不赘述了。]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>DNS</tag>
        <tag>应用层</tag>
        <tag>HTTP</tag>
        <tag>计算机网络自顶向下方法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[排序算法之归并排序]]></title>
    <url>%2F2019%2F10%2F06%2F%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E4%B9%8B%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[前面说完了用递归实现的快速排序，这次介绍一下另外一种新的递归排序算法–归并排序。归并排序不仅用到了递归，更重要的是其分治的思想。 算法思路将待排序数组递归分成左右两部分，使得左右两部分数组分别有序，最后合并左右两数组得到有序的数组。对于长度为n得数组，一共只需要进行n-1次合并。以数组{8, 4, 5, 7, 1, 3, 6, 2}为例 第一次{8，4}的左右两部分合并为有序数组得到{4，8} 第二次{5，7}的左右两部分合并为有序数组得到{5，7} 第三次{4，8，5，7}的左右两部分合并为有序数组得到{4，5，7，8} 第四次{1，3}的左右两部分合并为有序数组得到{1，3} 第五次{6，2}的左右两部分合并为有序数组得到{2，6} 第六次{1，3，2，6}的左右两部分合并为有序数组得到{1，2，3，6} 最后一次{4，5，7，8，1，2，3，6}的左右两部分合并为有序数组得到{1，2，3，4，5，6，7，8}，最终得到有序数组 12345678910//对数组&#123;8, 4, 5, 7, 1, 3, 6, 2&#125;进行排序每一轮排序后的输出初始数组[1, 2, 3, 4, 5, 6, 7, 8]第一次归并过后[#4, 8#, 5, 7, 1, 3, 6, 2]第二次归并过后[4, 8, #5, 7#, 1, 3, 6, 2]第三次归并过后[#4, 5, 7, 8#, 1, 3, 6, 2]第四次归并过后[4, 5, 7, 8, #1, 3#, 6, 2]第五次归并过后[4, 5, 7, 8, 1, 3, #2, 6#]第六次归并过后[4, 5, 7, 8, #1, 2, 3, 6#]第七次归并过后[#1, 2, 3, 4, 5, 6, 7, 8#]排序后数组[1, 2, 3, 4, 5, 6, 7, 8] 代码实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162/** * 归并算法 * @param arr 原始数组 * @param left 左边界 * @param right 有边界 * @param temp 中间数组 */public static void mergeSort(int[] arr, int left, int right, int[] temp) &#123; if (left &lt; right) &#123; int mid = (left + right) / 2; //中间索引 //向左递归 mergeSort(arr, left, mid, temp); //向右递归 mergeSort(arr, mid + 1, right, temp); //调用方法合并 merge(arr, left, right, mid, temp); &#125;&#125;=======================================================================================/** * 每一次完成归并的方法 * @param arr 排序的原始数组 * @param left 左边有序序列的初始索引 * @param right 右边索引 * @param mid 中间索引 * @param temp 中转数组 */public static void merge(int[] arr, int left, int right, int mid, int[] temp) &#123; int i = left; //初始化左边有序序列的初始索引 int j = mid + 1; //初始化右边有序序列的初始索引 int t = 0; //初始化temp数组的当前索引 //先把左右两边的数据按照规则填充到temp数组中，直到左右两边的有序序列有一方处理完毕为止 while (i &lt;= mid &amp;&amp; j &lt;= right) &#123; if (arr[i] &lt;= arr[j]) &#123; temp[t] = arr[i]; t++; i++; &#125;else &#123; temp[t] = arr[j]; t++; j++; &#125; &#125; //把有剩余的一边依次全部填充到temp数组中 while (i &lt;= mid) &#123; temp[t++] = arr[i++]; &#125; while (j &lt;= right) &#123; temp[t++] = arr[j++]; &#125; //将temp数组元素拷贝到arr数组中 t=0; int tempLeft = left; while (tempLeft &lt;= right) &#123; arr[tempLeft++] = temp[t++]; &#125;&#125; 分析 时间复杂度 最好情况：nlogn 最差情况：nlogn 空间复杂度 一个temp数组，所以为O(n) 稳定性 归并排序是稳定的 算法速度同前面一样，用一个大小为80000的随机数组进行测试 12345678910111213141516public static void main(String[] args) &#123; //随机生成一个数组，对其进行排序 int[] arr = new int[8000000]; int[] temp = new int[arr.length]; Random random = new Random(); for (int i = 0; i &lt; arr.length; i++) &#123; arr[i] = random.nextInt(800000); &#125; System.out.println(&quot;====================&quot;); long start = System.currentTimeMillis(); mergeSort(arr, 0, arr.length - 1, temp); long ends = System.currentTimeMillis(); System.out.println(&quot;归并排序共花费：&quot; + (ends - start) + &quot;毫秒&quot;);&#125;======测试结果稳定在16-20毫秒左右]]></content>
      <categories>
        <category>算法之美</category>
      </categories>
      <tags>
        <tag>排序</tag>
        <tag>归并排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之单例模式]]></title>
    <url>%2F2019%2F10%2F03%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[单例模式是23种设计模式中最简单的一种。简单地说，单例模式就是整个程序中有且只有一个实例。该类负责创建自己的对象，同时确保只有一个对象。 单例模式分为两种 懒汉式线程不安全，即在使用时在进行初始化。 饿汉式线程安全，容易产生垃圾，因为类加载时就将对象初始化。 饿汉式饿汉式的实现很简单，类的实例作为该类的静态的成员属性和一个静态的public成员方法用于获取该属性，类加载时就已经生成了类的实例，调用静态方法可以获取该实例。代码如下 12345678910111213public class Singleton1 &#123; //私有化构造方法 private Singleton1() &#123; &#125; //饿汉式，类加载时就已经创建 private static Singleton1 s = new Singleton1(); //通过静态方法获取单例 public static Singleton1 getInstance() &#123; return s; &#125;&#125; 显而易见，getInstance方法里面的操作是原子性的，因此饿汉式单例模式是线程安全的 懒汉式线程不安全的实现代码如下 12345678910111213public class Singleton2 &#123; private Singleton2()&#123;&#125;; private static Singleton2 instance; //线程不安全的单例模式 public static Singleton2 getInstance() &#123; if (instance == null) &#123; instance=new Singleton2(); &#125; return instance; &#125;&#125; 由于懒汉式是线程不安全的，因此有两种实现方式 给相应部分加上同步代码块，使之变成线程安全这里用的是双重检查加锁123456789101112131415161718//双重检查加锁public class Singleton2 &#123; private Singleton2()&#123;&#125;; private static volatile Singleton2 instance; //一个线程安全的单例模式 public static Singleton2 getInstance() &#123; if (instance == null) &#123; synchronized (Singleton2.class) &#123; if (instance == null) &#123; instance=new Singleton2(); &#125; &#125; &#125; return instance; &#125;&#125; 以上实现代码只需要在第一次实例化单例的时候会执行到同步代码部分。 利用内部类实现使用静态内部类123456789101112public class Singleton3 &#123; private Singleton3() &#123; &#125; private static class inner&#123; private static Singleton3 instance=new Singleton3(); &#125; public static Singleton3 getInstance() &#123; return inner.instance; &#125;&#125; 可以看出，在获取方法中的操作也是原子性的，因此是线程安全的。]]></content>
      <categories>
        <category>设计模式</category>
      </categories>
      <tags>
        <tag>多线程</tag>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java内存模型]]></title>
    <url>%2F2019%2F10%2F01%2FJava%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[由于计算机的存储设备与处理器的运算速度有几个数量级差距，所以现代计算机系统都不得不加入一层读写速度尽可能接近处理器运算速度的高速缓存来作为内存与处理器之间的缓冲：将运算需要用到的数据复制到缓存中，让运算能够快速运行，当运算结束后再从缓存同步回内存之中，这样处理器就不用等待患难的内存读写了。 基础介绍上面说的基于高速缓存的存储交互很好的解决了处理器和内存的速度矛盾，但是又引入了新的问题：缓存一致性。在多个处理器系统中，每个处理器都有自己的高速缓存，而他们又共享同一主存。那么当多个处理器的运算任务都涉及同一块主存区域时，将可能导致各自缓存数据不一致，如果发生这种情况，那同步回主内存时又以以谁为准呢？为了解决一致性问题，需要各个处理器访问缓存时都遵循一些协议，在读写时要根据协议来进行操作。 内存模型可以理解为在特定的操作协议下，对特定内存或高速缓存进行读写访问的过程抽象。处理器、高速缓存以及主内存间的交互关系 指令重排序为了使处理器内部的运算单元能尽量被充分利用，处理器可能会对输入代码进行乱序执行优化，处理器会在计算之后将乱序执行的结果重组，保证该结果与顺序执行的结果是一致的，但是并不保证程序中各个语句的执行顺序和输入代码中的顺序一致。Java虚拟机的即时编译器中也有类似的指令重排序优化。 Java内存模型(JMM)Java虚拟机规范中定义了一种Java内存模型(Java Memory Model)来屏蔽掉各种硬件和操作系统的内存访问差异，以实现让Java程序在各种平台上都能达到一致性的内存访问效果。 主内存与工作内存Java内存模型的主要目标是定义程序中各个变量的访问规则，即在虚拟机中将变量存储到内存和内存中取出变量这样的底层细节。这里说的变量,和Java编程中所说的变量有所不同，它包括了实例字段、静态字段和构成数组对象的元素，不包括局部变量和方法参数，因为这两者是线程私有的。Java内存模型规定了所有变量都存储在主内存中，每条线程还有自己的工作内存(和前面说的处理器高速缓存类似)，线程的工作内存中保存了被该线程使用到的变量的主内存的拷贝副本。不同线程之间也无法直接访问对方工作内存中的变量，线程间变量值的传递均需通过主内存来完成。线程、主内存以及工作内存三者关系 内存间交互关于一个变量如何从主内存拷贝到工作内存、如何从工作内存同不会主内存之类的实现细节，Java内存模型中定义了8种操作来完成，这8种操作都是原子性的。 lock(锁定)作用于主内存的变量，把变量标识为一条线程独占状态 unlock(解锁)作用于主内存的变量，把一个处于锁定状态的变量释放出来，释放后的变量才能被其他线程锁定 read(读取)作用于主内存的变量，他一个变量的值从主内存传输到线程的工作内存 load(载入)作用于工作内存的变量，把read操作从主内存中得到的变量值放入工作内存的变量副本中。 use(使用)作用于工作内存的变量，把工作内存的一个变量的值传递给执行引擎，每当虚拟机遇到一个需要使用变量值的字节码指令时将会执行这个操作 assign(赋值)作用于工作内存的变量，把一个从执行引擎收到的值赋给工作内存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时将会执行这个操作 store(存储)作用于工作内存的变量，把工作内存中一个变量的值传送到主内存中，以便随后的write操作使用。 write(写入)作用于主内存的变量，把store操作从工作内存中得到的变量的值放入主内存的变量中 同样Java内存模型还规定了在执行上述8种操作时必须满足一下条件 不允许read和load，store和write这两对操作之一单独出现，即如果执行了read操作，那么就必须执行load(但两个操作不一定要连续执行)。即不允许一个变量从主内存读取但工作内存不接受，或者从工作内存发起回写但主内存不接受的情况。 不允许一个线程丢弃它最近的assign(赋值)操作，即变量在工作内存中改变了之后必须把该变化同步回主内存 不允许线程无原因地(没有发生过assign操作)把数据从工作内存同步回主内存 一个新的变量只能在主内存中诞生，不允许在工作内存中直接使用一个未被初始化(load或assign)的变量。也就是说，对一个变量实施use、store操作之前，必须先执行过了assign和load操作 一个变量同一时刻只允许一条线程对其进行lock操作，但lock操作可以被同一条线程重复执行多次，多次执行lock后，只有执行相同次数的unlock操作，变量才会被解锁。 如果对一个变量执行lock操作，那将会清空工作内存中此变量的值，在执行引擎使用这个变量前，需要重新执行load或assign操作初始化变量的值 对一个变量执行unlock之前，必须先把此变量同步回主内存中(执行store、write操作) Java指令重排序在执行过程中为了提高性能，编译器和处理器经常会对指令进行重排序，重排序分成三种类型 编译器优化的重排序，编译器在不改变单线程程序语义前提下，可以重新安排语句的执行顺序。 指令级并行的重排序，现代处理器采用了指令级并行技术来将多条指令重叠执行。如果不存在数据依赖性(可以理解为指令A不用到指令B的数据)，处理器可以改变语句对应机器指令的执行顺序。 内存系统的重排序，由于处理器使用缓存和读写缓冲区，使得加载和存储操作看上去可能是在乱序执行。 从Java源码到最终实际执行的指令序列，会经过下面三种重排序 参考博客Java内存模型大致能介绍就这些，关于并发和多线程最近开始看书，有了初步的理解后逐步介绍。深入理解JVM虚拟机这本书也算是初步看完了，继续努力。]]></content>
      <categories>
        <category>JVM虚拟机</category>
      </categories>
      <tags>
        <tag>JMM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java中的语法糖]]></title>
    <url>%2F2019%2F09%2F30%2FJava%E4%B8%AD%E7%9A%84%E8%AF%AD%E6%B3%95%E7%B3%96%2F</url>
    <content type="text"><![CDATA[语法糖，是指在计算机中添加某种语法这种语法对语言的功能并没有影响，但是更方便程序员使用。通常来说，语法糖能够增加程序的可读性。Java中常用的语法糖有泛型、变长参数、自动拆箱/装箱等。下面就介绍一下这些语法糖的原理。 泛型和类型擦除类型擦除泛型时JDK1.5的新增特性，本质是参数化类型的应用。即将所操作的数据类型指定为一个参数，这种参数可以用在类、接口、方法的创建中，分别被称为泛型类、泛型接口和泛型方法。Java中的泛型被称为伪泛型，它只在Java源码中存在，在编译后的字节码文件中就已经被替换为原生类型了(裸类型)，并且在相应地方插入了强制转型代码。因此对于运行期的Java语言来说，ArrayList和ArrayList就是同一个类，所以Java中泛型实现方法被称为类型擦擦除。举一个Java泛型的例子 1234567public static void main(String[] args) &#123; Map&lt;String, String&gt; map = new HashMap&lt;&gt;(); map.put(&quot;hello&quot;, &quot;你好&quot;); map.put(&quot;how are you&quot;, &quot;吃了没&quot;); System.out.println(map.get(&quot;hello&quot;)); System.out.println(map.get(&quot;how are you&quot;));&#125; 对于上面代码，编译成Class文件，然后再反编译进行反编译后，会变成下main这样 1234567public static void main(String[] args) &#123; Map map = new HashMap(); map.put(&quot;hello&quot;, &quot;你好&quot;); map.put(&quot;how are you&quot;, &quot;吃了没&quot;); System.out.println((String) map.get(&quot;hello&quot;)); System.out.println((String) map.get(&quot;how are you&quot;));&#125; 从代码可以看到，程序中所有的泛型又变回的原生类型，并且加上了强制转型。这说明，在编译后的字节码文件中是没有泛型的，即泛型仅存在于源码中，在编译过程中已经被擦除。既然知道了泛型的实现原理，那么看一看下面这段代码 123456789public class Test1 &#123; public static void method(List&lt;String&gt; list) &#123; System.out.println(&quot;List&lt;String&gt; list&quot;); &#125; public static void method(List&lt;Integer&gt; list) &#123; System.out.println(&quot;List&lt;Integer&gt; list&quot;); &#125;&#125; 毫无疑问，上面这段代码是无法通过编译的，这是为什么呢？因为编译期对泛型进行类型擦除后，这两个方法实际上是一模一样的，不构成重载。因此自然无法通过编译。那么你可能会问：既然泛型只存在于源码中，那么JVM在运行时怎么知道这个对象的具体类型呢？(例如怎么知道List list中要添加Integer类型元素呢？) 如何得知具体类型要回答这个问题，我们需要回到前面的Class文件结构，了解三个属性表： Signature该属性可以用在类、方法表、字段表中。这个属性用于支持泛型，在Java中，任何类、接口、初始化方法或成员属性如果使用了泛型，那么该Signature将泛型记录下来。这样，即使在编译时泛型被擦除，JVM仍能通过该属性获知泛型的类型。 LocalVariableTable属性该属性可以用在用在Code属性中，用于描述栈帧中局部变量表中的变量和Java源码中定义的变量之间的关系。对于表的结构这里不作赘述，只介绍一下这个属性的作用：对于局部变量表的每一个变量，该属性记录了变量名称、在局部变量表中的位置、变量的描述符和作用域。 LocalVariableTypeTable属性该属性和LocalVariableTable属性相比，只改动了一处：它不记录字段的描述符，而是记录字段的特征签名(Signature属性)。 演示前面说了三个属性，其实是为了这里的实验做铺垫。我们将以下面的类为基础进行演示 1234567891011121314151617//泛型类public class test&lt;K&gt; &#123; //未使用泛型 String x = &quot;1&quot;; //使用泛型 ArrayList&lt;String&gt; strings; ArrayList&lt;Integer&gt; integers; K ele; public void foo() &#123; &#125; //使用泛型参数 public void bar(K ele, int x) &#123; &#125;&#125; 我们对上面类进行编译，然后查看字节码文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125public class jvmtest.test&lt;K extends java.lang.Object&gt; extends java.lang.Object minor version: 0 major version: 56 flags: (0x0021) ACC_PUBLIC, ACC_SUPER this_class: #4 // jvmtest/test super_class: #5 // java/lang/Object interfaces: 0, fields: 4, methods: 3, attributes: 2Constant pool: #1 = Methodref #5.#34 // java/lang/Object.&quot;&lt;init&gt;&quot;:()V #2 = String #35 // 1 #3 = Fieldref #4.#36 // jvmtest/test.x:Ljava/lang/String; #4 = Class #37 // jvmtest/test #5 = Class #38 // java/lang/Object #6 = Utf8 x #7 = Utf8 Ljava/lang/String; #8 = Utf8 strings #9 = Utf8 Ljava/util/ArrayList; #10 = Utf8 Signature #11 = Utf8 Ljava/util/ArrayList&lt;Ljava/lang/String;&gt;; #12 = Utf8 integers #13 = Utf8 Ljava/util/ArrayList&lt;Ljava/lang/Integer;&gt;; #14 = Utf8 ele #15 = Utf8 Ljava/lang/Object; #16 = Utf8 TK; #17 = Utf8 &lt;init&gt; #18 = Utf8 ()V #19 = Utf8 Code #20 = Utf8 LineNumberTable #21 = Utf8 LocalVariableTable #22 = Utf8 this #23 = Utf8 Ljvmtest/test; #24 = Utf8 LocalVariableTypeTable #25 = Utf8 Ljvmtest/test&lt;TK;&gt;; #26 = Utf8 foo #27 = Utf8 bar #28 = Utf8 (Ljava/lang/Object;I)V #29 = Utf8 I #30 = Utf8 (TK;I)V #31 = Utf8 &lt;K:Ljava/lang/Object;&gt;Ljava/lang/Object; #32 = Utf8 SourceFile #33 = Utf8 test.java #34 = NameAndType #17:#18 // &quot;&lt;init&gt;&quot;:()V #35 = Utf8 1 #36 = NameAndType #6:#7 // x:Ljava/lang/String; #37 = Utf8 jvmtest/test #38 = Utf8 java/lang/Object&#123; java.lang.String x; descriptor: Ljava/lang/String; flags: (0x0000) java.util.ArrayList&lt;java.lang.String&gt; strings; descriptor: Ljava/util/ArrayList; flags: (0x0000) Signature: #11 // Ljava/util/ArrayList&lt;Ljava/lang/String;&gt;; java.util.ArrayList&lt;java.lang.Integer&gt; integers; descriptor: Ljava/util/ArrayList; flags: (0x0000) Signature: #13 // Ljava/util/ArrayList&lt;Ljava/lang/Integer;&gt;; K ele; descriptor: Ljava/lang/Object; flags: (0x0000) Signature: #16 // TK; public jvmtest.test(); descriptor: ()V flags: (0x0001) ACC_PUBLIC Code: stack=2, locals=1, args_size=1 0: aload_0 1: invokespecial #1 // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V 4: aload_0 5: ldc #2 // String 1 7: putfield #3 // Field x:Ljava/lang/String; 10: return LineNumberTable: line 7: 0 line 8: 4 LocalVariableTable: Start Length Slot Name Signature 0 11 0 this Ljvmtest/test; LocalVariableTypeTable: Start Length Slot Name Signature 0 11 0 this Ljvmtest/test&lt;TK;&gt;; public void foo(); descriptor: ()V flags: (0x0001) ACC_PUBLIC Code: stack=0, locals=1, args_size=1 0: return LineNumberTable: line 19: 0 LocalVariableTable: Start Length Slot Name Signature 0 1 0 this Ljvmtest/test; LocalVariableTypeTable: Start Length Slot Name Signature 0 1 0 this Ljvmtest/test&lt;TK;&gt;; public void bar(K, int); descriptor: (Ljava/lang/Object;I)V flags: (0x0001) ACC_PUBLIC Code: stack=0, locals=3, args_size=3 0: return LineNumberTable: line 23: 0 LocalVariableTable: Start Length Slot Name Signature 0 1 0 this Ljvmtest/test; 0 1 1 ele Ljava/lang/Object; 0 1 2 x I LocalVariableTypeTable: Start Length Slot Name Signature 0 1 0 this Ljvmtest/test&lt;TK;&gt;; 0 1 1 ele TK; Signature: #30 // (TK;I)V&#125;Signature: #31 // &lt;K:Ljava/lang/Object;&gt;Ljava/lang/Object;SourceFile: &quot;test.java&quot;Process finished with exit code 0 我们先看类的成员属性123456789101112131415161718192021222324//未使用泛型java.lang.String x; descriptor: Ljava/lang/String; flags: (0x0000)==============================//使用了泛型java.util.ArrayList&lt;java.lang.String&gt; strings; //泛型被擦除 descriptor: Ljava/util/ArrayList; flags: (0x0000) Signature: #11 // Ljava/util/ArrayList&lt;Ljava/lang/String;&gt;;java.util.ArrayList&lt;java.lang.Integer&gt; integers; //泛型被擦除 descriptor: Ljava/util/ArrayList; flags: (0x0000) Signature: #13 // Ljava/util/ArrayList&lt;Ljava/lang/Integer;&gt;;K ele; //泛型被擦除 descriptor: Ljava/lang/Object; flags: (0x0000) Signature: #16 // TK;(T:Type K:泛型) 可以看出，三个使用了泛型的成员属性在编译成字节码后，泛型都被擦除了。但是和没有使用泛型的成员属性x相比，它们多了Signature属性，虽然泛型被擦除，但是我们通过该属性仍可以得知泛型的类型。 我们再来看看方法。1234567891011121314151617181920public void bar(K, int); //泛型被擦除 descriptor: (Ljava/lang/Object;I)V flags: (0x0001) ACC_PUBLIC Code: stack=0, locals=3, args_size=3 0: return LineNumberTable: line 23: 0 LocalVariableTable: Start Length Slot Name Signature 0 1 0 this Ljvmtest/test; //泛型被擦除 0 1 1 ele Ljava/lang/Object; 0 1 2 x I LocalVariableTypeTable: Start Length Slot Name Signature 0 1 0 this Ljvmtest/test&lt;TK;&gt;; 0 1 1 ele TK; Signature: #30 // (TK;I)V 我们看看带泛型参数的方法bar()，我们看到方法中前面说过的三个属性全部都有。我们来分析一下： 可以看到，该方法的泛型也被擦除了，在LocalVariableTable也不能查看到泛型参数的类型(也被擦除)，但是在LocalVariableTypeTable中，可以看到参数ele的泛型为K。另外，该方法的Signature属性记录了该方法的特征签名(方法名参数类型和顺序)，该属性中保存了泛型信息。 最后在看一下字节码的末尾1Signature: #31 // &lt;K:Ljava/lang/Object;&gt;Ljava/lang/Object; 可以看到，该类也有一个Signature属性，记录了泛型的信息。 总结Java的泛型是伪泛型，即泛型仅仅存在于源码中，在编译时泛型被擦除，所谓的擦除，仅仅是对方法的Code属性中的字节码进行擦除，实际上Signature属性和LocalVariableTypeTable属性还是保留了泛型信息，这也是我们能通过反射取得参数化类型的根本依据。 自动装箱、拆箱和遍历循环 自动装箱实际上调用的是包装类的valueOf()方法； 自动拆箱调用的则是包装类的xxxValue()方法。下面以Integer和int为例 1234567int i=1;//自动装箱Integer.valueOf(i)=======================Integer=new Integer(4)//自动拆箱i=Integer.intValue() 遍历循环for-each使用的则是Iterator迭代器来实现。 12345678List&lt;Integer&gt; list=new ArrayList;for(int i:list)&#123;&#125;//实际上是通过迭代器实现for(Iterator localIterator=list.iterator();localIterator.hasNext;)&#123;&#125; 使用包装类要注意两点 包装类的”==”再不遇到算术运算的情况下不会自动拆箱 包装类的”equals()方法”不处理数据转型的关系 给出下面一段测试代码 1234567891011121314151617181920public static void main(String[] args) &#123; Integer a = 1; Integer b = 2; Integer c = 3; Integer d = 3; Integer e = 321; Integer f = 321; Long g = 3L; System.out.println(c == d); //true ,-128~127之间用到Integer内的缓存池 System.out.println(e == f); //false //遇到算术运算，自动拆箱 System.out.println(c == (a + b)); //true //equals不会处理数据转型 System.out.println(c.equals(a + b));//true System.out.println(g.equals(a + b));//false //遇到算术运算自动拆箱，进行数据转型 System.out.println(g == a + b); //true&#125;]]></content>
      <categories>
        <category>Java编程思想</category>
      </categories>
      <tags>
        <tag>Java基础</tag>
        <tag>泛型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解JVM虚拟机四]]></title>
    <url>%2F2019%2F09%2F30%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%9B%9B%2F</url>
    <content type="text"><![CDATA[这一节主要介绍一下虚拟机是怎么执行Class文件的字节码以及《深入理解JVM虚拟机》后面一些知识，因为后面很多都不是很理解，所以结合在一起记录，如果以后再次翻看弄懂了一些，就再另外记录吧。 执行引擎是Java虚拟机最核心的组成部分之一，Java虚拟机在执行Java代码时可能会有解释执行(通过解释器执行)和编译执行(通过编译器执行)两种选择，或者两者都有。所有Java虚拟机的执行引擎都是一致的 输入过程：输入字节码文件 处理过程：字节码解析，执行相应指令 输出过程：输出执行结果 运行时栈帧结构 栈帧是用于支持虚拟机进行方法调用和方法执行的数据结构，它是虚拟机运行时数据区中的虚拟机栈的栈元素。每一个方法从调用开始到执行完成的过程，对应着栈帧在虚拟机中从入栈到出栈的过程。栈帧中包括 方法的局部变量表 操作数栈 动态连接 方法返回地址等 另外前面说到过，在编译阶段，局部变量表和操作数栈的大小都已经确定并写在Code属性中，因此一个栈桢分配多少内存不会受到运行时数据的影响。对于执行引擎来说，只有线程栈顶的栈帧才是有效的，称为当前栈帧，与栈帧相关联的方法称为当前方法。虚拟机使用局部变量表完成参数值到参数列表的传递过程，如果是一个实例方法，那局部变量表第0位索引的Slot默认用于传递方法所属对象实例的引用，在方法中可以通过this关键字来访问这个隐含的参数。其余参数按照参数表顺序排列，占用从1开始的Slot。参数表分配完毕后再根据方法体内定义变量的顺序和作用域分配其余Slot。局部变量表的Slot是可以重用的，如果当前字节码PC计数器已经超过了方法体中的某个变量的作用域，那么该变量对应的Slot就可以交给其他变量使用。 对于类变量(static)，会有两次赋值 一次是在准备阶段赋初始值 一次是在初始化阶段赋予程序设置的值因此初始化阶段不为类类变量赋值也可以直接使用。 对于局部变量，如果定义了但没有赋初始值是不能使用的。 对于类成员变量，也会有两次赋值 第一次是new指令过后，&lt; init&gt;方法执行之前，对象的字段(即成员变量)已经被赋初始化值 第二次是在&lt; init&gt;方法(实例构造器)，赋予字段程序设置的值因此对于成员变量，不赋初值也能直接使用 操作数栈和局部变量表一样，操作数栈的大小在编译后就已经确定，记录在Code属性中。操作数栈的每一个元素可以是任意的Java数据类型。当一个方法开始执行时，方法的操作数栈是空的，在方法的执行过程中，会有各种字节码指令往操作数栈中写入和提取内容，也就是入栈出栈操作。Java虚拟机的解释执行引擎被称为”基于栈的执行引擎”，这里指的就是操作数栈。 动态连接每个栈帧中都包含一个指向运行时常量池中该栈帧所属方法的引用。前面说到，Class文件的常量池中有大量符号引用，字节码中的方法调用指令就常以常量池中指向方法的符号引用作为参数，这些符号引用 一部分会在类加载阶段或第一次使用时转换为直接引用，即静态解析 另外一部分将在每次运行期间转换为直接引用，这部分称为动态连接 方法返回地址当一个方法开始执行，有两种方式可以退出这个方法。 执行引擎遇到任意一个方法返回的字节码指令。这时可能会有返回值传递给调用该方法的方法，至于是否有返回值或者返回值类型取决于返回指令的类型。这种退出方式被称为正常完成出口。此时调用该方法的方法PC计数器的值可以作为返回地址。 方法执行过程中遇到了异常，并且这个异常没有在方法体内得到处理。无论是Java虚拟机内部产生的异常，还是代码中使用athrow字节码产生的异常(throw语句)只要在方法的方法表中内有搜索到匹配的异常处理器(即不属于Java代码中catch语句列举的异常)，就会导致方法退出。这种退出方式被称为异常完成出口。是不会给上层调用方法任何返回值的。此时，返回地址是通过异常处理器来确定的。 方法调用方法调用不等同于方法执行，方法调用阶段唯一的任务就是确定被调用方法的版本，即调用哪一个方法(因为Java中重写和重载机制)，不涉及方法的执行。前面说过，一切调用在Class文件里存储的都只是符号引用，而不是方法在实际运行时内存布局的入口地址(直接引用)，这就导致Java方法调用时，需要在类加载期，甚至是运行期才能确定目标方法的直接引用。 解析在类加载的解析阶段，会将一部分符号引用转化为直接引用。这种解析能成立的前提是：方法在程序运行之前就有一个确定的调用版本，并且这个调用版本在运行期间是不可变的。即编译器可知，运行期不可变，这类方法主要有两类 静态方法与类型直接关联 私有方法外部不可被访问 实例构造器 父类方法这四类方法适合在类加载阶段进行解析。这四类方法又被称为非虚方法，其他方法都是虚方法。除此之外final方法也是非虚方法。 解析调用是静态过程在编译期就完全确定，在类加载的解析阶段就会把涉及的符号引用全部转变为直接引用。这时第一次的解析结果会被缓存在运行时常量池中，并将常量标识为已解析，从而避免重复解析。 分派调用可能是静态的也可能是动态的 静态分派Java具备三大特征：继承、封装和多态。分派将会揭示重写和重载在Java虚拟机中是如何实现的。来测试一下下面一段代码，然后看一看结果 123456789101112131415161718192021222324252627282930313233public class StaticDispath &#123; static abstract class Human&#123; &#125; static class Man extends Human &#123; &#125; static class Woman extends Human &#123; &#125; public void sayHello(Human human) &#123; System.out.println(&quot;Human&quot;); &#125; public void sayHello(Man human) &#123; System.out.println(&quot;Man&quot;); &#125; public void sayHello(Woman human) &#123; System.out.println(&quot;Woman&quot;); &#125; public static void main(String[] args) &#123; Human man = new Man(); Human woman=new Woman(); StaticDispath s=new StaticDispath(); s.sayHello(man); s.sayHello(woman); &#125;&#125; 执行结果有三个重载的方法，为什么会选择执行参数类型为Human的重载呢？先介绍一下两个概念 1Human man = new Man(); 上面这段代码中的”Human”被称为静态类型，new后面的”Man”被称为实际类型。 静态类型仅仅在使用时发生变化，而变量本身的静态类型不会改变，并且静态类型在编译期可知 实际类型在运行期才能确定变化的结果，编译器在编译时并不知道实际类型是什么 例如 12345678//在这里实际类型从Man变成了Woman，而静态类型仍是HunmanHuman man=new Man()man=new Woman()//这时候静态类型仅仅在使用时发生了变化，但是man和woman仍旧是Human类型。//如果这样调用，那么输出结果就是Man和Woman而不是Human了。s.sayHello((Man)man);s.sayHello((Woman)woman); 虚拟机(确切的说是编译器)在重载时通过参数的静态类型(即参数字面值)作为判定依据而不是实际类型。并且静态类型是编译期可知的，因此，在编译期Javac编译器会根据参数的静态类型选择使用哪个重载方法。所有依赖静态分派来定位方法执行版本的分派动作称为静态分派。静态分派的典型就是方法重载 动态分派同样的，还用一段代码来做测试12345678910111213141516171819202122232425262728293031public class DynamicDispatch &#123; public static void main(String[] args) &#123; Human man = new Man(); Human woman = new Woman(); man.sayHello(); woman.sayHello(); man=new Woman(); man.sayHello(); &#125;&#125;abstract class Human&#123; protected abstract void sayHello();&#125;class Man extends Human&#123; @Override protected void sayHello() &#123; System.out.println(&quot;man&quot;); &#125;&#125;class Woman extends Human &#123; @Override protected void sayHello() &#123; System.out.println(&quot;woman&quot;); &#125;&#125; 很简单的一段代码，用到了重写，运行结果这里显然不是根据静态类型来决定的，因为静态类型都是Human的两个变量在调用sayHello时执行了不同的方法，并且man两次调用sayHello方法输出结果不同。来看一下字节码 123416: aload_117: invokevirtual #6 // Method Human.sayHello:()V20: aload_221: invokevirtual #6 // Method Human.sayHello:()V 其中aload_1和aload_2就是将man和woman两个对象的引用入操作数栈，这两个对象是将要执行的sayHello方法的所有者。17和21行的invokevirtual是方法调用指令，从字节码角度来看，无论是指令(都是invokevirtual指令)还是参数(注释显示了参数是Human.sayHello的符号引用)都完全一样，两行指令一模一样。但是执行的结果却不同。这就要从invokevirtual的多态查找过程说起，该指令运行使得解析过程大致分为一下几个步骤 找到操作数栈顶的第一个元素指向的对象的实际类型(在这里man的实际类型是Man，woman的实际类型是Woman)，记为C。 如果在C中找到了与常量中的描述符和简单名称都相符(Human.sayHello:()V)的方法，则进行访问权限校验，如果通过返回该方法的直接引用，否则抛出异常。 否则，按照继承关系从下往上依次对C的父类进行第二步操作 如果始终没有找到，抛出异常。 从上面过程可以发现，该指令第一步就是在运行期间找到执行方法所有者的实际类型，所以两次invokevirtual虽然参数一模一样，但是却将符号引用解析到了不同的直接引用上，这就是Java重写的本质。这种运行期间根据实际类型确定具体实行哪个方法的分派过程称为动态分派。]]></content>
      <categories>
        <category>JVM虚拟机</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解JVM虚拟机三]]></title>
    <url>%2F2019%2F09%2F28%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM%E8%99%9A%E6%8B%9F%E6%9C%BA%E4%B8%89%2F</url>
    <content type="text"><![CDATA[前面已经介绍了JVM的内存布局、自动内存管理、垃圾回收以及Class文件结构，那么虚拟机又是怎么加载Class文件的？Class文件的信息进入到JVM中会不会发生变化呢？那么这次就记录一下虚拟机类加载机制。 虚拟机把描述类的数据从Class文件加载到内存，并对数据进行校验、转换解析以及初始化，最终形成可以被虚拟机直接使用的Java类型，这就是虚拟机的类加载机制。 在Java中，类型的加载、连接、初始化过程都是在程序运行期间完成的，这种做法会令加载时性能开销增加一些，但是却为Java程序提供了高灵活性。例如，对于一个接口，可以等到运行时在指定其实际的实现类。可以通过类加载器在程序运行时从其他地方加载一个二进制流作为代码的一部分。 类加载时机类从被加载到虚拟机内存中开始，到卸载出内存为止，它的生命周期如下加载==&gt;连接(验证==&gt;准备==&gt;解析)==&gt;初始化==&gt;运行==&gt;使用==&gt;卸载其中验证、准备、解析三个阶段统称为连接。并且加载、验证、准备、解析、初始化这5个阶段的顺序是确定的。那么什么情况下需要执行类加载的第一个过程：加载呢？对于初始化阶段，虚拟机严格规定了有且只有5种情况必须立即对类进行初始化(初始化之前自然要先进行加载、连接操作) 遇到new、getstatic、putstatic、invokestatic这四条指令时，如果类没有进行过初始化，则需要先对类进行初始化。可以概括为一下几个方面： 使用new关键字实例化对象时 读取或设置一个类的静态字段(被final修饰、已在编译器把结果放入常量池的静态字段除外)时 调用一个类的静态方法时 使用java.lang.reflect包的方法进行反射调用时，如果类没有进行过初始化，则需要先对类进行初始化。 初始化一个类时，如果发现其父类还没有进行过初始化，则需先对其父类进行初始化。 当虚拟机启动时，用户需要指定一个要执行的主类(含main方法的类)，虚拟机会先初始化这个类 如果一个java.lang.invoke.MethodHandle实例最后的解析结果为REF_getStatic、REF_putStati或REF_invokeStatic的方法句柄，并且这个方法句柄对应的类没有进行过初始化，则需要先对类进行初始化。 上面5种场景的行为称为对一个类的主动引用。除此之外，所有引用类的方法都不会触发其初始化，称为被动引用，如： 通过子类引用父类的静态字段，子类不会被初始化。对于静态字段，只有直接定义这个字段的类才会被初始化。 通过数组来引用类，不会触发此类的初始化。 常量在编译期进入调用类的常量池，本质上讲没有直接引用到定义常量的类，因此不会触发定义常量类的初始化。 (具体示例代码见书P211。)接口的类加载过程和类有所不同，主要体现在第3点，一个接口在初始化时，并不要求其父接口全部完成了初始化，只有在真正使用到父接口的时候才会初始化。 类加载过程下面说一下类加载的全过程：加载、验证、准备、解析和初始化。 加载加载时类加载过程的一个阶段，在加载阶段，虚拟机可以完成三件事 通过一个类的全限定名获取此类的二进制字节流 将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构 在内存中生成一个代表此类的java.lang.Class对象，作为方法区此类各种数据的访问入口。 相比于类加载过程的其他阶段，一个非数组类的加载阶段(确切的说是加载阶段中获取类的二进制字节流的操作)是开发人员可控性最强的。因为我们可以使用系统的的引导类加载器来完成，也可以使用自定义的类加载器完成。对于数组类而言，数组类本身不通过类加载器创建，它是由Java虚拟机直接创建的。但数组类和类加载器仍有密切的关系。数组类的元素类型(去掉所有[])最终要靠类加载器去创建。一个数组类C的创建过程如下 如果数组的组件类型(去掉一对[]的类型)是引用类型，那就递归采用前面说的加载过程去加载这个组件类型，数组C将在加载组件类型的类加载器的类名称空间上被标识 如果数组的组件类型不是引用类型(如int[] a或二维数组等)，Java虚拟机将会把数组标记为与引导类加载器关联 数组类的可见性与它的组件类型可见性一致，如果组件类型不是引用类型，那数组可见类型默认public。 加载完成后，虚拟机外部的二进制字节流就被加载进方法区中。然后在内存中实例化一个java.lang.Class对象，(对于HotSpot而言，该对象存放在方法区中) 验证加载阶段和连接阶段的部分内容是交叉进行的，如一部分字节码文件格式的验证动作。验证时连接阶段的第一步，是虚拟机对自身保护的一项重要工作。这一阶段的目的是为了确保Class文件的字节流中包含的信息符合虚拟机要求，并且不会危害虚拟机自身安全。该阶段分为四步： 文件格式验证 元数据验证 字节码验证 符号引用验证 文件格式验证验证字节码是否符合Class文件格式，并且能被当前版本虚拟机处理，可能包含一下验证点 是否以魔数”0xCAFEBABE”开头 主次版本号是否在当前虚拟机处理范围 常量池常量是否有不被支持的常量类型(检查tag标志)…. 实际上，该阶段的验证点有很多，该阶段的主要目的是保证输入的字节流能够正确的解析并存储与方法区内，格式上符合一个Java类型信息的要求。该方法是基于二进制字节流进行的，只有通过了该阶段，字节流才会进入方法区，后面的三个阶段都是基于方法区的存储结构进行，不会直接操作字节流。 元数据验证该阶段对字节码描述的信息进行语义分析，保证其描述的信息符合Java语言规范，可能的验证点 该类是否有父类(除了java.lang.Object以外，所有类都应该有父类) 该类是否继承了不允许被继承的类(final类) 该类如果不是抽象类，那么是否实现了其父类/父接口的抽象方法…… 该阶段的主要目的是对类的元数据信息进行语义校验，保证不存在不符合Java语言规范的元数据信息。 字节码验证该阶段最为复杂，主要目的是确定程序语义是否合法、符合逻辑，该阶段对方法体进行校验分析，确保被校验的方法在运行时不会做出危害虚拟机安全的事。可能验证的点 保证跳转指令不会跳转到方法体以外的字节码指令上 保证方法体中的类型转换是有效的，例如不能把对象赋值给与他毫无继承关系、完全不相干的数据类型，这是不合法的…… 如果一个类不能通过字节码验证，那么这个类肯定有问题，但是通过了字节码验证，并不能够说明其一定安全。 符号引用验证该阶段发生在虚拟机将符号引用转化为直接引用的时，这个转化动作将在连接的第三个阶段–解析阶段发生。符号引用验证可以看作是对类自身以外的信息(常量池中的各种符号引用)进行匹配性校验，通常需要校验以下内容 符号引用中通过字符串描述的全限定名是否能找到对应的类 在指定类中是否存在符合方法的字段描述符以及简单名称所描述的方法和字段。 符号引用中的类、字段、方法的访问性(public、private…)是否可以被当前类访问…… 符号引用验证的目的是确保解析动作能够正常进行，如果无法通过该阶段验证，那么会抛出异常。最后，对于虚拟机类加载机制来说，验证阶段非常重要、但却不一定必要。如果所运行的全部代码都已经被反复使用和验证过，那么可以通过”-Xverify:none”参数来关闭大部分验证措施。 准备准备阶段是正式为类变量分配内存并设置类变量初始值的阶段。这些变量所使用的内存都在方法区分配。这里说的初始化值通常情况下是数据类型的零值。例如一个类变量private static int value=123。在准备阶段过后的初始值是0值而不是123。而将value赋值为123的操作是在初始化阶段的类构造器&lt; clinit&gt;方法执行。如果一个类字段有ConstantValue属性，那么准备阶段变量value就会被初始化为ConstantValue属性所指定的值。 解析前面说过，Class文件中不会保存各个方法、字段最终在内存的哪个地方，因此这些字段、方法的符号引用不经过不经过运行期转换是无法得到字段、方法的内存入口。解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程。 符号引用用一组符号来描述所引用的目标(如字段表集合中对字段的描述)，符号引用可以是任意形式的字面量，只要能无歧义的定位到所引用的目标。符号引用的目标不一定已经被加载进内存。 直接引用可以是指向目标的指针的相对偏移量、或能间接定位目标的句柄，能够直接在内存中定位到目标。如果有了直接引用，那么引用的目标肯定在内存中存在。 需要注意的是，虚拟机规范并未规定解析阶段发生的具体时间，只要求在执行anewarray、checkcast、getfield、getstatic、instanceof、invokedynamic、invokespecial、invokestatic、invokevirtual、ldc、ldc_w、new、putfield、putstatic等操作符号引用的字节码指令之前，先对他们所使用的符号引用进行解析。对一个符号引用进行多次请求解析是很常见的，除了invokedynamic指令外，虚拟机实现可以对第一次解析的结果进行缓存(在运行时常量池中记录直接引用，并把常量标识为已解析状态)从而避免重复解析，这些解析被称为静态解析。而对于invokedynamic指令，必须等到程序实际运行到这条指令时，才会对符号引用进行解析，并且不会缓存。每一次运行时都要讲符号引用转换为直接引用，这种解析被称为动态连接。(后面讲到动态分派和重写时会介绍) 解析动作主要针对 类或接口 字段 类方法 接口方法等 具体对类、接口、类字段、类方法的解析见书P221 初始化该阶段是类加载过程的最后一步，前面的类加载过程，除了加载阶段用户可以参与，其余动作完全由虚拟机控制。到了初始化阶段，才真正开始执行类中定义的Java代码(Java代码编译后的字节码更准确一些)。在准备阶段，变量已经赋过一次值，而在初始化阶段，则根据程序员通过程序制定的计划去初始化类变量和其他资源。初始化阶段是执行类构造器&lt; clinit&gt;方法的过程。 &lt; clinit&gt;()方法 由编译器自动收集类中的所有类变量的赋值动作和静态代码块中的语句合并产生的。编译器手机的顺序是由语句在源文件中出现的顺序决定的。静态语句块只能访问到定义在静态语句块之前的变量，定义在它之后的变量，语句块只能赋值不能访问。(书P225) 该方法和实例构造器不同，不需要显式的调用父类构造器。虚拟机会保证在子类的&lt; clinit&gt;()方法执行前，父类的&lt; clinit&gt;()方法已经执行完毕。因此在虚拟机中第一个执行&lt; clinit&gt;()方法的类肯定是Object类。 由于父类的&lt; clinit&gt;()方法先执行，也就意味着父类中定义的静态语句块和静态变量赋值要优先于子类 &lt; clinit&gt;()方法对于接口或类来说不是必须的，如果类中没有静态代码块、也没有对类变量的赋值操作，那么编译器可以不生成&lt; clinit&gt;()方法 对于接口，执行接口的&lt; clinit&gt;()方法不需要先执行父接口的&lt; clinit&gt;()方法，只有当父接口中定义的变量使用时父接口才会被初始化。 同样的，接口的实现类在初始化时也一样不会执行接口的&lt; clinit&gt;()方法。 同一个类加载器下，一个类型只会初始化一次。 至此，一个类加载的全过程就完成了。 类加载器加载阶段中”通过一个类的全限定名来获取类的的二进制字节流”这个动作是在虚拟机外部实现的，实现这个动作的代码模块被称为类加载器。对于任意一个类，都需要由加载它的类加载器和这个类本身一同确立其在虚拟机中的唯一性，每一个类加载器，都拥有一个独立的类名称空间。即如果比较两个类是否”相等”，只有在这两个类是由同一个类加载器加载的前提下才有意义。否则，即使这两个类来源于同一个Class文件，被同一个虚拟机加载，只要加载它们的类加载器不同，那这两个类就必定不相等。这里说的相等 代表类的Class对象的equals()方法、isAssignableFrom()方法、isInstance()方法返回结果 使用instanceof关键字做对象所属关系判定结果…… 双亲委派模型对于开发人员来说，类加载器分为三种 启动类加载器(Bootstrap ClassLoader)=&gt;最顶层将存放在\lib目录中的虚拟机识别的类库加载到虚拟机内存中 扩展类加载器(Extension ClassLoader)=&gt;第二层负责加载lib目录下ext目录中的类库，开发者可以直接使用扩展类加载器 应用程序类加载器(Application ClassLoader)=&gt;第三层这个类加载器时ClassLoader中的getSystemClassLoader()方法返回值，所以也叫系统类加载器。如果应用程序没有自定义过自己的类加载器，一般情况下这个就是程序默认的类加载器。 自定义类加载器=&gt;最底层 双亲委派模型的工作过程如果一个类加载器收到了类加载的请求，它首先不会自己尝试加载这个类，而是把这个请求委派给父类加载器完成，每个层次的类加载器都是这样，因此所有的加载请求最终都应该传送到顶层的启动类加载器中，只有当父类反馈自己无法完成这个加载请求时，子类加载器才会尝试自己去加载。 好处使用双亲委派模型来组织类加载器的关系，Java类随着它的类加载器一起具备了一种带优先级的层次关系。例如java.lang.Object，无论哪一个类加载器要加载这个类，绥中都是委派给顶层的启动类加载器完成，因此Object类在程序中总是一个类。 破坏双亲委派模型没怎么理解，见书P234 至此，类加载机制也就介绍完了。主要介绍了类的加载、验证、准备、解析和初始化过程中虚拟机是怎么做的，以及类加载器的工作原理和双亲委派模型。]]></content>
      <categories>
        <category>JVM虚拟机</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解JVM虚拟机二]]></title>
    <url>%2F2019%2F09%2F26%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM%E8%99%9A%E6%8B%9F%E6%9C%BA%E4%BA%8C%2F</url>
    <content type="text"><![CDATA[前面说了JVM虚拟机的内存布局和自动内存管理机制，这次就着重记录一下Class文件的结构，毕竟JVM只是工具，而Class文件才是被执行的主体。 无关性基石这里说的无关性，包括两个方面 平台无关性 语言无关性 平台无关性你一定听过一句话–Write Once,Run AnyWhere。以前，一个应用程序要想在要想在不同的操作系统上运行，就要编写不同的代码。因为代码编译后得到的是本地机器码，而不同的操作系统机器码是不一样的，因此如果一个程序需要在多个系统上运行，就要编写不同的代码。平台无关性，顾名思义，就是同样的代码可以在不同的操作系统上正确的运行。这就要通过虚拟机来实现。我们编写的代码(并不是特指Java代码)，会通过编译器编译为字节码，而虚拟机能够载入和执行字节码，从而实现了平台无关性。运行在不同操作系统上的JVM虚拟机是不一样的。JVM虚拟机接收到字节码后，再将字节码转换为本地的机器码。虚拟机就相当于代码和机器码之间的转换器，能够将同一种字节码根据不同的操作系统转换成不同的机器码。通过上述的介绍不难发现，各种不同平台的虚拟机和所有平台都使用的统一的程序存储格式–字节码是构成平台无关性的基石。语言无关性语言无关性的基石仍然是虚拟机和字节码存储格式。Java虚拟机只认识字节码，只和”Class文件”这种特定的二进制文件关联。即如果你将其他语言编译成字节码交付给Java虚拟机，它一样能够执行。事实也是这样，Java程序通过Javac编译器将Java编译成字节码，其他语言如JRuby通过jruby编译器将JRuby编译成字节码，JVM都能够执行。 Java中的各种变量、关键字、和运算符号最周都是由多条字节码命令组合而成，因此字节码命令的语言描述能力肯定比Java更加强大。有一些Java语言本身无法支持的语言特性并不代表字节码本身无法识别。 Class类文件结构Class文件是一组以8位字节为基础单位的二进制流，各个数据项目都严格的按照顺序紧凑的排列在Class文件中，中间没有任何分隔符，也就是说，整个Class文件所存储的内容几乎都是程序运行时必要的数据。对于需要占用8位以上的数据项，会按照高位在前的方式将其分割成若干个8位字节进行存储。 魔数和Class文件版本 魔数每个Class文件的前四个字节，值为”0xCAFEBABE”(可以称为咖啡宝贝…)。它的唯一作用是确定这个文件是否为一个能被虚拟机接受的Class文件。 Class文件版本紧接着魔数的四个字节，前两个字节是Class文件的次版本号(Minor Version)，后两个字节是主版本号(Major Version)。高版本的JDK能够运行低版本的Class文件，但是不能运行更高版本的Class文件，即使这个Class文件没有发生任何变化。 常量池紧接着版本号之后就是常量池入口。常量池可以理解位Class文件的资源仓库。常量池中常量的数量是不确定的，因此需要一个常量池容量计数器。 常量池容量计数器紧接着版本号后的两个字节，但是要注意的是，&lt;?font color=blue&gt;容量计数是从1开始的。即如果容量转换为十进制是22，那么就有21项常量(1-21)。将0索引空出来的目的在于，当有些指向常量池的索引值的数据在特定情况下需要表达”不引用任何一个常量池项目”时，就可以把索引值置0。 常量池中主要存放两大类常量 字面量如文本字符串、声明为final的常量值等 符号引用 类和接口的全限定名 字段的名称和描述符 方法的名称和描述符 Java代码在进行Javac编译时，是在虚拟机加载Class文件的时候进行动态连接。也就是说，在Class文件中不会保存各个方法、字段最终在内存的哪个位置，因此这些字段、方法的符号引用要经过运行期的转换才能得到真真的内存地址。当虚拟机运行，需要从常量池获得符号引用，在类创建或运行时解析、翻译到具体内存地址中。(常量池表的类型和内容见书P169) 访问标志常量池结束后紧接着的两个字节就是访问标志(access_flags)，该标志用于识别一些类或者接口层次的访问信息。 该Class是类还是接口 是否为public类型 是否为abstruct 如果是类是否被声明为final等…(P173) 类索引、父类索引和索引接口集合紧接着访问标志之后 类索引两个字节，用于确定类的全限定名 父类索引两个字节，用于确定这个类的父类的全限定名，由于Java不允许多重继承，所以父类索引只有一个。如果没有显式的继承，那么此处父类字段为Object 接口索引集合 两个字节，接口计数器。表示类实现的接口数 每一组都是2个字节，用于确定类实现了哪些接口。如果接口计数器为0，那么一组都没有。 字段表集合用于描述接口或类中声明的变量。即字段表包括类级变量和实例级变量，但不包括方法内部声明的变量。 字段计数器(fields_count)紧接着接口集合后的两个字节，表示字段的数量。 每个字段都有一个字段表，用于记录字段信息，字段计数器为多少，后面就有多少个字段表。 字段表 access_flags(访问标志)两个字节，同类的访问标志一样，描述字段的信息(书P176) name_index(名称索引)两个字节，对常量池的引用，代表字段的简单名称(不包括类名包名等…) descriptor_index(描述索引)两个字节，对常量池的引用，字段的描述符(描述符含义表书P177) 属性表集合用于存储额外信息，字段可以有0至多项额外信息。例如一个final修饰的字段，额外信息中就可能(注意是可能！)包含一项ConstantValue属性，指向了该字段的值。 字段表集合中不会列出从超类或父接口中继承而来的字段，但有可能列出原本Java代码中不存在的字段，譬如一个内部类，在内部类中为了保持对外部类的访问性，会自动添加指向外部类实例的字段。并且，在Java中字段是无法重载的，两个字段的数据类型、描述符不管是否相同，都必须使用不一样的名称，但是对于字节码而言，如果两个字段的描述符不一致，那么字段可以重名。 方法表集合和字段表集合描述方式一模一样，分别是 方法计数器(fields_count)紧接着字段表集合后的两个字节，表示方法的数量。 方法表 access_flags(访问标志)两个字节，同字段的访问标志一样，描述方法的信息(书P179) name_index(名称索引)两个字节，对常量池的引用，代表方法的简单名称(int inc()==&gt;简单名称为inc) descriptor_index(描述索引)两个字节，对常量池的引用，方法的描述符(描述符含义表书P177) 属性表集合用于存储额外信息，字段可以有0至多项额外信息，例如方法的方法体编译为字节码后存放在Code属性中 与字段表集合相应的，如果父类方法在子类中没有被重写，方法表集合中就不会出现父类的方法信息。在Java中，要重载一个方法有两个要求 重载方法和原方法具有相同的简单名称 重载方法和原方法的特征签名不同。 特征签名(Signature) Java代码中包含了方法名称、参数类型、参数顺序 字节码中还包括了方法返回值和受检查异常表 因此Java中返回值的不同不能构成重载。但是在Class文件中却可以。 属性表集合前面以及提到了很多次，在Class文件、字段表、方法表都可以携带自己的属性表集合信息。(虚拟机规范预定义属性见书P181) Code属性 attribute_name_index(属性名称索引)两个字节，对常量池的引用，固定为Code，代表属性名称。 attribute_length四个字节属性值的长度 max_stack两个字节，操作数栈的最大深度，方法执行的任意时刻操作数栈都不会超过这个深度。虚拟机运行时需要根据这个值来分配栈帧。 max_locals两个字节，局部变量表所需的存储空间，单位是Slot(double和long占2个Slot，其他基本类型等长度不超过32位的占1个Slot)。局部变量表中存放着 方法参数(包括实例方法的隐藏参数this) 显示异常处理器参数(try-catch中catch块定义的异常) 方法中定义的局部变量 code_length和code分别为四个字节和一个字节，用于存储Java代码编译后生成的字节码指令。code_length代表字节码长度，code用于存储字节码指令。(每个指令占一个字节)。当虚拟机读取到一条指令时，就可以找到这个字节码代表的是什么指令，并且可以知道这条指令后有没有跟参数，以及参数该如何理解。 Code属性时Class文件最重要的属性。如果将Java程序分为元数据(类、字段、方法等信息)和代码，那么在Class文件中 Code属性用于描述代码 其他所有数据项目都用于描述元数据。 在任何实例方法中，都可通过this关键字访问到此方法所属的对象，这是为什么？ 通过Javac编译的时候把对this关键字的访问转变为对一个普通方法参数的访问 然后再虚拟机调用实例方法时自动传入此参数 因此在实例方法的局部变量表中至少会有一个指向当前实例对象的参数，局部变量表也会预留出一个Slot位来存放对象实例的引用。同样在Code属性中，字节码指令后存放的是方法的显式异常处理表(简称异常表)，该表对于Code属性来说不是必须存在的。(当方法中有try-catch语句时会有该表) 显式异常处理表 属于Java代码的一部分，编译器使用异常表来实现Java异常和finally处理机制，表结构如下 start_pc end_pc handler_pc catch_type 如果方法在start_pc行和end_pc行(不包括end_pc)间出现了catch_type异常，则转到handler_pc行继续处理。 Exceptions属性不要和前面的显式异常处理表混淆，显式异常处理表是Code属性的一部分，Exceptions属性是属性表集合中的一种属性，和Code属性平级。该属性的作用是列举出方法中可能抛出的受检查异常，也就是方法描述时throws关键字后面列举的异常。 attribute_name_index两个字节，对常量池的引用，固定为Exception，代表属性名称。 attribute_length四个字节属性值的长度 numbers_of_exception两个字节，可能抛出的受检查异常的个数 exception_index_table两个字节，对常量池的引用，代表了受检查异常的类型。 LineNumberTable属性用于描述Java源码行号和字节码行号之间对应关系(例如3：0，前面是字节码行号，后面是源码行号)。可以选择不生成，如果不生成，那么抛出异常时将不会显示出错的行号，并且调试程序时无法按照源码设置断点。 LocalVariable Table属性用于描述局部变量表中的变量和Java源码中定义的变量之间的关系，可以选择不生成。如果不生成，当其他人引入这个方法时，所有参数名称都会丢失，IDE会使用arg0、arg1等代替原参数名。该属性作用 描述局部变量在字节码中的作用域 存放局部变量的名称以及描述符 该局部变量在栈帧局部变量表中Slot位置，如果变量为64位，那么它占用的Slot为index和index+1。 ConstantValue属性通知虚拟机自动为静态变量赋值。只有被final修饰的变量并且满足一定的条件才可以使用这项属性。 对于实例变量，在实例构造器(&lt; init&gt;)方法中进行赋值 对于类变量(静态变量)，可以在类构造器(&lt; clinit&gt;)中进行赋值，也可以使用ConstantValue属性进行赋值。 如果同时也使用了final修饰、该变量数据类型为基本类型或String并且在定义时赋值，就生成ConstantValue属性。在编译期为该变量赋值 否则，在类构造器中进行赋值 对于final修饰的变量，该变量数据类型为基本类型或String并且在定义时赋值，就生成ConstantValue属性。在编译期为该变量赋值。 Signature属性可以用在类/接口、方法表、字段表上。在Java中，任何类、接口、初始化方法或成员如果使用了泛型，则该属性会记录泛型的类型(在Java的语法糖中会详细说到)。 Java代码的方法特征签名包括了方法名称、参数顺序以及参数类型 字节码层次的方法特征签名还包括了方法返回值和受检查异常表 可以出现在类、字段表和方法表结构的属性表中，可选属性。在Java中的泛型采用的是擦除机制，在Code属性中，泛型信息编译的(类型变量，参数化类型)之后都统统被擦除掉。好处是实现简单、运行期节省一些类型所占的空间。但坏处是无法将泛型类型和用户定义的普通类型同等对待。例如运行期反射无法获取到泛型信息。该属性就是为了弥补这个缺陷设计，Java反射API能够获取泛型类型，最终数据来源就是这个属性。 属性表还有很多其他属性，就不多记录了。Class文件结构就记录到这里。]]></content>
      <categories>
        <category>JVM虚拟机</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解JVM虚拟机一]]></title>
    <url>%2F2019%2F09%2F24%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM%E8%99%9A%E6%8B%9F%E6%9C%BA%E4%B8%80%2F</url>
    <content type="text"><![CDATA[作为Java程序员，对于JVM虚拟机的理解是必不可少的。今天刚看了周志明周老师的《深入理解JVM虚拟机》(第二版)，还是有所收获。看得不多，简单小结一下，后面会继续完善JVM方面的知识(本文及后面系列文章全部基于JDK1.7版本，JDK1.8以后方法区被移除)。 走进Java从传统意义上来讲，Java技术体系包括以下几个组成部分： Java程序设计语言 各种硬件平台上的Java虚拟机 Class文件格式 Java的API类库 来自商业机构和开源社区的第三方Java类库 其中JDK(Java Development Kit)是用于支持Java程序开发的最小环境，包括Java程序设计语言、各种硬件平台上的Java虚拟机以及Java的API类库。而JRE(Java Runtime Enviroment)是支持Java运行的标准环境，包括Java类库中Java SE API子集和Java虚拟机两部分。目前使用范围最广的Java虚拟机是HotSpot。 自动内存管理机制Java内存区域Java虚拟机在执行Java程序的过程中会把它所管理的内存划分为若干个不同的区域： 方法区(JDK1.8后被元空间代替) 堆 虚拟机栈 本地方法栈 程序计数器 下面来分别说一说这几个区域的作用。再说之前，先说一下线程私有的概念线程私有每条线程都需要有一个自己的内存区域，各线程之间互不影响，独立存储，我们称这类内存区域为线程私有。程序计数器 是一块较小的内存空间，它可以看作是当前线程所执行的字节码的行号指示器。 字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令 该区域是线程私有的 Java虚拟机栈 虚拟机栈也是线程私有的，生命周期和线程相同 每个方法在执行时会创建一个栈帧，用于存储局部变量表、操作数栈、动态链接和方法出口等信息，调用方法时，将栈帧入虚拟机栈；方法执行过后，栈帧出栈，因此不难发现，虚拟机栈可以看作是用于执行Java方法的内存 局部变量表 存放了编译期可知的各种基本数据类型，对象引用(reference类型)和returnAddress类型(指向一条字节码指令的地址) long和double类型数据占2个局部变量空间(Slot)，其余的只占1个。 局部变量表所需的内存空间在编译期间分配完成。当进入一个方法时，这个方法需要在栈帧中分配的局部变量空间是完全确定的。 在方法运行期间不会改变局部变量表大小 本地方法栈该栈和Java虚拟机栈的服务很类似，区别在于Java虚拟机栈为执行Java方法(字节码)服务，而本地方法栈为虚拟机使用到的Nativa方法(本地方法，由其他语言编写)服务。Java堆(Java Heap) 一般来说，堆是Java虚拟机管理的内存中最大的一块 被所有线程共享的内存区域，在虚拟机启动时创建 作用是存放对象实例，几乎所有的对象实例都在这里分配 字符串常量池在堆中(JDK1.8之前位于方法区) 同时，堆是垃圾收集器管理的主要区域，又被称为GC堆 Java堆还可以被细分为 新生代(1/3) Eden区(8/10) From Survivor区(1/10) ToSurvivor区(1/10) 老年代(2/3) 常见的配置堆的参数 -Xmx：堆内存的最大内存 -Xms：堆内存的最小内存 -Xmn：新生代的大小 XX:NewRatio：设置老年代是年轻代的几倍 XX:SurvivorRatio：设置Eden区是一个Survivor的几倍(注意是一个) 方法区 方法区也是各个线程共享的内存区域 用于存储一下信息 已被虚拟机加载的类信息 常量 静态变量 即时编译后的代码等 运行时常量池 该区域是方法区的一部分 Class文件除了有类的版本、字段、方法、接口等描述信息(后面会说到)外，还有一项信息是常量池，用于存放编译期生成的各种字面量和符号引用 这部分内容将在类加载后进入方法区的运行时常量池中 相比于Class文件的常量池，运行时常量池具备动态性。Java语言不要求常量一定只有编译期才能产生，也就是并不是只有预置入Class文件中常量池的内容才能进入方法区的运行时常量池，运行期间也可能有新的常量放入运行时常量池中，例如String类的intern方法。(关于此方法可以看我String源码的文章) 关于Java对象说完了JVM内存区域，就简单说一下Java对象的相关内容 对象的创建当遇到一条new指令时 检查这个指令的参数是否能在常量池中定位到一个类的符号引用，并且检查这个符号引用代表的类是否已经被加载、解析和初始化 如果没有，那必须先执行相应的类加载过程 类加载完成后，为新生对象分配内存。值得注意的是，对象所需内存大小在类加载完成后就已经完全确定。为对象分配内存的过程其实就是从堆内存中划分出一块确定大小的区域。 内存分配完成后，虚拟机将分配到的内存空间都初始化为零值，除了对象头以外(后面会说到)。这一操作保证了对象的实例字段在Java代码中可以不赋初始值就能使用。(不难理解，因为我们在创建Java对象时，成员变量就是默认零值) 接下来JVM对对象进行必要的配置，这些信息都存放在对象头中。例如 对象是哪个类的实例 如何找到类的元数据信息 对象的哈希值 对象的GC分代年龄(后面会说)等 到了这一步，已经执行完new指令了，但是此时对象的成员变量值都为0，显然不符合我们的实际情况。一般来说，这时候会执行&lt; init&gt;方法，把对象按照程序员的意愿进行初始化。这样，我们就得到了一个真正可用的对象。 对象的内存布局说完了对象的创建，紧接着自然就该说一说创建出来的对象是什么样的，有着什么样的内存布局。在HotSpot中虚拟机中，对象在内存中存储的布局可以分为三部分 对象头 实例数据 对齐填充 下面分别说一下这三个部分对象头前面说过，在创建对象分配内存阶段，会将除了对象头以外的内存空间初始化为零值，那接下来就看看对象头到底有什么作用吧。对象头包含两部分信息 一部分用于存储对象自身的运行时数据，如 哈希值 GC分代年龄 锁状态标志 线程持有的锁 偏向线程ID和偏向时间戳等 另一部分是类型指针，即对象指向它的类元数据的指针。通俗的讲，JVM通过这个指针来确定对象是哪个类的实例。 值得注意的是： 查找对象的元数据信息并不一定要经过对象本身(后面会说到)，因此并不是所有的虚拟机实现都必须在对象数据上保留类型指针。 除此之外，如果对象是Java数组，对象头中还必须有一块用于记录数组长度的数据。 实例数据 该部分是对象真正存储的有效信息，也是程序代码中所定义的各种类型的字段内容。 无论是从父类继承的，还是子类定义的，都会记录下来。 默认情况下，相同宽度的字段会分配到一起。在满足这个条件的前提下，父类中定义的变量会出现在子类之前。 对齐填充这一部分并不是必然存在的，也没有特别含义，仅仅起着占位符的作用。HotSpot VM的自动内存管理系统要求对象的起始地址必须是8字节的整数倍。因此实例对象的大小必须是8字节的整数倍，如果对象不是，那么就需要通过对齐填充来补全。 对象的定位访问介绍了对象的创建和内存布局，相比你对Java对象已经有了一定的了解了，那么我们又是怎么在堆中找到这个对象并使用它的呢？Java程序是通过栈上的reference类型数据(前面说过，存放在栈帧中的局部变量表)来操作堆上的具体对象。通过reference数据有两种方式可以定位到堆中的数据 使用句柄访问对象，此时会在堆中划出一块内存叫做句柄池，refenence中存储的就是对象的句柄地址。而句柄中包含了对象的实例数据和类型数据各自的地址信息 实例数据：可以理解为当前对象的所有数据，位于堆中。 类型数据：属于类的数据，如静态变量，常量等，位于方法区中。 使用指针直接访问，此时reference中存储的就是对象实例数据的地址。而在对象中有指向类型数据的指针，通过该指针可以访问类型数据。 以上两种访问方式都有各自的优势： 句柄访问，reference中存储的是稳定的句柄地址，在对象移动时(如GC过程中)只会改变句柄的实例数据指针，而reference本身不需要修改。 指针直接访问，速度更快，节省了一次指针定位的时间 在使用句柄访问时,reference 需要访问句柄池(1次) 通过句柄池中指向实例数据的指针访问堆上的实例数据(2次) 通过句柄池中指向类型数据的指针访问访问方法区上的类型数据(3次) 直接使用指针时，reference 直接访问堆上的实例数据(1次) 在示例数据中找到指向类型数据的指针 通过该指针访问方法区上的类型数据(2次) 由于对象的访问在Java中很频繁，因此这一次开销也是相当客观的。对于HotSpot而言，使用的是第二种情况。 垃圾收集器与内存分配策略前面说过，程序计数器、虚拟机栈、本地方法栈这三个区域和线程生命周期相同，每个栈帧中分配多少内存基本在类结构确定下来时就已知，这几个区域的内存分配的回收都具有确定性，因此不用过多考虑回收问题。但是Java堆和方法区不一样，一个接口中的多个实现类需要的内存可能不一样，一个方法不同的分支所需要的内存也可能不一样，只有在程序运行期间才能知道会创建哪些对象。这部分内存分配和回收都是动态的，垃圾收集器所关注的就是这一部分内存。 判断对象是否存活垃圾收集器在对堆进行回收前，首先要判断堆中的哪些对象还”存活”着，哪些对象已经”死去”(不可能再被任何途径使用的对象)，判断对象是否存活，有以下几种常用方法 引用计数法给对象添加一个引用计数器 每当有一个地方引用它时，计数器值+1 当引用失效时，计数器值-1； 这样一来，任何时候计数器值为0的对象就是不可能再被使用的，也就是已经”死去”的 这样的算法实现简单，效率也高，在大多数情况下都是一个不错的算法。但是它也有一个很大的缺陷，那就是无法解决两个对象相互引用的问题。什么是相互引用的问题呢？(代码见《深入理解JVM虚拟机》P63) 有两个对象A和B，A和B这两个对象已经不可能再被访问，但是它们之间相互引用 导致两者引用计数器都不为0，于是GC收集器也就无法收集它们。 可达性分析算法大多数的应用程序语言都是使用可达性分析算法来判定对象是否存活。基本思路 通过一系列被称为“GC Roots”的对象作为起始点，从这些节点向下搜索 搜索走过的路径称为”引用链”，当一个对象到GC Roots没有任何引用链相连时(即从GC Roots到这个对象不可达)，则该对象是”死亡”的。 在Java中，可作为GC Roots的对象有 虚拟机栈(栈帧中的本地变量表)中引用的对象 方法区中静态属性引用的对象 方法区中常量引用的对象 本地方法栈中Nativa方法引用的对象 引用前面说到的引用计数法和可达性分析法两种方法判断对象是否存活，都和”引用”有关，下面就详细说一下引用的类型 强引用(StrongReference)在程序代码中普遍存在，类似Object o=new Object()这类的引用。只要强引用还在，垃圾收集器永远不会回收掉被引用的对象。 软引用(SoftReference)用来描述一些还有用但并非必须的对象。对于这些对象，在系统将要发生内存溢出异常之前，将会把这些对象列进回收范围内进行第二次回收。但如果这次回收还没有足够的内存，就会抛出内存溢出异常。 弱引用(WeakReference)比软引用强度更弱，被弱引用关联的对象只能生存到下次垃圾收集发生之前。当垃圾收集器工作时，无论当前内存是否足够，都会回收掉被弱引用关联的对象。 虚引用(PhantomReference)最弱的一种引用关系，一个对象是否有虚引用存在，完全不影响其生存时间，也无法通过虚引用来获取一个对象实例。设置该引用的唯一目的就是能在这个对象被垃圾收集器回首时收到一个系统通知。 生存还是死亡即使在前面的可达性分析中得到不可达的对象，该对象也并是”非死不可”。这时候它们暂时处于”缓刑”，如果真正要宣告一个对象”死亡”，至少要经过两次标记过程。在其中对象还有”自救”的机会。 如果对象在可达性分析中发现没有和GC Roots相连的引用链，那么它将会被第一次标记并且进行筛选 如果该对象没有覆盖”finalize()”方法或该方法已经被虚拟机调用过，那么该对象被回收 如果该对象覆盖了”finalize()”方法并且没有被虚拟机调用过，那么该对象会被放置在F-Queue中。并在稍后由一个虚拟机自动建立的、低优先级的Finalizer线程执行它。 这里说的”执行”是指虚拟机会触发finalize()方法，但并不承诺会等待它运行结束。这样做的原因在于 如果一个对象在finalzie()方法中执行缓慢，或者发生了死循环，很可能会导致F-Queue队列中其他对象处于永久等待，甚至内存回收系统崩溃。 finalzie()方法是对象最后一次自救机会。稍后GC将对F-Queue队列中的对象进行第二次标记。 如果对象在finalxize()方法中成功拯救自己，和引用链上的任何一个对象建立关联(例如把自己this赋值给某个类的变量等)，那么在第二次标记时会被移出”即将回收”集合。 如果对象这时候没有成功拯救自己，那么基本就被回收了。 回收方法区方法区回收效率较低，这是由方法区存放的数据相关的。方法区主要回收两部分内容，废弃常量和无用的类。判断一个常量是否是废弃常量比较简单，但是要判定一个类是无用的类，条件就会严苛许多，这也是导致方法区回收效率低的原因。判断无用的类 该类的所有实例都被回收 加载该类的ClassLoader已被回收 该类对应的Class对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。 满足上述三个条件的类可以被回收，但并不是必然被回收。 垃圾收集算法正如书上所说，垃圾收集算法涉及大量的程序细节，这里只是大致的介绍三种算法的思想 标记清除算法 复制算法 标记整理算法 标记清除算法该算法分为标记和清除两个阶段。 标记出所有需要回收的对象(标记过程前面已经说过) 标记完成后统一回收所有被标记的对象。 这个方法主要有两个缺点 效率问题，标记和清除两个过程效率都不高。 空间问题，标记清楚过后会产生大量不连续的内存碎片，这类碎片过多可能会导致程序在分配较大对象时无法找到连续内存而不得不再进行一次GC。 复制算法为了解决效率问题，该算法出现了。它将可用内存按容量划分为大小相等的两块，每次只使用其中一块。当这一块内存用完了，将还存活着的对象复制到另一块内存上面，然后把自己使用过的内存空间一次清理掉。这样做的好处 每次都是对整个半区进行内存回收，内存分配时也不用考虑内存碎片等复杂情况，只需要移动堆顶的指针，按顺序分配内存即可，实现简单且运行高效。 缺点 将内存缩小为原来的一半，代价过高。 现在的虚拟机大多都采用这种方法来回收新生代(注意是新生代)。据分析，98%的对象都是朝生夕死的所以并不需要1：1的比例来分配内存空间。因此新生代就被划分为Eden区(8/10)、FromSurvivor区(1/10)和ToSurvivor区(1/10)三个区域。 每次使用Eden区和一块Survivor区 当回收时，将Eden和Survivor中还存活的对象一次性的复制到另外一块Survivor区中 清理Eden区和刚才用过的Survivor区。 当然，我们并不能保证每次回收后都只有不多于1/10的对象存活，即有可能某次回收后对象存活较多，Survivor空间不够。这时候就要依赖其他内存(老年代)进行分配担保。 标记整理算法 复制算法在对象存活率较高时，效率就会变低(因为要进行较多的复制操作) 更关键的是，使用复制算法就必须要有额外的空间进行分配担保。 对于老年代，没有空间进行担保，因此对于老年代不能够使用复制算法，应该使用标记整理算法。和标记清除算法思想一样，但是后续的步骤不是直接对可回收对象进行清理，而是让所有存活对象都向一端移动，然后直接清理掉边界以外的内存。 分代收集算法这种算法就是根据对象存活周期不同将内存划分为几块。一般是把Java堆划分为新生代和老年代，然后根据各个年代的特点采用最适当的收集算法。 对于新生代，每次垃圾收集都会有大量对象死去，只有少量存活，因此选用复制算法。 对于老年代，对象存活率较高且没有额外担保空间，不宜使用复制算法，因此选用标记清理或标记整理算法。 HotSpot算法实现前面从理论上介绍了对象的存货判定和垃圾收集算法，下面就具体说一下HotSpot的实现细节 HotSpot枚举根节点 在判断对象存活的可达性分析算法中，使用到了GC Roots。而可以作为GC Root的节点有很多，如果要逐一检查，无疑是很耗费时间的。 另外，可达性分析的过程中整个执行系统看起来就被冻结在某个时间点上，即GC停顿。不允许出现分析过程中对象的引用关系还在不断变化的情况，否则分析结果的准确性就不能得到保证。这就导致了GC进行时必须停掉所有的Java线程(Stop The World)。 由于大多虚拟机都是采用准确式GC(即虚拟机知道内存中某个地方的数据到底是什么类型，这样在GC时能够准确判断堆上的数据是否还可能被使用)。HotSpot虚拟机使用一组称为OopMap的数据结构，在类加载完成后，HotSpot就把对象内什么偏移量上是什么类型的数据计算出来，在JIT编译过程中，也会在特定位置记录下栈和寄存器中哪些位置是引用。这样，GC在扫描时就可以直接得知这些信息了。 安全点(SafePoint)前面说了，在OopMap的协助下，HotSpot可以准确地完成GC Roots枚举。但仍有一个问题，可能程序中，导致引用关系变化(即导致OopMap内容发生变化)的指令很多，如果每一条指令都生成对应的OopMap，这样很占内存。实际上，HotSpot也没有为每条指令都生成OopMap。前面说到了，它只是在特定位置记录这些信息，这些位置被称为安全点。即在程序执行时并非所有地方都能停顿下来开始GC，只有在到达安全点时才能暂停。安全点的选用既不能太少以至于让GC等待时间太长，也不能太多导致频繁GC增大运行负荷。安全点的选定基本上是以指令”是否具有让程序长时间执行的特征”为标准进行选定。这是因为：每条指令执行时间都非常短暂，”长时间执行”最明显的特征就是指令序列的复用，例如方法调用、循环跳转、异常跳转等。所以具有这些功能的指令才会产生SafePoint。 对于安全点，还有一个问题就是如何在GC发生时让除了执行Native的所有线程都”跑”到最近的安全点上再停顿下来？书上给了两种方案 抢先式中断不需线程的执行代码主动去配合，在GC发生时，首先把所有的线程全部中断，如果发现有线程中断的地方不在安全点上，就恢复该线程，让它跑到”安全点”上。(这种方法现在几乎不用) 主动式中断当GC需要中断线程时，不直接对线程进行操作，仅仅是简单地设定一个标志，各个线程执行时主动的去访问这个标志，发现中断标志为真时就自己中断挂起。标志的地方和安全点是重合的。 安全区域(Safe Region)前面的安全点并没有完全解决如何进入GC的问题。你发现没有，当一个线程不执行的时候(即没有分配到CPU时间，有可能是处于Sleep状态或者Blocked状态)，显然无法响应JVM的中断请求，”走”到安全点中断挂起；同样的JVM也不可能等待线程重新被分配CPU时间。这时，就需要安全区域来解决。 安全区域指的是在一段代码片段中，引用关系不会发生变化。那么在这个区域内的任意地方开始GC都是安全的。 对于安全区域的线程 在线程执行到安全区域中的代码时，首先标识自己已经进入了安全区域。 这样，当在这段时间里JVM要发起GC时，就不用管标识自己为Safe Region状态的线程。 线程要离开Safe Region时，它要检查系统是否已经完成了根节点枚举(或者是整个GC过程) 如果完成了，线程就继续执行 否则它就必须等待直到收到可以安全离开Safe Region的信号为止 内存分配和回收策略Java体系中的自动内存管理，实际上可以归结为给对象分配内存以及回收分配给对象的内存。前面已经大致介绍了内存回收这方面，下面就说一下给对象分配内存的细节。 对象内存的分配，基本都是分配在堆上。对象主要分配在新生代的Eden区。对象优先在Eden分配大多数情况下，对象在新生代Eden区分配。当Eden区没有足够的空间进行分配时，虚拟机将发起一次Minor GC。 Minor GC新生代GC，指发生在新生代的GC，因为Java对象大多都具有朝生夕灭的特性，所以Minor GC非常频繁，一般回收速度也较快。 Full GC老年代GC，指发生在老年代的GC，Full GC速度一般会比Minor GC慢10倍以上。 大对象直接进入老年代大对象，即需要大量连续内存空间的Java对象。最典型的有很长的字符串或数组。可以通过设置”-XX:PretenureSizeThreshold&lt;/font“参数，令大于这个设置值的对象直接在老年代分配。这样做的目的就是避免在Eden区以及两个Survivor区发生大量内存复制。长期存活的对象将进入老年代前面说过，JVM采用了分代收集的思想来管理内存，那么内存回收时就必须能识别哪些对象应放在新生代，哪些又该放在老年代。为此，虚拟机给每个对象定义了一个年龄(Age)计数器。 如果对象在Eden区出生并经过一次Minor GC后仍然存在，并且能够被Survivor区容纳，将被移动到Survivor区中，并且对象年龄设为1 对象在Survivor区中每熬过一次Minor GC，Age就+1，当年龄增加到一定数时(默认15)，就会被移到老年代。 对象晋升到老年代的阈值，可以通过参数”-XX:MaxTenuringThreshold“设置 动态对象年龄判断为了更好地适应不同程序的内存情况，对象并不是一定要达到阈值年龄才能晋升到老年代。如果Survivor区中相同年龄所有对象的大小总和大于Survovir空间(一个Survivor大小)的一半，年龄大于或等该年龄的对象就可以直接进入老年代。 对于JVM的简单介绍就记录到这里，回顾一下主要介绍了JVM内存模型、自动内存管理以及垃圾收集机制。下次会记录一下第六章内容，即JavaClass文件结构。]]></content>
      <categories>
        <category>JVM虚拟机</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[排序算法之快速排序]]></title>
    <url>%2F2019%2F09%2F22%2F%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E4%B9%8B%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[前面已经说过了四种排序算法，这次来讲一讲一种效率较高，应用也较多的一种排序，那就是快速排序。听名字就知道，这种排序算法速度是比较快的，那它究竟是怎么操作的呢？让我们来看一看吧 算法思路快速排序其实是对冒泡排序的一种改进，用到了分治和递归思想。通过一趟排序将要排序的数组分割成独立的两部分，其中一部分的所有数据都比另外一部分的所有数据小，然后再按照此方法对两部分数据分别进行快速排序，整个排序过程递归进行。 在待排序的数组中选定一个基数(作用后面说) 这里基数的选择有很多种方法： 数组的第一个元素作为基数 数组的最后一个元素作为基数 数组的中间元素作为基数 随机在数组中选择一个数作为基数 我这里是选择中间的数作为基数。 在当前数组的开头和末尾各定义一个指针，暂且命名为l和r l指针向右扫描，直到找到小于等于基数的数为止 r指针向左扫描，直到找到大于等于基数的数为止 交换arr[l]和arr[r]，重复3，4直到r&lt;=l为止 当r==l的时候，l和r指向基数。并且数组中比基数小的元素都在数组的左边，比基数大的元素都在数组的右边。 分别对数组的左边和右边递归进行2、3、4、5步，最后整个数组就被排序。 代码实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public static void quickSort(int[] arr,int left,int right) &#123; //左下标，初始值为0 int l=left; //右下标，初始值为最后一个元素的下标 int r = right; //基数 int pivot = arr[(left + right) / 2]; //while循环让比pivot小的值放到左边，大的放到右边 while (r &gt; l) &#123; //在pivot左边一直找，直到找到大于等于pivot的值，才退出 while (arr[l] &lt; pivot) &#123; l++; &#125; //在pivot右边一直找，直到找到小于等于pivot的值，才退出 while (arr[r] &gt; pivot) &#123; r--; &#125; //此时说明pivot左边的值都小于等于pivot，右边都大于等于pivot if (l &gt;= r) &#123; break; &#125; //交换 int temp; temp = arr[l]; arr[l] = arr[r]; arr[r] = temp; //如果交换完后发现arr[l]==pivot，让r前移一步，r-- if (arr[l] == pivot) &#123; r--; &#125; //如果如果交换完后发现arr[r]==pivot，让l后移一步，l++ if (arr[r] == pivot) &#123; l++; &#125; &#125; //注意：如果l==r，必须让l++,r--，否则会出现栈溢出 if (l == r) &#123; l++; r--; &#125; //向左递归 if (left &lt; r) &#123; quickSort(arr, left, r); &#125; //向右递归 if (l &lt; right) &#123; quickSort(arr, l, right); &#125;&#125; 细节解释我把我觉得代码中不好理解的地方说一下 这两个判断的作用是什么呢？举个例子： 现有一个待排序数组{3,1,1,2}，初始时l=0；r=3；pivot=arr[1]=1; 第一次扫描过后，得到数组{1,1,3,2}，此时l=0；r=2； 第二次扫描，因为arr[r]=3&gt;pivot,r左移，r=1；l不变，l=0 这时候问题就来了，这时候arr[l]==arr[r]==pivot，所以l和r会一直互相交换值，但是它们指向的位置不变，即l==r==1一直保持，这样就会陷入死循环为什么在arr[l] == pivot时是r–而不是l++呢？前面说过，因为最后r==l时，arr[r]==arr[l]==pivo一定是存在的。当arr[l] == pivot时，说明l已经找到了确定的位置，这时候如果移动l，那么最后l==r时，arrr[r]==arr[l]就有可能不等于pivot。为什么会出现栈溢出？可以这么理解，当第一趟排序过后，arr[r]==arr[l]==pivot，数组中小于pivot的都在左边，大于pivot的都在右边。这时候要递归对左右序列分别进行快排。通过下面的递归代码可以发现： 对其左序列进行快排时，以r为新的右边界 对其右序列进行快排时，以l为新的左边界 这时候r和l指向的值是已经确定了位置的基数值，自然就不需要参与后面的快排。所以要将r前移，l后移，目的就是将已经确定位置的基数值排除在外。 排序速度同样的，我们来测试一下快排有多快排序时间进过多次测试发现快排的速度大约在20ms左右，比前面的希尔排序还要快一倍，果然是快排，名不虚传。]]></content>
      <categories>
        <category>算法之美</category>
      </categories>
      <tags>
        <tag>排序</tag>
        <tag>快速排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[排序算法之希尔排序]]></title>
    <url>%2F2019%2F09%2F21%2F%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E4%B9%8B%E5%B8%8C%E5%B0%94%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[前面说到了插入排序，并且知道了它是不稳定的。并且测试速度后发现插入排序的速度与冒泡、选择相比还是比较可观的。但是，不知道你有没有发现，插入排序再某些情况下存在着一些弊端。比如有这样的一个数组arr={4,7,9,6,4,1}，数组自身的顺序接近于逆序，当将4、1插入到有序数组中时，需要将有序数组部分所有元素都后移一个位置，这无疑会有一定的时间消耗。那么在这种情况下，就出现了希尔排序，你可以将希尔排序理解为插入排序的增强版。 算法思路希尔排序，又称为缩小增量排序 设置一个步长step，通常初始化为arr.length/2，即数组长度的一半 间隔为一个步长的元素为一组 分别对同一组的元素进行插入排序 每一趟过后将step减半，即step/=2(缩小增量) 重复3和4，直到step为1 setp为1时，数组已经接近有序，这时对整个数组进行插入排序。 前面说过，插入排序适用于哪些自身顺序比较良好的数组，而希尔排序通过不断地缩小步长，将一个数组变成一个接近有序的数组后，直到step=1，此时就相当于对一个接近有序的数组进行插入排序。 代码实现1234567891011121314151617181920public static void Shellsort1(int[] arr) &#123; int count=0; for (int step = arr.length / 2; step &gt; 0; step /= 2) &#123; //类比于插入排序 for (int i = step; i &lt; arr.length; i++) &#123; //当前分组中有序部分的最后一个数下标 int insertIndex = i - step; //当前分组中待待插入的数 int insertVal = arr[i]; while (insertIndex &gt;= 0 &amp;&amp; insertVal &lt; arr[insertIndex]) &#123; arr[insertIndex + step] = arr[insertIndex]; insertIndex -= step; &#125; arr[insertIndex + step] = insertVal; &#125; &#125; System.out.println(&quot;希尔排序后的数组&quot;); System.out.println(Arrays.toString(arr));&#125; 分析 算法的时间复杂度 平均时间：O(nlogn) 最差情况：O(n的1.2次方) 这不难理解，因为对于一个简单地双重循环来说，时间复杂度都是O(n²) 空间复杂度 只用了一个insertIndex和一个insertVal，和n的大小无关，所以是O(1) 稳定性 和插入排序不同，希尔排序不是稳定的 算法速度既然说希尔排序时插入排序的增强版，那就来测试一下希尔排序和插入排序的速度谁更快一些，又快多少呢？同样的，创建一个80000大小的随机数组，来测试希尔排序的排序速度排序时间(毫秒)为通过前面插入排序的对比不难发现，希尔排序能够较大的提高插入排序的速度]]></content>
      <categories>
        <category>算法之美</category>
      </categories>
      <tags>
        <tag>排序</tag>
        <tag>希尔排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[排序算法之插入排序]]></title>
    <url>%2F2019%2F09%2F21%2F%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E4%B9%8B%E6%8F%92%E5%85%A5%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[前面说了两种排序算法，分别是冒泡排序和选择排序，这两种算法都比较容易理解。那么这次来学习第三种排序—-插入排序，这也是一种相对简单的排序算法，理解起来难度也不大。 算法思路将数组分成两部分： 一部分是有序数组 一部分是无序数组。 在每一趟排序中，从无序数组中拿出一个数来，放到有序数组的正确位置。即每一趟排序过后，无序数组元素减少一个，相应的有序数组元素增加一个。到最后该数组全部变为有序数组。 初始化有序数组长度为1，即arr[0]为有序数组。 第一趟排序，将无序数组中第一个元素arr[1]放到有序数组中，此时有序数组包含两个元素 第二趟排序，将无序数组中第一个元素arr[2]放到有序数组中，此时有序数组包含三个元素 …… 第n-1趟排序，将无序数组中第一个也是最后一个元素arr[n-1]放到有序数组中，至此数组全部有序可以看到，最后一趟排序过后，无序数组长度为0，至此数组全部有序。 代码实现1234567891011121314151617181920212223/** * 插入排序 * @param arr */public static void insertSort(int[] arr) &#123; //待插入的数，无序数组第一个元素 int insertIndex; //待插入的数前面一个数的下标，有序数组最后一个元素 int insertVal; for (int i = 0; i &lt; arr.length-1; i++) &#123; //待插入的数为无序数组第一个元素 insertVal = arr[i+1]; //有序数组最后一个元素 insertIndex = i ; while (insertIndex &gt;= 0 &amp;&amp; insertVal &lt; arr[insertIndex]) &#123; arr[insertIndex + 1] = arr[insertIndex]; insertIndex--; &#125; arr[insertIndex+1] = insertVal; &#125; System.out.println(&quot;排序后的数组&quot;); System.out.println(Arrays.toString(arr));&#125; 分析 算法的时间复杂度 平均时间：O(n²) 最差情况：O(n²) 这不难理解，因为对于一个简单地双重循环来说，时间复杂度都是O(n²) 空间复杂度 只用了一个insertIndex和一个insertVal，和n的大小无关，所以是O(1) 稳定性 不难发现，插入排序是稳定的 另外，该排序算法在大部分元素已经是有序时比较好 算法速度和前面两个排序算法一样，我们来随机创建一个80000大小的随机数组，测试所用的时间最后测得的排序时间为让我们以ms为单位，再测试一次通过结果可以发现，相比于冒泡排序和选择排序，插入排序的速度还是很可观的。]]></content>
      <categories>
        <category>算法之美</category>
      </categories>
      <tags>
        <tag>排序</tag>
        <tag>插入排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Web基础之JDBCUtils工具类]]></title>
    <url>%2F2019%2F09%2F20%2FWeb%E5%9F%BA%E7%A1%80%E4%B9%8BJDBCUtils%E5%B7%A5%E5%85%B7%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[每次使用JDBC操作数据库的时候，都需要导入驱动、获取连接等重复的操作，因此写了一个JDBC工具类，该工具类使用Druid数据库连接池，能够获取连接池(供JdbcTemplate使用)和连接对象，方便以后使用，本文基于Maven下的JavaWeb项目。 前期准备导入jar包要使用数据库连接和Druid连接池，需要导入MySQL驱动和Druid连接池相关jar包，我们打开pom.xml文件。在标签体中加入下面两个标签，如果没有标签则创建一个。 123456789101112131415&lt;!--mysql驱动--&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.26&lt;/version&gt; &lt;!--作用域--&gt; &lt;scope&gt;compile&lt;/scope&gt;&lt;/dependency&gt;&lt;!--druid连接池--&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.0.9&lt;/version&gt;&lt;/dependency&gt; 配置文件对于Druid连接池，除了导入相关jar包以外，我们还需要将Druid.properties配置文件放置到resources目录(该目录放置代码相关的配置文件)下，后面在使用时将配置文件加载进内存。 工具类编写到目前为止我们所有的前期工作已经完成，现在可以编写JDBCUtils工具类了 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465/* 1. 声明静态数据源成员变量 2. 创建连接池对象 3. 定义公有的得到数据源的方法 4. 定义得到连接对象的方法 5. 定义关闭资源的方法 */public class JDBCUtils &#123; // 1. 声明静态数据源成员变量 private static DataSource ds; // 2. 创建连接池对象 static &#123; // 加载配置文件中的数据 InputStream is = JDBCUtils.class.getClassLoader().getResourceAsStream(&quot;druid.properties&quot;); Properties pp = new Properties(); try &#123; pp.load(is); // 创建连接池，使用配置文件中的参数 ds = DruidDataSourceFactory.createDataSource(pp); &#125; catch (IOException e) &#123; System.out.println(&quot;JDBCUtils&quot;); //e.printStackTrace(); &#125; catch (Exception e) &#123; System.out.println(&quot;JDBCUtils&quot;); //e.printStackTrace(); &#125; &#125; // 3. 定义公有的得到数据源的方法 public static DataSource getDataSource() &#123; return ds; &#125; // 4. 定义得到连接对象的方法 public static Connection getConnection() throws SQLException &#123; return ds.getConnection(); &#125; // 5.定义关闭资源的方法 public static void close(Connection conn, Statement stmt, ResultSet rs) &#123; if (rs != null) &#123; try &#123; rs.close(); &#125; catch (SQLException e) &#123;&#125; &#125; if (stmt != null) &#123; try &#123; stmt.close(); &#125; catch (SQLException e) &#123;&#125; &#125; if (conn != null) &#123; try &#123; conn.close(); &#125; catch (SQLException e) &#123;&#125; &#125; &#125; // 6.重载关闭方法 public static void close(Connection conn, Statement stmt) &#123; close(conn, stmt, null); &#125;&#125; 代码其他部分都比较简单，主要记录一下记载配置文件时的路径 1InputStream is = JDBCUtils.class.getClassLoader().getResourceAsStream(&quot;druid.properties&quot;); maven编译完成后，所有的源文件，包括resources目录下的文件，默认都会放在target/classes下面，这个路径其实就是classPath(环境变量)的路径。在resources 根目录下的配置文件其实就是 classPath的路径。所以我们可以这么做： 1234567// 获取classpath下资源的URL对象java.net.URL appURL = App.class.getClassLoader().getResource(&quot;app.properties&quot;);System.out.println(appURL.getPath()); // 输出该文件的绝对路径// 获取classpath下资源的InputStream对象InputStream propertiesInputStream = App.class.getClassLoader().getResourceAsStream(&quot;app.properties&quot;);]]></content>
      <categories>
        <category>JAVAWEB</category>
      </categories>
      <tags>
        <tag>Maven</tag>
        <tag>工具类</tag>
        <tag>JDBC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[自顶向下之计算机网络和因特网]]></title>
    <url>%2F2019%2F09%2F20%2F%E8%87%AA%E9%A1%B6%E5%90%91%E4%B8%8B%E4%B9%8B%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E5%92%8C%E5%9B%A0%E7%89%B9%E7%BD%91%2F</url>
    <content type="text"><![CDATA[最近在读计算机网络方面的书—–《计算机网络自顶向下方法》(第七版)，个人觉得书中概念讲的很清楚，举例也是很形象易懂了，如果你想学计网的话，5星强烈推荐！刚读完第一章，做个小结，方便回头复习。书中有些图有助于理解，建议搭配书本一起学习。 什么是因特网这一节主要从两个方面来解释什么是因特网 从因特网得具体构成，也就是从因特网的基本硬件和软件组成方面解释 从为分布式应用程序提供服务得联网基础设施来描述 具体构成描述因特网是一个世界范围内的网络，一个互联了遍及全世界数十亿计算设备的网络，这些计算设备包括计算机、手机、智能手表、电视…，用因特网术语来说，这些和因特网被称为主机/端系统。端系统通过通信链路和分组交换机连接到一起 通信链路 用来传输数据，由不同类型的物理媒体组成，例如同轴电缆、铜线、光纤… 传输速率：链路传输数据的频率，比特/秒(bit/s) 分组交换机 顾名思义，分组交换机从它一条如通信链路接收到达的分组，并从它的一条出通信链路转发该分组 两种有名的分组交换机：路由器和链路层交换机 链路层交换机通常位于接入网中 路由器通常位于网络核心中 分组 当端系统向另一台端系统之间发送数据时，发送端系统将数据分段，并为每段加上首部字节 由此形成的信息包用计算机网络术语来说称为分组 分组通过网络发送到目的端系统，并在那里被装配成原始数据 路径 一个分组所经历的一系列通信链路和分组交换机被统称为通过该网络的路径 也许通过上面的描述，你还是不明白数据在网络中怎么传输的。不着急，我们来举个例子：一个工厂需要将大量的货物搬运到数千里以外的某个目的地仓库。在工厂中，货物要分开并装上卡车车队。然后每辆卡车独立的通过高速公路、公路或立交桥组成的运输网络向仓库运送货物。在目的地仓库，卸下这些货物，并且与一起装载的同一批货物的其余部分堆放在一起。 工厂就相当于源端系统 货物就相当于数据 目的地仓库就相当于目的端系统 在工厂中将货物分开并装上卡车，即将数据分段，为每段加上首部字节，形成分组。因此、分组就相当于卡车。 高速公路、立交桥就相当于各种通信链路 分组交换机则相当于路的交叉口 公路两边的建筑物就相当于端系统 就像卡车选取运输网路的一条路径前行一样，分组选取计算机网络的一条路径前行 这下你明白了么？端系统通过ISP(Internet Service Provider,因特网服务提供商)接入因特网 ISP一个由多台分组交换机和多段通信链路组成的网络。各ISP为端系统提供了不同类型的网络接入，因特网就是将端系统彼此互联，因此为端系统提供接入的ISP也必须互联，后面会详细说到ISP 协议 控制着因特网中信息的接受和发送，端系统、分组交换机和其他因特网部件都要运行一系列协议 TCP(Transmission Control Protocal，传输控制协议)和IP(Internet Protocol，网际协议)是因特网中最为重要的协议 IP协议定义了在路由器和端系统之间发送和接收的分组格式 服务描述除了电子邮件、Web冲浪等传统应用外，因特网应用还包括手机和平板的应用程序。例如在线电影、多人游戏、视频会议…因为这些应用&lt;font color=bllue涉及到多个相互交换数据的系统，故它们被称为分布式应用程序。重要的是，这些因特网应用程序都是运行在端系统上的，即它们并不运行在位于网络核心的分组交换机中。假如你写了一个应用程序，运行在不同端系统上的软件需要相互发送数据(例如QQ、微博…)，这时候问题就来了，你怎么才能让运行在一个端系统上的应用程序指令因特网向运行在另一个端系统的软件发送数据呢？这个问题引出了另一种描述因特网的方法：即将因特网描述为应用程序的平台。与因特网相连的端系统提供了一个套接字接口(在Java中，接口就是规则)，该接口规定了运行在端系统上的应用程序请求因特网向运行在另一个端系统上的特定目的地程序交付数据的方式。 套接字 由端系统提供 规定了端系统上的应用程序请求因特网向另一个端系统上的特定目的地程序交付数据的方式。 一套发送程序必须遵循的规则集合 我们继续来做一个类比假设张三使用邮政服务向李四发送一封信。那我们知道，张三不能只是写了这封信，然后丢出窗外，这样邮政服务是不会接收的，李四也收不到信。正确的做法是什么呢？张三应该将信装在信封里，在信封上写李四的姓名、住址、邮编；在信封右上角贴上邮票；最后将信封丢进邮政的服务信箱中。这是邮政服务定义的规则，是每个要发信的人必须遵守的。同理，因特网也有一个发送数据的程序必须遵守的套接字接口(规则)，是因特网能向接收数据的程序交付数据。 什么是协议同样的，为了帮助理解，我们像举个例子类比一下协议这个概念。我们的生活中，无时无刻不在执行协议。假设张三遇到了李四，发生了下面一段对话 张三：你好，李四(李四发送报文) 李四：你好，张三(发送报文) 这时，李四对张三的回应按时着两人可以继续进行交谈(通信)。 但是如果是这样的： 张三：你好啊李四 李四：别烦我/没有理张三 李四的反应表明两人之间的交谈(通信)很勉强或者无法进行，这时张三可能会放弃和李四的交谈。 通过上面两段对话，可以知道，发送和接收的报文，以及这些报文发送、接收报文(在第一段中，李四接收报文后对张三进行了回复)或者其他事件出现时所采取的动作(在第二段中，李四没有进行回复)，在一个人类协议中起到了核心作用。如果两个人交谈时，使用不同的协议，例如张三和李四的语言不通，那么他们就无法通信。同样的，在网络中为了完成一项工作，要求两个(多个)通信实体运行相同的协议。网络的协议和人类协议类似，交换报文和采取动作的实体时设备而不是人 协议定义了在两个或多个通信实体间交换报文的&lt;font color=bllue格式和顺序，以及报文发送和或接受一条报文或其他事件发生时所采取的动作。因特网广泛的使用了协议，不同的协议用于完成不同的通信任务，掌握计算机网络领域知识的过程就是理解网络协议的构成、原理和工作方式的过程。 网络边缘前面说过，通常把与因特网相连的计算机或其他设备称为端系统，它们位于互联网的边缘，因此被称为端系统。想象一下，在现实生活中，各种各样的房子/建筑物就相当于各种各样的端系统，建筑物前的公路将数以亿计的建筑物连接在一起，就相当于因特网将无数端系统连接在一起。通常路的尽头都是建筑物，建筑物位于公路系统的边缘，同样的端系统也位于互联网的边缘。端系统也称为主机，因为它们运行应用程序，主机有时又被分为两类：客户端和服务器。 接入网前面说到了位于网络边缘的端系统和应用程序，现在主要说一下接入网，这是指将端系统物理连接到边缘路由器的网络 边缘路由器端系统到任何其他远程端系统路径上的第一台路由器。下面说一下使用接入网的几种环境。 家庭接入家庭接入有大致4种不同的接入链路 DSL(Digital Subscriber Line，数字用户线) 电缆 FTTH(Fiber To The Home，光纤到户) 拨号和卫星 下面分别做一下了解 DSL-数字用户线住户通常从提供本地电话接入的本地电话公司处获得DSL因特网接入。当使用DSL时，本地电话公司也是它的ISP(因特网服务提供商)。每个用户的DSL调制解调器使用现有的电话线(双绞铜线)与电话公司的数字用户线接入复用器(DSLAM)交换数据。家庭的DSL调制解调器得到数字信号后将其转换为高频音，通过电话线传输给电话公司，在电话公司的DSLAM处转换回数字信号。这样，电话线同时承载了数据和传统的电话信号，它们通过不同的频率进行编码 高速上行信道：50kHz-1MHz频段 中速下行信道：4kHz-50kHz频段 普通双向电话信道：0-4kHz频段 这种方法使得单根的DSL线路看起来就像有三根一样，因此一个电话呼叫和一个因特网连接能够同时共享DSL链路(后面会说到这种频分复用技术) 用户一侧：一个分配器把到达家庭的数据信号和电话信号分开，并将数据信号转发给DSL调制解调器 电话公司一侧：DSLAM把数据和电话信号分开，并将数据信号发送到因特网。 以上就是DSL接入方式。适用于短距离接入 电缆接入DSL利用电话公司的本地电话基础设施，而电缆因特网接入利用有线电视公司的有线电视基础设施。住宅从提供有线电视的公司获得电缆因特网接入。电视公司的电缆头端和地区枢纽通过光缆连接，地区枢纽使用传统的同轴电缆到达各家各户，每个地区枢纽通常支持500~5000个家庭。电缆因特网接入需要特殊的调制解调器，即电缆调制解调器。 家庭端类似DSL调制解调器，电缆调制解调器通常是一个外部设备，通过一个以太网端口连接到家庭PC，将数字信号转换为模拟信号。 电视公司的电缆头端电缆调制解调器端接系统(CMTS)，类似于DSL中的DSLAM，功能也类似。即将来自住户的电缆调制解调器发送的模拟信号转换回数字信号。 共享广播媒体 电缆因特网接入一个重要的特征是共享广播媒体。 由头端发送的每个分组向下行经每段链路到每个家庭，每个家庭发送的每个分组经上行信道向头端传输。因此，如果几个用户同时经下行信道下载一个视频文件，每个用户接收视频文件的实际速率将大大低于电缆总计的下行速率。 FTTH(光纤到户)从本地中心局直接到家庭提供了一条光纤路径，有两种方案 直接光纤，从本地中心局到每户设置一个光纤 从中心局出来的每根光纤实际上由多个家庭共享，直到相对接近这些家庭的位置，该光纤才分成每户一根光纤，进行这种分配形成了两种光纤分布体系方案 主动光纤网络(Active Optical NetWork,AON)，AON本质上就是交换因特网，后面会说到 被动光纤网络(Passive Optical NetWork,PON) 简单说一下PON 家庭端每个家庭具有一个光纤网络端接器(ONT)，用户将一台家庭路由器和ONT相连,并通过这台路由器接入因特网。ONT由专门的光纤连接到邻近的分配器，分配器把一些家庭(一般100个)集结到一根共享的光纤。 公司端该光纤在连接到本地公司的光纤线路端接器(OLT)，OLT提供了光信号和电信号之间的转换，经过本地公司的路由器和因特网相连 在PON体系中，所有从OLT发送到分配器的分组在分配器处复制。 拨号和卫星在无法提供上面三种接入的地方，能够使用这两种方式，速度较慢。 企业和家庭接入在公司和大学校园以及越来越多的家庭环境中，使用局域网(LAN)将端系统连接到边缘路由器，局域网技术有很多种，目前以太网是最流行的接入技术(会在后面讲到该技术)。 以太网用户使用双绞铜线与一台以太网交换机相连 以太网交换机或者这样相连的网络再与更大的因特网相连。 还有越来越多的手机等设备无线接入因特网。在无线LAN环境中： 无限用户从一个接入点发送/接收分组； 该接入点与企业网连接(可能是用了有线以太网)； 企业网再与有线因特网相连。现在我们知道的WiFi，就是基于IEEE802.11技术的无线LAN接入。 广域无线接入：4G和LTE 4G(第四代广域无线网络)我们平常使用的手机网络(联通、电信…)也能够接入因特网，这就用到了与蜂窝电话相同的无线基础设施，通过蜂窝网提供商(电信…)运营的基站来发送和接收分组。和WiFi不同的是，我们在使用4G网络的时候，并不需要在接入点几十米范围内，而是在基站数万米内都可以使用。 LTE(Long-Term-Evolutuon,长期演进)来源于3G技术 物理媒体在前面说到因特网一些接入技术的时候，说到了所使用的物理媒体。例如DSL使用了双绞铜线，电缆接入网络使用了光纤和同轴电缆…接下来就简要说一下常用的物理媒体。我们描述下一个bit从一个端系统开始传输，经过一系列链路和路由器，到达另一个端系统的历程。 源端系统发送这个bit，不久后第一台路由器接收该bit 第一台路由器转发该bit，不久后第二台路由器接收 ……中间经历了若干个路由器最终到达端系统 因此，该bit从源到目的地传输时，通过一系列的“发射器-接收器”对。对于每个发射器-接收器对，通过跨越一种物理媒体传播电磁波或光脉冲来发送该比特。物理媒体有多种形状和形式，并且对沿途的每一个发射器-接收器对来说不必具有相同的类型。物理媒体分为两种 引导型媒体：电波沿着固体媒体前行，如光缆、双绞铜线以及同轴电缆…… 非引导型媒体：电波在空气或外层空间种传播，如无线局域网或数字卫星频道中。 另外，物理链路(铜线、光缆等)的实际成本与其他网络成本相比通常小很多。下面说几种常见的物理媒体： 双绞铜线 最便宜最常用的引导型传输媒体； 由两根绝缘铜线组成以规则的螺旋排列，一对电线构成了一个通信链路。 数据传输速率取决于线的粗细以及传输方和接收方之间的距离。 同轴电缆和双绞线类似，由两个铜导体组成，但这两个铜导体是同心而不是并行的，同轴电缆能够达到较高的数据传输速率，在电缆电视系统中相当普遍。特别的，许多端系统能够直接与该电缆相连，每个端系统都能接收由其他端系统发送的内容。 光纤一种柔软的、能够引导光脉冲的媒体，每个脉冲表示一个bit。有以下特点： 比特速率极高 不受电磁干扰并且光缆信号衰减极低 很难窃听 这些特征使得光纤成为长途引导型传输媒体，特别是跨海链路&gt;。 陆地无线电信道无线电信道承载电磁频谱中的信号，不需要安装物理线路，并且具有穿透墙壁、提供与移动用户的连接以及长距离承载信号的能力。无线电信道的特性依赖于传播环境和信号传输距离。环境上取决于 路径损耗 遮挡衰落(信号跨距离传播通过阻碍物时信号强度降低) 多径衰落(干扰对象的信号反射) 干扰(由于其他传输或电磁信号) 陆地无线电信道大致划分为三类 运行在很短距离：个人设备如无线头戴耳机、无线鼠标… 运行在局域，通常数十到几百米：无线LAN技术使用的就是该局域无线电信道 运行在广域，跨越数万米：蜂窝接入技术使用的就是该广域无线电信道 卫星无线电信道一颗通信卫星连接地球上两个或多个微波发射/接收器，它们被称为地面站。该卫星在一个频段上接受传输，使用一个转发器(后面会说到)再生信号，并在另一个频段上发射信号。通常用于无法使用DSL或电缆接入的区域。 网络核心前面说完了网络边缘，现在这里说一下网络核心，即由互联因特网端系统的分组交换机和链路构成的网状网路。 分组交换在各种应用程序中，端系统彼此交换报文。报文能够包含协议设计者需要的任何东西，可以包含控制功能，也可以包含数据。源将长报文划分为较小的数据块，称之为分组。在源和目的地之间，每个分组都通过通信链路和分组交换机传送。分组以等于该链路最大传输速率的速度通过通信链路。例如，源或分组交换机将一个长为L的分组发送出去，链路的传输速率为R(bit/s)，那么传输该分组的时间为L/R秒。 存储转发传输交换机能够开始向输出链路传输该分组的第一个bit之前，必须接收到整个分组。多数分组交换机在链路的输入端使用存储转发传输。 排队时延和分组丢失每台分组交换机有多条链路与之相连，对于每条相连的链路，该分组交换机具有一个输出缓存/输出队列 输出缓存/输出队列用于存储路由器正准备发往那条链路的分组。 该输出缓存在分组交换中作用很大，如果到达的分组需要传输到某条链路，但发现该链路正在忙于传输其他分组，那么该分组必须在输出缓存中等待。因此，除了存储转发时延以外，分组还要承受输出缓存的排队时延。这些时延是变化的，取决于网络的拥塞程度。 分组丢失前面说过，分组可能将会在路由器中的输出缓存中等待，因为缓存空间大小是有限的，一个到达的分组可能发现路由器的缓存空间已经被其他等待传输的分组完全充满。在这种情况下，将会出现分组丢失/丢包。到达的分组或已经排队的分组之一将被丢弃。 转发表和路由选择协议路由器从一条通信链路得到分组，然后向与它相连的另一条链路转发分组，那么问题来了，路由器是怎么决定它应当向哪条链路进行转发呢？在因特网中，每个端系统都有一个地址，被称为IP地址。当源主机要向目的主机发送一个分组时，源在该分组的首部包含了目的主机的IP地址。如同邮政地址一样，该地址具有等级结构。分组到达路由器时，路由器检查该分组目的地址的一部分，并向一台相邻的路由器转发该分组。更特别的，每台路由器具有一个转发表 转发表用于将目的地址(或目的地址的一部分)映射成输出链路。 当分组到达路由器时，路由器检查分组的目的地址(或一部分)，用这个地址搜索转发表，找到合适的出链路，路由器将分组导向该链路。 转发表的设置因特网具有一些特殊的路由选择协议，用于自动的设置这些转发表。 电路交换在电路交换网络中，端系统会话期间，预留了端系统间路径通信所需要的资源。而在分组交换网络中，这些资源则不是预留的，会话的报文按需使用资源，这样就带来了等待(排队)接入链路。 举例说明，现有两家餐馆 分组交换不需要预定，但不保证能安排顾客，即顾客去的时候可能餐馆满了，就需要排队等待 电路交换在去之前必须提前预定，虽然麻烦，但是我们到的的时候能够立即入座点菜。 传统的电话网络就是电路交换的例子，在发送方能够发送信息之前，该网络必须在发送方和接收方建立一个名副其实的连接，因此此时沿着该发送方和接收方之间路径上的交换机都将为该连接维护连接状态。该连接被称为一条电路 当网络创建这种电路时，也在连接期间为该网络链路上预留了恒定的传输速率(每条链路传输容量的一部分)，能够确保发送方以恒定速率向接收方传输数据。 例如：A向B发送报文，网络必须在链路中预留一条电路，如果一个链路的传输速率为1Mbps，有四条电路，那么A向B发送报文的速率恒定为250kbps，即使该链路此时只有这一条连接。 电路交换网络中的复用前面说的电路是通过频分复用(FDM)或时分复用(TDM)来实现的，并不是真正的电线电路。 频分复用(FDM)链路的频谱由跨越该链路创建的所有连接共享。特别的，在连接期间为每条连接专用一个频段。在电话网络中，这个频段的宽度通常为4kHz。这个频段的宽度称为带宽 时分复用(TDM)对于时分复用，时间被划分为固定时期的帧，每个帧又被划为为固定数量的时隙。当网络跨越链路创建一条连接时，网络在每个帧中为该连接指定一个时隙。这些时隙专门由该连接单独使用。在TDM中，一条电路的传输速度等于帧速率乘一个时隙中的比特数量。例如一个帧为1分钟，一个帧有60个时隙(即一个时隙1秒)，如果网络指定第二个时隙为该连接专用，那么在每分钟的第二秒时间内为该链接传送数据，其他的时隙即使没有连接使用，该链接也不能使用。 通过上面的描述我们不难发现，电路交换虽然能够保证数据传输的速率，但是往往会造成资源的浪费，总体上说分组交换要更优一些。 网络的网络前面说过，端系统通过一个接入ISP和因特网相连，因为因特网是将数以亿计的端系统相连，因为ISP自身也必须互联，通过创建网络的网络可以做到这点。 网络的网络可以理解为将ISP连接成网络，因为ISP自身就是一个网络，将许多ISP连接成网络，就实现了与不同ISP相连的端系统相连。 总的来说，今天的因特网是一个网络的网络，由十多个第一层ISP和数十万个较底层的ISP组成，较低层的ISP与较高层的ISP相连，较高层的ISP彼此互联。用户和内容提供商是较低层ISP的客户，较底层ISP是较高层ISP的客户。也有一下大型的内容提供商(谷歌等)创建自己的网路，直接在一些地方和较低层ISP互联。从而减少这些大型内容提供商向顶层ISP支付的费用。 分组交换网中的延时、丢包和吞吐量因特网能够看成是一种基础设施，为运行在端系统上的分布式应用提供服务。在理想情况下，我们希望它能够在任意两个目标端系统之间随心所欲地移动数据而不会产生数据丢失。然而，这是很难做到的。相反的，计算机网络必定要限制在端系统之间的吞吐量，在端系统之间引入时延、并且也会丢失分组。 吞吐量每秒能够传送的数据量 时延概述前面说过，分组从源到目的地的过程中，当分组从每个节点(主机或路由器)沿着这条路径到后继节点，该分组在每个节点经受了几种不同类型的时延 节点处理时延 排队时延 传输时延 传播时延 这些时延加起来就是节点总时延。 节点处理时延检查分组首部和决定该分组导向何处所需要的时延是节点处理时延的一部分，通常是微秒或更低的数量级 排队时延在队列中，当分组在链路上等待传输时，它经受排队时延。一个分组排队时延取决于在它前面正在排队等待向链路传输的分组数量如果队列为空，那么排队时延为0。通常是毫秒到微秒量级 传输时延将所有分组的bit推向链路所需要的时间，单位是bit/s，通常是毫秒到微秒量级 传播时延当比特被推向链路后，该比特需要向下一个路由器传播。从该链路的起点到路由器B传播所需要的时间是传播时延。传播时延等于两台路由器之间距离除以传播速率。在广域网中，通常是毫秒量级 传输时延和传播时延的比较 传输时延由路由器将分组推向链路所需要的时间，和距离无关，和分组大小相关；单位是bit/s。 传播时延是分组被路由器推出链路后经过链路传播到下一台路由器所需要的时间，和分组长度无关，和两台路由器之间的距离相关；单位是m/s。 排队时延和丢包排队时延 假设a表示分组到达队列的平均速率(以bps/s为单位) R表示传输速率，即从队列中推出比特的速率(以bps/s为单位) 假定所有的分组都由L个比特组成。 那么bit到达队列的平均速率为(La)bps/s。最后，假设该队列很大，能够容纳无限数量的bit，那么比率La/R被称为流量强度 流量强度 La/R&gt;1，即比特到达队列的平均速率超过从该队列传输出去的速率。这时，队列将会无限增加，排队时延就会趋于无穷大。 La/R≤1，这时，到达流量的性质将影响排队时延。 分组周期性到达，即每L/R秒到达一个分组，则每个分组到达时，队列刚好将上一个分组全部推出。此时队列为空，就不会有排队时延 分组以突发形式到达，即在某个时刻同时到达很多分组。就可能会有很大的平均排队时延 因此：设计系统时流量强度不能大于1。通常情况下，分组到达队列的时间是随机的 到达速率小于传输能力时队列的长度将缩短 流量强度接近于1时平均队列长度将会变得越来越长。 丢包在上面，我们假设了队列能够容纳无穷多的分组，在现实中，链路的队列容量是有限的。随着流量强度接近于1，队列并不是趋于无穷大。到达的分组发现一个满的队列，该分组将会被路由器丢掉。丢失的比例随着流量强度的增加而增加。因此，一个节点的性能不仅根据时延来度量，也根据丢包的概率来度量。后面会说到，丢失的分组可能基于端到端的原则重传，以确保所有的数据最终从源送到了目的地。 端到端时延前面的讨论集中在节点时延上，即在单台路由器上的时延，这里考虑从源到目的地的总时延(端到端时延)端到端的时延就是源主机的时延和路由器时延之和，即节点时延的总和 计算机网络中的吞吐量 瞬时吞吐量A向B发送数据，任何时间瞬间B接收该文件的速率 平均吞吐量A向B发送大小为Fbit的文件，B接收所有Fbit用了Ts，则平均吞吐量为F/T 服务器传送一个文件到客户端，两者之间只有一台路由器 假设Rs为服务器和路由器之间的链路速率 假设Rc为路由器和客户端之间的链路速录 假设网络中只有该服务器到客户端的bit在传送 那么服务器到客户端的吞吐量就是min(Rs,Rc)我们想象bit是流体，链路是管道。显然，这台服务器不能以超过Rs的速率发送bit，路由器也不能以超过Rc的速率转发，最终的吞吐量取决去两者中小的那一个。服务器传送一个文件到客户端，两者之间有N-1台路由器 那么就有N条链路 假设这N条链路的速率分别是R1、R2…Rn 那么服务器到客户端的吞吐量就是min(R1,R2…Rn)目前，因特网核心都超量配置了高速率的链路，很少发生拥塞，今天在因特网中对吞吐量的限制因素通常是接入网。但是并不绝对，当很多客户端和服务器公用一条共享链路时，由于链路需要同时为多个客户端服务器传输数据。这时共享链路可能称为限制吞吐率的因素。 协议层次机器服务模型各层的所有协议被称为协议栈。因特网协议栈由5个层次组成，从上到下依次是 应用层 运输层 网络层 链路层 物理层 下面就分别简要的说一下每一层 应用层网络应用程序以及它们的应用层协议存留的地方应用层协议包括 HTTP：HyperText Transfer Protocol(超文本传输协议)，提供了Web文档的请求和传送 SMTP：Simple Mail Transfer Protocol(简单邮件传输协议)，提供了电子邮件报文的传输 FTP：File Transfer Protocol(文件传输协议)，提供了两个端系统之间文件传送 DNS：Domain Name System(域名系统) …… 应用层协议分布在多个端系统上，端系统的应用陈旭之间使用协议交换信息分组。这种位于应用层的信息分组称为报文。 运输层因特网运输层在应用程序端点之间传送应用层报文。两种应用层协议 TCP：向应用程序提供了面向连接的服务，包括应用层报文向目的地传输的确保传递和流量控制(发送方/接收方速率匹配)TCP将长报文划分为短报文，并提供拥塞控制机制，当网络拥塞时，源抑制其传输速率。 UDP向应用程序提供了无连接的服务，没有可靠性、没有流量控制、也没有拥塞控制。 将运输层的分组称为报文段。 网络层因特网网络层负责将网络层分组(数据报)从一台主机移动到另一台主机。源主机中的运输层协议(TCP/UDP)向网络层递交运输层报文段和目的地址，就像你通过邮政服务寄信时提供的地址一样网络层协议 IP协议：该协议定义了在数据报中的各个字段以及端系统和路由器如何作用于这些字段。 路由选择协议：确定路由器的转发表。 …… 将网络层的分组称为数据报。 链路层因特网的网络层通过源和目的地之间一系列的路由器来路由数据报。为了将分组从一个节点(路由器/主机)移动到下一个节点，网络层必须依靠链路层的服务。 在每个节点，网络层将数据下传给链路层，链路层沿着路径(链路)将数据报传递给下一个节点。 到达下一个节点，链路层再将数据上传给网络层。 链路层提供的服务取决于应用于该链路的特定的链路层协议。例如，某些协议基于链路提供可靠传递，从传输节点跨越一条链路到接收节点。注意：这里的可靠连接服务不同于TCP的可靠传输服务。TCP提供从一个端系统到另一个端系统的可靠交付。链路层协议 以太网 WiFi 电缆接入网的DOCSIS协议 因为数据从源到目的地通常会经过几条链路，这些链路可能应用的链路层协议不同。网络层将受到每个不同链路层协议的不同服务将链路层的分组称为帧。 物理层链路层的任务是将整个帧从一个节点移动到临近的节点，而物理层的任务是将该帧的一个个bit从一个节点移动到临近的节点。该层的协议仍和链路层相关，并且进一步和该链路的实际传输媒体相关。例如以太网具有很多物理层协议： 关于双绞铜线的 关于同轴电缆的 关于光纤的 …… 封装数据从发送端系统的协议栈向下，沿着中间的链路层交换机的路由器协议栈上上下下，然后向上到达接收端系统的协议栈。 链路层交换机实现了第一层和第二层，即物理层和链路层 路由器实现了第一层到第三层，即物理层到链路层再到网络层。 这意味着路由器能实现IP协议，链路层交换机则不能。但是链路层交换机能够识别第二层地址如以太网地址。主机实现了所有5个层次，因为在发送数据时，需要将数据层层封装，最后封装为帧(链路层分组)，在接收数据时相反。因此主机必须实现所有的5个层次。 每一层的封装 在发送主机端应用层报文被传送给传输层 运输层传输层收取到报文并附上附加信息，该首部信息将被接收端的运输层使用。应用层报文和运输层首部信息一起构成了运输层分组—-报文段。并将该报文段传递给网络层。 网络层增加了源和目的地端系统的地址等网络层首部信息，运输层报文段和网络层首部信息一起构成了网络层分组—-数据报。并将该数据报传递给链路层。 链路层增加自己的链路层首部信息，网络层数据报和链路层首部信息一起构成了链路层分组—-帧。 所以我们看到，在每一层，一个分组具有两种类型的字段 首部字段：在当前层添加上的 有效载荷字段：该字段通常是来自于上一层的分组 实际上，封装的过程可能更加复杂。例如，一个大报文可能被划分为多个运输层的报文段(同样的，这些报文段可能被划分为多个网络层数据报)，在接收端，必须从其连续的数据包中重构这样一个报文段。 第一章内容大致就这些，后面的网络攻击就不说了。后续的等看完一章写一章吧，一共16k个字，纯手打。在记录的过程中无形中对第一章内容又回顾了一遍，很明显感觉得到理解的更深入了，希望看完这篇博客的你也能学到一些知识哦。]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>计算机网络自顶向下方法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[排序算法之选择排序]]></title>
    <url>%2F2019%2F09%2F18%2F%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E4%B9%8B%E9%80%89%E6%8B%A9%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[前面说过了冒泡排序，这次来说一下选择排序。同样的，这次也会从算法思路、代码实现以及算法分析三个思路来剖析选择排序 算法思路 第一次从arr[0]和arr[n-1]中选取最小值，与arr[0]交换 第二次从arr[1]和arr[n-1]中选取最小值，与arr[1]交换 ……以此类推 第n-1次从arr[n-2]和arr[n-1]中选取最小值，与arr[n-2]交换 至此，得到一个从小到大的有序数组，一共进行n-1轮 对于一个数组arr={3,-1,9,10,-2} 代码实现12345678910111213141516171819202122public static void SelSort(int[] arr) &#123; int min; int index; //一共进行n-1趟排序，当确定了n-1个元素的位置后，最后一个元素的位置自然也就确定了 for (int i = 0; i &lt; arr.length - 1; i++) &#123; //假定最大值为arr[i]，下标为i min = arr[i]; index = i; //找到i+1到最后一个元素的最大值，记录该元素的值和下标位置 for (int j = i + 1; j &lt; arr.length; j++) &#123; if (arr[j] &lt; min) &#123; min=arr[j]; index = j; &#125; &#125; //如果index发生了变化，说明arr[i]不是最大的，那么就将最大值和arr[i]交换 if (index != i) &#123; arr[index]=arr[i]; arr[i] = min; &#125; &#125;&#125; 分析 算法的时间复杂度 平均时间：O(n²) 最差情况：O(n²) 这不难理解，因为对于一个简单地双重循环来说，时间复杂度都是O(n²) 空间复杂度 只用了一个min和一个index，和n的大小无关，所以是O(1) 稳定性 不难发现，选择排序不是稳定的 另外，该排序算法在n比较小时较好 和冒泡排序比较这里，我创建了一个80000大小的数组对其进行排序，分别使用冒泡排序和选择排序，并记录两种排序耗费的时间 冒泡排序 选择排序 通过上面的对比发现，对同样规模的随机生成的数组进行排序，选择排序要比冒泡排序快很多 通过查看两种排序的实现过程不难发现： 冒泡排序，每一趟排序中，相邻元素如果逆序，都要进行交换操作，整个排序过程会进行很多次交换操作 选择排序，每一趟排序中，只需要找到最大值/最小值的元素即其下标，最后只进行一次交换交换操作，整个排序过程最多进行n-1次交换操作 两方法时间上的差异就在这里体现的]]></content>
      <categories>
        <category>算法之美</category>
      </categories>
      <tags>
        <tag>排序</tag>
        <tag>选择排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[排序算法之冒泡排序]]></title>
    <url>%2F2019%2F09%2F18%2F%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%E4%B9%8B%E5%86%92%E6%B3%A1%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[正如categories所言：算法之美，是的，算法是美妙的，尤其是好的算法，总会让人感到眼前一亮，让人茅塞顿开。而今天说到的排序算法，是我们日常生活中用的及其之多的一种算法，排序算法种类也有很多，这篇博客记录的是其中较为简单地一种——冒泡排序 算法思路 通过对排序序列从前向后(数组下标从小到大)开始，依次比较相邻元素的值 若发现两相邻元素逆序，则交换两相邻元素的位置，使值较大的元素逐渐从前移到后 第一趟排序使序列中最大的元素移到最后一个位置 第二趟排序使序列中第二大的元素移到倒数第二个位置 ……以此类推 一共需要n-1趟排序(n为序列的大小) 对于一个数组arr={3,-1,9,10,-2} 代码实现 优化冒泡排序因为每一趟排序都是将未排序部分的相邻元素进行比较，逆序则交换位置，那么反过来，在某一趟排序中，如果没有发生元素交换，说明该数组已经有序，就不用在进行之后的排序对于一个数组arr={3,-1,9,10,20} 设置一个boolean类型的flag，初始化为true 将循环趟数的条件改为flag==true&amp;&amp;i &lt; arr.length 在进入某一趟排序之前，先将flag设置为false。 如果在这一趟排序中，发生了相邻元素的交换，那么将flag重新设置为true 如果在这一趟排序中，没有发生相邻元素的交换，flag不变 在进行下一趟循环时，判断flag是否为true 如果为true，进行下一趟循环 如果为false，说明在上一趟排序中已经得到有序数组，那么不再进行下一趟排序 优化冒泡排序算法代码实现 12345678910111213141516public static void BuSortBatter(int[] arr) &#123; int temp; //设置一个flag，判断当前趟是否进行过交换 boolean flag = true; for (int i = 1; flag==true&amp;&amp;i &lt; arr.length; i++) &#123; flag = false; for (int j = 0; j &lt; arr.length - i; j++) &#123; if (arr[j] &gt; arr[j + 1]) &#123; temp = arr[j]; arr[j] = arr[j + 1]; arr[j + 1] = temp; flag = true; &#125; &#125; &#125;&#125; 同样对于上面的数组arr={3,-1,9,10,20}，使用优化冒泡排序这样就达到了优化的目的 分析 算法的时间复杂度 平均时间：O(n²) 最差情况：O(n²) 这不难理解，因为对于一个简单地双重循环来说，时间复杂度都是O(n²) 空间复杂度 只用了一个临时变量和一个flag，和n的大小无关，所以是O(1) 稳定性 稳定性：即在排序过程中，对于两个大小相等的数A和B，排序前A在B的前面，如果排序后A还在B的前面，即排序前后不改变想等元素的顺序，那么称该排序方法是稳定的 不难发现，冒泡排序是稳定的 另外，该排序算法在n比较小时较好]]></content>
      <categories>
        <category>算法之美</category>
      </categories>
      <tags>
        <tag>排序</tag>
        <tag>冒泡排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[八皇后问题]]></title>
    <url>%2F2019%2F09%2F18%2F%E5%85%AB%E7%9A%87%E5%90%8E%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[八皇后问题一个古老而著名的问题，该问题是回溯算法的典型案例。在8*8格的国际棋盘上摆放8个皇后，使其相互不能攻击。即：任意两个皇后不能处于同一行、同一列或同意斜线上，问有多少中摆法？ 问题分析 第一个皇后先放在第一行第一列 第二个皇后放在第二行第一列，然后判断是否满足条件 不满足：继续放在第二行第二列…依次把所有列放完，找到一个合适的位置 满足：摆放下一个皇后(递归) 直到第八个皇后也能放在一个满足条件的位置，就算找到一个正确解(递归出口) 当得到第一个正确解时，就会开始回溯，即将第一个皇后放在第一列的所有正确节点全部找到 然后回头继续将第一个皇后放在第二列，后面继续循环执行上面的步骤 一维数组代替二维数组理论上，我们应该创建一个二维数组表示棋盘，但实际上可以通过算法，用一个一维数组解决问题例如：arr[8]={0,4,7,5,2,6,1,3} 数组arr的下标：表示第几行，即第几个皇后 arr[i]=val：表示第i+1个皇后放在第i+1行的val+1的位置 检查冲突的方法该方法用于检查当前第n个皇后和前面的n-1个皇后是否发生冲突(即是否在同一行、同一列或同一斜线上) arr[n] == arr[i]：数组的值表示的是列，这里是判断第i+1个皇后是否和第n+1个皇后在同一列 Math.abs(n-i)==Math.abs(arr[n]-arr[i])：判断第i+1个皇后是否和第n+1个皇后在同一斜线 Math.abs(n-i)：第i+1个皇后和第n+1个皇后的行数差 Math.abs(arr[n]-arr[i])：第i+1个皇后和第n+1个皇后的列数差如果行数差==列数差，说明两个皇后在同一斜线上 递归回溯方法 首先，创建一个长度为9的数组，0-7用于表示8个皇后，最后一个用于记录摆放方法个数 当n==MAX=8时：之前说过，n代表第n+1个皇后(例如n=0时代表第一个皇后)，那么n=8应该代表的是第9个皇后，这时候说明前8个皇后都已经摆放好了，即找到了一种摆放方法 arr[MAX]++：个数+1； 打印当前摆放方法 n&lt;MAX说明皇后还没有摆放完，先将当前皇后摆放在第i列，检查这个位置是否和前面已经摆放的皇后位置冲突 如果不冲突，递归调用方法，摆放下一个皇后 如果冲突，i++，回到第3步。(即将当前皇后摆放到下一列，继续判断) 当找到一种正确方法后，会向上回溯 前面7个皇后位置不变，将第8个皇后从当前列往后摆，找到所有正确的摆法 前面6个皇后不变，将第7个皇后向后摆放1列 将第8个皇后从第1列往后摆，找到所有正确的摆法 回到第2步，直到将第7个皇后摆放到最后1列，找到所有正确的摆法 前面5个皇后不变…. 以此类推，直到最后将第1个皇后摆放到最后1列。这样，就找到了所有正确的解法！]]></content>
      <categories>
        <category>算法之美</category>
      </categories>
      <tags>
        <tag>递归</tag>
        <tag>回溯</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[迷宫问题]]></title>
    <url>%2F2019%2F09%2F18%2F%E8%BF%B7%E5%AE%AB%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[迷宫问题有一个迷宫，迷宫中有一个小球，要求给小球一个起始位置和迷宫的终点位置，给小球找到一条路能够到达终点位置。 构建迷宫 用一个二维数组模拟迷宫 用1表示围墙和障碍物 用2表示小球从起始位置到终点位置走过的点以下就是构建好的迷宫 递归解决 定义一个方法、传递一下参数 毫无疑问、要将map二维数组传递进去 将小球的起始位置传递进去 由于这里默认出口是最右下角，就不传递终点位置了 递归出口：前面说到了，用2表示小球走过的点，那么当终点位置map[6][5]==2时，说明小球已经走到了终点，递归结束 判断当前点map[i][j]是否为0,如果为0 先假定通过当前点能到达终点位置，即将当前点设置为2 设置寻路策略：即每次到达一个点，就会有上下左右四种走法，所谓寻路策略，即指定小球先向哪个方向走，该方向走不通后再向哪个方向走，这里我指定的寻路策略是下右上左 如果该点的四个位置都走不通，那么说明该点不通，此时将当前点设置为3，即map[i][j]=3,表明该点走过，确认走不通 如果不为0，那么当前点的取值情况有三种 map[i][j]==1，说明该点为墙，走不通，返回false map[i][j]==2，说明该点走过了，就不能再走了，返回false map[i][j]==3，说明该点已经确定了走不通，返回false 找到出路最后根据我下右上左的寻路策略找到的路线其中2代表的就是起点到终点的路线，通过不同寻路策略找到的路线可能不同 对于递归解决迷宫问题，我想可以这么理解每次走到一个点时，都会按照寻路策略的顺序走 如果某个方向能走通，那就继续往下走 如果到了某个点时，该点四个方向都走不通，那么就回溯，即回到该点的上一个节点，从上一个点的其他方向继续走 例如：对于A点，我们按照寻路策略先向下走，走到了B点，这时候发现，B点四个方向都走不通，那么就回退到A点，按照寻路策略向右走。以此类推，直到找到终点和每个点都被标记为3。]]></content>
      <categories>
        <category>算法之美</category>
      </categories>
      <tags>
        <tag>递归</tag>
        <tag>回溯</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Web基础之JSP简单介绍]]></title>
    <url>%2F2019%2F09%2F17%2FWeb%E5%9F%BA%E7%A1%80%E4%B9%8BJsp%E7%AE%80%E5%8D%95%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[今天就来介绍Web基础的另一部分知识–JSP页面，学习了JSP页面后，就能够像浏览器动态的展示页面。 什么是JSPJSP–Java Servlet Pages，Java服务器端页面，可以理解为一个特殊的页面，其中既可以指定html标签，又可以定义Java代码。JSP本质上就是一个Java的Servlet类。既然说JSP中可以定义Java代码，那么下面就说一下JSP中定义Java代码的格式： &lt;% 代码 %&gt;转换成Servlet之后存在于在service方法中。Servlet中service方法中可以定义什么，该脚本中就可以定义什么。 &lt;%! 代码 %&gt;转换成Servlet之后存在于Servlet类的成员位置。 &lt;%= 代码 %&gt;转换成Servlet之后会输出到页面上。输出语句中可以定义什么，该脚本中就可以定义什么。 JSP指令和注释在本节主要介绍JSP的指令和注释 JSP指令JSP指令用于配置JSP页面，导入资源文件。格式为：&lt;%@ 指令名称 属性名1=属性值1 属性名2=属性值2 … %&gt;，JSP有以下几种指令 page指令：用于配置JSP页面该指令可以设置的属性有(这里介绍一部分) contentType：等同于response.setContentType() 设置响应体的mime类型以及字符集 设置当前jsp页面的编码（只能是高级的IDE才能生效，如果使用低级工具，则需要设置pageEncoding属性设置当前页面的字符集） import：导包 errorPage：当前页面发生异常后，会自动跳转到指定的错误页面 isErrorPage：标识当前也是是否是错误页面。 true：是，可以使用内置对象exception false：否。默认值。不可以使用内置对象exception include指令：用于导入资源文件 &lt;%@include file=”top.jsp”%&gt; taglib指令：导入资源例如我们导入jstl的标签库可以使用：&lt;%@ taglib prefix=”c” uri=”http: //java.sun.com/jsp/jstl/core” %&gt;。prefix：前缀(可以自定义，一般使用c) JSP注释下面介绍一下JSP页面的注释： html注释： :只能注释html代码片段 jsp注释：推荐使用 &lt;%– –%&gt;：可以注释所有 JSP内置对象介绍完JSP的指令和注释后，下面来介绍JSP很重要的一部分：即JSP的内置对象。JSP有九种内置对象，这些对象在jsp页面中不需要创建，可以直接使用。 变量名 真实类型 作用 pageContext PageContext 当前页面共享数据，获取其他八个内置对象 request HttpServletRequest 请求转发中共享数据 session HttpSession 一次会话中共享数据 application ServletContext 所有用户间共享数据 response HttpServletResponse 响应对象 page Object 当前页面(Servlet)的对象-this out JspWriter 将数据输出到页面上 config ServletConfig Servlet的配置对象 exception Throwable 异常对象 EL表达式前面说过，在JSP页面中可以写HTML标签，也可以写Java代码，那么这势必会带来一个问题：导致我们的JSP页面中包含很多元素，难以阅读和维护，因此在这里我们介绍一下EL表达式和jstl标签库。本节先介绍EL表达式。 概述EL，即Expression Language 表达式语言。它能够替换和简化jsp页面中java代码的编写。它的语法为${表达式}。并且有一点需要注意，JSP是默认支持EL表达式的，如果你想将EL表达式当作文本字符串输出，有两个方法： 设置jsp中page指令中：isELIgnored=”true” 忽略当前jsp页面中所有的el表达式 ${表达式}：使用转义字符”&quot;忽略当前这个el表达式， EL表达式使用下面将简单地介绍一下EL表达式是如何使用的 运算 算数运算符： + - * /(div) %(mod) 比较运算符： &gt; &lt; &gt;= &lt;= == != 逻辑运算符： &amp;&amp;(and) ||(or) !(not) 空运算符： empty 用于判断字符串、集合、数组对象是否为null或者长度是否为0 ${empty list}:判断字符串、集合、数组对象是否为null或者长度为0 ${not empty str}:表示判断字符串、集合、数组对象是否不为null 并且 长度&gt;0 获取值EL表达式只能从域对象中获取值，域对象用来共享数据，即上面JSP内置对象的前4个都是域对象。我们使用${域名称.键名}从指定域中获取指定键的值。 域名称 域对象 pageScope pageContext requestScope request sessionScope session applicationScope application（ServletContext） 例如，我们在request域中存储了name=张三。那么我们使用${requestScope.name}就可以获得request域中name的值。如果我们直接使用${键名}，表示依次从最小的域中查找是否有该键对应的值，直到找到为止。 获取对象当我们使用EL获取基本类型和String值时，会直接得到值，那么如果我们想要获取一个对象，如果不加以处理会打印出对象的地址。 对象${域名称.键名.属性名}：假设我们在request域中存储了(“user”,user)，其中user是一个JavaBean对象，此时通过EL获取user对象的属性，本质上会去调用对象的getter方法。 List集合${域名称.键名[索引]}：获取List集合中指定位置的元素 Map集合有两种方式都可以获得Map集合中指定key对应的值 ${域名称.键名.key名称} ${域名称.键名[“key名称”]} 隐式对象el表达式中有11个隐式对象，类似于JSP的内置对象，其实前面介绍的四个域就是EL的四个隐式对象。在这里介绍一个隐式对象。 pageContext：能够获取JSP其它八个内置对象。例如：我们可以使用${pageContext.request.contextPath}来动态获取虚拟目录。 JSTL前面说过，我们要尽量避免在JSP中编写Java代码，但是在有些时候我们不得不在JSP中编写Java代码。例如当我们要遍历一个集合时，EL表达式就无法满足我们的需求。为了解决这种问题，我们引入了JSTL技术。 JSTL简介JSTL-JavaServer Pages Tag Library：JSP标准标签库。是由Apache组织提供的开源的免费的jsp标签，用于简化和替换jsp页面上的java代码。它的使用步骤如下： 导入jstl相关jar包 引入标签库：taglib指令： &lt;%@ taglib %&gt; 使用标签 长江的JSTL标签下面介绍三个常见的和流程控制相关的JSTL标签 if标签该标签相当于java代码的if语句。它有一个必须的属性test，接收boolean表达式。 如果表达式为true，则显示if标签体内容，如果为false，则不显示标签体内容。 一般情况下，test属性值会结合el表达式一起使用 注意：if标签没有else情况，想要else情况，则可以再定义一个if标签 12345//假定前缀为c&lt;c:if test=&quot;true&quot;&gt; &lt;h1&gt;我是真...&lt;/h1&gt;&lt;/c:if&gt;该语句会将语句显示在浏览器上 choose标签该标签相当于java代码的switch语句 choose switch 使用choose标签声明 switch声明 使用when标签做判断 相当于case 使用otherwise标签做其他情况的声明 相当于default 1234567891011&lt;c:choose&gt; &lt;c:when test=&quot;$&#123;number == 1&#125;&quot;&gt;星期一&lt;/c:when&gt; &lt;c:when test=&quot;$&#123;number == 2&#125;&quot;&gt;星期二&lt;/c:when&gt; &lt;c:when test=&quot;$&#123;number == 3&#125;&quot;&gt;星期三&lt;/c:when&gt; &lt;c:when test=&quot;$&#123;number == 4&#125;&quot;&gt;星期四&lt;/c:when&gt; &lt;c:when test=&quot;$&#123;number == 5&#125;&quot;&gt;星期五&lt;/c:when&gt; &lt;c:when test=&quot;$&#123;number == 6&#125;&quot;&gt;星期六&lt;/c:when&gt; &lt;c:when test=&quot;$&#123;number == 7&#125;&quot;&gt;星期天&lt;/c:when&gt; &lt;c:otherwise&gt;数字输入有误&lt;/c:otherwise&gt;&lt;/c:choose&gt; foreach标签该标签相当于java代码的for语句。它既可以完成重复操作又可以遍历容器 完成重复操作 begin：开始值 end：结束值 var：临时变量 step：步长 varStatus:循环状态对象，该属性又有两个属性 index:容器中元素的索引，从0开始 count:循环次数，从1开始 12345678&lt;c:forEach begin=&quot;1&quot; end=&quot;10&quot; var=&quot;i&quot; step=&quot;1&quot;&gt; $&#123;i&#125;&lt;br&gt;&lt;/c:forEach&gt;相当于Java代码for(int i = 0; i &lt; 10; i ++)&#123; System.out.println(i);&#125; 遍历容器 items:容器对象 var:容器中元素的临时变量 varStatus:循环状态对象 index:容器中元素的索引，从0开始 count:循环次数，从1开始 1234567891011121314现在我们在request域中定义了(&quot;list&quot;,list&lt;String&gt;(集合对象))&lt;c:forEach items=&quot;$&#123;list&#125;&quot; var=&quot;str&quot; varStatus=&quot;s&quot;&gt; $&#123;str&#125;&lt;br&gt;&lt;/c:forEach&gt;相当于Java代码List&lt;String&gt; list;for(String str : list)&#123; System.out.println(str);&#125; * 属性： 总结对于JSP相关知识到这里告一段落，这里只是进行简单的总结方便后期使用时能够有所参考，如果想要熟悉还需要多加练习。]]></content>
      <categories>
        <category>JAVAWEB</category>
      </categories>
      <tags>
        <tag>Jsp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Web基础之Ajax和JSON]]></title>
    <url>%2F2019%2F09%2F17%2FWeb%E5%9F%BA%E7%A1%80%E4%B9%8BAjax%E5%92%8CJSON%2F</url>
    <content type="text"><![CDATA[如题，本文将对Ajax和JSON两部分内容进行一个简单地总结介绍，方便后期使用时查看。 AjaxAjax-ASynchronous JavaScript And XML：异步的JavaScript 和 XML。这里的异步和同步是建立在客户端和服务器端相互通信的基础上。 Ajax简介 同步客户端必须等待服务器端的响应。在等待的期间客户端不能做其他操作。 异步客户端不需要等待服务器端的响应。在服务器处理请求的过程中，客户端可以进行其他的操作。 Ajax 是一种在无需重新加载整个网页的情况下，能够更新部分网页的技术。通过在后台与服务器进行少量数据交换，Ajax 可以使网页实现异步更新。这意味着可以在不重新加载整个网页的情况下，对网页的某部分进行更新。传统的网页（不使用 Ajax）如果需要更新内容，必须重载整个网页页面。使用Ajax能够提升用户体验。 Ajax实现Ajax有两种实现方式： 使用原生JS方式 使用JQeury方式 由于JQeury方式对原生JS方式进行了封装，能够大大的简化我们的操作，因此这里只介绍JQeury方式实现Ajax。在使用该方式时需要先导入JQeury相关jar包。 $.ajax({键值对},{键值对}…)下面介绍几个键值对 url:”/xxx” 指定请求路径 type:”POST” 指定请求方式 data:{若干个键值对} 指定请求参数 dataType:”text” 设置接收到的数据的响应格式 $.get(url, [data], [callback], [type])发送get请求，其中url是必须参数，其它三个可选 url： 请求路径 data： 请求参数 callback：回调函数 type：响应结果的类型 语法：$.post(url, [data], [callback], [type])发送post请求，同样的url是必须参数 url：请求路径 data：请求参数 callback：回调函数 type：响应结果的类型 JSONJSON-JavaScript Object Notation：JavaScript对象表示法。多用于存储和交换文本信息，进行数据的传输。JSON 比 XML 更小、更快，更易解析。 JSON语法JSON数据是由键值对构成的，键用引号(单双都行)引起来(也可以不使用引号)。值可以取一下几种类型 1234567值的取值类型1. 数字（整数或浮点数）2. 字符串（在双引号中）3. 逻辑值（true 或 false）4. 数组（在方括号中） &#123;&quot;persons&quot;:[&#123;&#125;,&#123;&#125;]&#125;5. 对象（在花括号中） &#123;&quot;address&quot;:&#123;&quot;province&quot;：&quot;陕西&quot;....&#125;&#125;6. null 并且多个键值对之间使用逗号分隔，使用花括号保存对象，中括号保存数组。 获取JSON数据我们可以使用一下方式获取JSON中的数据 json对象.键名 json对象[“键名”] 数组对象[索引] 1234567891011121314151617181920//1.定义基本格式var person = &#123;&quot;name&quot;: &quot;张三&quot;, age: 23, &apos;gender&apos;: true&#125;;获取name的值person.name//定义了一个数组var ps = [&#123;&quot;name&quot;: &quot;张三&quot;, &quot;age&quot;: 23, &quot;gender&quot;: true&#125;, &#123;&quot;name&quot;: &quot;李四&quot;, &quot;age&quot;: 24, &quot;gender&quot;: true&#125;, &#123;&quot;name&quot;: &quot;王五&quot;, &quot;age&quot;: 25, &quot;gender&quot;: false&#125; ];//获取ps中的所有值for (var i = 0; i &lt; ps.length; i++) &#123; var p = ps[i]; for(var key in p)&#123; //这样的方式获取不行。因为相当于 person.&quot;name&quot; //alert(key + &quot;:&quot; + person.key); alert(key+&quot;:&quot;+p[key]); &#125;&#125; JSON数据和Java对象转换当浏览器和服务器通信时，将JSON当作数据的载体在网络中传输，当服务器端收到JSON数据后，需要将JSON数据转换成Java对象(JSON数据可以转换成任意对象，只不过我学习的是Java)。同样的，服务器端通过操作获得一系列的数据，我们可以将这些数据转换为JSON数据发送给浏览器，这样浏览器能够很方便的解析JSON获得数据。一般我们使用JSON解析器完成JSON数据和Java对象之间的相互转换。常见得JSON解析器有Jsonlib，Gson，fastjson，jackson…由于jackson是Spring框架使用的解析器，因此这里介绍一下jackson的使用。 JSON数据转Java对象将JSON转为Java对象，主要有下面几个步骤： 导入jackson的相关jar包 创建Jackson核心对象–ObjectMapper 调用ObjectMapper的相关方法进行转换 readValue(json字符串数据,Class) Java对象转JSON数据将Java对象转换JSON，也有下面几个步骤 导入jackson的相关jar包 创建Jackson核心对象 ObjectMapper 调用ObjectMapper的相关方法进行转换 writeValue(参数1，obj):参数1有以下三种：File：将obj对象转换为JSON字符串，并保存到指定的文件中 Writer：将obj对象转换为JSON字符串，并将json数据填充到字符输出流中 OutputStream：将obj对象转换为JSON字符串，并将json数据填充到字节输出流中 writeValueAsString(obj):将对象转为json字符串 对于一个对象集合，转换为JSON数据后格式为：[{},{}…] 对于一个Map集合，转换为JSON数据后和对象格式一样，也是键值对形式。 总结对于Ajax和JSON的简单总结就到这里，如果学习过程中有所疑惑，参考w3school网站即可。]]></content>
      <categories>
        <category>JAVAWEB</category>
      </categories>
      <tags>
        <tag>Ajax</tag>
        <tag>JSON</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[逆波兰计算器]]></title>
    <url>%2F2019%2F09%2F16%2F%E9%80%86%E6%B3%A2%E5%85%B0%E8%AE%A1%E7%AE%97%E5%99%A8%2F</url>
    <content type="text"><![CDATA[今天重新学习了一下栈这一经典的数据结构，突然想起来当时大二为了进实验室用安卓写的一个计算器app，当时也是年轻，虽然写出来了，但是对于中缀转后缀却仍是似懂非懂、迷迷糊糊，所以趁着刚复习完栈这个号时候，准备趁热打铁，把这方面给弄明白了。 概念什么是中缀表达式中缀表达式，就是我们平常见到的表达式，例如1+((2+3)*4)-5。它便于我们理解和计算，但是却不利于计算机来运算，因为在运算过程中需要不停的判断操作符优先级 什么是后缀表达式后缀表达式，又称为逆波兰式，上面的1+((2+3)4)-5。转换成后缀表达式就是123+4+5-，计算机在计算后缀表达式的时候，不用判断操作符的优先级，每次遇到操作符，直接从栈中弹出两个操作数进行相应的运算即可，但是这样的表达式对我们来说写出来就比较困难，尤其是在表达式比较长比较复杂的时候。 中缀转后缀首先，我先说一下我的大致思路 将中缀表达式的字符串存储到一个ArrayList中==&gt;这一步主要是方便操作、 一个存放操作符的栈s1 注意：网上大多的教程是准备两个栈，一个存放操作符，一个存放的是逆序的后缀表达式，但这里我用ArrayList集合代替了第二个栈，这样做的好处就是可以直接得到后缀表达式，而非逆序的，至于为什么后面会说 中缀表达式集合 遍历字符串 如果当前字符是操作符，那么直接加入到集合中 如果当前字符是操作数，那么就要考虑多位数操作数的问题 继续向后遍历，如果后面的字符仍是操作数，就将这些数拼接起来 直到当前字符不是操作数为止，将拼接的字符串加入到集合中 判断操作符优先级 后缀表达式集合上一步我们得到了一个集合，集合中存储着中缀表达式内容，这一步就要将中缀表达式转换为后缀表达式并存储到集合中步骤： 创建变量 栈s1用于存放操作数 集合ls用于存放后缀表达式 遍历中缀表达式集合list，如果是操作数，直接放到ls集合中 如果是”(“，直接压入s1中 如果是”)”，将s1中的操作符出栈并加入到ls集合中，直到s1栈顶元素为”(“为止，最后将”(“也出栈(但是不加入ls中)，这一步操作目的是消去”()” 如果是操作符 如果s1栈为空，那么直接入栈 如果当前操作符优先级大于栈顶操作符优先级，将当前操作符入栈 如果当前操作符优先级不大于栈顶操作符优先级，那么将栈顶元素出栈并加入到ls集合中，继续和新的栈顶操作符比较，直到栈为空或者当前操作符优先级大于栈顶操作符优先级为止 将当前操作符压入s1中 集合list遍历完毕后，将s1中所有元素依次出栈加入到ls集合中 最后得到的ls集合就是后缀表达式 注意：这里如果用栈代替集合，那么由于栈先进后出的特性，得到的只能是逆序的后缀表达式，还要进一步的转换才能得到后缀表达式 计算后缀表达式 创建一个栈stack用于存放操作数 从左向右扫描后缀表达式集合 如果是操作数，直接入栈 如果是操作符，就从stack中弹出两个操作数进行运算，并将运算结果重新入栈 集合遍历完毕，stack剩下的元素就是最后的结果 这样一个简单地逆波兰计算器就成功了，核心逻辑在于如何利用栈将中缀表达式转换为后缀表达式(逆波兰式)]]></content>
      <categories>
        <category>算法之美</category>
      </categories>
      <tags>
        <tag>栈</tag>
        <tag>逆波兰表达式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Web基础之会话技术]]></title>
    <url>%2F2019%2F09%2F15%2FWeb%E5%9F%BA%E7%A1%80%E4%B9%8B%E4%BC%9A%E8%AF%9D%E6%8A%80%E6%9C%AF-Cookie%2F</url>
    <content type="text"><![CDATA[会话：一次会话中包含多次请求和响应。在一次会话中，浏览器第一次给服务器资源发送请求，会话建立，直到有一方断开为止会话技术能够在一次会话的多次请求响应间共享数据 会话技术的实现方式 客户端会话技术：Cookie 服务器端会话技术：Session 客户端会话技术–CookieCookie使用步骤 创建Cookie对象，绑定数据:new Cookie(String name, String value) 发送Cookie对象::response.addCookie(Cookie cookie) 获取Cookie，拿到数据:Cookie[] request.getCookies() Cookie实现原理基于响应头set-cookie和请求头cookie实现 客户端和服务器第一次请求响应：服务器创建Cookie对象，并在set-cookie响应头将Cookie响应给浏览器 浏览器接收到服务器带有set-cookie头的响应后，将Cookie存储在浏览器中，当下一次浏览器向服务器发送请求时，会在请求头cookie头中附带这cookie 这样就实现了多次请求响应之间的数据共享 Cookie的细节 一次可以发送多个cookie：在服务器端创建多个Cookie对象，多次调用response的addCookie方法将多个Cookie对象发送，但是如果两个Cookie的值相同，那么后加入的Cookie值会覆盖前面的值 cookie在浏览器中保存时间 默认情况下，当浏览器关闭后，Cookie数据被销毁(服务器关闭，Cookie仍然存在，因为Cookie存储在浏览器中) 持久化存储：调用Cookie对象的setMaxAge(int seconds)方法实现 参数取值情况： 正数：将Cookie数据写到硬盘的文件中。持久化存储。并指定cookie存活时间，时间到后，cookie文件自动失效 负数：默认值，即浏览器关闭后Cookie被销毁 零：删除cookie信息 cookie存储中文问题:在tomcat 8 之前 cookie中不能直接存储中文数据。但是在tomcat8之后，支持直接存储中文，但是对于一些特殊字符(如空格等)，仍不能直接存储，需要借助URL编码才行(具体步骤下一篇文章说到) cookie的共享 在一个tomcat服务器中部署了多个项目，在默认情况下，这些项目之间的Cookie是不能共享的但是可以通过Cookie对象的setPath(String path)方法来设置Cookie的共享范围 默认情况下，设置的是当前项目的虚拟目录 如果要在多个项目之间共享，则可以将path设置为"/"(“/”为服务器路径) 不同服务器之间Cookie的共享 setDomain(String path):如果设置一级域名相同，那么多个服务器之间cookie可以共享 例如：设置path为".baidu.com"，那么tieba.baidu.com和news.baidu.com两个不同的服务器之间可以共享数据，因为它们的一级域名是.baidu.com Cookie的特点和作用 特点 cookie存储数据在客户端浏览器 浏览器对于单个cookie 的大小有限制(4kb) 以及 对同一个域名下的总cookie数量也有限制(20个) Cookie存储的键值对都是String类型 作用 cookie一般用于存出少量的不太敏感的数据，这是因为Cookie的存储位置决定的，存储在客户端容易丢失和被篡改。 在不登录的情况下，完成服务器对客户端的身份识别 服务器端会话技术–SessionSession使用步骤 通过resquest获取Session对象：request.getSession() 调用Session对象的方法存储数据(和request请求转发方法一样) Object getAttribute(String name)：通过键获取值 void setAttribute(String name, Object value)：将数据存储进Session对象 void removeAttribute(String name)：通过键移除相应的键值对 Session实现原理Session的实现是依赖于Cookie的。 客户端第一次向服务器发送请求，服务器在服务器内部开辟一块内存空间，存放Session对象，并给该内存空间指定一个id 服务器在响应头set-cookie中设置JSESSIONID=id这个键值对发送给客户端 客户端接收到服务器的相应后，会将保存着Sessionid的Cookie对象保存在浏览器内存 当客户端下一次向服务器发送请求的时候，会带着Cookie一起(在请求头cookie中有JSESSIONID=id键值对) 服务器接收到请求后，得到JSESSIONID=id键值对的id后，会在内存中找到对应id的Session对象 这就是为什么说Session依赖于Cookie的原因以及多次请求响应之间共享数据的原理 Session细节 当客户端关闭后，服务器不关闭，两次获取session不是同一个：前面说到过，Session是依赖于Cookie的，Cookie在默认情况下当客户端浏览器关闭后是自动销毁的，因此Cookie中的键值对自然也就销毁了，所以两次获取的Session不是同一个，如果需要两次的Cookie是同一个 创建一个Cookie对象，设置cookie的键为JSESSIONID，值为session对象的id 设置cookie的存活时间 那么在cookie存活时间内，服务器通过cookie请求头拿到session的id都是一样的，这样通过id找到的Session对象自然也是同一个 客户端不关闭，服务器关闭后，两次获取的session不是同一个，因为服务器关闭后相应内存会被释放，Session自然也会被释放 但是一般我们需要获取到的Session对象是同一个，确保数据不丢失，tomcat会自动完成Session的钝化和活化 Session的钝化：在服务器正常关闭之前，将session对象序列化到硬盘上 Session的活化：在服务器启动后，将session文件转化为内存中的session对象。 Session被销毁 服务器关闭 session对象调用invalidate() 自杀 session默认失效时间 30分钟,可以tomcat服务器的web.xml配置文件中session-config设置所有项目的失效时间,也可以在项目的wen.xml配置文件单独配置项目的失效时间 Session的特点 用于一次会话的多次请求间共享数据，存储在服务器端 session可以存储任意类型，任意大小的数据]]></content>
      <categories>
        <category>JAVAWEB</category>
      </categories>
      <tags>
        <tag>会话技术</tag>
        <tag>Cookie</tag>
        <tag>Session</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Web基础之Response发送Http响应消息]]></title>
    <url>%2F2019%2F09%2F15%2FWeb%E5%9F%BA%E7%A1%80%E4%B9%8BResponse%E5%8F%91%E9%80%81Http%E5%93%8D%E5%BA%94%E6%B6%88%E6%81%AF%2F</url>
    <content type="text"><![CDATA[在前面一节中，对Servlet的Requset如何获取Http请求消息进行了介绍。因为Http基于请求响应模型，那么这里就介绍一下Servlet的另一个对象–Response，该对象用于发送Http响应消息。 Http响应消息格式可以类比Http请求消息格式，Http的响应消息格式也分为四部分 响应行 响应头 响应空行 响应体 下面分别介绍一下这几部分 响应行响应行格式：协议/版本 响应状态码 状态码描述 协议/版本字段和请求消息格式一样 响应状态码(3位数字)：服务器告诉客户端浏览器本次请求和响应的一个状态。主要分为5类：1. 1xx：服务器就收客户端消息，但没有接受完成，等待一段时间后，发送1xx多状态码 2. 2xx：成功。代表：200 3. 3xx：重定向。代表：302(重定向)，304(访问缓存) 4. 4xx：客户端错误。(404：请求路径没有对应的资源；405：请求方式没有对象的doXXX方法) 5. 5xx：服务器端错误。代表：500(服务器内部出现异常) 响应头和请求头一样，响应头也是键值对的形式，这里主要介绍两种常见的响应头： Content-Type：服务器告诉客户端本次响应体数据格式以及编码格式 Content-disposition：服务器告诉客户端以什么格式打开响应体数据，该头可以设置两个值 in-line:默认值,在当前页面内打开 attachment;filename=xxx：以附件形式打开响应体。文件下载 响应空行和响应体响应空行用于分割，就是个空行，没有实际意义。而响应体则是服务器给客户端发送的数据，如html页面等。 Response对象Response对象方法该对象用于设置响应消息，下面介绍几种方法： 设置响应行 格式：HTTP/1.1 200 ok 设置状态码：setStatus(int sc) 设置响应头 setHeader(String name, String value) 设置响应体使用步骤如下： 获取输出流 字符输出流：PrintWriter getWriter() 字节输出流：ServletOutputStream getOutputStream() 使用输出流，将数据输出到客户端浏览器 但是要注意，因为tomcat默认使用iso8859-1编码，而浏览器默认使用操作系统的编码方式(GBK)，因此将中文数据输出到浏览器时会出现乱码情况。我们要再获取流之前，我们使用response.setContentType(“text/html;charset=utf-8”);设置流的编码，并通知服务器使用相同的格式解码。 重定向前面介绍Request对象时说过，该对象可以进行请求转发，并且也说过请求转发的特点，那么这里介绍一下Response对象的重定向功能以及和请求转发的区别。重定向是一种资源跳转的方式 代码实现 设置状态码为302response.setStatus(302); 设置响应头location response.setHeader(“location”,新的资源的路径); 简单的重定向方法response.sendRedirect(“新的资源的路径”); 重定向原理如图所示，重定向的原理和请求转发有所不同 重定向和请求转发的区别 重定向的特点:redirect 地址栏发生变化 重定向可以访问其他站点(服务器)的资源 重定向是两次请求。不能使用request对象来共享数据 请求转发的特点：forward 转发地址栏路径不变 转发只能访问当前服务器下的资源 转发是一次请求，可以使用request对象来共享数据 ServletContext对象前面在介绍Request对象时说过，通过Request的getServletContext()方法可以获取到该对象。那么该对象是什么呢？该对象代表整个web应用，可以和程序的容器(服务器)来通信。下面简单介绍一下该对象的功能： 获取MIME类型 MIME类型:在互联网通信过程中定义的一种文件数据类型格式： 大类型/小类型 text/html image/jpeg 获取：String getMimeType(String file) 域对象：共享数据由于ServletContext代表整个Web容器，并且随着Web的启动而创建，随着Web的停止而销毁，因此这里的共享数据和Request对象的共享数据不同。使用Request对象共享数据时，仅在一次请求周期内可以使用，而使用ServletContext对象共享的数据，在整个Web存活周期内，所有的资源都可以共享该数据。因此要谨慎使用。 setAttribute(String name,Object value) getAttribute(String name) removeAttribute(String name) 获取文件的真实(服务器)路径当我们要将服务器上的一个资源(比如说txt文件发送给浏览器时)发送给浏览器时，需要先将txt加载进内存。此时需要获取资源的真实路径用于创建流对象。我们使用String getRealPath(String path)方法获取资源的真实路径。 对于我们的IDEA项目，获取不同目录下的资源时，getRealPath方法传递的参数不同 web目录下资源访问String path = context.getRealPath(“/资源名称”); WEB-INF目录下的资源访问String path = context.getRealPath(“/WEB-INF/资源名称”); src目录下的资源访问String path = context.getRealPath(“/WEB-INF/classes/资源路径”); 总结对于Response对象的简单介绍到此为止，其实可以发现，该对象主要用和服务器向浏览器响应消息。除此之外还介绍了Response相关的重定向方法以及和请求转发的不同；最后简单地介绍了一下ServletContext对象的简单使用。]]></content>
      <categories>
        <category>JAVAWEB</category>
      </categories>
      <tags>
        <tag>Response</tag>
        <tag>Http响应消息格式</tag>
        <tag>ServletContext</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[单链表的环问题]]></title>
    <url>%2F2019%2F09%2F15%2F%E5%8D%95%E9%93%BE%E8%A1%A8%E7%9A%84%E7%8E%AF%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[首先，关于单链表的环，一般涉及到以下几个问题 给一个单链表，判断是否有环 如果存在环，找出环的入口点 如果存在环，求出环上节点的个数 如果存在环，求出链表的长度 判断是否有环解法一：快慢指针法 有两个指针fast和slow，开始时两个指针都指向链表头head 将两个指针同时向后移动 fast每次走两步==&gt;fast=fast.next.next slow每次走一步==&gt;slow=slow.next 如果没有环，那么fast和slow一定不会相遇；当fast.next==null||slow==null时说明该链表没有环，因为有环的链表没有nul指针 如果有环，那么slow一定会和fast相遇,并且此时slow指针最多绕环一圈，即slow走的步数一定小于等于单链表的节点数 可以这么理解，当链表时环形链表时，环是最大的，此时slow刚好绕环一圈回到头指针指向的节点时 fast的速度是slow的二倍(因为fast每次走2步)，所以fast此时一定走了两圈，也回到了头指针指向的节点，最终会在头节点相遇 如果链表不是环形链表，那么环的长度就会更短，此时fast一定能在slow走完一圈之前和slow相遇 (可以画图帮助理解)方法返回的是相遇的节点 解法二：HashSet法 遍历链表，将当前节点的引用存储到HashSet中 如果当遍历到某个节点时，HashSet集合中已经存在该节点的引用，那么说明该链表有环，并且第一个重复的节点就是入环口 找出环的入口点如果用HashSet方法来解决第一个问题，那么这个问题就同时得到了解决如果用快慢指针法解决第一题，那么得到fast和slow第一次相遇的节点， 假设slow和fast相遇时，slow还没有走完链表，即链表不是首尾相接的环形链表分析 假设 链表的长度为L 环的长度为r(即环有r个节点) head节点到入环口的距离为a(即从head到入环节点要走a步) 入环口和相遇点的距离是x(从入环节点到相遇点要走a步) 假设fast和slow相遇时，fast已经在环内循环了n圈，slow走了s步，在环内走一圈的步数=环的长度 那么fast走过的步数为：2s步 则有：2s=s+n *r–&gt;s=nr 又有s=a+x–&gt;因为前面说过slow节点没有走完一圈，所以这就是最简单的步数相加 所以得到a+x=n*r a+x=(n-1)*r+r a+x=(n-1)*r+L-a a=(n-1)*r+(L-a-x) a：head到入环节点要走a步 (L-a-x)：从向相遇节点到入环节点要走(L-a-x)步 经过上面分析可以总结得到解决方法 设置两个临时指针str1和str2 str1=head str2=slow(slow是第一问得出的相遇节点) 让两个节点同时往后走，直到str1==str2为止 str1=str1.next str2=str2.next str1==str2时退出循环，此时的str1/str2就是入环节点 特殊情况：即链表首尾相接(环长度最大) 此时slow节点和fast节点在head相遇，即slow==head 根据上面的代码会直接返回head/slow，因此也满足特殊情况 求出环上节点的个数解法一：相遇节点法 设置一个临时指针temp=slow(相遇节点) 让临时指针temp后移–&gt;temp=temp.next，并记录移动次数count 当temp==slow时，说明temp绕环走了一圈，count就是换的长度 解法二：快慢指针法 设置两个临时指针，str1=str2=slow(相遇节点) str1每次走一步、str2每次走两步，并记录str1走的步数count str1=str1.next str2=str2.next.next 当str1==str2(再次相遇)时，说明str2刚好比str1多走1圈，此时count就是环上节点的个数 假设再次相遇时str1走了s步、str2走了2*s步、环的长度为r 由分析得到2*s=s+r，所以s=r; 求出链表的长度链表长度L=head节点到入口节点的距离a+环的长度r根据上面两个问题，这个就很好解决]]></content>
      <categories>
        <category>算法之美</category>
      </categories>
      <tags>
        <tag>集合</tag>
        <tag>链表</tag>
        <tag>HashSet</tag>
        <tag>快慢指针法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Josefu问题(约瑟夫环)两种解决方法]]></title>
    <url>%2F2019%2F09%2F15%2FJosefu%E9%97%AE%E9%A2%98-%E7%BA%A6%E7%91%9F%E5%A4%AB%E7%8E%AF-%E4%B8%A4%E7%A7%8D%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[约瑟夫问题设编号为1、2….n的n个人坐一圈，约定编号为k(1&lt;=k&lt;=n)的人从1开始报数，数到m的那个人出圈，他的下一位又从1开始报数，数到m的人又出圈，以此类推，直到所有人出圈为止，由此产生一个出圈编号的序列 解法一：循环链表 首先对参数k、m、n进行校验，确保k、m、n在正常范围内 创建一个辅助指针helper 让helper指向first前一个节点，即指向最初链表的最后一个节点 将first和helper向后移动k-1次，即让first指向开始报数的小孩 当helper==first时，说明圈中只有一个小孩 helper！=first时，将first和helper同时向后移动m-1次 将移动m-1此之后first指向的节点出圈 继续执行5，直到helper==first为止 其中方法的参数： k：第一次开始报数的小孩 count：每次数几下(m) nums：最开始圈中小孩数 这个约瑟夫问题是基于我自己创建的单向环形链表实现的(或者说我创建的单向环形链表是用来解决约瑟夫问题的)，helper节点最初就指向first前一个节点，所以2和3两步骤可以省略(可以看一下我创建单项循环链表的博客) 解法二：数组对于数组，进行出圈操作的时候就不能向链表一样删除节点了，因为数组的长度是固定的，那么怎么解决呢？我们可以将已经出圈的孩子所在的元素值赋值为0，这样，当我们遍历到元素值为0的节点时，就可以跳过该节点。步骤： 首先对参数k、m、n进行校验，确保k、m、n在正常范围内 因为数组下标是从0开始，小孩编号从1开始，所以让开始数数的小孩编号-1==&gt;k=k-1 根据nums创建数组，模拟nums个小孩组成的圈 一共有nums个小孩，所以一共要循环报数nums次==&gt;for (int i = 0; i &lt; nums; i++) {} 每一次报数m次，所以k要移动m-1次(起初报数时，自己也算一次)，当k代表的数组元素a[k]==0时，说明当前孩子已经出圈，所以需要k再次移动，直到a[k]!=0==&gt;for (int j = 0; j &lt; m - 1||arr[k]==0;) {} 第5步得到的k是该赋值为0的元素，即该出圈的孩子编号-1==&gt;k+1即为当前该出圈的孩子编号 a[k]=0，并且将k取模移向下一位 重复567nums次，直到所有孩子都出圈]]></content>
      <categories>
        <category>算法之美</category>
      </categories>
      <tags>
        <tag>环形链表</tag>
        <tag>数组</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构-环形链表]]></title>
    <url>%2F2019%2F09%2F15%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E7%8E%AF%E5%BD%A2%E9%93%BE%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[环形链表，顾名思义，就是整个链表构成一个环，将单链表的最后一个节点的next指针指向头节点，这样就构成了循环链表。这里说的循环链表主要用于解决约瑟夫环问题和判断链表是否有环两个算法问题。 环形链表节点 int val：存储数据 Node next：指向另外一个Node节点 单向循环链表成员变量 head：环形链表的头指针 helper：环形链表的尾指针，每次都指向新插入的节点(helper.next=head) 成员方法public void Add(int ele)向链表中添加元素 在添加之前，判断当前链表是否为空 如果为空 将head头指针指向新创建的节点==&gt;head=new Node(ele) helper指针也指向新创建的节点==&gt;helper=head 将新创建节点的next指针指向head，构成一个环==&gt;helper.next=head 如果不为空 将helper指针指向节点(尾节点)的next指针指向新节点==&gt;helper.next=new Node(ele) 将helper指针向后移，保证helper指针仍然指向尾节点==&gt;helper=helper.next 将尾节点的next指针指向head头节点，形成一个环==&gt;helper.next=head 环形链表，其实就是将单链表的尾节点的next指针指向头节点 public void show()打印环形链表逻辑比较简单，因为在打印的过程中指针会移动，所以可以创建两个临时变量，这样打印过后head和helper指针都没有发生变化，下次添加元素的时候仍然能够按照顺序添加 单链表的两个算法问题会在算法之美分类中说到]]></content>
      <categories>
        <category>DataStructure</category>
      </categories>
      <tags>
        <tag>环形链表</tag>
        <tag>链表</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Web基础之Request获取Http请求消息]]></title>
    <url>%2F2019%2F09%2F14%2FWeb%E5%9F%BA%E7%A1%80%E4%B9%8BRequest%E8%8E%B7%E5%8F%96Http%E8%AF%B7%E6%B1%82%E6%B6%88%E6%81%AF%2F</url>
    <content type="text"><![CDATA[本文主要介绍Http协议的请求消息格式，以及如何通过Request对象获取Http请求消息的内容。 Http 请求消息格式如下所示是一个简单地Http请求消息，以这个请求消息为例对Http请求消息格式进行介绍 123456789101112131415161718192021请求头POST /login.html HTTP/1.1===========================请求行Host: localhostUser-Agent: Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:60.0) Gecko/20100101 Firefox/60.0Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8Accept-Language: zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2Accept-Encoding: gzip, deflateReferer: http://localhost/login.htmlConnection: keep-aliveUpgrade-Insecure-Requests: 1================================请求空行=======================请求体username=zhangsan 请求行请求方式 请求url 请求协议/版本GET /login.html HTTP/1.1 HTTP协议有7中请求方式，常用的有2种 GET：请求参数在请求行中，在url后，并且请求的url长度有限制的，不太安全。 POST：请求参数在请求体中，请求的url长度没有限制的，相对安全。 请求头：客户端浏览器告诉服务器一些信息请求头名称: 请求头值(键值对形式) 常见的请求头有： User-Agent：浏览器告诉服务器，我访问你使用的浏览器版本信息。可以在服务器端获取该头的信息，解决浏览器的兼容性问题 Referer：http:/ /localhost/login.html。告诉服务器，我(当前请求)从哪里来？能够防盗链和进行统计工作。 请求空行空行，就是用于分割POST请求的请求头，和请求体的。 请求体(正文)封装POST请求消息的请求参数的，GET方式请求体为空 Request对象 request对象和response对象的原理它们都是由服务器创建的，我们只是使用它。request对象是来获取请求消息，response对象是来设置响应消息 request对象继承体系结构： ServletRequest – 接口 | 继承 HttpServletRequest – 接口 | 实现 org.apache.catalina.connector.RequestFacade 类(tomcat) request功能 获取请求消息数据 获取请求行数据 获取请求方式:String getMethod() 获取虚拟目录(常用):String getContextPath() 获取Servlet路径:String getServletPath() 获取get方式请求参数String getQueryString() 获取请求URI(常用):String getRequestURI()StringBuffer getRequestURL() 获取协议及版本:String getProtocol() 获取客户机的IP地址:String getRemoteAddr() 获取请求头数据String getHeader(String name)(常用):通过请求头的名称获取请求头的值Enumeration getHeaderNames():获取所有的请求头名称 获取请求体数据: 获取流对象 BufferedReader getReader()：获取字符输入流，只能操作字符数据 ServletInputStream getInputStream()：获取字节输入流，可以操作所有类型数据 再从流对象中拿数据 其他功能 获取请求参数通用方式：不论get还是post请求方式都可以使用下列方法来获取请求参数 String getParameter(String name):根据参数名称获取参数值 String[] getParameterValues(String name):根据参数名称获取参数值的数组 Enumeration getParameterNames():获取所有请求的参数名称 Map&lt;String,String[]&gt; getParameterMap():获取所有参数的map集合 中文乱码问题get方式：tomcat 8 已经将get方式乱码问题解决了post方式：会乱码。获取参数前，设置request编码request.setCharacterEncoding(“utf-8”); request请求转发请求转发是一种在服务器内部的资源跳转方式，它的原理如下图 使用步骤 通过request对象获取请求转发器对象：RequestDispatcher getRequestDispatcher(String path) 使用RequestDispatcher对象来进行转发：forward(ServletRequest request, ServletResponse response) 请求转发有如下特点 浏览器地址栏路径不发生变化 只能转发到当前服务器内部资源中。 转发是一次请求 共享数据当我们使用请求转发时，在服务器内部会从一个资源跳转到另一个资源，我们可以通过域对象在资源之间共享数据 域对象：一个有作用范围的对象，可以在范围内共享数据 request域：代表一次请求的范围，一般用于请求转发的多个资源中共享数据 方法： void setAttribute(String name,Object obj):存储数据 Object getAttitude(String name):通过键获取值 void removeAttribute(String name):通过键移除键值对 总结这样一来，request对象的基本功能就介绍的差不多了，说起来也比较简单：该对象主要用于接收从客户端发送过来的数据，并可以在服务器内部进行资源的跳转。]]></content>
      <categories>
        <category>JAVAWEB</category>
      </categories>
      <tags>
        <tag>Request</tag>
        <tag>Http请求消息格式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构-队列]]></title>
    <url>%2F2019%2F09%2F14%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E9%98%9F%E5%88%97%2F</url>
    <content type="text"><![CDATA[队列的特点：FIFO–&gt;First in First out，即先进先出这篇文章讲的是数组结构存储队列，队列从功能上来说分为两种 普通队列 循环队列。 后面将会分别用Java手写两个队列类来讲述普通队列和循环队列 普通队列概述队列本身是一个有序列表，因为队列的输入、输出是分别从前后端来处理，因此需要两个变量front和rear分别记录队头和队尾 front会随着数据输出而改变 rear会随着数据输入而改变 成员变量 private int maxSize; –&gt;队列最大容量 private int front; –&gt;队列头 private int rear; –&gt;队列尾 private T[] arr;(使用泛型) –&gt;队列存储结构：数组 构造方法这里创建了两个构造方法： 通过参数确定数组大小，即队列的容量 无参构造方法默认数组大小为10 front和rear指向的位置 front：指向队列头的前一个位置 rear：指向队列最后一个元素 成员方法public boolean isFull()对于非循环队列来说，判断队列是否已满很简单，只需要判断rear是否到达数组末尾即可 public boolean isEmpty()对于非循环队列来说，队列为空就是初始状态，即rear==front public void Add(T ele)对于添加元素的方法，有两个步骤 先判断队列是否已满 如果队满，抛出异常 否则，先将rear后移，再进行赋值操作 public T get()取队头元素的方法，同样有两个步骤 判断队列是否为空 如果队空，抛出异常 否则，先将front后移指向队头元素，再返回队头元素 public void show()打印当前队列所有元素 以上就是一个基本的普通数组模拟队列类，不难发现这样的队列是有很大缺陷的 无法复用：即只能用一次，当front指向arr[maxSize-1]的时候，就算此时队列中没有元素，也无法向队列中添加数据。下面来说循环队列 循环队列成员变量 private int maxSize; –&gt;队列最大容量 private int front; –&gt;队列头 private int rear; –&gt;队列尾 private T[] arr;(使用泛型) –&gt;队列存储结构：数组 构造方法这里创建了两个构造方法： 通过参数确定数组大小，即队列的容量 无参构造方法默认数组大小为10 front和rear指向的位置和普通队列不同 front：指向队列头元素 rear：指向队列尾元素的后一个位置 为了便于循环，rear指向的位置自始至终都是空着的，即队列的容量=maxsize-1 public boolean isFull()在循环队列中，判断队满的条件(rear+1)%maxSize==front public boolean isEmpty()在循环队列中，判断队满的条件仍是rear==front，因为rear指向的位置是不存放元素的，当front==rear时，说明队列已经没有元素了 public void Add(T ele)在循环队列中，当rear到达队列末尾时，我们需要它从0开始，因此不能+1，要用取模运算 public T get()在循环队列中，对于front也要用取模运算 public int getNum()对于(rear - front + mixsize) % mixsize运算，可以这么理解 当rear&gt;front时候，说明所有的元素都处于rear和front中间，num=rear-front 当rear&lt;front时候，说明所有元素都处在rear和front两边，即rear比front多走了一个mixsize的长度，num=rear+maxSize-front; 因此两者加起来就是(rear - front + mixsize) % mixsize public void show()特别注意循环条件，i从front开始，做带循环的后移(取模)，直到i==rear是遍历完所有元素]]></content>
      <categories>
        <category>DataStructure</category>
      </categories>
      <tags>
        <tag>数组</tag>
        <tag>队列</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Web基础之Druid数据库连接池]]></title>
    <url>%2F2019%2F09%2F13%2FWeb%E5%9F%BA%E7%A1%80%E4%B9%8BDruid%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%9E%E6%8E%A5%E6%B1%A0%2F</url>
    <content type="text"><![CDATA[最近在学习Java Web基础知识，为了防止遗忘，因此准备边学习边记录，方便后期回顾，今天就来介绍一款国产的性能优良的数据库连接池技术–Druid(本文基于MySQL5.5和Tomcat 8.5.31版本，在IDEA IDE下)。本文仅为自己复习用，其中依赖jar包具体名称均未说明。 JDBC我们通过JDBC可以用Java操作数据库，那么什么时JDBC呢？JDBC–Java DataBase Conectivity，即Java 数据库连接。这是一套由Sun公司定义的接口集，各个数据库厂商实现该接口，我们就可以通过这些接口来操作数据库。下面我以MySQL为例，介绍一下如何通过JDBC来操作MySQL。 基本流程我们有以下步骤 导入驱动jar包(很重要)复制mysql-connector-java-5.1.37-bin.jar到WEB-INF/libs目录下，右键–&gt;Add As Library 注册驱动 获取数据库连接对象 Connection 代码演示 12345678910111213141516//1. 导入驱动jar包//2.注册驱动Class.forName(&quot;com.mysql.jdbc.Driver&quot;);//3.获取数据库连接对象Connection conn = DriverManager.getConnection(&quot;jdbc:mysql://localhost:3306/db3&quot;, [数据库用户名], [数据库密码]);//4.定义sql语句String sql = &quot;update account set balance = 500 where id = 1&quot;;//5.获取执行sql的对象 StatementStatement stmt = conn.createStatement();//6.执行sqlint count = stmt.executeUpdate(sql);//7.处理结果System.out.println(count);//8.释放资源stmt.close();conn.close(); 类介绍下面我们来介绍一下JDBC中几个常用的类 Connection(数据库连接对象) 获取执行sql的对象 Statement createStatement() PreparedStatement prepareStatement(String sql) 管理事务 开启事务：setAutoCommit(boolean autoCommit) ：调用该方法设置参数为false，即开启事务 提交事务：commit() 回滚事务：rollback() Statement(执行sql的对象) boolean execute(String sql)：可以执行任意的sql(了解，一般不用) int executeUpdate(String sql)：执行DML（insert、update、delete）语句、DDL(create，alter、drop)语句 返回值：影响的行数，可以通过这个影响的行数判断DML语句是否执行成功 返回值&gt;0的则执行成功，反之，则失败。 ResultSet executeQuery(String sql)：执行DQL（select)语句，返回一个结果集对象 ResultSet(结果集对象,封装查询结果) boolean next()(初始时游标指向第一行数据的前一行)游标向下移动一行，判断当前行是否是最后一行末尾(是否有数据)，如果是，则返回false，如果不是则返回true getXxx(int colIndex/String colName)获取数据 PreparedStatement：执行sql的对象(用于解决SQL注入问题) SQL注入问题：在拼接sql时，有一些sql的特殊关键字参与字符串的拼接。会造成安全性问题 输入用户随便，输入密码：a’ or ‘a’ = ‘a sql：select * from user where username = ‘fhdsjkf’ and password = ‘a’ or ‘a’ = ‘a’ 解决sql注入问题：使用PreparedStatement对象来解决 预编译的SQL：参数使用?作为占位符 获取执行sql语句的对象 PreparedStatement Connection.prepareStatement(String sql) 使用setXxx(index，value)给？赋值： index:？的位置编号 从1 开始 value:？的值 执行sql，接受返回结果，不需要传递sql语句。 注意：后期都会使用PreparedStatement来完成增删改查的所有操作，它可以可以防止SQL注入并且效率更高 数据库连接池在使用JBDC创建数据库连接对象Connection时，我们每次使用过后都会关掉连接，在下一次执行SQL时再重新创建，这样会消耗时间，因此我们使用数据库连接池技术：一个数据库连接池中包含多个数据库连接，当查询使用完连接后并不会关掉该连接，而是将其归还给数据库连接池，以便复用该连接。我们这里主要介绍Druid数据库连接池。 Druid连接池 导入jar包druid-1.0.9.jar，和前面JDBC一样。 定义配置文件：properties形式的，可以叫任意名称(假设就叫druid.properties)，可以放在任意目录下 加载配置文件：Properties 123Properties pro = new Properties();InputStream is = 类名.class.getClassLoader().getResourceAsStream(&quot;druid.properties&quot;);pro.load(is); 获取数据库连接池对象：通过工厂来来获取 DruidDataSourceFactory 1DataSource ds = DruidDataSourceFactory.createDataSource(pro); 获取连接：getConnection 1Connection conn = ds.getConnection(); JDBCTemplate我们使用数据库连接池后，能够避免频繁的创建数据库连接，但是我们在执行SQL语句时，还是比较麻烦：要获取连接对象，获取执行对象，要定义SQL，要处理结果(将查询到的语句封装成对象)，要释放资源…这些都很麻烦并且是体力活。因此，Spring框架对JDBC的简单封装。提供了一个JDBCTemplate对象简化JDBC的开发 使用步骤 导入jar包，和前面的操作一样 创建JdbcTemplate对象。依赖于数据源DataSource JdbcTemplate template = new JdbcTemplate(ds); 调用JdbcTemplate的方法来完成CRUD的操作 update():执行DML语句。增、删、改语句 queryForMap():查询结果将结果集封装为map集合，将列名作为key，将值作为value 将这条记录封装为一个map集合，该方法最多只能返回一条记录并将该记录封装为Map集合。 queryForList():查询结果将结果集封装为list集合，将每一条记录封装为一个Map集合，再将Map集合装载到List集合中 query():查询结果，将结果封装为JavaBean对象 query的参数：RowMapper 一般我们使用BeanPropertyRowMapper实现类。可以完成数据到JavaBean的自动封装 new BeanPropertyRowMapper&lt;类型&gt;(类型.class) queryForObject：查询结果，将结果封装为对象 一般用于聚合函数的查询 JavaBean对象 JavaBean：标准的Java类 要求： 类必须被public修饰 必须提供空参的构造器 成员变量必须使用private修饰 提供公共setter和getter方法 功能：封装数据 同样的，使用BeanUtils工具类需要导入依赖jar包 我们使用BeanUtils工具类来将获取的数据封装为一个JavaBean对象 我们通过request.getParameterMap()方法能够获取到记录返回一个Map&lt;String,String[])集合 我们使用BeanUtils的populate(Object obj , Map map)方法，将map集合的键值对信息，封装到对应的JavaBean对象中]]></content>
      <categories>
        <category>JAVAWEB</category>
      </categories>
      <tags>
        <tag>Druid</tag>
        <tag>数据库连接池</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构--稀疏数组]]></title>
    <url>%2F2019%2F09%2F13%2F%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-%E7%A8%80%E7%96%8F%E6%95%B0%E7%BB%84%C2%9E%2F</url>
    <content type="text"><![CDATA[这篇文章主要讲的是数组的应用之一–稀疏数组。那么什么是稀疏数组呢？我们来看一个问题：假设你做了一个五子棋游戏，玩儿过的都知道这个游戏有一个叫做复盘的功能，就是你可以将这句游戏先存档，之后再读档的时候就会接着之前的继续下。我们都知道 用二维数组来构造棋盘 用0表示棋盘上没有落子的位置 用1和2分别表示黑棋和白棋的位置 存档：把二维数组通过流保存到硬盘中那么这里面就有一个问题：如果要存档的棋盘中有大片的空白(数组中有大量的元素为0)，直接将原数组存储进去会浪费空间，这时候可以用到稀疏数组来压缩 稀疏数组的结构行 稀疏数组的行数取决于原数组非0元素的个数–&gt;row=num+1; 第一行存储着原数组的信息 [0][0]=原数组的行数 [0][1]=原数组列数 [0][2]=原数组非0元素的个数 剩下的每一行都存储着原数组非0元素的信息 [i][0]=元素所在行 [i][1]=元素所在列 [i][2]=元素的值 稀疏数组的行数row=num+1：稀疏数组的第一行要用来存储原数组的信息，在还原的时候会用到 列 所有的稀疏数组都只有3列 除了第一行外： 第一列存储非0元素的行位置 第二列存储非0元素的列位置 第三列存储非0元素的值 上面说的非0元素，只是在数组中存在的大量重复元素值为0时的情况 数组–&gt;稀疏数组假设存在一个数组 遍历原数组，获取非0元素的个数 创建稀疏数组 稀疏数组的行数row=num+1 稀疏数组的列数col=3 将原数组信息存储到稀疏数组第一行 稀疏数组的第一行，存储原数组的行数、列数以及非0元素个数 遍历原数组，储存其中非0元素的信息 每一行的第一列存储元素的行信息 每一行的第二列存储元素的列信息 每一行第三列存储元素的值 最后得到的稀疏数组 稀疏数组–&gt;数组 创建普通数组 数组的行数为稀疏数组第一行第一列的值 数组的列数为稀疏数组第一行第二列的值 遍历稀疏数组的每一行 当前行的第一列为元素的行位置 当前行的第二列为元素的列位置 当前行的第三列为元素的值 最后得到原数组 通过实际操作我们发现，将数组转换为稀疏数组后，节省的空间还较为客观，当要存储的数组中含有大量的重复元素时，我们可以采用稀疏数组来存储，能够在一定程度上节省空间]]></content>
      <categories>
        <category>DataStructure</category>
      </categories>
      <tags>
        <tag>数组</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JDK源码--String类]]></title>
    <url>%2F2019%2F09%2F10%2FJDK%E6%BA%90%E7%A0%81-String%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[这一篇的String源码基于JDK8版本，来自于慕课网上文贺老师的JAVA源码专栏(收费)结合张家界的雪以及自己学习String源码的总结，主要的目的在于总结知识，方便后续回顾查看，如转载，请注明出处 成员变量在学习String源码之前，首先要知道String对象再内存中的存放位置，我们都知道JAVA对象一般都是存放在堆中，但是String对象是一个特例，它被存放在常量池中可以看到，String类实现了 Serializable：序列化接口，String对象可以被序列化 Comparable：表明字符串可以比较 CharSequence：表明String对象是一个字符序列 String底层实现是一个char类型的数组并且被final修饰 构造方法public String()值为空串，很少使用 *public String(String original)这个构造方法在创建的过程中会创建两个对象，一个在堆中，一个在常量池中当调用这个构造方法时String str=new String(“abc”) 现在堆中new出一个String对象，并将str指向该对象 查看常量池中是否存在”abc” 如果不存在，那么就会在常量池中在创建一个String对象 如果存在，不做操作 最终str是指向堆中的对象，而不是常量池中的对象 str1和str3都是指向常量池中的”abc”对象，所以str1==str3返回true str4涉及到了变量的相加，内部实现是先new一个StringBuilder，然后 append(str2),append(“c”);然后让str4引用toString()返回的对象;如图，StringBuilder的toString方法实质上也是new了一个String对象，所以str4指向堆中的另外一个String对象，所以str1==str4返回false 上面说了，str5指向堆中的一个String对象，所以str1==str5返回falsepublic String(char value[])如图，该构造方法实质上是调用Arrays工具类的copyof方法public String(char value[], int offset, int count)如图，该构造方法会先对起始位置进行判断，如果不合法会抛出异常。最后调用Arrays工具类的copyOfRange来实现public String(byte bytes[], int offset, int length, String charsetName)如图，该构造方法用byte数组构造String对象，用指定字符集转换后构造String对象。其中StringCoding.decode(charsetName, bytes, offset, length)方法根据指定编码对byte数组进行解码，返回char数组checkBounds方法是对参数进行检查，该方法为私有，只能在String类中使用该构造方法如果不指定charsetName，那么按照系统默认字符集进行解码public String(StringBuffer buffer)通过StringBuffer构造String，因为StringBuffer内部也是一个char数组，所以实质上还是调用Arrays.copyOf方法实现，并且由于StringBuffer是线程安全的，所以这里也加了synchronized块保证线程安全通过StringBuilder构造String对象和StringBuffer原理相同。不过由于StringBuilder是线程不安全的，所以没有加synchronized块*String(char value[] boolean share)这个构造方法是protected修饰的，它和public String(char value[])的区别在于多了一个boolean参数，并且不支持false只支持true，这样做的原因是为了和public String(char value[])方法进行区分，否则没办法构成重载，查看方法体可以发现，它直接将char数组的的地址传递给String对象，要比注意拷贝快很多但是这样做的弊端很大：String对象和char数组共享同一块内存，破坏了String的不可变性，所以将该构造方法设置为protected保证安全,但是由于性能比较好，节约内存，所以replace、concat、valueof等方法也用到了这个构造方法 成员方法public int length()返回char数组的长度 public boolean isEmpty()char数组长度是否为0 public char charAt(int index) 判断index是否超出char数组长度，超出则抛异常 否则返回value[index]。 public void getChars(int srcBegin, int srcEnd, char dst[], int dstBegin)将String对象指定的字符从dst[]数组的dstBegin位置向后复制,通过System.arraycopy实现，这是一个本地方法(native)。参数： srcBegin：复制的起始位置(包括) srcEnd：复制的结束位置(不包括) dst[]：目的数组 dstBegin：目的数组dstBegin起始 如果要复制的字符个数srcEnd-srcBegin&gt;dst.length-dstBegin,会抛出异常 public byte[] getBytes(String charsetName)和前面传递Byte数组的构造方法相反，这里将String对象的value数组按照指定字符集编码成字符数组并返回如果不指定字符集，按照默认字符集编码 public boolean equals(Object anObject)重写了Object的equals方法 public boolean equalsIgnoreCase(String anotherString)先判断地址是否相同，地址相同内容肯定相同，再判断长度是否相同，如果长度一样再调用regionMatches方法进行判断，这里用了&amp;&amp;运算符的断路原理regionMatches方法有两种形式 没有boolean参数的 有boolean参数的 该方法的作用是区域比较，比较两个字符串指定长度的内容是否相等，从指定位置开始逐一比较字符数组内容是否相等两方法的区别在于：如果booloean参数为true，那么当字符不相等时 先将两字符转换成大写字符比较，还不相等 将两字符转换成小写比较，还不相等返回false 和String的内部类实现原理一样 public int compareTo(String anotherString)这个方法是实现Comparable接口的方法，用于对字符串大小进行比较这个方法取了两个字符串长度较小的那个作为循环次数，对两个字符串进行逐位比较。 如果不同，就返回两字符串不同那一位字符的差 如果都相同，就返回两字符串的长度差 差的计算:调用方法的字符串-参数字符串 public int compareToIgnoreCase(String str)该方法实际上是调用了静态内部类对象的忽略大小写的compareTo方法 public boolean startsWith(String prefix, int toffset) public int hashCode()重写了Object的hashCode方法在JAVA中，hashCode有两个作用： Object的hashCode返回对象的内存地址 重写的hashCode配合基于散列的集合使用 在使用散列集合例如HashMap时，要保证key唯一，但是对于大量元素比较时直接比较equals效率低下，可以先判断hashCode，如果hashCode相等，然后判断equals，因为不同的对象其hashCode值可能相同，例如”通话”和”重地”、”Aa”和”BB” 为了使字符串计算的hashCode尽可能地少重复(降低哈希冲突)，这里采用的是31这个乘数，有两个好处 31是个不大不小的质数，是作为hashCode乘子的优秀质数之一 31可以被JVM优化，31*i=(i&lt;&lt;5)-i(暂时没弄明白JVM优化) public int indexOf(int ch, int fromIndex)作用：找到ch字符从字符串fromIndex位置开始第一次出现的位置方法中的判断条件ch &lt; Character.MIN_SUPPLEMENTARY_CODE_POINT是什么意思呢？我们知道，在JAVA中，一个char类型字符占2个字节也就是16位 当参数中的ch在这个范围内时，就在String中从fromIndex开始逐一查找ch第一次上出现的位置 当参数超过这个范围(即大于65535)时，调用indexOfSupplementary()方法进行比较 通过查看Character源码可知这个数值就是65535 public int indexOfSupplementary(int ch, int fromIndex)这个方法是private修饰的，只能由String内部调用，用来处理当参数ch大于2个字节时的查找方法不难发现，它将ch字符拆分成高低位来查找，高位和value[i]比较，低位和value[i+1]比较lastIndexof逻辑和Indexof基本类似，不多说 public int indexOf(String str, int fromIndex)参数为字符串，实际上比较的时字符串里的char数组方法是保护的，只能在包内调用 首先分析一下方法的参数： char[] source：调用方法的字符串内部数组–&gt;暂且称为源数组 int sourceOffset：数组的起始位置(一般是0) int sourceCount：数组的长度 char[] target：参数字符串的内部数组–&gt;暂且称为目的数组 int targetOffset：数组的起始位置(一般是0) int targetCount：数组的长度 int fromIndex：从源数组fromIndex位置开始向后查找 前三个if条件判断 当fromIndex &gt;= sourceCount(即指定的起始搜索位置大于源数组数组的长度)时 判断目的数组是否为空串 若为空，则返回源数组的长度 不为空，返回-1 当指定起始搜索位置小于0，默认从0开始搜索 当目的数组为空，并且fromIndex在正常范围内，返回fromIndex 找源数组和目的数组第一个字符相同的位置记为i 逐一比较接来的字符是否相等，如果遍历完目的数组后仍相等，返回i，不相等进行5 从源数组第i个位置后找与目的数组第一个字符相等的位置，再比较接下来的每一个字符是否相等 一直循环查找直到找到i并返回，或源字符串遍历完毕返回-1对于几种特殊情况的测试public int indexOf(String str)默认fromIndex=0，调用上面的indexOf方法 public int lastIndexOf(String str, int fromIndex)逻辑和上面个一样，都是调用比较char数组的保护方法，需要时查看一下JDK8的源码 public String substring(int beginIndex) 对beginIndex进行判断 beginIndex&lt;0，抛出StringIndexOutOfBoundsException异常 大于源数组的长度，抛出StringIndexOutOfBoundsException异常 begin=0，直接返回当前字符串 调用String(char[] value,int beginIndex,int count(value.length-beginIndex))来实现 public String substring(int beginIndex, int endIndex)逻辑和上面一样(含头不含尾) public String concat(String str)拼接字符串，将str拼接到this串后面 如果参数串为空串，直接返回this(当前字符串) 调用Arrays.copyOf方法创建一个新的字符串buf，长度为this.length+str.length，内容为this.value 调用String类的getChars方法，将str复制到buf串中(从buf串的this.length位置开始) 调用String类的protected修饰的构造方法，直接将buf串的地址赋值给新创建的字符串对象–&gt;参考前面protected的构造方法 大致上来说，该方法的实现原理：先创建一个字符数组，复制了两个字符串中的内容，然后通过String(char value[] boolean share)方法来new一个新的字符串因为buf串是在方法内部创建的，外部是不可见的，因此不会破坏String对象的不可变性 public String replace(char oldChar, char newChar)将字符串中所有的oldChar替换为newChar 如果OldChar==newChar，直接返回当前字符串 找到字符串中第一个OldChar，记录位置为i； 新建一个char数组buf，将字符串赋值给buf数组，从buf的i开始，将所有的OldChar替换为newChar 通过String(char value[] boolean share)来创建新的字符串对象并返回 说一下为什么要重建一个val数组，用val数组给buf数组赋值，而不直接用value数组赋值呢？上网查阅，val数组是局部变量，value数组是类变量，getfield操作是一个访问类变量的操作当使用value数组循环赋值的时候，每一次循环都会有一个getfield操作入栈使用局部变量val时，只有一次getfield操作操作，就是将value数组赋值给val的时候当数组长度很大的时候，使用局部变量性能会更好一些(大神真不愧是大神，太细节了) public boolean contains(CharSequence s)判断字符串是否包含制定的字符序列，实际上是调用indexOf(String str)方法，查找序列在字符串中出现的位置来判断的，如果不包含返回-1。 public String toLowerCase()/toUpperCase()对字符串进行大小写转换，只对英文字符有效 public String trim()去掉两端空白字符(空格、tab、回车符) 从左到右循环字符数组，若字符为空字符则继续循环，直到第一个不为空的字符记录位置st 从右往左循环字符数组，若字符为空字符则继续循环，直到第一个不为空的字符记录位置len 如果st=0并且len=value.length，说明该字符两端没有空字符，直接返回字符串 否则，调用substring(st, len)方法获取去掉首尾空字符的字串。 通过分析：一个首尾没有空字符的str调用trim方法，返回它本身，所以得到的新String对象地址相同一个开头或结尾存在空字符的str调用trim方法，返回的新String对象是new出来的，两者地址不同 public String toString()返回他自身 public char[] toCharArray()创建一个resault数组，调用System.arraycopy方法将value复制给resault数组并返回不能直接返回value数组，破坏了String的不可变性源码中有一行注释：Cannot use Arrays.copyOf because of class initialization order issues，由于类初始化顺序问题，不能使用Arrays.copyOf方法可能的原因：String初始化比Arrays早，但是在JDK中存在其他对象使用了toCharArray()方法，而这个对象初始化比String晚但是比Arrays早，导致在使用时Arrays还没有初始化完成而报错而Syatem.arraycopy不会有这样的问题，因为这是本地方法 public static String valueOf系列方法直接查看JDK源码即可，很简单，就不赘述 public native String intern();本地方法，详细解释请见传送门，讲的挺好传送门1传送门2 静态内部类实际上就是String内部定义的一个比较器，用于忽略大小写比较字符串是否相等，CompareToIgnoreCase方法用到了这个类 到这里String类也大致总结完了，但是对于String类，我想要学的远不止这些，做这些只是整理方便后期学习理解，如果哪里不对或者有其他源码学习途径，欢迎私信我一起讨论交流，让我们一起学习，共同进步 暂时只能通过微博，后续会开微信公众号来一起交流，毕竟现在实力还不够]]></content>
      <categories>
        <category>JDK源码</category>
      </categories>
      <tags>
        <tag>源码</tag>
        <tag>String类</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库基础--基础查询语句]]></title>
    <url>%2F2019%2F09%2F09%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9F%BA%E7%A1%80-%E5%9F%BA%E7%A1%80%E6%9F%A5%E8%AF%A2%E8%AF%AD%E5%8F%A5%2F</url>
    <content type="text"><![CDATA[之前介绍了SQL中的DDL和DML语句，现在就来介绍一下DQL语句，这也是平时使用最多的类型 整体语法1234567SELECT (DISTINCT) &lt;列名&gt; (AS) &lt;别名&gt;,&lt;列名&gt; (AS) &lt;别名&gt;.... FROM &lt;表名&gt; WHERE 条件 GROUP BY 分组条件 HAVING 条件 ORDER BY 排序 LIMIT 分页限定 以上各种条件，可以选择其中一些搭配使用使用，但是各个条件之间的顺序是不能改变的。并且必须有SELECT子句、FROM子句。 运算符运算符分为算术运算符、比较运算符以及逻辑运算符三种，下面分别进行介绍 算术运算符1234+-*/ SQL语句中可以使用计算表达式，如1SELECT &lt;列名&gt;*2 FROM &lt;表名&gt; 除了SELECT子句，在WHERE子句、HAVING子句中同样可以使用 包含NULL的计算，12345+NULLNULL/9NULL/0...... 对于所有包含NULL的计算，结果肯定是NULL。 比较运算符123456=&lt;&gt;或!=&gt;=&lt;=&gt;&lt; 对于字符串的比较大小，是按照字典顺序比较，和数值型有所不同 NULL数据对于上面的两种运算符，都无法查询到NULL数据，如果我们想要查询NULL数据，可以使用 12IS NULL 希望选取NULL数据IS NOT NULL 排除NULL数据 这两个条件 逻辑运算符通过逻辑运算符，可以将多个查询条件进行组合 NOT运算符(!非)否定条件，参考前面的NULL AND运算符(&amp;&amp;与)选出同时满足两条件的记录 1条件A AND 条件B OR运算符(||或)选出满足条件A或条件B的数据 1条件A OR 条件B 注意 当多个条件需要进行组合时，需要使用AND或OR运算符 AND运算符的优先级高于OR运算符，必要的时候需要使用括号。 聚合函数通过SQL对数据进行某种操作或计算时需要使用函数，例如：计算表中全部数据的行数时，可以使用COUNT()函数，SQL中有很多用于汇总的函数，下面介绍5中 12345COUNT():计算表中的记录数SUM():计算某一列中数据的和AVG():计算某一列数据的平均值MAX():求出某一列数据中的最大值MIN():求出某一列数据中的最小值 如上所示，用于汇总的函数称为聚合函数，所谓聚合，就是将多行汇聚成一行。实际上，所有的聚合函数最后得到的都是一行数据 COUNT(&lt;列名&gt;)参数为列名，计算该列除了NULL数据之外记录数，如果要得到该表的记录数(行数)，应使用使用COUNT(*)或者参数使用有非空约束的列 SUM(&lt;列名&gt;)参数为列名，如果该列存在NULL数据，那么NULL数据不参与计算。 AVG(&lt;列名&gt;)同样的，参数为列名，如果该列存在NULL数据，那么NULL数据不参与计算。 NULL数据统一解决方式对于以上三个聚合函数，我们可以看到，都无法处理NULL数据，那么我们能不能在使用这些函数时将NULL数据临时替换为其他数值呢？答案是可以的 123456IFNULL(列名，想要替换的数)//例如SELECT AVG(IFNULL(&lt;列名,0&gt;))计算某一列中数据的平均值，当该列存在NULL数据时，将NULL数据替换为0参与计算同样的对于另外两种聚合函数也可以使用这种方式 注意AVG和SUM只能用于数值类型的列，而MAX和MIN可以用于任意类型可以在聚合函数中使用DISTINCT关键字首先过滤掉重复数据，剩下的数据参与计算 1SUM(DISTINCT &lt;列名&gt;) 子句介绍下面就来介绍一下查询语法中的各个子句的使用以及注意事项 DISTINCT从结果中删除重复行，该关键字只能用在第一个列名之前。 SELECT子句 如果想要查询所有列，那么可以在SELECT中使用SELECT *。 查询结果中列的顺序和SELECT子句中的顺序相同 WHERE子句通过WHERE子句可以查询满足条件的行(记录)。 对于SELECT子句和WHERE子句的执行顺序:首先通过WHERE子句查询出符合指定条件的记录，然后再选取出SELECT子句指定的列。 WHERE子句中不能使用聚合函数 GROUP BY在GROUP BY子句中指定的列称为聚合键或者分组列。如果聚合键中含有NULL值，那么所有的NULL数据会分成单独一组。 在SELECT子句中不能书写多余的列。通过某个聚合键将表分组后，结果中的一行数据就代表一组。在使用GROUP BY子句时，SELECT子句中不能出现聚合键以外的列名在使用COUNT这样的聚合函数时，SELECT子句中的元素有严格的限制： 常数 聚合函数 GROUP BY子句中指定的列名 在GROUP BY子句中不能使用别名SQL语句在DBMS内部的执行顺序导致了这种结果，后面会介绍具体执行的先后顺序。现在只需要知道，GROUP BY子句在SELECT子句之前执行，因此当GROUP BY子句执行时列的别名还没有被定义，因此不能使用。 GROUP BY子句的结果不能排序 不能在WHERE子句中使用聚合函数只有SELECT子句和HAVING子句中能够使用聚合函数(后面会介绍HAVING子句)，WHERE子句中一定不要使用聚合函数。 HAVING前面介绍了GROUP BY子句，可以得到记录分组后的结果，那如果我们想要选取符合条件的组，那又该怎么办呢？这里不能使用WHERE子句，因为WHERE只能指定记录(行)的条件，不能用来指定组的条件。如果需要对组指定条件，就要用到HAVING子句。 HAVING子句的构成要素HAVING子句和包含GROUP BY时的SELECT子句一样，子句的内容有着相同的限制 常数 聚合函数 GROUP BY子句中指定的列名 HAVING和WHEREHAVING子句和WHERE子句的作用不同，前者用于指定组的条件，和GROUP BY子句搭配使用，后者用于指定行的条件。 WHERE子句=指定行对应的条件 HAVING子句=指定组对应的条件 ORDER BY使用ORDER BY子句可以对查询结果进行排序，具体用法 1ORDER BY &lt;列名1&gt; ASC/DESC,&lt;列名2&gt; ASC/DESC,&lt;列名3&gt;...... ASC:升序排列(需要升序排列时，可以省略该关键字)DESC:降序排列排序规则：先以列1为标准对查询的结果进行排序，对于列1中相等的数据，以列2为基准进行排序….. 在ORDER BY子句中可以使用别名由于ORDER BY子句在SELECT子句之后执行，因此ORDER BY子句中可以使用列的别名 ORDER BY子句中可以使用SELECT子句中为使用的列和聚合函数 各子句执行顺序最后，再来看一下以上所有子句中各个子句的执行顺序 FROM子句组装来自不同数据源的分组 WHERE对记录进行初步筛选 GROUP BY子句将WHERE删选后的数据划分为不同的分组 使用聚合函数进行运算 HAVING子句对GROUP BY子句得到的分组进行筛选，得到满足条件的分组 计算所有表达式 SELECT子句获取指定的列 ORDER BY子句对数据进行排序 LIMIT子句限制数据的个数 以上就是查询语句所有子句的执行先后顺序。]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>数据库</tag>
        <tag>SQL基础教程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[会话技术--Cookie&Session]]></title>
    <url>%2F2019%2F09%2F08%2F%E4%BC%9A%E8%AF%9D%E6%8A%80%E6%9C%AF-Cookie-Session%2F</url>
    <content type="text"><![CDATA[会话：一次会话中包含多次请求和响应。在一次会话中，浏览器第一次给服务器资源发送请求，会话建立，直到有一方断开为止会话技术能够在一次会话的多次请求响应间共享数据 会话技术的实现方式 客户端会话技术：Cookie 服务器端会话技术：Session 客户端会话技术–CookieCookie使用步骤 创建Cookie对象，绑定数据:new Cookie(String name, String value) 发送Cookie对象::response.addCookie(Cookie cookie) 获取Cookie，拿到数据:Cookie[] request.getCookies() Cookie实现原理基于响应头set-cookie和请求头cookie实现 客户端和服务器第一次请求响应：服务器创建Cookie对象，并在set-cookie响应头将Cookie响应给浏览器 浏览器接收到服务器带有set-cookie头的响应后，将Cookie存储在浏览器中，当下一次浏览器向服务器发送请求时，会在请求头cookie头中附带这cookie 这样就实现了多次请求响应之间的数据共享 Cookie的细节 一次可以发送多个cookie：在服务器端创建多个Cookie对象，多次调用response的addCookie方法将多个Cookie对象发送，但是如果两个Cookie的值相同，那么后加入的Cookie值会覆盖前面的值 cookie在浏览器中保存时间 默认情况下，当浏览器关闭后，Cookie数据被销毁(服务器关闭，Cookie仍然存在，因为Cookie存储在浏览器中) 持久化存储：调用Cookie对象的setMaxAge(int seconds)方法实现 参数取值情况： 正数：将Cookie数据写到硬盘的文件中。持久化存储。并指定cookie存活时间，时间到后，cookie文件自动失效 负数：默认值，即浏览器关闭后Cookie被销毁 零：删除cookie信息 cookie存储中文问题:在tomcat 8 之前 cookie中不能直接存储中文数据。但是在tomcat8之后，支持直接存储中文，但是对于一些特殊字符(如空格等)，仍不能直接存储，需要借助URL编码才行(具体步骤下一篇文章说到) cookie的共享 在一个tomcat服务器中部署了多个项目，在默认情况下，这些项目之间的Cookie是不能共享的但是可以通过Cookie对象的setPath(String path)方法来设置Cookie的共享范围 默认情况下，设置的是当前项目的虚拟目录 如果要在多个项目之间共享，则可以将path设置为"/"(“/”为服务器路径) 不同服务器之间Cookie的共享 setDomain(String path):如果设置一级域名相同，那么多个服务器之间cookie可以共享 例如：设置path为".baidu.com"，那么tieba.baidu.com和news.baidu.com两个不同的服务器之间可以共享数据，因为它们的一级域名是.baidu.com Cookie的特点和作用 特点 cookie存储数据在客户端浏览器 浏览器对于单个cookie 的大小有限制(4kb) 以及 对同一个域名下的总cookie数量也有限制(20个) Cookie存储的键值对都是String类型 作用 cookie一般用于存出少量的不太敏感的数据，这是因为Cookie的存储位置决定的，存储在客户端容易丢失和被篡改。 在不登录的情况下，完成服务器对客户端的身份识别 服务器端会话技术–SessionSession使用步骤 通过resquest获取Session对象：request.getSession() 调用Session对象的方法存储数据(和request请求转发方法一样) Object getAttribute(String name)：通过键获取值 void setAttribute(String name, Object value)：将数据存储进Session对象 void removeAttribute(String name)：通过键移除相应的键值对 Session实现原理Session的实现是依赖于Cookie的。 客户端第一次向服务器发送请求，服务器在服务器内部开辟一块内存空间，存放Session对象，并给该内存空间指定一个id 服务器在响应头set-cookie中设置JSESSIONID=id这个键值对发送给客户端 客户端接收到服务器的相应后，会将保存着Sessionid的Cookie对象保存在浏览器内存 当客户端下一次向服务器发送请求的时候，会带着Cookie一起(在请求头cookie中有JSESSIONID=id键值对) 服务器接收到请求后，得到JSESSIONID=id键值对的id后，会在内存中找到对应id的Session对象 这就是为什么说Session依赖于Cookie的原因以及多次请求响应之间共享数据的原理 Session细节 当客户端关闭后，服务器不关闭，两次获取session不是同一个：前面说到过，Session是依赖于Cookie的，Cookie在默认情况下当客户端浏览器关闭后是自动销毁的，因此Cookie中的键值对自然也就销毁了，所以两次获取的Session不是同一个，如果需要两次的Cookie是同一个 创建一个Cookie对象，设置cookie的键为JSESSIONID，值为session对象的id 设置cookie的存活时间 那么在cookie存活时间内，服务器通过cookie请求头拿到session的id都是一样的，这样通过id找到的Session对象自然也是同一个 客户端不关闭，服务器关闭后，两次获取的session不是同一个，因为服务器关闭后相应内存会被释放，Session自然也会被释放 但是一般我们需要获取到的Session对象是同一个，确保数据不丢失，tomcat会自动完成Session的钝化和活化 Session的钝化：在服务器正常关闭之前，将session对象序列化到硬盘上 Session的活化：在服务器启动后，将session文件转化为内存中的session对象。 Session被销毁 服务器关闭 session对象调用invalidate() 自杀 session默认失效时间 30分钟,可以tomcat服务器的web.xml配置文件中session-config设置所有项目的失效时间,也可以在项目的wen.xml配置文件单独配置项目的失效时间 Session的特点 用于一次会话的多次请求间共享数据，存储在服务器端 session可以存储任意类型，任意大小的数据]]></content>
      <categories>
        <category>JAVAWEB</category>
      </categories>
      <tags>
        <tag>会话技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[服务器中的四种路径]]></title>
    <url>%2F2019%2F09%2F08%2F%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%AD%E7%9A%84%E5%9B%9B%E7%A7%8D%E8%B7%AF%E5%BE%84%2F</url>
    <content type="text"><![CDATA[在Web开发中，会很频繁的用到各种路径，路径又大致分为四种，分别是相对路径、绝对路径、虚拟路径、资源路径 # 相对路径 通过相对路径不能确定唯一资源 例如：./index.html ## 相对路径的使用规则 以"./"开头, 在使用时先确定当前资源和目标资源的之间的相对位置关系 如果两资源位于同一级目录：./+目标资源名称 ./可以不加，默认有./ 如果目标资源位于上一级目录：../+目标资源名称 如何确定当前资源和目标资源的关系 对于src目录下的资源，可以用request.getRequestURL()来得到该资源的位置src下的java资源的URI都是虚拟路径+资源名称无论该java文件位于src下的哪一级目录，只要在src目录里，都是这个形式。这里说的资源名称并不是实际的java类名，而是@WebServlet中的资源名称，服务器通过这个资源名称找到实际的类。 对于web目录下的资源，如果直接在web目录下，那么资源的URI就是虚拟路径+/文件名称如果在web目录下的其他目录，那么资源的URI就是虚拟路径+/目录名称+/文件名称，有几级目录写几级目录。 绝对路径通过绝对路径确定唯一资源例如：http://localhost/response/responseDemo2或者/response/responseDemo2协议名+ip地址+端口号+虚拟路径+文件资源 两种路径使用规则规则：判断要定义的路径是给谁用的，即判断请求将来从哪发出 给客户端浏览器使用 需要加虚拟目录(项目的访问路径,查看项目的xml配置文件) 例如：&lt;\a&gt;标签，&lt;\form&gt;，重定向等从浏览器发出，需要加虚拟路径 给服务器使用不需要加虚拟目录例如：请求转发就是服务器内部的资源跳转，不需要加虚拟路径，直接写资源名称就可以了 虚拟路径虚拟路径代表的是项目实际部署的位置，服务器通过虚拟路径能够映射到项目实际部署的位置通过查看项目的xml文件可以发现:&lt;\Context path=”虚拟路径” docBase=”资源在电脑上存储的位置” /&gt;这就是配置文件的内容，我们在浏览器输入的是Contextpath，也就是项目的虚拟路径，服务器就通过该虚拟目录映射到后面项目部署的真实目录 虚拟路径的好处 虚拟目录的名称通常要比物理目录的名称易记，因此更便于用户访问。 使用虚拟目录可以提高安全性，因为客户端并不知道文件在服务器上的实际物理位置，所以无法使用该信息来修改服务器中的目标文件。 使用虚拟目录可以更方便地移动网站中的目录，只需更改虚拟目录物理位置之间的映射，无需更改目录的URL。 使用虚拟目录可以发布多个目录下的内容，并可以单独控制每个虚拟目录的访问权限。 使用虚拟目录可以均衡Web服务器的负载，因为网站中资源来自于多个不同的服务器，从而避免单一服务器负载过重，响应缓慢。 资源路径资源路径也不是文件的真实路径，它和真是路径之间存在着映射关系，服务器可以通过资源路径找到文件link这篇文章提到了配置Servlet的方法，一种是通过web.xml来配置，通过这种方法很容易理解资源路径和文件路径的映射关系，服务器通过资源路径映射到实际文件，通过@WebServlet配置原理一样 我们在浏览器输入的是项目的URL是由协议名+ip地址+端口号+虚拟路径+文件资源组成，服务器会通过虚拟路径找到项目在电脑上部署的位置，通过文件资源路径找到文件在电脑上的实际位置]]></content>
      <categories>
        <category>JAVAWEB</category>
      </categories>
      <tags>
        <tag>Http协议</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ServletContext对象]]></title>
    <url>%2F2019%2F09%2F08%2FServletContext%E5%AF%B9%E8%B1%A1%2F</url>
    <content type="text"><![CDATA[ServletContext对象，代表了整个web应用，可以和程序的容器(服务器)来通信 获取方式 通过request对象获取:request.getServletContext() 通过HttpServlet获取:this.getServletContext(); ServletContext对象的功能 获取MIME类型(文后将什么是MIME类型):String getMimeType(String file) 获取到数据的类型后，可以用于设置响应头content-type的值 获取方法：String getMimeType(String file)； 域对象：共享数据，前面说到，ServletContext代表了整个web应用，因此ServletContext对象中存放的数据整个web应用的资源都可以访问和修改 方法和request域对象的三个方法一样，只是两者的作用范围不同 动态的获取文件的真实(服务器)路径 方法：String getRealPath(String path) 文件直接位于web目录下时：context.getRealPath("/+文件名称"); 文件位于web目录下下的目录a中时：context.getRealPath("/a/+文件名称"); 文件直接位于src目录下时：context.getRealPath("/WEB-INF/classes+文件名称"); 以上可以通过查看tomcat项目的层次结构，以tomcat项目的web目录为基准 tomcat项目目录位于IDEA工作空间目录的\out\artifacts下 MIME类型MIME类型:在互联网通信过程中定义的一种文件数据类型MIME类型的格式：大类型/小类型&nbsp;&nbsp;&nbsp;&nbsp;例如：text/html、image/jpg getMimeType方法获取MIME类型的原理在web.xml配置文件中，tomcat定义了上千种MIME类型和文件后缀名的对应关系，而ServletContext又可以和服务器通信，所以ServletContext的getMimeType实际上是通过文件的后缀名来映射获取的文件的MIME类型。]]></content>
      <categories>
        <category>JAVAWEB</category>
      </categories>
      <tags>
        <tag>Http协议</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[请求转发和重定向]]></title>
    <url>%2F2019%2F09%2F08%2F%E8%AF%B7%E6%B1%82%E8%BD%AC%E5%8F%91%E5%92%8C%E9%87%8D%E5%AE%9A%E5%90%91%2F</url>
    <content type="text"><![CDATA[目前已经学习了两种资源跳转的方式：分别是request对象的请求转发和response的重定向，那么这两者各自有什么特点以及它们之间的区别是什么呢？ request请求转发一种在服务器内部的资源跳转方式举个例子：浏览器向服务器发出请求，服务器中的AServlet收到了请求，但是AServlet无法单独完成这个请求，如果要完成这个请求，还需要服务器内BServlet的参与，这时候就会用到请求转发，AServlet执行完自己能执行的部分后跳转到BServlet中继续执行，(这中间还涉及到了共享数据，文章后面会将) 请求转发的特点 浏览器地址栏路径不发生变化：就是说，浏览器请求访问AServlet，Aservlet执行完自己能执行的部分后跳转到BServlet，在这个过程中浏览器地址栏的路径还是AServlet的路径，并不会发生改变 只能转发到当前服务器内部资源中。 转发是一次请求：从上面的例子可以看出，整个转发的过程中，无论在服务器内部资源跳转多少次，浏览器只发出过一次请求，而服务请经过多次跳转处理完浏览器的请求后只会做出一次响应 共享数据上面说到了，AServlet和BServlet一起完成浏览器的请求，那么这两者之间必定是有数据交互的，因为AServlet要告诉BServlet自己做了哪些部分(修改了那些数据..)，并将这些部分共享给BServlet说共享数据之前，先说一个概念域对象：一个有作用范围的对象，可以在范围内共享数据request域：代表一次请求的范围，即在一个请求的范围内各个服务器资源可以共享数据。因为上面说到了请求转发这个过程是一次请求响应的过程，所以请求转发过程中的多个资源可以共享数据 存储数据，在当前资源中调用此方法(转发之前调用)void setAttribute(String name, Object o)参数：String name：给数据起一个名，在后面取出数据用到Object o：要共享的数据 在跳转后的资源调用此方法，可以达到共享数据的目的：Object getAttribute(String name) 参数：String name：存储数据时起的名 还有一个相关的方法：通过键来移除键值对void removeAttribute(String name) response重定向一种资源跳转的方式，不限于服务器内部，可以跳转到其他服务器资源(如跳转到百度) 重定向实现步骤 设置状态码为302(代表重定向) 设置响应头location：response.setHeader("location","目的资源的路径"); 以上是分步实现，其实一个方法就能够完成上述步骤 调用response的sendRedirect方法，方法中传递跳转资源的路径 response.sendRedirect("https://www.baidu.com"); 重定向的原理 浏览器向服务器发出请求，AServlet接收到了这个请求,AServlet表示无法处理服务器的这个请求，但AServlet却知道BServlet(可以是服务器内部的资源也可以是其他服务器的资源) 所以AServlet在在响应消息中干了两件事情 设置状态码为302，告诉服务器重定向 告诉浏览器BServlet的路径，(设置响应头location为BServlet的路径) 浏览器收到了AServlet的响应消息后，根据AServlet给出的location路径去访问BServlet 重定向的特点 地址栏发生变化：在资源跳转的过程中，浏览器地址栏会发生变化 重定向可以访问其他站点(服务器)的资源 重定向是两次请求。不能使用request对象来共享数据]]></content>
      <categories>
        <category>JAVAWEB</category>
      </categories>
      <tags>
        <tag>Http协议</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[response输出中文乱码]]></title>
    <url>%2F2019%2F09%2F08%2Fresponse%E8%BE%93%E5%87%BA%E4%B8%AD%E6%96%87%E4%B9%B1%E7%A0%81%2F</url>
    <content type="text"><![CDATA[使用response对象设置响应体时有两个步骤： 获取输出流(字节流或字符流) 使用输出流，将数据输出到客户端浏览器这时候如果传输的数据是中文，输出到浏览器就会乱码 乱码原因首先，要知道乱码的根本原因是什么，乱码的根本原因在于编码和解码使用的字符集不一样。那么在从服务器输出数据到客户端的过程中，有几次编码和解码过程？又分别是在哪里执行的？在输出数据的过程中，有一次编码，是tomcat执行的，它按照自己的字符集将数据编码后发送给客户端浏览器有一次解码，是浏览器执行的，浏览器将接收的数据按照自己的字符集解码后打印在屏幕上。而tomcat的默认编码是ISO-8859-1，浏览器的默认编码是操作系统的编码，也就是GBK，两者的编码格式不一样，就造成了中文乱码问题 解决方案解决方案不止一种，记录一种比较简单地使用response设置响应头的方法来设置 Content-Type 具体操作在获取输出流之前(一定是之前)设置响应头content-typeresponse.setHeader(“content-type”,”text/html;charset=utf-8”);这个方法不仅可以设置流的编码，还可以告诉浏览器发送数据的编码方式，并建议浏览器使用同样的字符集解码，这样就解决了乱码的问题由于只需要设置content-type这个响应头，所以有另一个方法更为简单response.setContentType(“text/html;charset=utf-8”);]]></content>
      <categories>
        <category>JAVAWEB</category>
      </categories>
      <tags>
        <tag>Http协议</tag>
        <tag>乱码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Http协议概述--request和response对象]]></title>
    <url>%2F2019%2F09%2F08%2FHttp%E5%8D%8F%E8%AE%AE%E6%A6%82%E8%BF%B0-request%E5%92%8Cresponse%E5%AF%B9%E8%B1%A1%2F</url>
    <content type="text"><![CDATA[首先要知道request对象和response对象是由服务器创建的，我们只是使用并不创建request对象是来获取请求消息，response对象是来设置响应消息 request对象request继承结构&nbsp;&nbsp;&nbsp;&nbsp;ServletRequest(接口)–&gt;HttpServletRequest(接口)–&gt;RequestFacade 类(tomcat实现) request功能获取请求消息数据 获取请求行数据:这是一个GET请求方式的请求行：GET /day14/demo1?name=zhangsan HTTP/1.1 获取请求方式 ：String getMethod() -->上例得到结果：GET 获取虚拟目录(常用)：String getContextPath() -->上例得到结果：/day14 获取Servlet路径: String getServletPath()-->上例得到结果：/demo1 获取get方式请求参数：String getQueryString()-->上例得到结果：name=zhangsan 获取请求URI(常用)(有两个方法) String getRequestURI()-->上例得到结果：/day14/demo1 StringBuffer getRequestURL()上例得到结果 :http://localhost/day14/demo1 获取协议及版本：String getProtocol()-->上例得到结果：HTTP/1.1 获取客户机的IP地址：String getRemoteAddr() 获取请求头数据: 通过请求头的名称获取请求头的值(常用):String getHeader(String name) 获取所有的请求头名称:Enumeration getHeaderNames() 获取请求体数据:只有POST请求方式，才有请求体，在请求体中封装了POST请求的请求参数 获取流对象 获取字符输入流，只能操作字符数据:BufferedReader getReader() 获取字节输入流，可以操作所有类型数据:ServletInputStream getInputStream() 其他功能因为对于不同的请求方式，它们的请求参数所在位置不同，GET方式请求参数在请求行中，POST方式请求参数封装在请求体中，所以服务器在获取请求参数的时候，需要分别在doGet和doPost方法中写不同的逻辑代码来获取请求参数，比较麻烦，因此就有一种通用的获取请求参数的方法 获取请求参数通用方式 根据参数名称获取参数值:String getParameter(String name) 根据参数名称获取参数值的数组(多选框):String[] getParameterValues(String name) 获取所有请求的参数名称:Enumeration getParameterNames() 获取所有参数的map集合:Map' 请求转发:一种在服务器内部的资源跳转方式 通过request对象获取请求转发器对象:RequestDispatcher getRequestDispatcher(String path) 使用RequestDispatcher对象来进行转发:forward(ServletRequest re, ServletResponse res) 注意:path是要跳转的资源的路径， 获取ServletContext(后面博客会详细讲到): ServletContext getServletContext() request的请求转发和资源共享以及response的重定向，它们各自的特点和区别会新开一篇博客 response对象response功能:设置响应消息 设置响应行(设置状态码):setStatus(int sc) 设置响应头:setHeader(String name, String value) 设置响应体: 使用步骤 获取输出流 字符输出流:PrintWriter getWriter() 字节输出流:ServletOutputStream getOutputStream() 使用输出流，将数据输出到客户端浏览器]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>Http协议</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Http协议概述--请求响应模型]]></title>
    <url>%2F2019%2F09%2F08%2FHttp%E5%8D%8F%E8%AE%AE%E6%A6%82%E8%BF%B0-%E8%AF%B7%E6%B1%82%E5%93%8D%E5%BA%94%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[Http–Hyper Text Transfer Protocol 超文本传输协议传输协议：定义了客户端和服务器端通信时，发送数据的格式 # Http协议的特点 基于TCP/IP的高级协议,默认端口是80 基于请求/响应模型的:一次请求对应一次响应 无状态的：每次请求之间相互独立，不能交互数据 Http协议的历史版本 1.0版本每次请求响应之后都会断开连接，下一次请求响应又会建立新的连接，即每次请求响应都会建立新的连接缺点：连接会被多次建立和多次丢弃掉，影响传输速度，消耗资源 1.1版本在一次请求响应之后，连接不会立刻断开，而是会等待一定的时间，如果在这一定时间内，还有其他请求，就会默认使用该连接，而不去建立新的连接，这样就实现了连接的复用 上面说了，Http定义了客户端和服务器通信时传输数据的格式，而传输数据分为两种： 客户端向服务器传输数据：请求消息数据 服务器向客户端传输数据：相应消息数据 Http请求消息数据格式 请求行:请求方式 请求url 请求协议/版本例如：GET /login.html HTTP/1.1请求url=虚拟路径+Servlet资源路径 请求头：客户端浏览器告诉服务器一些信息请求头消息以键值对的方式给出：请求头名称：请求头值常见的请求头： User-Agent：浏览器告诉服务器，使用的浏览器版本信息,可以在服务器端获取该头的信息，解决浏览器的兼容性问题(可以在服务器端对不同的服务器写不同的逻辑代码，然后根据该头的内容获取浏览器名称，执行对应浏览器的代码) Referer：告诉服务器，当前请求从哪里来？可以用来防盗链和统计工作 请求空行：一个空行，用于分割请求头和请求体 请求体(正文)：封装POST请求消息的请求参数 对于请求行中的请求方式，http协议7中请求方式，常用的有2种 GET:请求参数在请求行中，跟在url后。 请求的url长度有限制的 不太安全 POST: 请求参数在请求体中 请求的url长度没有限制的 相对安全 Http响应消息数据格式 响应行:协议/版本 响应状态码 状态码描述例如：HTTP/1.1 200 OK请求url=虚拟路径+Servlet资源路径 响应头：服务器告诉浏览器一些信息响应头消息以键值对的方式给出：响应头名称：响应头值常见的响应头： Content-Type：服务器告诉客户端本次响应体数据格式以及编码格式 Content-disposition：服务器告诉客户端以什么格式打开响应体数据常见有两种取值 in-line:默认值,在当前页面内打开 attachment;filename=xxx：以附件形式打开响应体，用于文件下载 注意：这个filename是浏览器在弹出框显示，和服务器中要下载的文件名无关 响应空行：一个空行，用于分割响应头和响应体 响应体(正文)：传输的数据 响应状态码服务器告诉客户端浏览器本次请求和响应的一个状态。状态码都是3位数字 1xx：服务器接收客户端消息，但没有接受完成，等待一段时间后，发送1xx多状态码 2xx：本次请求响应成功。代表码：200 4xx：客户端错误。 404:请求路径没有对应的资源-->路径错误 405:请求方式没有对应的doxxx方法-->比如浏览器请求方式是Post方式，而客户端没有doPost方法 5xx：服务器端错误。代表码：500(服务器内部出现异常)]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
      <tags>
        <tag>Http协议</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Servlet基础学习]]></title>
    <url>%2F2019%2F09%2F08%2FServlet%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[Servlet：server applet官方给出的解释是运行在服务器端的小程序 # Servlet的本质 浏览器通过ip和端口来找到服务器，服务器中的资源分为两类 静态资源， 动态资源所谓动态资源，就是不同的用户访问到的页面是不一样的，这说明动态资源中肯定有一些逻辑性，来实现不同的用户访问同样的资源看到的是不一样的。而这些逻辑性，就要通过Java代码(Java类)来实现。 也就是说浏览器请求动态资源的时候，访问的就是服务器上的Java类 要注意的是：这里说的Java类没有main方法，不能自己运行，需要依赖服务器才能运行，相当于Tomcat(服务器软件)来执行它。那么问题来了，如果要Tomcat能够认识这个类并执行这个类，这个类就需要遵守一定的规则，在Java中，规则==接口 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;上面说的规则，就是Servlet，它本质上就是一个接口，定义了Java类被tomcat识别的规则 Servlet的使用 创建JavaEE项目 在src目录内定义一个类，实现Servlet接口 实现接口中的抽象方法 配置Servlet(一共有两种方法，这里先记录第一种)在web.xml中配置 123456789&lt;servlet&gt; &lt;servlet-name&gt;demo1&lt;/servlet-name&gt; &lt;servlet-class&gt;全类名(包名+类名)&lt;/servlet-class&gt;&lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;demo1&lt;/servlet-name&gt; &lt;url-pattern&gt;/demo1(Servlet资源路径)&lt;/url-pattern&gt;&lt;/servlet-mapping&gt; 在web.xml中加上以上内容 Servlet配置原理 当服务器接受到客户端浏览器的请求后，会解析请求URL路径，获取访问的Servlet的资源路径 查找web.xml文件，是否有对应的url-pattern标签体内容。 如果有，则通过映射找到对应的servlet-class全类名 tomcat会将字节码文件加载进内存，并且创建其对象注意：这个实现了Servlet接口的类是由Tomcat通过反射创建的对象，并不是由程序员创建的 调用对象的方法 Servlet的生命周期 被创建：执行init()方法，该方法只执行一次 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;那么Servlet在什么时候被创建呢？&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;默认情况下，在资源第一次被访问时，Servlet被创建 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;可以在web.xml文件中配置改变Servlet被创建的时机&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在上面说到的servlet标签下配置，具体下面有图 提供服务：执行service方法，可以执行多次&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &nbsp;每次访问Servlet时，Service方法都会被调用一次。 被销毁：执行destroy方法，只执行一次&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;只有服务器正常关闭时，才会执行destroy方法。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;destroy方法在Servlet被销毁之前执行，一般用于释放资源 设置Servlet被创建的时机使用load-on-startup标签，这是一个围堵标签，当标签的值为负数的时候，默认第一次被访问时创建当标签的值为正数或0的时候，服务器启动时创建 注解配置Servlet在Servlet3.0以后，可以使用注解配置Servlet，相比较在web.xml文件中配置更加方便使用方法：在类上加注解@WebServlet(“资源路径”)，这样就可以通过注解的资源路径找到相应的类，直接将类加载进内存 Servlet体系结构 Servlet是一个接口，里面有5个抽象方法，每次继承Servlet接口的时候，都需要重写这5个抽象方法，而实际上，很多时候并用不到其中的有些方法，所以每次都要重写，很麻烦 Servlet的子类GenericServletGenericServlet也是一个抽象类，将Servlet接口中其他的方法做了默认空实现，只将service()方法作为抽象，将来定义Servlet类时，可以继承GenericServlet，只实现service()方法即可(但实际上，这种方法使用较少) HttpServletHttpServlet出现原因HttpServlet extends GenericServlet该类是对Http协议的一种封装和描述对于一般的Servlet实现类，在service方法中通过一些操作获取浏览器的数据，但在获取数据之前，需要判断浏览器的请求方式是get方式还是put方式，因为两种方式封装数据的位置和格式是不一样的，对于不同的方式需要进行不同的逻辑处理。也就是说，我们需要在service方法里作两步操作： 判断浏览器请求方式 根据不同的请求方式编写不同的逻辑代码 HttpServlet实现原理这个过程比较麻烦，但却是所有的service方法都必须要做的一个过程，因此sun公司就提供了HttpServlet这个类。在HttpServlet类的Service方法中，已经写好了判断浏览器请求方式的逻辑代码，我们需要做的就是重写相应doxxx()方法，service方法判断请求方式后，会根据判断的结果调用我们重写的doxxx()方法以上是HttpServlet类service的源码，可以发现，HttpServlet中的service方法主要用于判断浏览器的请求方式，然后根据不同的请求方式调用相应的doxxx()方法，我们只需要重写这些方法，省略了判断请求方式的步骤]]></content>
      <categories>
        <category>JAVAWEB</category>
      </categories>
      <tags>
        <tag>Servlet类</tag>
        <tag>HttpServlet类</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库基础--操作数据库和表]]></title>
    <url>%2F2019%2F09%2F08%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9F%BA%E7%A1%80-%E6%93%8D%E4%BD%9C%E6%95%B0%E6%8D%AE%E5%BA%93%E5%92%8C%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[这里主要总结两类SQL语句 DDL和DML，即操作数据库和表的语句以及对表中数据进行增删改操作的语句 DDL语句这类语句又分为两部分 操作数据库(CRUD) 操作表(CRUD) 操作数据库(Create)创建123456create database 数据库名称;create database if not exists 数据库名称;create database 数据库名称 character set 字符集名;//创建db4数据库，判断是否存在，并指定字符集为gbkcreate database if not exists db4 character set gbk; (Retrieve)查询12345//查询所有数据库show databases;查询某个数据库的字符集show create database 数据库名称; (Update)修改12//修改数据库的字符集alter database 数据库名称 character set 字符集名称; (Delete)删除 删除数据库 12drop database 数据库名称;drop database if exists 数据库名称; 使用数据库 12345//查询当前正在使用的数据库名称select database();//使用数据库use 数据库名称; 操作表(Create)创建 创建表 123456CREATE TABLE 表名( 列名1 数据类型 该列所需要的约束， 列名2 数据类型 该列所需要的约束， 列名3 数据类型 该列所需要的约束);最后一列不加逗号 复制表 12345CREATE TABLE 表名1 LIKE 表名2;以上语句的作用是：创建一个新表，和原来的表有相同的列，但是新表中没有任何数据如果想要将原来表中的数据复制到新表中:INSERT TO 表名1 SELECT * FROM 表名2; 以上两个SQL语句能够得到一张和原来一模一样的新表。 数据库数据类型12345678int：整数类型double:小数类型date:日期，只包含年月日，形如yyyy-MM-dddatetime:日期，包含年月日时分秒yyyy-MM-dd HH:mm:sstimestamp:时间戳类型，包含年月日时分秒yyyy-MM-dd HH:mm:ss如果不给这个字段赋值，或赋值为null，则默认使用当前的系统时间，来自动赋值char：定长字符串，在使用的时候需要指定长度varchar：可变长字符串，在使用的时候需要指定长度 (Retrieve)查询 查询某个数据库中所有的表名称 1SHOW tables; 查询表结构 1DESC 表名; (Update)修改 修改表名 1ALTER TABLE 表名 RENAME TO 新的表名; 修改表的字符集 1ALTER TABLE 表名 CHARACTER SET 字符集名称; 增删列 12345//添加列ALTER TABLE 表名 ADD 列名 数据类型;//删除列ALTER TABLE 表名 DROP 列名; 修改列的类型 1ALTER TABLE 表名 MODIFY 列名 新数据类型; (Delete)删除 判断数据库存在，存在再删除1DROP TABLE IF EXISTS 表名; 从上面这些语句不难总结得出，无论是数据库还是表，它们的增删改语句都和create、alter、drop、show有关 DML语句增删改表中的语句 添加数据12345INSERT INTO 表名 (列名1,列名2,...列名n) VALUES(值1,值2,...值n);除了数字类型，其他数据类型都要使用引号(单双都可)引起来 在前面介绍的INSERT……SELECT搭配使用复制表的SQL语句中，可以在SELECT语句使用任何条件(WHERE,GROUP….)。列名和值要一一对应如果不指定列名，则默认给所有列添加值。 删除数据12DELETE FROM 表名 WHERE 条件; 如果不加条件，则默认删除表中所有数据但是，如果要删除表中所有的话，不推荐使用这种方法，因为效率低 12TRUNCATE TABLE 表名;效率更高 先删除表，然后再创建一张一样的表。 修改数据123UPDATE 表名 SET 列名1 = 值1, 列名2 = 值2,... WHERE 条件; 注意：如果不加条件，则会将表中的记录全部修改 总结：DML语句用来操作表中的数据，主要对数据进行增删改操作，主要有insert 、delete、update三个关键字]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>读书笔记</tag>
        <tag>数据库</tag>
        <tag>SQL基础教程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库基础--数据库概念和SQL简介]]></title>
    <url>%2F2019%2F09%2F08%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9F%BA%E7%A1%80-%E6%95%B0%E6%8D%AE%E5%BA%93%E6%A6%82%E5%BF%B5%E5%92%8CSQL%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[数据库(DataBase)，简称DB，用于存储和管理数据的仓库能够持久化存储数据，实际上，数据库就是一个文件系统，能够方便的存储和管理数据，使用了统一的方式来操作数据库，即SQL MySQL的配置MySQL服务启动 cmd--> services.msc 打开服务的窗口 使用管理员方式打开cmd net start mysql : 启动mysql的服务 net start mysql :关闭mysql的服务 MySQL登录 mysql -uroot -p密码 mysql -hip -uroot -p连接目标的密码 mysql –host=ip –user=root –password=连接目标的密码 MySQL退出 exit/quit命令 SQLStructured Query Language：结构化查询语言定义了操作所有关系型数据库的规则，但是不同的数据库操作的方式可能存在不同的地方，可以理解为‘方言’SQL分为四类 DDL(Data Definition Language)数据定义语言用来定义数据库对象：数据库，表，列等。关键字：create, drop,alter 等 DML(Data Manipulation Language)数据操作语言用来对数据库中表的数据进行增删改。关键字：insert, delete, update 等 DQL(Data Query Language)数据查询语言用来查询数据库中表的记录(数据)。关键字：select, where 等 DCL(Data Control Language)数据控制语言用来定义数据库的访问权限和安全级别，及创建用户。关键字：GRANT， REVOKE 等 一张图来帮助理解四类SQL语句]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IDEA中创建多个Project]]></title>
    <url>%2F2019%2F09%2F08%2FIDEA%E4%B8%AD%E5%88%9B%E5%BB%BA%E5%A4%9A%E4%B8%AAProject%2F</url>
    <content type="text"><![CDATA[我们知道，IDEA是没有workspace这个概念的，它是以Project为单位，一个窗口对应着一个Project，而一个Project对应着很多Model，Model相当于eclipse中的project，那么如何在一个项目中存放多个Project呢？ 首先，创建一个空的Project 给项目命名并点击finish会进入到新创建的Project窗口中，接着IDEA就会弹出下面界面，让你为新的Priject创建一个Model：在这里很重要，不选择给新的Project创建一个Model，直接点OK这样，常见出来的没有Model的Project就相当于一个空文件夹，(查看创建的Project文件夹，会发现它是没有src的) 在新的Projrect中，new一个Model我这里创建的时web项目，如果要创建普通的项目，点击左侧第一个按钮JAVA就可以给新创建的Model起名，通过这里就可以发现，第一个untitled是创建的project名(由于没有命名，默认就是untitled)，第二个是正在创建的Model名，点击finish这样就创建成功了一个，按照上面的方法再来一遍这样就成功地在一个窗口创建了两个Project 另外IDEA会为这两个web项目分别部署一份配置文件，这样这两个web项目就可以分别设置不同的端口，虚拟路径等配置运行项目的时候，查看控制台的log：Using CATALINA_BASE: 的值，就能找到配置文件的路径]]></content>
      <categories>
        <category>Utils</category>
      </categories>
      <tags>
        <tag>IDEA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tomcat部署项目的方式]]></title>
    <url>%2F2019%2F09%2F08%2FTomcat%E9%83%A8%E7%BD%B2%E9%A1%B9%E7%9B%AE%E7%9A%84%E6%96%B9%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[Tomcat有三种部署项目的方式将项目直接放到Tomcat的webapps目录下也可以将项目打包成war包，放到webapps目录下，运行时Tomcat会自动解压 利用Tomcat的配置文件sever.xm打开conf目录，找到sever.xml配置文件(先关闭Tomcat服务) 找到Host标签，加上一个Context标签，path值可以自己设置 启动Tomcat服务 在浏览器输入localhost:8080(端口号)/path的值/docBase的值就能正确访问项目 这种部署方式项目可以放在硬盘上的任意位置，Tomcat会通过path映射到docBase。 注意：因为server.xml是Tomcat服务核心的配置文件，是配置Tomcat整体的，在里面配置项目有可能损坏配置文件，导致出错，比较危险，所以一般不推荐使用 自定义xml配置文件(先**关闭Tomcat**) 打开Tomcat下的conf\Catalina\localhost这个目录，在localhost下创建一个xml配置文件， 文件名可以任意起(但是这个文件名就是浏览器搜索时的虚拟路径)，假设是aaa.xml； 在配置文件中：将上图中红框里的Context标签及内容写进去，把后面的path键值对删掉(因为虚拟路径已经指定为xml文件名，所以不需要再指定虚拟路径) 再次启动Tomcat 浏览器搜索**localhost:8080(端口号)/xml文件名/docBase的值**即可这种部署方式还有一个好处： 这是一种热部署的方式，如果不想要这个项目，可以将创建的xml文件删掉，或者后缀名改一下 例如：将aaa.xml改为aaa.xml_bak；无需重新启动Tomcat就能生效(浏览器就访问不到项目资源)]]></content>
      <categories>
        <category>JAVAWEB</category>
      </categories>
      <tags>
        <tag>Tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tomcat启动问题分析]]></title>
    <url>%2F2019%2F09%2F08%2Ftomcat%E5%90%AF%E5%8A%A8%E9%97%AE%E9%A2%98%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[问题前提在Tomcat目录下的bin目录中双击startup.bat直接打开tomcat时，可能会出现以下两个问题 Tomcat的窗口一闪而过 启动报错 Tomcat的窗口一闪而过原因没有正确配置JAVA_HOME环境变量在安装JDK时，需要将JDK的目录配置到Path变量下，问题就在这里，因为配置的时候，有可能是直接将JDK的目录配置到了Path环境变量双击Path变量，如下图所示这样的做法是错误的 正确的做法应该先创建一个JAVA_HOME环境变量将JAVA_HOME的值设置问JDK的路径，如下图然后再将JAVA_HOME代替JDK安装路径给Path变量将startup.bat关掉，重新启动即可 分析一下原因先以文档的形式打开startup.bat，发现和catolina.bat有关，我们就以文档形式打开bin目录下的catolina.bat在文档里可以看到，这里用到了环境变量的JAVA_HOME，所以在配置环境变量的时候，必须用JAVA_HOME来设置JDK路径，否则这里就无法找到JDK，由于Tomcat是纯java编写的，它的启动和运行要依赖与JDK，所以Tomcat就无法正常运行 启动报错，然后窗口自动关闭原因有可能是已经打开了一个Tomcat(或者有其他程序占用了Tomcat的端口号)，再次启动的时候由于端口被占用，所以无法正常启动如果是这种情况，通过查看日志会发现有一个异常：java.net.BindException:Address already in use 解决方法找到占用Tomcat端口号(一般是8080)的程序，关闭该程序1、打开cmd窗口，输入 netstat -ano命令找到Tomcat端口(我的是默认8080)，记录该端口程序的PID2、打开任务管理器找到刚记录的PID对应的程序，把它关掉。这样，Tomcat就能正确启动了]]></content>
      <categories>
        <category>JAVAWEB</category>
      </categories>
      <tags>
        <tag>Tomcat</tag>
        <tag>问题分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BOM模型基础学习]]></title>
    <url>%2F2019%2F09%2F08%2FBOM%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[BOM，全称Browser Object Model，浏览器对象模型它将浏览器的各个组成部分封装成对象 五个对象window-窗口对象Location-地址栏对象History-历史记录对象Screen-显示器屏幕对象Navigator-浏览器对象 window-窗口对象该对象无需创建，可以直接使用对象的方法和属性 window对象的方法与弹出框有关的方法alert()显示带有一段消息和一个确认按钮的警告框。 confirm()显示带有一段消息以及确认按钮和取消按钮的对话框。 如果用户点击确定按钮，则方法返回true 如果用户点击取消按钮，则方法返回false prompt()显示可提示用户输入的对话框。 返回值：获取用户输入的值 与打开关闭有关的方法close()关闭浏览器窗口。 谁调用我 ，我关谁 open()打开一个新的浏览器窗口 返回新的Window对象 与定时器有关的方式setTimeout()在指定的毫秒数后调用函数或计算表达式。 参数： js代码或者方法对象 毫秒值 返回值：唯一标识，用于取消定时器clearTimeout()取消由 setTimeout() 方法设置的 timeout。setInterval()按照指定的周期（以毫秒计）来调用函数或计算表达式。clearInterval()取消由 setInterval() 设置的 timeout。window对象的属性获取其他BOM对象historylocationNavigatorScreen获取DOM对象document Location-地址栏对象创建(获取)1. window.location 2. location方法reload() 重新加载当前文档。刷新 属性href 设置或返回完整的 URL。如图，给按钮设置监听器，点击按钮后修改页面的URL为百度页面，就会自动跳转到百度的页面 History-历史记录对象创建(获取)1. window.history 2. history方法back()加载 history 列表中的前一个 URL。 forward()加载 history 列表中的下一个 URL。 go(参数)加载 history 列表中的某个具体页面。 参数： 正数：前进几个历史记录 负数：后退几个历史记录 属性length返回当前窗口历史列表中的 URL 数量。]]></content>
      <categories>
        <category>前端基础</category>
      </categories>
      <tags>
        <tag>前端</tag>
        <tag>BOM</tag>
        <tag>JavaScript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JavaScript基础]]></title>
    <url>%2F2019%2F09%2F08%2FJavaScript%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[JS和HTML结合方式内部样式在html文件内部定义一个script标签、在标签里面写的JS代码注意：和CSS不同的是，JS标签可以有很多个，而且可以写在HTML文件中的任意位置 外部样式在html文件内部定义一个script标签，通过script的src属性，来指定JS配置文件的路径 JS代码写在JS配置文件中 数据类型和变量JS数据类型和JAVA类似，分为**原始数据类型**和**引用数据类型**两大类数据类型number包括整数、小数和NaN类型(不是数字的数字类型 not a numebr) string字符/字符串类型 booleantrue/false、 null一个对象为空的占位符 undefined未定义，如果一个表量没有给初始化值，就会被默认赋值为 undefined ![在这里插入图片描述](https://img-blog.csdnimg.cn/20190828110402952.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjM4NzQxMQ==,size_16,color_FFFFFF,t_70)变量一小块存储数据的内存空间 JAVA是强类型语言，而JavaScript是弱类型语言强类型在开辟内存空间时，定义了空间将来存储数据的类型，只能存储固定的类型 弱类型在开辟内存空间时，没有定义空间将来存储数据的类型，可以存放任意类型的数据 运算符在JS中，如果运算数不是运算符要求的类型，那么JS会自动将运算数进行类型转换 例如：一元运算符+(正号)和-(负号)是对数字类型进行操作，但是有+&apos;a&apos;这样的运算，就会将字符串类型的&apos;a&apos;转换为number类型其他类型转numberstring--&gt;number：**按照字面值转换**，如果字面值是数字，如&apos;123&apos;，会转换成数字123， 如果字面值不是数字，如&apos;abc&apos;，会转换为NaN(不是数字的数字)注意：NaN和整数小数运算，还是NaN; boolean–&gt;number: true=1 false=0 比较运算符字符串按照字典顺序比较(如c&gt;b),按位逐一比较，直到得出大小 **类型不同比较，先进行类型转换** ”===“运算符：在比较之前先进行类型判断，如果类型不同，直接返回false逻辑运算符！：非运算其他类型转boolean number--&gt;boolean：0和NaN为false，其他都是true string--&gt;boolean：除了空字符串，都是true null/undefined--&gt;boolean：false 对象--&gt;boolean：true 注意：在JS中，所有的**变量都是关键字var**定义的，var可以省略，但是，**用var定义的是局部变量**，不用var定义的 是全局变量常用对象function对象 方法对象 Array对象数组对象 数组长度可变 Date对象 Math对象该对象不用创建，可以直接使用对象的方法和属性，Math.调用 常用方法和属性： Global对象 特点：是一个全局对象，这个对象中封装的方法不需要对象就能够直接使用,和Math不同的是，使用它的方法前面不 用加对象名 在说该对象的方法之前先说一下**URL编码**： 浏览器将从表单中收集的数据经过URL编码后发送给服务器，服务器再将接收到的URL编码的数据解码。 URL编码的规则：对于汉字，先将汉字按照GBK/UTF8编码成对应的二进制数字，再将每四位二进制数字组合在 一起转换成十六进制数字，这样就将汉字转换成了一串十六进制数字，最后，每两个十六进制数字一组，在前面 +%，这样就组成了URL编码，字母和数字不编码第二组方法编码的字符更多，会将网址中./等符号也用URL编码]]></content>
      <categories>
        <category>前端基础</category>
      </categories>
      <tags>
        <tag>前端</tag>
        <tag>JavaScript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CSS选择器和常用属性]]></title>
    <url>%2F2019%2F09%2F08%2FCSS%E9%80%89%E6%8B%A9%E5%99%A8%E5%92%8C%E5%B8%B8%E7%94%A8%E5%B1%9E%E6%80%A7%2F</url>
    <content type="text"><![CDATA[基础选择器id选择器使用此选择器要求HTML相应的标签必须指定了id属性 格式： #+标签id属性{ //对应id标签的属性 如color等}通过HTML标签的id来指定标签，修改样式 元素选择器格式：标签名称{ //通过标签名称找到标签(可能不止一个)并修改内容样式 }这个元素选择器会找到HTML中所有的div标签，并将标签内容字体改为红色 类选择器 格式： .+类名{ 通过标签的class属性值找到标签 }其中：三个选择器中 id选择器优先级最高，元素选择器优先级最低 扩展选择器![在这里插入图片描述](https://img-blog.csdnimg.cn/20190828103900651.png) CSS常见属性 盒子模型 参见JAVA_WEB/HTML&amp;CSS]]></content>
      <categories>
        <category>前端基础</category>
      </categories>
      <tags>
        <tag>前端</tag>
        <tag>CSS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTML5基础回顾]]></title>
    <url>%2F2019%2F09%2F08%2FHTML5%E5%9F%BA%E7%A1%80%E5%9B%9E%E9%A1%BE%2F</url>
    <content type="text"><![CDATA[HTML用于搭建基础页面，展示页面内容，一般和CSS以及JS搭配使用HTML标签分类# 1、围堵标签 顾名思义，就是开始和结束标签，例如&lt; html&gt; &lt; /html&gt;，内容放在标签中 # 2、自闭合标签 开始标签和结束标签在一起。例如换行标签&lt; br/&gt;、超链接标签&lt; a&gt;等 标签不区分大小写，建议小写无论是哪种标签，都可以在开始标签中定义属性，属性是由键值对组成，其中值需要由引(单/双)号引起来 &lt; html&gt; &lt;head&gt; &lt;title&gt;title&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;FONT color=&apos;red&apos;&gt;Hello World&lt;/font&gt;&lt;br/&gt; &lt;font color=&apos;green&apos;&gt;Hello World&lt;/font&gt; &lt;/body&gt; &lt; /html&gt;文件标签&lt; html&gt;文档的根标签 &lt; head&gt;头标签，用于指定html文档的一些属性，引入外部资源，如CSS、JS文件等 &lt; title&gt; 标题标签 &lt; body&gt; 体标签，html代码写在body标签中 以上均为围堵标签 文本标签&lt; h1&gt;~&lt; h6&gt;标题标签，从h1到h6字体大小递减 –&gt;围堵标签 &lt; p&gt;段落标签：被该标签包裹的文本会换行两次 –&gt;围堵标签 &lt; br&gt;换行标签 &lt; hr&gt;展示一条水平线 该标签有一些属性：color、width、height、align(对齐方式)来设置水平线的样式 &lt; b&gt;字体加粗标签 &lt; i&gt;字体斜体标签以上四个均为自闭合标签 &lt; font&gt;字体标签 该标签属性：color、size、face(字体)来改变字体 center：文本居中标签 图片标签&lt; img&gt;图片标签，是一个自闭合标签，其中有src属性，可以指定展示图片的路径 相对路径： 其中如果html文件和图片所在文件夹目录是同一级目录，那么./+图片所在文件夹目录/图片 如果图片所在文件夹目录是html文件上一级目录，那么就用../ 列表标签&lt; ol&gt;/&lt; li&gt;有序列表 type属性：指定序号的样式 &lt; ul&gt;/&lt; li&gt;无序列表无序列表的type属性有三种： disc：原点 square：正方形点 circle：圆圈 链接标签&lt; a&gt;定义一个超链接 属性： href 指定访问资源的URL()统一资源定位符)，可以是网址 target 指定打开资源的方式，有两种方式 _ selt:在当前页面打开 _ blank：在新空白页面打开 和CSS以及JS搭配的标签 div标签和span标签，两者的区别是div自带换行，而span没有换行功能 表格标签&lt; table&gt; 定义表格，table的开始标签可以指定一些属性 width：表格宽度 border：边框 cellpadding：定义内容和单元格的距离 cellspacing：定义单元格之间的距离。如果指定为0，则单元格的线会合为一条 bgcolor：背景色 align：对齐方式 &lt; tr&gt;标签定义行标签 &lt; td&gt;标签定义单元格标签 &lt; th&gt;标签定义表头单元格标签 表单标签注意：表单中的数据要想被提交，必须指定其name属性 表单：用于采集用户输入的数据，用于和服务器进行交互 &lt; form&gt;用于定义表单的，可以定义一个范围，范围代表采集用户数据的范围form标签有以下属性 action：指定提交数据的URL路径 method：指定提交方式，有两种比较常用，分别是post和get form只是制定了收集用户数据的范围，并没有指定提交形式(输入框、按钮、下拉列表…)因此就会用到表单项标签表单项标签主要有三种：input标签、select标签、textarea标签 &lt; input&gt;标签展示效果 &lt; select&gt;标签子元素：option，指定列表项展示效果 文本域标签主要有两个属性：cols：指定列数，每一行有多少个字符rows：默认多少行。]]></content>
      <categories>
        <category>前端基础</category>
      </categories>
      <tags>
        <tag>前端</tag>
        <tag>HTML5</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JDK源码--Byte类]]></title>
    <url>%2F2019%2F09%2F08%2F%E5%B0%8F%E7%99%BD%E5%AD%A6JDK%E6%BA%90%E7%A0%81--Byte%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[学习过程中参考此篇文章，写的很好 1、观察它继承的父类，实现了那些接口 2、找到它的成员变量 3、学习构造方法 4、学习方法 父类和接口从图中可以知道，Byte类继承了Number类，实现了Comparable接口 对于Comparable接口，只有一个抽象方法这个接口赋予它和它的子类比较的能力，用于排序，比较大小对于一个存储自定义类的数组或集合，只有这个类实现了该接口，重写了接口中的compareTo()方法，重写了排序规则才能使用Arrays类的sort方法进行排序； 成员变量定义了Byte类型数据的边界值，就是说，Byte类型的值只能在-128~127之间TYPE是一个Byte的Class类对象，相当于TYPE=Byte.class；这就是Byte类型的基础类型，数据存储的地方(从下面的构造方法可以看出)这三个成员变量分别表示Byte数据的位数，字节数和UID(用于序列化和反序列化) 构造方法Byte的构造方法有两个，可以看出，两个构造方法都会将传入的数据存放到成员变量byte中 私有静态内部类这是Byte类的一个静态内部类，类里面还有一个静态代码块静态代码块会在类第一次被加载的时候执行，并且只执行一次这里的作用就是，创建一个Byte类型的数组，数组的长度是256里面存储着-128~127的数字(Byte类数据所有可能的取值)并且数组是静态的并且final修饰，因为后面的有些成员方法会需要用到Byte对象，所以这样做就避免了重复创建对象和回收对象 成员方法toString(byte b)方法注意：这个toString()方法不是重写Object的toString方法，因为它有参数作用：将一个byte类型数据转化为String字符串类型实质上是直接调用Integer类的toString方法，radix：10：用10进制表示 valueOf(byte b)作用：将基本类型–&gt;包装类型，直接从上面的数组中得到 parseByte(String s,int radix)参数：String s:要解析的字符串int radix:指定字符串表示的进制例如：s=“10000”，radix=2，解析出来的值就是16作用：将字符串按照指定进制解析为byte类型实质上调用的是Integer的parseInt方法，解析成int类型判断是否超出范围，超出范围就抛异常，否则就返回 parseByte(String s)指定进制默认十进制解析 valueOf(String s,int radix) 参数：String s:要转换的字符串int radix：字符串表示的进制，和解析方法一样作用：将字符串转换为按照指定进制形式表示的Byte类型，先将字符串解析为byte类型，在调用valueOf()方法，从静态代码块初始的数组中找到对应的Byte并返回 valueOf(String s)默认10进制 xxxValue()方法重写父类的方法，由于byte数值最小，不用担心出现溢出直接用强制类型转换，然后return hashCode()重写了父类的hashCode方法，对于Byte类型，它的hashCode方法实质上就是返回它的值 equals()方法重写了父类的equals方法 compareTo()方法重写了接口中的compareTo方法，直接返回两个对象的差值调用方法的对象-方法的参数]]></content>
      <categories>
        <category>JDK源码</category>
      </categories>
      <tags>
        <tag>源码</tag>
        <tag>Byte</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[字符流和字节流]]></title>
    <url>%2F2019%2F09%2F07%2FJAVA%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E6%B5%81-%E5%AD%97%E7%AC%A6%E6%B5%81%E5%92%8C%E5%AD%97%E8%8A%82%E6%B5%81%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[深入理解字符流编码 首先要理解字符流输入的原理：字符流输入其实底层也是字节流输入 字符–&gt;计算机二进制数字（字节）：编码字节(计算机二进制数字)–&gt;字符：解码 写入时：1、当使用字符流的write方法向文件写入数据的时候，数据会先写进内存缓冲区中， 2、内存缓冲区会先字符对比着系统码表编码(中文系统是GBK)为对应的字节：字符--&gt;数字 3、调用了flush方法或者是close方法后，内存缓冲区中编码为字节(数字)会写入到文件中读取时：使用read方法读取文件的时候，文建会先将存储在计算机中的二进制对照系统码表解码成相应的字符，读入程序图片不能用字符流的原因因为图片是字节文件，计算机中存储的也是字节数字，所以用字节流输入的时候不需要编码解码的过程，直接将计算机中的字节读取写入就可以了 但是用字符流读取的时候，一次读取两个字节，然后将这两个字节按照码表解码成相应的字符，当读取图片的时候，将两个字节拼在一起对比码表解码，码表中可能没有相应的字符，就会将此二进制数据标记为未知字符， 在写入的时候，会将未知字符丢掉，所以图片拷贝不成功 因为原图片和你拷贝的“图片”在计算机中的字节都是不一样的 拷贝的“图片”丢失了很多 **解码后**被标记为“未知字符”的**字节** 举个例子：一个图片在计算机中存储的字节是：-121，34，124，53，-65，-43，1.... 使用字节流读取的时候，一次读取一个字节，会原封不动的读取出来：-121，34，124，53，-65，-43，1.... 但是当使用字符流读取的时候，一次读两个字节-12134，12453....然后将每次读取到的两个字节对照系统码表解码成相应的字符，但是码表中可能没有相应的字符； 例如没有和-12134对应的字符，就会将此二进制数据标记为未知字符(假设标记为￥)； 在写入的时候，就会将￥字符给丢掉，所以**最后实际写入的数据为**124，53，-65，-43，1.... 这样拷贝自然就失败了关于写入字符到文件中，打开文件查看乱码的原因，参考上面链接**最后**：字符流因为解码编码等原因，比字节流慢很多 字符流一般用于传输纯文本文件，尤其是中文文档，不能用于视频，图片等传输 图片等视频音频文件要用字节流]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>I/O</tag>
        <tag>乱码</tag>
        <tag>字符流/字节流</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[二叉树镜像对称]]></title>
    <url>%2F2019%2F09%2F07%2FLeetCode-%E7%AC%AC101%E9%A2%98%2F</url>
    <content type="text"><![CDATA[难度–简单题目 分析： 通过题目可以知道，这个树镜像对称，那么这棵树关于根节点这条线对称 就是说，将它所有的左子树变成右子树，所有右子树变成左子树，它是不变的 递归//这里直接传递tree根节点的左右子树会比pre(TreeNode tree,TreeNode tree)好，因为减少一层递归，LeetCode速度直接 //快1ms，亲测 1、pre(TreeNode tree.left,TreeNode tree.right) 2、如果A.val==B.val --&gt;return true 3、如果A==null&amp;&amp;B==null --&gt;return true 4、如果A和B不同时为空，说明树是不对称的 --&gt;return false 5、遍历A的左子树和B的右子树 //pre(A.left,B.right) 6、遍历A的右子树和A的左子树 //pre(A.right,B.left)迭代法使用队列，比较容易理解，直接上代码(LeetCode官方题解)]]></content>
      <categories>
        <category>算法之美</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
        <tag>递归</tag>
        <tag>迭代法</tag>
        <tag>二叉树</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[青蛙跳台阶]]></title>
    <url>%2F2019%2F09%2F07%2FLeetCode-%E7%AC%AC70%E9%A2%98%2F</url>
    <content type="text"><![CDATA[难度： 简单 1、动态规划可以知道，如果要到达第n阶台阶，有两种方式：第一：从n-1阶台阶跨1步第二：从n-2阶台阶跨2步设到达第n阶台阶的方法总数为sum(n)那么由上面可以知道：sum(n)=sum(n-2)+sum(n-1) 可以举例假设一下假设n等于3，那么到达第3阶台阶由两种方法1、从第1阶台阶跨2步上去2、从第2阶跨1步上去 相应的，到达第1阶台阶只有一种方法，sum(1)=1；到达第2阶台阶也有两种方法：从起始位置跨2步，和先跨1步再跨1步，sum(2)=2；所以sum(3)=3; 2、斐波那契数列通过观察规律可以知道：假设第0阶为1；那么可以得到从第1阶往后分别是：1，2，3，5，8，13…..这是一个很明显的斐波那契数列 3、递归同样的思路，爬第n阶台阶的方法和等于爬上第n-1阶台阶和爬上第n-2阶台阶方法之和递归出口：n=0的时候返回1，n&lt;0的时候返回0；运行到44个样例的时候栈爆了…..]]></content>
      <categories>
        <category>算法之美</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
        <tag>动态规划</tag>
        <tag>斐波那契数列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2019%2F09%2F07%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
</search>
